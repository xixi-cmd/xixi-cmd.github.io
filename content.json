{"pages":[{"title":"","text":"Hey guys,look at this. 我是ChenShang，现在是一位高中生，好吧也许你不信，但这是真的。你们也可以叫我先生，即便我不是先生，但是相信我会成为一个先生。今年是2022年，我十五岁，我喜欢打游戏，比如说原神，崩坏3这样肝的游戏，也比如王者荣耀，LOL这样的MoBa游戏。当然，学习是不可能落下的，我喜欢学习，喜欢搜集各种好词好句，好的文章，好的书籍，我喜欢科幻小说，比如《三体》，《银河帝国》系列；我喜欢心理学的书籍，比如《人性的弱点》，《墨菲定律》；我喜欢好词好句，比如说我的qq签名 风流不是无佳句，两字相思写不成。 人我有喜欢的人，我喜欢我的爸爸妈妈，爷爷奶奶，我喜欢活着，我喜欢白天，我爱着她，当然这些东西很私密，你能看到，是你的幸运，因为这是博客，博客当然可以在法律规定的范围内畅所欲言。我当然知道违法是可耻的，我也知道违法是决不允许的。 景我喜欢在夜晚的时候走上楼顶，找一个干净的地方就那么坐着，把头抬起来，仰望星空，那个时候，只有月亮和星星陪伴着我，学习的压力也一扫而空；我喜欢在每一个傍晚看天边的火烧云，喜欢在每一个清晨看东方升起的太阳，四个季节的阳光每天都沐浴着我，我不再感到寒冷。这是一个孩子，对于风景的理解。。 文我对于文化的理解可能会比一般的中学生要深刻一点，我喜欢鸡汤，也喜欢给别人灌鸡汤，但我从不认为自己站在到的的制高点，那里太冷了。话又说回来了，也许你对于鸡汤的理解在于这样？ 如果吃亏是福的话，那我可能早就福如东海了。 又或者这样？ 俗话说祸不单行，可见连祸都是有伴儿的，你再看看你。 但是这只是一种我喜欢的可不是这样子的，我喜欢说话，也会学着怎么说话，我不会话里有话，但是我会有话直说。(这也许就是所谓的，高情商？bushi)，我理解文化，正因为我是中国人，文化的底蕴没有哪一个瞬间不把我撼动，我之前看过一篇文章，叫做我们凭什么民族自信，深深的触动了我，也许写的不是很好，但是它确实令我大受震撼，于是我开始学习，查阅文化，文化是我们最深层的底蕴，中国上下5000年，这就是我们的文化自信，我国历史悠久，所以我们的底蕴深厚，不是空谈，在这个世界上，中文是最难的语言，但是我们会说，在这个世界上，英语有26个字母，你也许可以全部念出来，但是我中华随便找一个字你都可以拥有四个读法，就说一吧，四个声，甚至可以轻声，这就是汉字，这便是我对于文化的一点理解。 我喜欢学习，也喜欢学各种东西，三人行必有我师，何止是三人？两人中另外一个都可以是我的师傅。","link":"/about/index.html"},{"title":"所有分类","text":"","link":"/categories/index.html"},{"title":"友人帐","text":"hey,boys.你想要把你的名字写入我的友人帐吗？那就来留言吧！ 很抱歉，之前添加过我的友联的同学，由于换主题了，还请重新添加，真的很抱歉，我之前的主题文件误删了。 我的友联方便butterfly玩家 - name: ChenShang link: https://weikecc.top/ avatar: https://thirdqq.qlogo.cn/g?b=sdk&amp;nk=3225454747&amp;s=140 descr: 做生活的船夫。 本主题 - title: ChenShang avatar: https://thirdqq.qlogo.cn/g?b=sdk&amp;nk=3225454747&amp;s=140 # 头像 url: https://cn.weikecc.top # 链接 screenshot: https://image.thum.io/get/width/400/crop/800/allowJPG/wait/20/noanimate/https://weikecc.top/ keywords: ChenShang # 关键词 description: 做生活的船夫。 # 描述","link":"/links/index.html"},{"title":"所有标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"VSCode插件—CloudMusic","text":"介绍这是一款傻瓜式的VSC网抑云在线插件。 本插件具有以下特点： 简单：开箱即用，无需安装、修改任何文件 快速：使用本机模块，资源占用低，速度快 强大：借助网页 API，能实现所有常用功能 已实现的功能： 每日签到 歌曲播放，收藏，喜欢 听歌打卡 心动模式 私人 FM 歌词显示 搜索（热搜/单曲/专辑/歌手…） 缓存管理 可选无损音质 媒体控制支持 更多功能等待发现 安装点击这里直接访问插件商店网页版本 直接点击这里安装 使用 设置 cloudmusic.account.autoCheck: 登录后自动签到 cloudmusic.cache.size: 缓存大小限制 cloudmusic.music.quality: 音质选择 命令 Cloudmusic: Sign in: 登录 Cloudmusic: Sign out :登出 Cloudmusic: Daily check: 每日签到 Cloudmusic: Toggle button: 显示/隐藏按钮 已知问题 对于使用代理软件的用户，如果播放出现网络错误，请设置http.proxy（不是cloudmusic.music.proxy） 发行说明发行说明 声明转载于时过境迁","link":"/2020/08/08/1/"},{"title":"live2d-web","text":"转载于 隔壁Yun主题的猫九。 萌萌哒的看板娘，以下资源来源于互联网，最底下会给出相关链接，[github示例](https://github.com/jianchengwang/live2d_models) 使用方法 mocHexo# 进入hexo根目录 cd hexo-dir # 安装hexo-helper-live2d npm install --save hexo-helper-live2d # 创建目录live2d_models mkdir live2d_models # 把模型文件放进创建目录live2d_models，比如我这边下载的是index模型 cd live2d_models &amp;&amp; wget index #重命名模型文件中的json文件，比如我下载的模型是index，所以model.json -&gt; index.model.json cd index mv model.json index.model.json # 修改配置文件 vim hexo-dir/_config.yml live2d: enable: true # 是否开启live2d scriptFrom: local # 脚本从本地引入 pluginRootPath: live2dw/ # 插件在站点上的根目录(相对路径) pluginJsPath: lib/ # 脚本文件相对与插件根目录路径 pluginModelPath: assets/ # 模型文件相对与插件根目录路径 tagMode: false # 标签模式, 是否仅替换 live2d tag标签而非插入到所有页面中 debug: false # 调试, 是否在控制台输出日志 model: use: index # 填写放进live2d_models文件夹中的模型文件夹名字 scale: 1 # canvas 模型与canvas的缩放 display: width: 150 # 宽度 height: 300 # 高度 position: left # 显示位置 hOffset: 0 #水平偏移 vOffset: -20 #垂直偏移 mobile: show: true # 手机端是否显示 scale: 0.5 # 移动设备上的缩放 Typecho下载保罗的看板娘插件，并上传到你的插件目录（一般为 usr/plugins）。进入你的网站后台，在顶部的“控制台”下找到“插件” -&gt; Pio -&gt; 启用。启用之后我们就可以开始设置啦！ 引用模型 插件默认提供两种方式引用模型，一个是读取插件指定目录下的模型，还有一个是另外引用。对于新手，我们比较推荐放在插件目录的 model 文件夹下。只要你在本站下载模型，都已经为这个插件专门做过一定的优化处理啦。 显示不全？ 待我们放好模型之后可能会发现，模型显示不太齐全。这是由于高宽度设置不正确导致的~ 由于插件默认的模型是 Pio，而其他模型的比例和它不同，所以我们就需要在插件目录下手动设置它的宽度和高度啦！这样我们的模型就能正常显示出来了！ 遮住内容？ 如果你用的主题默认在左侧有侧边栏，发现模型遮住了菜单，那么我们就可以在插件设置里面修改它的位置，这样就可以遮住你的内容啦！ 更多介绍详见：给你的博客增加动态看板娘 EmLog详见广树的文章 - 博客通用版 Live2D 伊斯特瓦尔发布 其他平台其他平台可以通过修改插件或是修改模板的方式引用看板娘。这里的方法适用于 WordPress、EMLog、Z-Blog 甚至是静态网站。 保罗的 插件文档 里已经提供了完整的独立版使用教程，你可以在不使用插件的情况下正常食用看板娘。以下方法仅简单引用了看板娘，但并不包含交互功能。 下载 来自玩水大佬的封装 项目，我们会在 src/lib 目录下得到一个 live2d.min.js 。这个就是核心啦！ 然后在你的网页上添加一个 canvas 画布，一般放在 footer.php 即页尾文件里面。一般写成这样： &lt;canvas id=&quot;paul&quot; width=&quot;280&quot; height=&quot;250&quot;&gt;&lt;/canvas&gt; 其中 id 部分负责让脚本获得画布的位置，width 和 height 分别是宽度和高度，在这里设置你的模型宽高。 然后我们就需要引用这个 JS 文件啦！方法也很简单，你把这个文件放在合适的位置，或是用 CDN 引用皆可。 &lt;script src=&quot;live2d.min.js&quot;&gt;&lt;/script&gt; 注意：要确认画布放在 &lt;script&gt; 的前面！ 接着我们再通过一段简单的代码来开始引用我们的模型： &lt;script&gt;loadlive2d('paul', '模型路径/model.json');&lt;/script&gt; 这样我们的网站上，就显示出自己的看板娘啦！ 细心的你肯定会发现，看板娘被放在了正常的位置显示了出来，而不是 “悬挂” 在页面的某个位置。我们通过添加一段简单的 CSS 就可以做到了！ #paul{ left: 0; bottom: 0; z-index: 520; /* 如果模型被遮住可以把它改的更大 */ position: fixed; pointer-events: none; /* 防止遮住鼠标点击页面其他内容 */ } 于是我们网站上就有了自己的看板娘啦！ 使用方法 moc3参考 https://github.com/HCLonely/Live2dV3 https://github.com/Yukariin/AzurLaneL2DViewer &lt;!------ 位置可自定义 ------&gt; &lt;div class=&quot;Canvas&quot; style=&quot;position: fixed; right: 10px; bottom: 10px;z-index: 99999999&quot; id=&quot;L2dCanvas&quot;&gt;&lt;/div&gt; &lt;!-- Pollyfill script --&gt; &lt;script src=&quot;https://unpkg.com/core-js-bundle@3.6.1/minified.js&quot;&gt;&lt;/script&gt; &lt;!-- Live2DCubismCore script --&gt; &lt;script src = &quot;https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js&quot;&gt;&lt;/script&gt; &lt;!-- Build script --&gt; &lt;script src = &quot;./assets/js/live2dv3.js&quot;&gt;&lt;/script&gt; &lt;!------ 加载Live2d模型 | Load Live2d model ------&gt; &lt;script&gt; var l2dv; window.onload = () =&gt; { l2dv = new L2dViewer({ el: document.getElementById('L2dCanvas'), modelHomePath: './assets/model/moc3/', // modelHomePath: 'https://cdn.jsdelivr.net/gh/alg-wiki/AzurLaneL2DViewer@gh-pages/assets/', model: 'yichui_2', // bgImg: 'https://cdn.jsdelivr.net/gh/alg-wiki/AzurLaneL2DViewer@gh-pages/assets/bg/bg_church_jp.png', bgImg: './assets/image/bg/bg_1.png', width: 500, height: 300, autoMotion: false, _finishedLoadModel: function() { var motionDiv = document.getElementById(&quot;motionDiv&quot;); motionDiv.innerHTML = &quot;&quot;; l2dv.getMotions().forEach((v,k) =&gt; { let motionName = k; if(motionName.startsWith('motions/')) { motionName = motionName.replace('motions/', ''); } motionName = motionName.replace('.motion3.json', ''); var bt = document.createElement(&quot;button&quot;); bt.innerHTML = motionName; bt.classList.add('btnGenericText'); bt.onclick = function () { //绑定点击事件 l2dv.startMotion(k); }; motionDiv.appendChild(bt); }) }, _onTap: function() { // 点击canvas触发事件 } }); } &lt;/script&gt; 参数 类型 描述 默认 el [必需] DOM 对象或 jQuery 对象 要挂载Live2d模型的元素, 支持DOM选择器和jQuery选择器，例：document.getElementById('L2dCanvas')或document.querySelector('#L2dCanvas')或$('#L2dCanvas') null modelHomePath [必需] String 模型根目录 null model [必需] String 初始显示模型 null bgImg [可选] String Canvas背景图片，有图片的话，Canvas的宽高会等于背景图片宽高 null width [可选] Number Canvas宽度，单位: px 500 height [可选] Number Canvas高度，单位: px 00 autoMotion [可选] Boolean 是否自动随机触发Motion true _finishedLoadModel [可选] Function 模型加载完回调函数 null _onTap [可选] Function 点击模型触发函数，为空的话会默认触发随机Motion null // L2dViewer 对外暴露的方法 // 获取模型信息 public getModel(): LAppModel { } // 加载模型 public loadModel(modelName: string) { } // 触发模型 motion public startMotion(motionName: string) { } // 获取模型 motion public getMotions(): Map&lt;any,any&gt; { } // 设置模型背景 public setBgImg(bgImg: string) { } 当然，你感兴趣的话，并且有一定的前端基础，建议自己构建 live2dv3.js，可以下载官方提供的Live2d Web Sdk，里面已经包含一个简单示例了， lappdefine.ts 定义基本的参数lappdelegate.ts 初始化,释放资源,事件绑定lapplive2dmanager.ts 模型的管理类,进行模型生成和废弃,事件的处理,模型切换.lappmodel.ts 模型类,定义模型的基本属性lappal.ts 读取文件,抽象文件数据(算是工具类)lappsprite.ts 动画精灵类,(有h5游戏开发应该了解)lapptexturemanager.ts 纹理管理类,进行图像读取和管理的类lappview.ts 视图类,生成模型的图像被lapplive2dmanager管理main.ts 主程序启动程序touchmanager.ts 事件的管理类(比如移动鼠标,点击鼠标,触摸屏触碰等) 简单修改下就可以了，也可以参照我的demo代码 模型预览梦象网站资源 moc茵蒂克丝 index 动漫《魔法禁书目录》中女主角。有着银色的长发、绿色的眼瞳、雪白的肌肤，年龄约十四五岁，却有着可爱的幼儿体型。 模型作者：未知模型出处：网络搜集 尤莉 youri 尤莉是由 つくみず 创作的漫画《少女终末旅行》及其衍生作品中的登场角色。性格极度乐观，非常喜欢吃东西。 模型作者：罐装猫粮君模型出处：【Live2D工房】Vol.1 Part2 尤 脸扁再来一份 《少女终末旅行》 雪未来 snow_miku 雪未来是 Crypton 旗下虚拟歌手初音未来的二次创作系列造型，民间有时称其为 “雪初音” 或 “雪 MIKU”。自 2010 年被确立为日本北海道札幌冰雪节的应援角色。自 2012 年起，每年会以网络征集投票的形式决定新的雪未来人物形象。 模型作者：未知模型出处：网络搜集 推荐设置： 宽度：300高度：300 凉风青叶 aoba来自 New Game! 的凉风青叶和你见面啦！ 推荐设置： 高度：250宽度：200 工作中的血小板 platelet 模型作者：Neko_KK模型出处：Live2DViewer 创意工坊 干物妹小埋 umaru 模型作者：未知模型出处：未知 推荐设置： 高度：300宽度：100 和泉纱雾 sagiri 模型作者：oukaitou模型出处：Live2DViewer 创意工坊 推荐设置： 高度：500宽度：默认 康娜 kanna 模型作者：oukaitou模型出处：Live2DViewer 创意工坊 时崎狂三 kurumi 模型作者：未知模型出处：约会大作战手游官网 雷姆 rem 提取自 广树的项目。 推荐设置： 高度：275宽度：230 高度：335宽度：280 香风智乃 chino 香风智乃，漫画《请问您今天要来点兔子吗？》中及其衍生作品中女主角之一。咖啡店 Rabbit House 老板的孙女，13 岁的初中生。身形娇小却意外地能干，店内杂务也几乎由她一手包办，个性冷静又沉默寡言，但其实是在人际交往上有点笨拙。 模型作者：Hernes_VR模型出处：FaceRig 创意工坊 鹿目圆 madoka 鹿目圆是原创动画《魔法少女小圆》及其衍生作品中主角。就读于市立见泷原中学二年级的一位普通初中生。个头小巧可爱，性格温柔且为朋友着想。因为本身的潜质，而成为魔法少女。后成为神，消失在世界上。 模型作者：未知模型出处：网络搜集 推荐设置： 高度：300宽度：230 22 娘全身版 22 娘是娱乐向弹幕视频站点 Bilibili 的吉祥物。阳光元气娘，火拼有精神。对人热情、热心，但有些冒失。 模型作者：未知模型出处：网络搜集 推荐设置： 高度：400宽度：150 涅普迪努 neptune 涅普迪努，又称 “涅普顿”。是《超次元游戏：海王星》等海王星系列游戏中紫色大陆 Planeptune 的守护女神。性格乐天、天真浪漫，很擅长调节气氛。有时会从女神的工作中翘班，经常懒懒的，但因为天生的性格原因，仍然受到周围人的欢迎。 模型作者：未知模型出处：网络搜集 Eikanya提取 moc3这个大佬提取了很多，所以这里只列出我喜欢的部分模型，在线预览 yichui_2 dujiaoshou_6 资源来源Live2d官网 梦象 Live2D 模型站 Eikanya/Live2d-model Azur Lane Live2D Viewer DownGit","link":"/2021/09/10/2/"},{"title":"CentOS7下安装和配置redis","text":"Redis是一个高性能的，开源key-value型数据库。是构建高性能，可扩展的Web应用的完美解决方案，可以内存存储亦可持久化存储。因为要使用跨进程，跨服务级别的数据缓存，在对比多个方案后，决定使用Redis。顺便整理下Redis的安装过程，以便查阅。 1 . 下载Redis目前，最新的Redist版本为3.0，使用wget下载，命令如下： # wget http://download.redis.io/releases/redis-3.0.4.tar.gz 2 . 解压Redis下载完成后，使用tar命令解压下载文件： # tar -xzvf redis-3.0.4.tar.gz 3 . 编译安装Redis切换至程序目录，并执行make命令编译： # cd redis-3.0.4 # make 执行安装命令 # make install make install安装完成后，会在/usr/local/bin目录下生成下面几个可执行文件，它们的作用分别是： redis-server：Redis服务器端启动程序 redis-cli：Redis客户端操作工具。也可以用telnet根据其纯文本协议来操作 redis-benchmark：Redis性能测试工具 redis-check-aof：数据修复工具 redis-check-dump：检查导出工具 备注 有的机器会出现类似以下错误： make[1]: Entering directory `/root/redis/src' You need tcl 8.5 or newer in order to run the Redis test …… 这是因为没有安装tcl导致，yum安装即可： yum install tcl 4 . 配置Redis复制配置文件到/etc/目录： # cp redis.conf /etc/ 为了让Redis后台运行，一般还需要修改redis.conf文件： vi /etc/redis.conf 修改daemonize配置项为yes，使Redis进程在后台运行： daemonize yes 5 . 启动Redis配置完成后，启动Redis： # cd /usr/local/bin # ./redis-server /etc/redis.conf 检查启动情况： # ps -ef | grep redis 看到类似下面的一行，表示启动成功： root 18443 1 0 13:05 ? 00:00:00 ./redis-server *:6379 6 . 添加开机启动项让Redis开机运行可以将其添加到rc.local文件，也可将添加为系统服务service。本文使用rc.local的方式，添加service请参考：Redis 配置为 Service 系统服务 。 为了能让Redis在服务器重启后自动启动，需要将启动命令写入开机启动项： echo &quot;/usr/local/bin/redis-server /etc/redis.conf&quot; &gt;&gt;/etc/rc.local 7 . Redis配置参数在 前面的操作中，我们用到了使Redis进程在后台运行的参数，下面介绍其它一些常用的Redis启动参数： daemonize：是否以后台daemon方式运行 pidfile：pid文件位置 port：监听的端口号 timeout：请求超时时间 loglevel：log信息级别 logfile：log文件位置 databases：开启数据库的数量 save * *：保存快照的频率，第一个*表示多长时间，第三个*表示执行多少次写操作。在一定时间内执行一定数量的写操作时，自动保存快照。可设置多个条件。 rdbcompression：是否使用压缩 dbfilename：数据快照文件名（只是文件名） dir：数据快照的保存目录（仅目录） appendonly：是否开启appendonlylog，开启的话每次写操作会记一条log，这会提高数据抗风险能力，但影响效率。 appendfsync：appendonlylog如何同步到磁盘。三个选项，分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步","link":"/2016/10/04/CentOS7%E4%B8%8B%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AEredis/"},{"title":"CentOS安装node8.x版本","text":"CentOS 安装 node 8.x 版本由于一些原因需要给CentOS服务器安装8.0以上版本的node, 本来直接通过yum管理安装管理，但是没找到好办法，在此记录一下自己最后使用的简单过程： 安装之前删除原来的node和npm (我原来是用yum安装的，如果是第一次安装可以省略这一步): yum remove nodejs npm -y 首先我们随便进入服务器的一个目录，然后从淘宝的源拉取内容: wget https://npm.taobao.org/mirrors/node/v8.0.0/node-v8.0.0-linux-x64.tar.xz 解压缩: sudo tar -xvf node-v8.0.0-linux-x64.tar.xz 进入解压目录下的 bin 目录，执行 ls 命令 cd node-v8.0.0-linux-x64/bin &amp;&amp; ls 我们发现有node 和 npm 这个时候我们测试: ./node -v 这个时候我们发现实际上已经安装好了，接下来就是要建立链接文件。 这里还是，如果我们之前已经安装过了，那么我们要先删除之前建立的链接文件： sudo rm -rf /usr/bin/node sudo rm -rf /usr/bin/npm 然后建立链接文件: sudo ln -s /usr/share/node-v8.0.0-linux-x64/bin/node /usr/bin/node sudo ln -s /usr/share/node-v8.0.0-linux-x64/bin/npm /usr/bin/npm 注意这里的第一个路径不要直接复制粘贴，要写当前文件的真正的路径，这个可以通过pwd获取。 然后我们可以通过node -v等测试已经安装成功。","link":"/2017/12/15/CentOS%E5%AE%89%E8%A3%85node8-x%E7%89%88%E6%9C%AC/"},{"title":"抓包工具 Fiddler 相关知识总结","text":"本文初衷 整理对 Fiddler 工具的知识积累 分享给更多需要使用抓包工具的人 Fiddler 介绍它是什么 术语定义 官网定义：http://www.telerik.com/fiddler 百度百科定义：http://baike.baidu.com/item/Fiddler 维基百科定义：https://en.wikipedia.org/wiki/Fiddler_%28software%29 简单地讲就是一个抓包工具，或者是叫做网络嗅探器，把网络传输的数据抓取下来进行分析、Debug 它可以对常用的浏览器：IE、Chrome、Firefox、Safari 等进行抓包，支持 HTTP、HTTPS 支持代理，可以通过它，在同一个局域网中抓取 APP 的网络请求，然后进行分析 一般我们用来做测试 支持插件扩展 其本质： 图片来源：http://www.jikexueyuan.com/course/1926_2.html 别人这样说： Fiddler是位于客户端和服务器端的HTTP代理，也是目前最常用的http抓包工具之一 。它能够记录客户端和服务器之间的所有HTTP请求，可以针对特定的HTTP请求，分析请求数据、设置断点、调试web应用、修改请求的数据，甚至可以修改服务器返回的数据，功能非常强大，是web调试的利器。 来源：http://blog.csdn.net/ohmygirl/article/details/17846199 官网资料： Windows 版本需要 .NetFrameWork 环境 官网下载（Windows-大小 1M）：https://www.telerik.com/download/fiddler 官网下载（Linux-大小 1M）：http://fiddler.wikidot.com/mono 插件官网：http://www.telerik.com/fiddler/add-ons 官网文档：http://docs.telerik.com/fiddler/configure-fiddler/tasks/configurefiddler 官网博客：http://www.telerik.com/blogs/tag/fiddler 它的历史 版本发布历史：http://www.telerik.com/support/whats-new/fiddler/release-history/fiddler-v2.x 同类技术： Wireshark（强大）、httpwatch（浏览器扩展）、firebug（浏览器扩展）、Chrome 开发者模式 学习前提/依赖 略懂 HTTP 相关知识，比如 GET POST PUT 等这类 request method，Content-type 等这种 request header 如果你没有相关知识，可以看下面视频教程： 了解 web 及网络基础 细说 HTTP 的报文格式和工作流程 深入学习 URL 哪些人不喜欢它 非 Web 端开发人员 为什么学习它 因为开发中需要测试，需要了解整个 Web 应用的具体细节，了解细节后可以尽可量防止漏洞，可以对细节做性能测试 不管是 Web 开发的前端还是后端，都需要，或者是说只要开发中含有 HTTP 请求的都需要抓包工具 积累我要怎么做 看教程 极客学院教程：http://search.jikexueyuan.com/course/?q=Fiddler 2014 年出版过一本书：Fiddler调试权威指南 【HTTP】Fiddler（一） - Fiddler简介 【HTTP】Fiddler（二） - 使用Fiddler做抓包分析 【HTTP】Fiddler（三）- Fiddler命令行和HTTP断点调试 使用前端开发利器Fiddler调试手机程序 Web工作方式 神器——Chrome开发者工具(一) Fiddler In Action - Part 1 Fiddler In Action - Part 2 Fiddler实用教程 Fiddler实战 使用Fiddler自定义百度云分享提取码 猫哥网络编程系列：HTTP PEM 万能调试法 App测试-&gt;抓取手机网络请求 抓包与安全 Web开发利器-Fiddler简介 Fiddler 扩展使用 细节积累 Fiddler 的界面介绍，如下图（图片来源） Fiddler 工具栏介绍，如下图 Fiddler 自定义显示列信息，如下图 Fiddler 选中会话后的常用右键菜单，如下图 按 Ctrl + A 全选所有会话，右边可以查看所有请求的一个总的情况 修改某个请求数据，进行模拟 开启 HTTPS 捕获，默认是没有开启的 使用 AutoResponder，这是前端开发必备技能 AutoResponder 作用：可用于截拦某一请求，并重定向到本地资源，或者使用 Fiddler 内置响应。 使用场景：比如线上服务器的某个 JavaScript / Images 有问题，正常修改此 Bug 的流程应该是这样的：本地修改后提交到服务器预览修改后效果，但是作为前端开发者其实很多时候是不具备使用服务器的权限的。这时候 AutoResponder 就起作用了，在页面加载的时候，我们让服务器不加载服务器的那个 JavaScript 请求，而是使用本地的那个 JavaScript 文件。 但是使用该场景需要有一个特别注意的：在使用规则之后，重新刷新网页的时候最好是先清除下浏览器缓存，省得有意外，浪费你时间。 下图演示的是我把博客的头像换成一张橘黄色的图片 Fiddler 的命令行工具中常用命令： 官网对这些命令的整理：http://docs.telerik.com/fiddler/knowledgebase/quickexec ?cc=，用来匹配请求地址中含有 ?cc 的请求 &gt; 5000 或 &lt; 5000，找响应大小大于 5000 字节，或小于 5000 字节的请求 关于 Debug 命令： 开启中断请求命令 bpafter beautiful，中断 URL 包含 beautiful 字符的全部会话 bpu beautiful，中断 URL 包含 beautiful 字符的全部会话 bps 404，中断 HTTP 响应状态为 404 的全部会话 bpm GET 或者 bpv GET，中断 GET 请求方式的全部会话 取消中断请求命令 使用同样的开启命令，但是不带参数即可取消，比如我们使用了 bpu code.youmeek.com 中断，我们要取消这个中断，则使用：bpu 即可 结束语 更多的细节还需要你自己继续去摸索","link":"/2016/04/30/Fiddler/"},{"title":"我的 Firefox 扩展 和 主题（不间断更新）","text":"初衷 整理自己的习惯，也希望你有好的扩展可以留言给我推荐，能提高效率的事情我非常需要！ 不对下面扩展进行再唠叨，具体点击到扩展主页可以看到对应的说明。 扩展整合 YouMeek-Firefox-扩展收藏集 具体 官网：https://addons.mozilla.org/zh-CN/firefox/extensions/ Adblock Plus：https://addons.mozilla.org/zh-CN/firefox/addon/adblock-plus LastPass：https://addons.mozilla.org/zh-CN/firefox/addon/lastpass-password-manager Xmarks：https://addons.mozilla.org/zh-CN/firefox/addon/xmarks-sync Flashblock：https://addons.mozilla.org/zh-CN/firefox/addon/flashblock/ Add Bookmark Here ²：https://addons.mozilla.org/zh-CN/firefox/addon/add-bookmark-here-2 Google search link fix：https://addons.mozilla.org/zh-CN/firefox/addon/google-search-link-fix/ QrCodeR：https://addons.mozilla.org/zh-CN/firefox/addon/qrcoder/?src=search Wired-Marker：https://addons.mozilla.org/zh-CN/firefox/addon/wired-marker/?src=search FoxyProxy Standard：https://addons.mozilla.org/zh-CN/firefox/addon/foxyproxy-standard/ FindBar Tweak：https://addons.mozilla.org/zh-CN/firefox/addon/findbar-tweak Tab Mix Plus：https://addons.mozilla.org/zh-CN/firefox/addon/tab-mix-plus Firebug：https://addons.mozilla.org/zh-CN/firefox/addon/firebug iMacros for Firefox：https://addons.mozilla.org/zh-CN/firefox/addon/imacros-for-firefox Tile Tabs：https://addons.mozilla.org/zh-CN/firefox/addon/tile-tabs Add to Search Bar：https://addons.mozilla.org/zh-CN/firefox/addon/add-to-search-bar Text Link：https://addons.mozilla.org/zh-CN/firefox/addon/text-link Beyond Australis：https://addons.mozilla.org/zh-CN/firefox/addon/the-fox-only-better AutoPagerize：https://addons.mozilla.org/zh-CN/firefox/addon/autopagerize/ SearchWP：https://addons.mozilla.org/zh-CN/firefox/addon/searchwp Simplify Awesome Bar 随打即找：https://addons.mozilla.org/zh-CN/firefox/addon/simplify-awesome-bar/ gooreplacer：https://addons.mozilla.org/zh-CN/firefox/addon/gooreplacer Location Bar Enhancer：https://addons.mozilla.org/zh-CN/firefox/addon/ui-enhancer Ghostery：https://addons.mozilla.org/zh-CN/firefox/addon/ghostery NoScript：https://addons.mozilla.org/zh-CN/firefox/addon/noscript DownThemAll：https://addons.mozilla.org/zh-CN/firefox/addon/downthemall/ WizNote Web Clipper：http://www.wiz.cn/downloads-webclipper.html Markdown Here：https://addons.mozilla.org/zh-CN/firefox/addon/markdown-here NetVideoHunter：https://addons.mozilla.org/zh-CN/firefox/addon/netvideohunter-video-downloade Video DownloadHelper：https://addons.mozilla.org/zh-CN/firefox/addon/video-downloadhelper/ RightToClick：https://addons.mozilla.org/zh-CN/firefox/addon/righttoclick Thumbnail Zoom：https://addons.mozilla.org/zh-CN/firefox/addon/thumbnail-zoom JSONView：https://addons.mozilla.org/zh-CN/firefox/addon/jsonview Stylish：https://addons.mozilla.org/zh-CN/firefox/addon/stylish/ Bookmarks Checker：https://addons.mozilla.org/zh-CN/firefox/addon/bookmarks-checker/ 购物党全网自动比价工具 Multifox：https://addons.mozilla.org/zh-CN/firefox/addon/multifox/?src=cb-dl-featured FireQuery：https://addons.mozilla.org/zh-CN/firefox/addon/firequery/?src=api RESTer：https://addons.mozilla.org/zh-CN/firefox/addon/rester/?src=search Copy Urls Expert：https://addons.mozilla.org/zh-CN/firefox/addon/copy-urls-expert/?src=api User-Agent Switcher：https://addons.mozilla.org/zh-CN/firefox/addon/user-agent-switcher-firefox **Cookies Manager+**：https://addons.mozilla.org/zh-CN/firefox/addon/cookies-manager-plus/?src=search HttpRequester：https://addons.mozilla.org/zh-CN/firefox/addon/httprequester 关闭扩展签名校验 在地址栏输入：about:config，找到：xpinstall.signatures.required，然后设置为 false 主题整合 YouMeek-Firefox-主题收藏集 具体 官网：https://addons.mozilla.org/zh-CN/firefox/themes/ Carbon Pro：https://addons.mozilla.org/zh-CN/firefox/addon/carbon-pro/ Carbon Light：https://addons.mozilla.org/zh-CN/firefox/addon/carbon-light/ Carbon Dark：https://addons.mozilla.org/zh-CN/firefox/addon/carbon-dark/ Aurora Australis：https://addons.mozilla.org/zh-CN/firefox/addon/aurora-australis/ cubiccube：https://addons.mozilla.org/zh-CN/firefox/addon/cubiccube/","link":"/2016/03/19/Firefox-Extensions-Themes/"},{"title":"Genshin-Impact（原神）","text":"新手指导&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;原神新手15级之前开荒期建议多收集资源 ，每天4个委托必做；&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;16级开启多人游戏，25级开狼，35级开公子，基本来说周本是龙狼公子每周必刷。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;前期记住练好一个主c，副c，辅助，奶妈打龙剧情就会送，香菱打到深渊3-3就会送，多打一些武器本和天赋本多收集资源到中期使用。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;中期可以选择打无相系列、两树，中期靠三星到4星圣遗物过渡，&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;到35级之后打boss会有一定的概率掉5星，&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;到45级之后再开始刷圣遗物，45级打圣遗物必出金 北斗圣遗物四星圣遗物 【奇迹两件套+守护之心两件套、赌徒和武人四件套】：生存和输出能力同时兼顾。前者加防御和抗性，后者普攻和技能的伤害。 五星圣遗物 【如雷的盛怒两件套&amp;四件套、平息鸣雷尊者两件套和四件套】：大幅提高输出能力，对雷元素影响下的敌人增伤效果超过50%，还能增加高额的雷元素抗性。 凝光圣遗物搭配四星 【血战之人】：【二件套】暴击率提高15%。【四件套】生命低于70%，暴击率额外提高25%。 【行者之心】：【二件套】基础攻击力提高20%。【四件套】重击暴击率提高30%。 【勇者之心】：【二件套】基础攻击力提高20%。【四件套】对生命值高于50%的敌人，造成伤害增加30%。 五星 【流浪大地的乐团】：【二件套】元素精通提高80点。【四件套】装备该圣遗物的角色为弓箭、法器角色时，角色重击造成的伤害提高35%。&amp;nbsp;&amp;nbsp;&amp;nbsp;总而言之，凝光圣遗物搭配的关键词条，就是【基础攻击力】、【暴击率】、【爆伤】和【元素精通】，因为凝光靠普攻和技能打伤害，上述的四套圣遗物都比较符合条件。 甘雨圣遗物推荐五星推荐 【流浪大地的乐团】：【四件套】 【冰封迷途的勇士】：【四件套】","link":"/2021/02/02/Genshin-Impact/"},{"title":"Github的使用","text":"web这里我简单介绍一个网页版的基本使用方法，如果大家使用网页版的话，我建议英语不好的人使用谷歌浏览器，谷歌浏览器的好处就在于可以一键翻译当前网页成中文。 登陆到自己的主页之后，右侧就是自己的所有分支，我的是我自己创建了两个，中间那个是当时为了测试保存的别人代码。 如果想创建新的分支的话可以点右侧绿色的按钮，创建分支的方法和桌面版是一样的。我现在要往bit这个分支里边上传代码。 进入分支之后，你可以选择，创建新的文件，或者说上传新的文件。这里创建新的文件和上传文件在我看来是有区别的。 创建新的文件，和写博客是一样的，首先起个名字，然后将你的代码复制进去。 往下拉然后点绿色按钮上传就可以了。 如果点上传文件的话就可以直接将你之前所写的.c、.cpp文件直接上传。 点击选择文件，然后找到你的文件直接上传即可。 但是，其实github网页版是可以直接上传文件夹的，但是这算是一个隐藏的功能，如果想上传文件夹的话需要找到你上传的文件夹，直接拖入到刚刚的对话框内。 直接将文件夹拖入对话框就可以直接上传文件夹。 如果想要删除某个文件或者文件夹的话，github是相对来说比较难找到的。 找到你想要删除的文件夹，点击进入之后找到setting按钮，之后拉到界面的最下边 指向的按钮就是删除按钮。 这就是github网页版的简单操作。不知道是不是真的网页版被墙了的原因，我上传经常上传失败，各个步骤的上传失败，多试几次就行了。 教程首先，我先对GitHub来一个简单的介绍，GitHub有一个很强大的功能就是，你在服务器上边可以创建一个库（稍后会介绍怎么创建），写代码是一件很重的任务，尤其是很多人完成一个很大的项目的时候，就十分的复杂，一群人一起来写某个项目，大家完成的时间，完成的进度都是不相同的，你写一点我写一点，甚至可能你今天写的出现了错误，影响到了我昨天写的代码，最后怎么才能将大家的代码轻松的汇总起来，又怎么在汇总所有人的代码之后发现错误等等一系列问题。这样我们就用到了GitHub这个软件。我们在GitHub服务器上有一个主仓库，这里用来储存你的所有代码，如果不付费的话是所有人都可以看的，如果你不想让别人看到你的代码，可以选择付费仓库。我们创建了主仓库之后，就可以在电脑上创建分支，之后你就可以在电脑上完成自己的代码，写完之后直接同步在电脑的分支，当你认为可以上传的自己的主仓库时，就可以申请更新，当通过审核的时候，你代码就出现在了自己的主仓库中，这样全世界的程序员都可以查看你的代码。全世界现在已经有300万的注册用户，甚至还有一些相当知名的开源项目也在其中公布代码。在GitHub上你可以看到很多计算机领域的精英所分享的自己的代码。这是GitHub的两个主要优点，适合团队协作，以及下载其他优秀者的代码。 今天，GitHub已是：一个拥有143万开发者的社区。其中不乏Linux发明者Torvalds这样的顶级黑客，以及Rails创始人DHH这样的年轻极客。 · 这个星球上最流行的开源托管服务。目前已托管431万git项目，不仅越来越多知名开源项目迁入GitHub，比如Ruby on Rails、jQuery、Ruby、Erlang/OTP；近三年流行的开源库往往在GitHub首发，例如：BootStrap、Node.js、CoffeScript等。alexa全球排名414的网站。 https://github.com/ 这是GitHub的官方网站，在官网上可以注册属于自己的GitHub账号，网上是全英文的，对于英语不好的同学建议使用谷歌浏览器，谷歌浏览器可以翻译网页变为中文使用起来十分方便。 通过简单的步骤之后你就会有一个属于自己的GitHub账号。再简单注册完成之后会需要验证你所输入的邮箱才能正常使用你的GitHub。 在注册完成之后，完成一些简单的设置之后，你需要创建一个属于自己的库 在登陆自己的GitHub账号之后，在网页右上角的小加号是用来创建自己的库的按钮，之后的步骤将网页翻译成中文之后，按提示进行创建自己的库即可。 第一个框是自己为自己的库起一个名字，第二个框是自己对库的一个简单介绍 在创建完成自己的库之后，下面就要让自己的电脑克隆一个自己所创建的库，方面自己电脑上的代码同步到GitHub你所创建的库当中。 为了实现，就需要安装一个软件，Git Bash。 下面我就介绍一下这个软件的安装，以及简单的配置。 git-scm.com 首先进入GitHub官网，下载适合自己电脑的版本 下载完安装包之后运行 在安装过程中直接默认选项即可。 很多人第一次打开这个GitHub的时候一脸懵逼，认为这是什么。对于一个新手来说看到这个是没有任何思路，没有任何想法的。 这一栏 开始是你的计算机的名字在我这里就是Hanani @后边的内容是你的计算机型号，很多时候有的人打开之后@后边是乱码，这个时候也不要在意，因为有些电脑型号是中文的，可能在显示的时候出现了问题，不影响你后期的操作。 接下来，就要开始获取属于你自己的密匙。在git bash中所有功能都是通过简单的一些代码来实现的。获取密匙的时候需要输入 $ ssh-keygen-t rsa-C &quot;your_email@youremail.com&quot; 需要输入这个代码，引号内需要改成你在注册GitHub的时候绑定的邮箱账号。之后会有一些简单的让你确认的操作，之后让你会提示操作路径、密码等等，一般情况下就直接按回车一路过就可以 如果之后你出现了这个界面之后，就说明你的密匙已经成功创建了。现在你就需要去他刚刚显示的存储位置打开它，把其中的内容复制出来。 之后你会看到这些内容，有的人会在id_rsa后边带有一个pub，之前看网上教程需要找到带pub的文件，因为我在生成后没有带.pub的文件，怀着忐忑的心打开id_rsa后发现这里边的密匙也是可以使用的。打开id_rsa的时候需要用记事本的方式打开。 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDIskXqZF3SSFtACK6zoNGJabikTBC3kig6+4j4dCq1tswhA9YkuJCi0WpRmGYWBQ67dyT2or7RedFZlULLZN3nL6AWlo5V2jRXw4WQxCon2rU1p122wmiTzqYOfsykjwullWV4bYcZU4n77A4/9WwlSqZCpEbcdwV8IMkvwfJUInSWqTvmgsL/Tfx7aEB8UjDNJ6SPw30Yijy+62YrftYGgbuwoiL9hDNGO2LfjgOkglHTBJaZe31uQLLWc5uCzd+7Dgh7RaKMmeuz2Uv7yqm/IEU9jH8cPMR9YRPIhmzg38G2s9ILn27QqW9j1hrFY1V 15229020556@163.com 这就是我所获取的密匙(删改，保密)，打开之后很长的一段，不要惊讶，没有问题，这就是你所需要的密匙。 现在你就需要登录到你的GitHub上边添加这个密匙， 打开你GitHub的设置界面，找到SSH and GPG keys这个选项之后，在网页右上角有一个添加新的SSH keys 点击 这里的title 是让你给你的密匙起一个名字，根据个人喜好，什么名字都可以，然后把你在刚刚文件中复制的密匙，填写在下边的大框里。保存即可。 之后你就可以回到你的Git bash上边了 $ ssh -T git@github.com 然后输入上边的代码，来检查是否成功绑定。第一次绑定的时候输入上边的代码之后会提示是否continue，在输入yes后如果出现了：You’ve successfully authenticated, but GitHub does not provide shell access 。那就说明，已经成功连上了GitHub。接下来还需要简单的设置一些东西。 $ git config --global user.email “you@example.com” $ git config --global user.name “Your Name” 输入上边的代码，name最好和GitHub上边的一样，email是一定要是注册GitHub的那个邮箱地址 这两个的顺序可以颠倒，没有固定的顺序。 下面就要将你的库克隆下来到本地电脑中，方便以后进行上传代码。 在库创建完成之后 会有一个网址出现在网页中。 个人习惯将自己的文件储存在d盘之中，所以你先需要将git bash定位在d盘中 在git bash中输入 cd /D 注意盘名字一定要是大写。如不输入这个语句 不给git bash定位的话，默认的本地文件位置是在c盘中。 开始推文件到你的GitHub仓库，打开iGithub个人主页，如果格子绿了，那就是推上去了。 再之后，你只需要将你的代码，放到库的对应的文件夹中，然后使用，git add 、git commit -m “ “ 、最后git push origin master，将你的代码提交就可以了。","link":"/2020/11/15/Github%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"为什么不尝试下 IntelliJ IDEA？我想劝说你","text":"本文对象 Eclipse、MyEclipse、NetBeans、Vim、Sublime Text 重度患者 本文目标 本篇不讲 IntelliJ IDEA 技巧类的具体东西，关于技巧这类东西我已经系统整理过了，你可以去这里看：https://github.com/judasn/IntelliJ-IDEA-Tutorial 写这篇文章主要目的是想给你留下一个印象，关于一个沉浸式的 IDE。 学习过程的核心思想：IntelliJ IDEA 跟 Eclipse 或是其他 IDE 完全不一样，所以放下过去的思维。 懂 Maven 和 Gradle 学习它会更快，因为它本身就是模块化的。 过去有感 在我记忆中，所有的大学 Java IDE 只有一个：Eclipse，所以我也是这样过来的。 我知道做 Java 开发的你们 Eclipse 用得很习惯，可能要怪大学老师。也知道 MyEclipse 能解决做 Java 开发的常见问题。所以我理解你们还在坚持它们的原因，就像几年前刚到一家公司的时候，我暗地里认为我的 MyEclipse 会是如何如何地好，了解的插件是如何如何多。你们那个 IntelliJ IDEA 界面丑、默认字体丑、占用内存又高，我是排斥的。 可是为了融入圈子我只能自己去适应周边的人，我开始逼着自己去了解 IntelliJ IDEA。后来，我专门为它配置了一台 i7、SSD、16G 的机子来伺候它。 IntelliJ IDEA 特色 下面我说几个它特殊的地方，跟 Eclipse / Myeclipse 有重叠或是类似的我这里你就不说了，这些细节在你学习的过程中你自己会发现、对比。 我是这样形容 IntelliJ IDEA 的：沉浸式 IDE。 鲜明特色： 特点一： 下面一些语言的支持需要额外装官网提供的插件，具体可以到插件库里找 支持的语言/平台： Java、JavaScript、TypeScript 、CoffeeScript、Node.js、AngularJS、React、JRuby、ActionScript、SASS、LESS、HTML、CSS Bash、Markdown、Kotlin、PHP、Python、Ruby、Scala、Clojure、Groovy、Android、PhoneGap、Cordova、Ionic 支持的框架： Spring、Spring Boot、Spring MVC、Hibernate、Struts、Mybatis、Flex、JSF、Play Web Services、Grails、GWT、Vaadin、Guice、FreeMarker、Velocity、Thymeleaf 支持的构建工具：Maven、Gradle、SBT、Grunt、Bower 支持的应用容器：Tomcat、TomEE、WebLogin、JBoss、Jetty、WebSphere 支持的版本工具：Git、SVN、CVS、Mercurial、Perforce, ClearCase、TFS 额外支持： 自带反编译、可以在反编译的类中 Debug、如果是开源框架会自动帮你下载源码 终端、数据库 GUI（Oracle、SQL Server、PostgreSQL、MySQL），REST Client 特点二： 它有美妙的快捷键，以及任何地方都支持自定义快捷键，是一个完全可以离开鼠标的 IDE，撒谎的人是小狗。 特点三： 无限制、无条件地搜索。IntelliJ IDEA 是有索引的概念，也因为有索引的原因，我们对整个项目进行全文检索是非常非常非常快的，但是也是这个索引，所以当它首次启动某个项目的时候都需要先扫描一下这个项目的所有文件来创建成它的索引，所以，IntelliJ IDEA 首次启动某个项目花的时间会比较多、而且卡。但是我认为这是值得的，后面有无数次的开发我们可以加倍返还。 特点四： 高效的导航。IntelliJ IDEA 除了各种搜索无敌，还有各种导航。 你任何时候都可以快速到某个类的父类、子类、接口、测试类、引用地，可以快速到某个变量、方法、文件、包。 沉浸式的原因是：IntelliJ IDEA 一站解决基本上市场上常见的开发所需。 也许你第一眼看到上面的关键字会认为我在说梦话，而我也搞不懂 JetBrains 那些人 结束语 IntelliJ IDEA 功能多，耗内存，后端开发内存最好 8 G 以上，前端开发 4 G 以上。 Android 的开发人员是比较有权力说 Eclipse 和 IntelliJ IDEA 的差异的，希望 IntelliJ IDEA 家的产品没有托你后退。","link":"/2016/03/11/IntelliJ-IDEA-ER/"},{"title":"IntelliJ IDEA 插件开发详细视频教程","text":"重要说明 IntelliJ IDEA 的插件理论上是同时也适用于 JetBrains 公司下的其他大多数 IDE 的，因为这些 IDE 都是基于 IntelliJ IDEA 的基础平台进行开发的，请牢记这一点。 教程视频下载和介绍 视频章节结构： 01_AS插件是什么_和IntellijIDEA关系 02_常见的AS开发插件 03_创建第一个Plugin插件 04_翻译插件需求 05_翻译开发过程整理 06_获取用户选中的文本 07_翻译插件显示气泡 08_把插件上传到公共仓库 视频教程下载地址 原下载地址：http://pan.baidu.com/s/1nv79ptZ 备用下载地址：http://pan.baidu.com/s/1eSoQHoA，密码：gqo2，如果哪天下载地址失效，请在本 Github 项目发 Issues。 这套教程视频不是本人录制的，所以需要特别强调下，本套视频来自：传智播客公开课：Android Studio插件开发，在此特别感谢别人的付出（鞠躬）。 其他图文资料介绍 http://blog.csdn.net/dc_726/article/details/14139155 http://www.mobile-open.com/2016/973070.html 插件开发说明 如果你 Java 基础还算过关，看完这套教程简单的插件基本不会有任何问题的。 IntelliJ IDEA 本身平台就自带了很多依赖包，如果能尽量用 IntelliJ IDEA 平台的依赖包就尽量别自己添加 jar，减少插件的容量。 IntelliJ IDEA 官网插件开发相关资料 插件提交地址 官网插件开发指导文档 IntelliJ IDEA Community 源码 一些开源的 IntelliJ IDEA 插件介绍 阅读别人插件有助于你的开发，希望你有一天能开发一个好用的插件。 IntelliJ IDEA 的大量插件都是开源的，如果你有遇到你喜欢的插件，可以到 JetBrains 官网上找到这个插件的主页，很有可能在介绍中就有 Github 地址。感谢 Github 的存在。 我写的插件：ChineseTypography，也是一个最简单的插件 https://github.com/Skykai521/ECTranslation https://github.com/avast/android-butterknife-zelezny https://github.com/zzz40500/GsonFormat https://github.com/kstenschke/shifter-plugin https://github.com/jansorg/SmarterEditor https://github.com/jansorg/BashSupport https://github.com/hsz/idea-gitignore https://github.com/JetBrains/ideavim https://github.com/krasa/EclipseCodeFormatter https://github.com/krasa/StringManipulation https://github.com/krasa/GrepConsole 我的公众号：","link":"/2016/12/28/IntelliJ-IDEA-plugins-develop/"},{"title":"JS逆向的简单分析","text":"基于requests\\hashlib模块实现md5加密方式的有道翻译接口破解第一步打开控制台查询任意一个单词进行抓包,获取请求方式和查看所需的查询参数(salt,ts,sign)第二部,根据所需查询参数在控制台中搜索参数所在的 js文件的位置,打断点调试,查看各个参数在js文件中对应函数的实现过程；经调试发现ts是一个时间戳，salt是0-9和时间戳拼接成的一个字符串，sign是所查询单词和salt以及两个固定字符串的一个拼接.第三步，用python实现Form Data中查询参数的动态生成.第四步，发请求，传入第三步实现的参数，获取相应结果 源码如下 ： 看不懂的同学，b站搜 一只会唱歌的程序狗，里面有一期讲述了整个分析过程，每一步打印非常详细。 import requestsimport timeimport randomfrom hashlib import md5 class YdSpider():def init(self):self.url = “http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule”self.headers = {“Accept”: “application/json, text/javascript, /; q=0.01”,“Accept-Encoding”: “gzip, deflate”,“Accept-Language”: “zh-CN,zh;q=0.9,en;q=0.8”,“Cache-Control”: “no-cache”,“Connection”: “keep-alive”,“Content-Length”: “239”,“Content-Type”: “application/x-www-form-urlencoded; charset=UTF-8”,“Cookie”: “OUTFOX_SEARCH_USER_ID=1324296819@123.160.225.181; OUTFOX_SEARCH_USER_ID_NCOO=146889837.6278171; _ga=GA1.2.828762415.1557487039; P_INFO=18203678715|1557487117|1|youdaonote|00&amp;99|null&amp;null&amp;null#hen&amp;410100#10#0|&amp;0||18203678715; _ntes_nnid=66628fdd0933b91b9f3b3f4e77e6ace3,1557741619397; UM_distinctid=16c2c70da34500-02a227a759081c-15231708-1fa400-16c2c70da35658; JSESSIONID=aaaXbo2PVTqwr6xtLBiYw; ___rl__test__cookies=1565689925539”,“Host”: “fanyi.youdao.com”,“Origin”: “http://fanyi.youdao.com”,“Pragma”: “no-cache”,“Referer”: “http://fanyi.youdao.com/”,“User-Agent”: “Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36”,“X-Requested-With”: “XMLHttpRequest”} def get_salt_sign_ts(self,word): # ts ts = str(int(time.time() * 1000)) # salt salt = ts + str(random.randint(0, 9)) # sign string = &quot;fanyideskweb&quot; + word + salt + &quot;n%A-rKaT5fb[Gy?;N5@Tj&quot; s = md5() s.update(string.encode()) sign = s.hexdigest() return salt, sign, ts def attack_yd(self,word): #1.先拿到salt,sign,ts salt, sign, ts = self.get_salt_sign_ts(word) #2.定义form表单数据为字典:data={} data = { 'i': word, 'from': 'AUTO', 'to': 'AUTO', 'smartresult': 'dict', 'client': 'fanyideskweb', 'salt': salt, 'sign': sign, 'ts': ts, 'bv': 'cf156b581152bd0b259b90070b1120e6', 'doctype': 'json', 'version': '2.1', 'keyfrom': 'fanyi.web', 'action': 'FY_BY_REALTlME' } #3.直接发送请求:request.post(url,data=data,headers=headers) res = requests.post(url=self.url,data=data,headers=self.headers) html = res.json() result = html[&quot;translateResult&quot;][0][0][&quot;tgt&quot;] #4.获取相应内容 print(result) def main(self): #输入翻译单词 word = input(&quot;input your word:&quot;) self.attack_yd(word)","link":"/2021/02/14/JSnxfx/"},{"title":"JS的静态作用域","text":"静态作用域我们先来看下面这个小程序： //JS版本： function sub1() { var x; function sub2() { alert(x); } function sub3() { var x; x=3; sub4(sub2); } function sub4(subx) { var x; x=4; subx(); } x = 1; sub3(); } sub1(); #Python版本 def sub1(): def sub2(): print x def sub3(): x=3 sub4(sub2) def sub4(subx): x=4 subx() x = 1 sub3() sub1() 不用亲自运行，实际上输出结果都是1，这可能不难猜到，但是需要解释一番，鉴于Python和JS在这一点上表现的类似，我就以JS来分析。 我们知道，JS是静态作用域的，所谓静态作用域就是作用域在编译时确定，所以sub2中引用的x，实际上和x=3以及x=4的x没有任何关系，指向第二行的var x; 子程序的引用环境实际上这里面还有一个子程序(注：子程序和函数不是很一样，但我们可以认为子程序包括函数，也约等于函数)的概念，sub2、sub3、sub4都是子程序，对于允许嵌套子程序的语言，应该如何使用执行传递的子程序的引用环境？ 浅绑定：如果这样的话，应该输出4，这对动态作用域的语言来说比较自然。 深绑定：也就是输出1的情况，这对静态作用域的语言来说比较自然。 Ad hoc binding: 这是第三种，将子程序作为实际参数传递到调用语句的环境。 参数传递类型参数传递类型我们普遍认为有按值传递和按引用传递两种，实际上不止。 下面是一张图： 这张图对应的第一种传递方式，叫做Pass-by-Value(In mode)，第二种是Pass-by-Result(Out mode)，第三种是Pass-by-Value-Result(Inout mode),图上说的比较明白，实际上如果有result就是说明最后把结果再赋值给参数。 第二种和第三种编程语言用的少，原因如下： Potential problem: sub(p1, p1)With the two corresponding formal parameters having different names, whichever formal parameter is copied back last will represent current value of p1","link":"/2017/01/11/JS%E7%9A%84%E9%9D%99%E6%80%81%E4%BD%9C%E7%94%A8%E5%9F%9F%E3%80%81%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%BC%95%E7%94%A8%E7%8E%AF%E5%A2%83%E4%B8%8E%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92%E7%B1%BB%E5%9E%8B/"},{"title":"我们来聊聊JAVA8","text":"Java8 从2014年发行到现在已经有六个年头了，之前公司的项目都还是基于Java7，所以对 Java8 不甚了解。于是乎，花一两个礼拜学习下，做个记录，以下部分文字复制于其他文章，最底下会列出相关链接，感兴趣的可以去了解下。 JAVA8 的发展JDK 5自动装箱与拆箱JDK1.5为每一个基本数据类型定义了一个封装类。使java中的基本数据类型也有自己的对象 int --&gt;Integer double --&gt; Double long --&gt; Long char --&gt; Character float --&gt; Float boolean --&gt; Boolean short --&gt; Short byte -- &gt; Byte 自动装箱：将基本类型转换成为对象，例如：int --&gt; Integer 自动拆箱：将对象转换成为基本数据类型，例如：Integer --&gt; int 对于 JDK1.5 之前集合总不能存放基本数据类型的问题，现在也能够解决。 枚举枚举是 JDK1.5 推出的一个比较重要的特性。其关键字为 enum 例如：定义代表交通灯的枚举 public enum MyEnum{ RED,GREEN,YELLOW } 静态导入 优点：使用静态导入可以使被导入类的所有静态变量和静态方法在当前类直接可见，使用这些静态成员无需再给出他们的类名。 缺点：过度使用会降低代码的可读性 变长参数在JDK1.5以前，当我们要为一个方法传递多个类型相同的参数时， 我们有两种方法解决 直接传递一个数组过去 有多少个参数就传递多少个参数。 例如： public void printColor(String red,String green,String yellow){ } 或者 public void printColor(String[] colors){ } 这样编写方法参数虽然能够实现我们想要的效果，但是，这样是不是有点麻烦呢？ 再者，如果参数个数不确定，我们怎么办呢？Java JDK1.5为我们提供的可变参数就能够完美的解决这个问题. 例如： public void printColor(String... colors){ } 如果参数的类型相同，那么可以使用 类型+三个点 ，后面跟一个参数名称的形式。 这样的好处就是，只要参数类型相同，无论传递几个参数都没有限制 注意：可变参数必须是参数列表的最后一项（该特性对对象和基本数据类型都适用） 泛型//给集合指定存入类型，上面这个集合在存入数据的时候必须存入String类型的数据，否则编译器会报错 List&lt;String&gt; strs = new ArrayList&lt;String&gt;(); 泛型 意味着编写的代码可以被不同类型的对象所重用。 可见泛型的提出是为了编写重用性更好的代码。 泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。 比如常见的集合类 LinkedList，其实现的接口名后有个特殊的部分 &lt;&gt;，而且它的成员的类型 Link 也包含一个 &lt;&gt;，这个符号的就是类型参数， 它使得在运行中，创建一个 LinkedList 时可以传入不同的类型，比如 new LinkedList，这样它的成员存放的类型也是 String。 For-Each循环例如上面这个集合我们可以通过for-each遍历，这样更加简单清晰 for(String s : strs){ System.out.println(s); } 注意：使用for-each遍历集合时，要遍历的集合必须实现了Iterator接口 线程并发库 JUC线程并发库是 Java1.5 提出的关于多线程处理的高级功能，所在包：java.util.concurrent 包括 线程互斥工具类：Lock，ReadWriteLock 线程通信：Condition 线程池：ExecutorService 同步队列：ArrayBlockingQueue 同步集合：ConcurrentHashMap，CopyOnWriteArrayList 线程同步工具：Semaphore JDK 6Desktop类和SystemTray类前者可以用来打开系统默认浏览器浏览指定的URL，打开系统默认邮件客户端给指定的邮箱发邮件， 用默认应用程序打开或编辑文件(比如，用记事本打开以 txt 为后缀名的文件)，用系统默认的打印机打印文档；后者可以用来在系统托盘区创建一个托盘程序。 使用Compiler API现在我们可以用JDK1.6 的Compiler API(JSR 199)去动态编译Java源文件， Compiler API结合反射功能就可以实现动态的产生Java代码并编译执行这些代码，有点动态语言的特征。 这个特性对于某些需要用到动态编译的应用程序相当有用，比如JSP Web Server，当我们手动修改JSP后， 是不希望需要重启Web Server才可以看到效果的，这时候我们就可以用Compiler API来实现动态编译JSP文件。 当然，现在的JSP Web Server也是支持JSP热部署的，现在的JSP Web Server通过在运行期间通过Runtime.exec或ProcessBuilder来调用javac来编译代码， 这种方式需要我们产生另一个进程去做编译工作，不够优雅而且容易使代码依赖与特定的操作系统； Compiler API通过一套易用的标准的API提供了更加丰富的方式去做动态编译，而且是跨平台的。 轻量级Http Server APIJDK1.6 提供了一个简单的 Http Server API，据此我们可以构建自己的嵌入式 Http Server， 它支持Http和Https协议，提供了HTTP1.1的部分实现，没有被实现的那部分可以通过扩展已有的 Http Server API来实现， 程序员必须自己实现 HttpHandler 接口，HttpServer 会调用 HttpHandler 实现类的回调方法来处理客户端请求， 在这里，我们把一个 Http 请求和它的响应称为一个交换，包装成 HttpExchange 类，HttpServer 负责将 HttpExchange 传给 HttpHandler 实现类的回调方法。 用Console开发控制台程序JDK1.6 中提供了 java.io.Console 类专用来访问基于字符的控制台设备。 你的程序如果要与 Windows 下的 cmd 或者 Linux 下的 Terminal 交互，就可以用 Console 类代劳。 但我们不总是能得到可用的 Console，一个JVM是否有可用的 Console 依赖于底层平台和 JVM 如何被调用。 如果JVM是在交互式命令行(比如 Windows 的 cmd)中启动的，并且输入输出没有重定向到另外的地方，那么就可以得到一个可用的 Console 实例。 对脚本语言的支持如：ruby，groovy，javascript。 JDK 7数字变量对下滑线的支持JDK1.7可以在数值类型的变量里添加下滑线，但是有几个地方是不能添加的 数字的开头和结尾 小数点前后 F或者L前 例如： int num = 1234_5678_9; float num2 = 222_33F; long num3 = 123_000_111L; switch对String的支持String status = &quot;orderState&quot;; switch (status) { case &quot;ordercancel&quot;: System.out.println(&quot;订单取消&quot;); break; case &quot;orderSuccess&quot;: System.out.println(&quot;预订成功&quot;); break; default: System.out.println(&quot;状态未知&quot;); } try-with-resource try-with-resources 是一个定义了一个或多个资源的 try 声明，这个资源是指程序处理完它之后需要关闭它的对象。 try-with-resources 确保每一个资源在处理完成后都会被关闭。 可以使用try-with-resources的资源有： 任何实现了 java.lang.AutoCloseable 接口 java.io.Closeable 接口的对象。 例如： public static String readFirstLineFromFile(String path) throws IOException { try (BufferedReader br = new BufferedReader(new FileReader(path))) { return br.readLine(); } } 在 java 7 以及以后的版本里，BufferedReader 实现了 java.lang.AutoCloseable 接口。 由于 BufferedReader 定义在 try-with-resources 声明里，无论 try 语句正常还是异常的结束， 它都会自动的关掉。而在 java7 以前，你需要使用 finally 块来关掉这个对象。 捕获多种异常并用改进后的类型检查来重新抛出异常public static void first(){ try { BufferedReader reader = new BufferedReader(new FileReader(&quot;&quot;)); Connection con = null; Statement stmt = con.createStatement(); } catch (IOException | SQLException e) { //捕获多个异常，e就是final类型的 e.printStackTrace(); } } 优点：用一个 catch 处理多个异常，比用多个 catch 每个处理一个异常生成的字节码要更小更高效。 创建泛型时类型推断只要编译器可以从上下文中推断出类型参数，你就可以用一对空着的尖括号 &lt;&gt; 来代替泛型参数。 这对括号私下被称为菱形(diamond)。 在Java SE 7之前，你声明泛型对象时要这样 List&lt;String&gt; list = new ArrayList&lt;String&gt;(); 而在Java SE7以后，你可以这样 List&lt;String&gt; list = new ArrayList&lt;&gt;(); 因为编译器可以从前面(List)推断出推断出类型参数，所以后面的 ArrayList 之后可以不用写泛型参数了，只用一对空着的尖括号就行。 当然，你必须带着菱形 &lt;&gt;，否则会有警告的。 Java SE7 只支持有限的类型推断：只有构造器的参数化类型在上下文中被显著的声明了，你才可以使用类型推断，否则不行。 List&lt;String&gt; list = new ArrayList&lt;&gt;();l list.add(&quot;A&quot;); //这个不行 list.addAll(new ArrayList&lt;&gt;()); // 这个可以 List&lt;? extends String&gt; list2 = new ArrayList&lt;&gt;(); list.addAll(list2); JDK 8Lambda表达式和函数式接口Lambda表达式（也称为闭包）是Java 8中最大和最令人期待的语言改变。它允许我们将函数当成参数传递给某个方法， 或者把代码本身当作数据处理：函数式开发者非常熟悉这些概念。很多JVM平台上的语言（Groovy、Scala等）从诞生之日就支持Lambda表达式，但是Java开发者没有选择，只能使用匿名内部类代替Lambda表达式。 Lambda的设计耗费了很多时间和很大的社区力量，最终找到一种折中的实现方案，可以实现简洁而紧凑的语言结构。最简单的Lambda表达式可由逗号分隔的参数列表、-&gt;符号和语句块组成。 Lambda的设计者们为了让现有的功能与Lambda表达式良好兼容，考虑了很多方法，于是产生了函数接口这个概念。函数接口指的是只有一个函数的接口，这样的接口可以隐式转换为Lambda表达式。java.lang.Runnable和java.util.concurrent.Callable是函数式接口的最佳例子。在实践中，函数式接口非常脆弱：只要某个开发者在该接口中添加一个函数，则该接口就不再是函数式接口进而导致编译失败。为了克服这种代码层面的脆弱性，并显式说明某个接口是函数式接口，Java 8 提供了一个特殊的注解@FunctionalInterface（Java 库中的所有相关接口都已经带有这个注解了），举个简单的函数式接口的定义 接口的默认方法和静态方法Java 8使用两个新概念扩展了接口的含义：默认方法和静态方法。默认方法使得接口有点类似traits，不过要实现的目标不一样。默认方法使得开发者可以在 不破坏二进制兼容性的前提下，往现存接口中添加新的方法，即不强制那些实现了该接口的类也同时实现这个新加的方法。 默认方法和抽象方法之间的区别在于抽象方法需要实现，而默认方法不需要。接口提供的默认方法会被接口的实现类继承或者覆写 由于JVM上的默认方法的实现在字节码层面提供了支持，因此效率非常高。默认方法允许在不打破现有继承体系的基础上改进接口。该特性在官方库中的应用是：给java.util.Collection接口添加新方法，如stream()、parallelStream()、forEach()和removeIf()等等。 尽管默认方法有这么多好处，但在实际开发中应该谨慎使用：在复杂的继承体系中，默认方法可能引起歧义和编译错误。如果你想了解更多细节，可以参考官方文档。 更好的类型推断Java 8 编译器在类型推断方面有很大的提升，在很多场景下编译器可以推导出某个参数的数据类型，从而使得代码更为简洁。 参数 Value.defaultValue() 的类型由编译器推导得出，不需要显式指明。在Java 7中这段代码会有编译错误，除非使用 Value.&lt;String&gt;defaultValue()。 OptionalJava应用中最常见的bug就是空值异常。在Java 8之前，Google Guava引入了 Optionals 类来解决 NullPointerException， 从而避免源码被各种 null 检查污染，以便开发者写出更加整洁的代码。Java 8也将Optional加入了官方库。 Optional 仅仅是一个容易存放T类型的值或者null。它提供了一些有用的接口来避免显式的null检查，可以参考Java 8官方文档了解更多细节。 如果Optional实例持有一个非空值，则 isPresent() 方法返回true，否则返回false；orElseGet() 方法，Optional实例持有null， 则可以接受一个lambda表达式生成的默认值；map()方法可以将现有的 Optional 实例的值转换成新的值；orElse()方法与orElseGet()方法类似， 但是在持有null的时候返回传入的默认值。 Streams新增的Stream API（java.util.stream）将生成环境的函数式编程引入了Java库中。 这是目前为止最大的一次对Java库的完善，以便开发者能够写出更加有效、更加简洁和紧凑的代码。 Task 类有一个分数（或伪复杂度）的概念，另外还有两种状态：OPEN 或者 CLOSED。现在假设有一个task集合， 首先看一个问题：在这个task集合中一共有多少个OPEN状态的点？在Java 8之前，要解决这个问题，则需要使用foreach循环遍历task集合； 但是在Java 8中可以利用steams解决：包括一系列元素的列表，并且支持顺序和并行处理。 final Collection&lt;Task&gt; tasks = Arrays.asList( new Task(Status.OPEN, 5), new Task(Status.OPEN, 13), new Task(Status.CLOSED, 8) ); // Calculate total points of all active tasks using sum() final long totalPointsOfOpenTasks = tasks .stream() .filter(task -&gt; task.getStatus() == Status.OPEN) .mapToInt(Task::getPoints) .sum(); System.out.println(&quot;Total points: &quot; + totalPointsOfOpenTasks); 这里有很多知识点值得说。首先，tasks集合被转换成steam表示；其次，在steam上的filter操作会过滤掉所有CLOSED的task； 第三，mapToInt操作基于每个task实例的Task::getPoints方法将task流转换成Integer集合；最后，通过sum方法计算总和，得出最后的结果。 新的日期时间 APIJava 8引入了新的Date-Time API(JSR 310)来改进时间、日期的处理。时间和日期的管理一直是最令Java开发者痛苦的问题。 java.util.Date 和后来的 java.util.Calendar 一直没有解决这个问题（甚至令开发者更加迷茫）。 因为上面这些原因，诞生了第三方库Joda-Time，可以替代Java的时间管理API。 Java 8中新的时间和日期管理API深受Joda-Time影响，并吸收了很多Joda-Time的精华。 新的java.time包包含了所有关于日期、时间、时区、Instant（跟日期类似但是精确到纳秒）、duration（持续时间）和时钟操作的类。 新设计的API认真考虑了这些类的不变性（从java.util.Calendar吸取的教训），如果某个实例需要修改，则返回一个新的对象。 第二，关注下LocalDate和LocalTime类。LocalDate仅仅包含ISO-8601日历系统中的日期部分；LocalTime则仅仅包含该日历系统中的时间部分。这两个类的对象都可以使用Clock对象构建得到。 LocalDateTime类包含了LocalDate和LocalTime的信息，但是不包含ISO-8601日历系统中的时区信息。这里有一些关于LocalDate和LocalTime的例子： 如果你需要特定时区的data/time信息，则可以使用ZoneDateTime，它保存有ISO-8601日期系统的日期和时间，而且有时区信息。 Nashorn JavaScript引擎Java 8提供了新的Nashorn JavaScript引擎，使得我们可以在JVM上开发和运行JS应用。 Nashorn JavaScript引擎是javax.script.ScriptEngine的另一个实现版本，这类Script引擎遵循相同的规则，允许Java和JavaScript交互使用，例子代码如下： var fun1 = function(name) { print('Hi there from Javascript, ' + name); return &quot;greetings from javascript&quot;; }; var fun2 = function (object) { print(&quot;JS Class Definition: &quot; + Object.prototype.toString.call(object)); }; ScriptEngine engine = new ScriptEngineManager().getEngineByName(&quot;nashorn&quot;); engine.eval(new FileReader(&quot;java8-nashorn/src/main/resources/nashorn1.js&quot;)); Invocable invocable = (Invocable) engine; Object result = invocable.invokeFunction(&quot;fun1&quot;, &quot;Peter Parker&quot;); System.out.println(result); System.out.println(result.getClass()); invocable.invokeFunction(&quot;fun2&quot;, new Date()); invocable.invokeFunction(&quot;fun2&quot;, LocalDateTime.now()); invocable.invokeFunction(&quot;fun2&quot;, new Person()); Base64对 Base64 编码的支持已经被加入到Java 8官方库中，这样不需要使用第三方库就可以进行Base64编码，例子代码如下： final String text = &quot;Lets Learn Java 8!&quot;; final String encoded = Base64 .getEncoder() .encodeToString(text.getBytes(StandardCharsets.UTF_8)); System.out.println(encoded); final String decoded = new String( Base64.getDecoder().decode(encoded), StandardCharsets.UTF_8); System.out.println(decoded); 新的Base64API也支持URL和MINE的编码解码。 Default Methods for InterfaceJava 8 允许我们为接口添加非抽象的方法通过 default 关键字。当然静态方法的实现也是允许的。 interface Formula { double calculate(int a); // 默认方法实现 default double sqrt(int a) { return Math.sqrt(a); } // 静态方法实现 static void hello() { System.out.println(&quot;hello world&quot;);} } 所以我们实现接口的时候只需要实现抽象方法就可以了，默认方法可以直接使用。下面例子 The formula is implemented as an anonymous object. Formula formula = new Formula() { @Override public double calculate(int a) { return sqrt(a * 100); } }; formula.calculate(100); // 100.0 formula.sqrt(16); // 4.0 Lambda expressionλ演算（英语：lambda calculus，λ-calculus）是一套从数学逻辑中发展，以变量绑定和替换的规则，来研究函数如何抽象化定义、函数如何被应用以及递归的形式系统。它由数学家阿隆佐·邱奇在20世纪30年代首次发表。lambda演算作为一种广泛用途的计算模型，可以清晰地定义什么是一个可计算函数，而任何可计算函数都能以这种形式表达和求值，它能模拟单一磁带图灵机的计算过程；尽管如此，lambda演算强调的是变换规则的运用，而非实现它们的具体机器。 更多介绍请教wiki爸爸，虽然我看的一脸懵逼 wiki 简单的说 lambda expression就是一个匿名的函数，通常作为其他函数的参数。 下面通过一个例子简单介绍下 之前版本的我们写 List&lt;String&gt; names = Arrays.asList(&quot;peter&quot;, &quot;anna&quot;, &quot;mike&quot;, &quot;xenia&quot;); Collections.sort(names, new Comparator&lt;String&gt;() { @Override public int compare(String a, String b) { return b.compareTo(a); } }); 取代之前创建匿名内部类的方法，通过 Java8 我们可以用更少的代码来实现： Collections.sort(names, (String a, String b) -&gt; { return b.compareTo(a); }); 如果方法只有一行语句，那么花括号 {} 是可选的，并且假如这一行语句有返回值，那么 return 关键字也是可选的。所以我们的代码更精简了： Collections.sort(names, (String a, String b) -&gt; b.compareTo(a)); Lambda 的参数类型可以由上下文推算而出，所以，参数类型也是可选的， Collections.sort(names, (a, b) -&gt; b.compareTo(a)); 下面我们就看看 lambda的相关特性和实现 Diff with Anonymous Classes在JVM层面，Lambda表达式和匿名内部类有着明显的差别。 匿名内部类仍然是一个类，只是不需要程序员显示指定类名，编译器会自动为该类取名。因此如果有如下形式的代码，编译之后将会产生两个class文件： public class MainAnonymousClass { public static void main(String[] args) { new Thread(new Runnable(){ @Override public void run(){ System.out.println(&quot;Anonymous Class Thread run()&quot;); } }).start();; } } 编译之后文件分布如下，两个class文件分别是主类和匿名内部类产生的： 进一步分析主类MainAnonymousClass.class的字节码，可发现其创建了匿名内部类的对象： // javap -c MainAnonymousClass.class public class MainAnonymousClass { ... public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Thread 3: dup 4: new #3 // class MainAnonymousClass$1 /*创建内部类对象*/ 7: dup 8: invokespecial #4 // Method MainAnonymousClass$1.&quot;&lt;init&gt;&quot;:()V 11: invokespecial #5 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 14: invokevirtual #6 // Method java/lang/Thread.start:()V 17: return } Lambda表达式通过invokedynamic指令实现，书写Lambda表达式不会产生新的类。如果有如下代码，编译之后只有一个class文件： public class MainLambda { public static void main(String[] args) { new Thread( () -&gt; System.out.println(&quot;Lambda Thread run()&quot;) ).start();; } } 编译之后的结果： 通过javap反编译命名，我们更能看出Lambda表达式内部表示的不同： // javap -c -p MainLambda.class public class MainLambda { ... public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Thread 3: dup 4: invokedynamic #3, 0 // InvokeDynamic #0:run:()Ljava/lang/Runnable; /*使用invokedynamic指令调用*/ 9: invokespecial #4 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 12: invokevirtual #5 // Method java/lang/Thread.start:()V 15: return private static void lambda$main$0(); /*Lambda表达式被封装成主类的私有方法*/ Code: 0: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #7 // String Lambda Thread run() 5: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return } 反编译之后我们发现Lambda表达式被封装成了主类的一个私有方法，并通过invokedynamic指令进行调用。 既然Lambda表达式不是内部类的简写，那么Lambda内部的this引用也就跟内部类对象没什么关系了。在Lambda表达式中this的意义跟在表达式外部完全一样。因此下列代码将输出两遍Hello Hoolee，而不是两个引用地址。 public class Hello { Runnable r1 = () -&gt; { System.out.println(this); }; Runnable r2 = () -&gt; { System.out.println(toString()); }; public static void main(String[] args) { new Hello().r1.run(); new Hello().r2.run(); } public String toString() { return &quot;Hello Hoolee&quot;; } } lambda Scopelambda Scope实际上跟匿名内部类差不多，只不过 local variables 可以不声明未final，但是实际上是一个隐final。因为java8 中 lambda 代码块相当于闭包，闭包中被引用的局部变量是不能进行更改的。这也是为什么函数式编程可以很容易做到线程安全，很适合并发编程的原因。 下面通过几个小例子说明一下 lambda 的作用域 final int num = 1; Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num); stringConverter.convert(2); // 3 int num = 1; Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num); stringConverter.convert(2); // 3 int num = 1; // Variable used in lambda expression should be final or effectively final Converter&lt;Integer, String&gt; stringConverter = (from) -&gt; String.valueOf(from + num); // 无法编译 num = 3; 在lambda表达式中更改局部变量 num 的值同样是不允许的。 如果是 static variables 或是 fields 就跟匿名内部类一样了，无论在lambda 表达式内部还是外部都是进行修改 class Lambda4 { static int outerStaticNum; int outerNum; void testScopes() { Converter&lt;Integer, String&gt; stringConverter1 = (from) -&gt; { outerNum = 23; return String.valueOf(from); }; Converter&lt;Integer, String&gt; stringConverter2 = (from) -&gt; { outerStaticNum = 72; return String.valueOf(from); }; } } 还记得前面我们定义的函数接口 Formula 吗，接口公式定义了一个默认方法sqrt，可以从包括匿名对象在内的每个公式实例访问该方法。这不适用于lambda表达式。 不能从lambda表达式中访问 default interface method，以下代码无法编译 Formula formula = (a) -&gt; sqrt( a * 100); Functional Interfaceslambda 表达式如何适应Java的类型系统呢？转换lambda表达式的类型总是函数接口类型。所以，一个函数接口必须有且只有一个抽象方法声明。该类型的每个lambda表达式都将匹配到这个抽象方法。 下面有个小例子，Runnable是一个函数接口，它只有一个方法run()。因此，当您将lambda表达式传递给Thread类的构造函数时，编译器会尝试将该表达式转换为等价的可运行代码，如第一个代码示例所示。如果编译器成功，则一切正常运行，如果编译器无法将表达式转换为等效的实现代码，则会产生错误。在上面的例子中，lambda表达式被转换为Runnable类型。 new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;howtodoinjava&quot;); } }).start(); new Thread( () -&gt; { System.out.println(&quot;My Runnable&quot;); } ).start(); 为了确保接口满足需求，您应该添加 @FunctionalInterface 注解，编译器知道这个注释，并在您试图向接口添加第二个抽象方法声明时抛出编译器错误。当然，注解省略也是可以的。 因为默认方法有一个实现，所以它们不是抽象的。因为默认方法不是抽象的，所以您可以随意将默认方法添加到您的函数接口中。当然静态方法也同理。 如果接口声明一个抽象方法覆盖 java.lang.Object 的一个公共方法，这也不计入接口的抽象方法计数，因为该接口的任何实现都有一个来自 java.lang.Object 的实现。Comparator是一个函数接口，尽管它声明了两个抽象方法。为什么?因为其中一个抽象方法equals()它的签名等于Object类中的public方法。 @FunctionalInterface interface Converter&lt;F, T&gt; { T convert(F from); void haha(); // 编译错误 // 默认方法 default void hello() { System.out.println(&quot;hello world&quot;); } // 静态方法也是允许的，可以少写工具类 static void fourWork() { System.out.println(&quot;today is a nice day&quot;); } @Override public String toString(); //Overridden from Object class @Override public boolean equals(Object obj); //Overridden from Object class } Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from); Integer converted = converter.convert(&quot;123&quot;); System.out.println(converted); // 123 功能接口只显示一个功能。例如，使用具有单个方法 compareTo 的可比较接口进行比较。 Method References简单的说就是对于 lambda 表达式中只有一个参数，并且箭头右边的逻辑是对入参执行一个函数： 即 x =&gt; f(x)则可以简写为f Java8 用 class::methodName 来表示 eta-conversion Method references help to point to methods by their names. A method reference is described using :: symbol. A method reference can be used to point the following types of methods − Static methods Instance methods Constructors using new operator (TreeSet::new) 下面看一些简单例子 // static method -&gt; Math::max = Math.max(x,y) List&lt;Integer&gt; integers = Arrays.asList(1,12,433,5); Optional&lt;Integer&gt; max = integers.stream().reduce( Math::max ); max.ifPresent(value -&gt; System.out.println(value)); // instance method from instance -&gt; System.out::println = System.out.println(x) ArrayList&lt;Integer&gt; numberList = new ArrayList&lt;&gt;(Arrays.asList(1,2,3,4,5)); Consumer&lt;Integer&gt; action = System.out::println; numberList.forEach(action); // instance method from class type -&gt; String::compareTo = s1.compareTo(s2) List&lt;String&gt; strings = Arrays .asList(&quot;how&quot;, &quot;to&quot;, &quot;do&quot;, &quot;in&quot;, &quot;java&quot;, &quot;dot&quot;, &quot;com&quot;); List&lt;String&gt; sorted = strings .stream() .sorted((s1, s2) -&gt; s1.compareTo(s2)) .collect(Collectors.toList()); System.out.println(sorted); List&lt;String&gt; sortedAlt = strings .stream() .sorted(String::compareTo) .collect(Collectors.toList()); System.out.println(sortedAlt); // constructor -&gt; ArrayList::new = new ArrayList List&lt;Integer&gt; integers1 = IntStream .range(1, 100) .boxed() .collect(Collectors.toCollection( ArrayList::new )); Optional&lt;Integer&gt; max1 = integers.stream().reduce(Math::max); max.ifPresent(System.out::println); Built-in Functional InterfacesJava 8 内置了许多函数接口，可在lambda表达式中广泛使用。 有一些是兼容旧版本的比如 Comparator 或者 Runnable， 还有一些是吸取了 Google Guava library ，比如在 java.util.Function package 就定义了很多实用的函数接口。 不过一般我们不需要去死记它们，因为类型推导帮我们做了一切。 比如举个简单的例子，collection 的forEach方法，该方法的签名为void forEach(Consumer&lt;? super E&gt; action)，作用是对容器中的每个元素执行action指定的动作，其中Consumer是个函数接口，里面只有一个待实现方法void accept(T t)（后面我们会看到，这个方法叫什么根本不重要，你甚至不需要记忆它的名字）。 需求：假设有一个字符串列表，需要打印出其中所有长度大于3的字符串. Java7及以前我们可以用增强的for循环实现： // 使用增强for循环迭代 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;)); for(String str : list){ if(str.length()&gt;3) System.out.println(str); } 现在使用forEach()方法结合匿名内部类，可以这样实现： // 使用forEach()结合匿名内部类迭代 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;)); list.forEach(new Consumer&lt;String&gt;(){ @Override public void accept(String str){ if(str.length()&gt;3) System.out.println(str); } }); 上述代码调用forEach()方法，并使用匿名内部类实现Comsumer接口。到目前为止我们没看到这种设计有什么好处，但是不要忘记Lambda表达式，使用Lambda表达式实现如下： // 使用forEach()结合Lambda表达式迭代 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;)); list.forEach(str -&gt; { if(str.length()&gt;3) System.out.println(str); }); 上述代码给forEach()方法传入一个Lambda表达式，我们不需要知道accept()方法，也不需要知道Consumer接口，类型推导帮我们做了一切。 这里，简单列几个常用的函数接口， PredicateRepresents a predicate (Boolean-valued function) of one argument.The interface contains various default methods for composing predicates to complex logical terms (and, or, negate) public static void main(String args[]) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); // Predicate&lt;Integer&gt; predicate = n -&gt; true // n is passed as parameter to test method of Predicate interface // test method will always return true no matter what value n has. System.out.println(&quot;Print all numbers:&quot;); //pass n as parameter eval(list, n-&gt;true); // Predicate&lt;Integer&gt; predicate1 = n -&gt; n%2 == 0 // n is passed as parameter to test method of Predicate interface // test method will return true if n%2 comes to be zero System.out.println(&quot;Print even numbers:&quot;); eval(list, n-&gt; n%2 == 0 ); // Predicate&lt;Integer&gt; predicate2 = n -&gt; n &gt; 3 // n is passed as parameter to test method of Predicate interface // test method will return true if n is greater than 3. System.out.println(&quot;Print numbers greater than 3:&quot;); eval(list, n-&gt; n &gt; 3 ); } public static void eval(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) { for(Integer n: list) { if(predicate.test(n)) { System.out.println(n + &quot; &quot;); } } } Function&lt;T,R&gt;Represents a function that accepts one argument and produces a result.Default methods can be used to chain multiple functions together (compose, andThen). Function&lt;String, Integer&gt; toInteger = Integer::valueOf; Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf); backToString.apply(&quot;123&quot;); // &quot;123&quot; SupplierSuppliers produce a result of a given generic type. Unlike Functions, Suppliers don't accept arguments. Supplier&lt;Person&gt; personSupplier = Person::new; personSupplier.get(); // new Person ConsumerConsumers represents operations to be performed on a single input argument. consumer&lt;Person&gt; greeter = (p) -&gt; System.out.println(&quot;Hello, &quot; + p.firstName); greeter.accept(new Person(&quot;Luke&quot;, &quot;Skywalker&quot;)); ComparatorsComparators are well known from older versions of Java. Java 8 adds various default methods to the interface. Comparator&lt;Person&gt; comparator = (p1, p2) -&gt; p1.firstName.compareTo(p2.firstName); Person p1 = new Person(&quot;John&quot;, &quot;Doe&quot;); Person p2 = new Person(&quot;Alice&quot;, &quot;Wonderland&quot;); comparator.compare(p1, p2); // &gt; 0 comparator.reversed().compare(p1, p2); // &lt; 0 StreamsA Collection is an in-memory data structure, A Stream is a conceptually fixed data structure, in which elements are computed on demand. This is a form of a producer-consumer relationship. In java, java.util.Stream represents a stream on which one or more operations can be performed. Stream operations are either intermediate or terminal. While terminal operations return a result of a certain type, intermediate operations return the stream itself so you can chain multiple method calls in a row. Streams are created on a source, e.g. a java.util.Collection like lists or sets (maps are not supported). Stream operations can either be executed sequential or parallel. 简单来说，流就相当于我们在线看电影一样，不需要下载整部电影，只关注我们感兴趣的地方。流只是数据源的一个视图，我们可以对这个视图进行过滤，映射，排序，统计等一系列操作，而不会影响到数据源，并且在流上的操作是按需执行的，执行后即失效，所以很适合于函数编程。 Streams processing order衔接操作的一个重要特性就是延迟性。观察下面没有终止操作的例子： Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return true; }); 执行这段代码时，不向控制台打印任何东西。这是因为衔接操作只在终止操作调用时被执行。 让我们通过添加终止操作forEach来扩展这个例子： Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return true; }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s)); 执行这段代码会得到如下输出： filter: d2 forEach: d2 filter: a2 forEach: a2 filter: b1 forEach: b1 filter: b3 forEach: b3 filter: c forEach: c 结果的顺序可能出人意料。原始的方法会在数据流的所有元素上，一个接一个地水平执行所有操作。但是每个元素在调用链上垂直移动。第一个字符串&quot;d2&quot;首先经过filter然后是forEach，执行完后才开始处理第二个字符串&quot;a2&quot;。 这种行为可以减少每个元素上所执行的实际操作数量，就像我们在下个例子中看到的那样： Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .anyMatch(s -&gt; { System.out.println(&quot;anyMatch: &quot; + s); return s.startsWith(&quot;A&quot;); }); // map: d2 // anyMatch: D2 // map: a2 // anyMatch: A2 只要提供的数据元素满足了谓词，anyMatch操作就会返回true。对于第二个传递&quot;A2&quot;的元素，它的结果为真。由于数据流的链式调用是垂直执行的，map这里只需要执行两次。所以map会执行尽可能少的次数，而不是把所有元素都映射一遍。 为什么顺序如此重要下面的例子由两个衔接操作map和filter，以及一个终止操作forEach组成。让我们再来看看这些操作如何执行： Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;A&quot;); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s)); // map: d2 // filter: D2 // map: a2 // filter: A2 // forEach: A2 // map: b1 // filter: B1 // map: b3 // filter: B3 // map: c // filter: C 就像你可能猜到的那样，map和filter会对底层集合的每个字符串调用五次，而forEach只会调用一次。 如果我们调整操作顺序，将filter移动到调用链的顶端，就可以极大减少操作的执行次数: Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;a&quot;); }) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s)); // filter: d2 // filter: a2 // map: a2 // forEach: A2 // filter: b1 // filter: b3 // filter: c 现在，map只会调用一次，所以操作流水线对于更多的输入元素会执行更快。在整合复杂的方法链时，要记住这一点。 让我们通过添加额外的方法sorted来扩展上面的例子： Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .sorted((s1, s2) -&gt; { System.out.printf(&quot;sort: %s; %s\\n&quot;, s1, s2); return s1.compareTo(s2); }) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;a&quot;); }) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s)); 排序是一类特殊的衔接操作。它是有状态的操作，因为你需要在处理中保存状态来对集合中的元素排序。 执行这个例子会得到如下输入： sort: a2; d2 sort: b1; a2 sort: b1; d2 sort: b1; a2 sort: b3; b1 sort: b3; d2 sort: c; b3 sort: c; d2 filter: a2 map: a2 forEach: A2 filter: b1 filter: b3 filter: c filter: d2 首先，排序操作在整个输入集合上执行。也就是说，sorted以水平方式执行。所以这里sorted对输入集合中每个元素的多种组合调用了八次。 我们同样可以通过重排调用链来优化性能： Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;a&quot;); }) .sorted((s1, s2) -&gt; { System.out.printf(&quot;sort: %s; %s\\n&quot;, s1, s2); return s1.compareTo(s2); }) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s)); // filter: d2 // filter: a2 // filter: b1 // filter: b3 // filter: c // map: a2 // forEach: A2 这个例子中sorted永远不会调用，因为filter把输入集合减少至只有一个元素。所以对于更大的输入集合会极大提升性能。 复用数据流Java8的数据流不能被复用。一旦你调用了任何终止操作，数据流就关闭了： Stream&lt;String&gt; stream = Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; s.startsWith(&quot;a&quot;)); stream.anyMatch(s -&gt; true); // ok stream.noneMatch(s -&gt; true); // exception 在相同数据流上，在anyMatch之后调用noneMatch会产生下面的异常： java.lang.IllegalStateException: stream has already been operated upon or closed at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:229) at java.util.stream.ReferencePipeline.noneMatch(ReferencePipeline.java:459) at com.winterbe.java8.Streams5.test7(Streams5.java:38) at com.winterbe.java8.Streams5.main(Streams5.java:28) 要克服这个限制，我们需要为每个我们想要执行的终止操作创建新的数据流调用链。例如，我们创建一个数据流供应器，来构建新的数据流，并且设置好所有衔接操作： Supplier&lt;Stream&lt;String&gt;&gt; streamSupplier = () -&gt; Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; s.startsWith(&quot;a&quot;)); streamSupplier.get().anyMatch(s -&gt; true); // ok streamSupplier.get().noneMatch(s -&gt; true); // ok 每次对get()的调用都构造了一个新的数据流，我们将其保存来调用终止操作。 Create Stream// Stream.of(val1, val2, val3….) Stream&lt;Integer&gt; stream1 = Stream.of(1,2,3,4,5,6,7,8,9); stream1.forEach(p -&gt; System.out.println(p)); // Stream.of(arrayOfElements) Stream&lt;Integer&gt; stream2 = Stream.of( new Integer[]{1,2,3,4,5,6,7,8,9} ); stream2.forEach(p -&gt; System.out.println(p)); // List.stream() List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); for(int i = 1; i&lt; 10; i++){ list.add(i); } Stream&lt;Integer&gt; stream3 = list.stream(); stream3.forEach(p -&gt; System.out.println(p)); // String chars or String tokens IntStream stream5 = &quot;12345_abcdefg&quot;.chars(); stream5.forEach(p -&gt; System.out.println(p)); //OR Stream&lt;String&gt; stream6 = Stream.of(&quot;A$B$C&quot;.split(&quot;\\\\$&quot;)); stream6.forEach(p -&gt; System.out.println(p)); // file try(Stream lines = Files.lines(Paths.get(&quot;文件路径名&quot;),Charset.defaultCharset())){ //可对lines做一些操作 }catch(IOException e){ } // create iterator stream, 创建迭代或者无限流，大都数情况需要添加limit函数限制 // Stream.generate() or Stream.iterate() Stream&lt;Date&gt; stream4 = Stream.generate(() -&gt; { return new Date(); }).limit(10); stream4.forEach(p -&gt; System.out.println(p)); Stream.iterate(0, n -&gt; n + 2) .limit(10) .forEach(System.out::println); Convert streams to collectionsIt’s just collecting the elements from the stream into a collection or array. // Convert Stream to List – Stream.collect( Collectors.toList() ) List&lt;Integer&gt; list1 = new ArrayList&lt;Integer&gt;(); for(int i = 1; i&lt; 10; i++){ list1.add(i); } Stream&lt;Integer&gt; stream1 = list1.stream(); List&lt;Integer&gt; evenNumbersList = stream1.filter(i -&gt; i%2 == 0).collect(Collectors.toList()); System.out.print(evenNumbersList); // Convert Stream to array – Stream.toArray( EntryType[]::new ) List&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;(); for(int i = 1; i&lt; 10; i++){ list2.add(i); } Stream&lt;Integer&gt; stream2 = list2.stream(); Integer[] evenNumbersArr = stream2.filter(i -&gt; i%2 == 0).toArray(Integer[]::new); System.out.print(evenNumbersArr); Core stream operations 操作分类 操作 类型 返回类型 使用的类型/函数式接口 函数描述符 filter 中间 Stream&lt;T&gt; Predicate&lt;T&gt; T -&gt; boolean distinct 中间 Stream&lt;T&gt; skip 中间 Stream&lt;T&gt; long map 中间 Stream&lt;R&gt; Function&lt;T, R&gt; T -&gt; R flatMap 中间 Stream&lt;R&gt; Function&lt;T, Stream&lt;R&gt;&gt; T -&gt; Stream&lt;R&gt; limit 中间 Stream&lt;T&gt; long sorted 中间 Stream&lt;T&gt; Comparator&lt;T&gt; (T, T) -&gt; int anyMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean noneMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean allMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean findAny 终端 Optional&lt;T&gt; findFirst 终端 Optional&lt;T&gt; forEach 终端 void Consumer&lt;T&gt; T -&gt; void collect 终端 R Collector&lt;T, A, R&gt; reduce 终端 Optional&lt;T&gt; BinaryOperator&lt;T&gt; (T, T) -&gt; T count 终端 long Intermediate operationsIntermediate operations return the stream itself, so you can chain multiple method calls in a row. 中间流返回流本身。 这个简单的说就是pipeline操作了，类比linux的管道流， 比如我要统计一个目录下所有文件包含hello的字数并且统计出现的次数并且排序，然后筛选出前几个 grep -l 'hello' /tmp/* | xargs wc -w | sort -nr | head -3 更多介绍请戳 collection-pipeline 下面我们先定义一个集合然后操作几种常用的流操作。 List&lt;String&gt; memberNames = new ArrayList&lt;&gt;(); memberNames.add(&quot;Amitabh&quot;); memberNames.add(&quot;Shekhar&quot;); memberNames.add(&quot;Aman&quot;); memberNames.add(&quot;Rahul&quot;); memberNames.add(&quot;Shahrukh&quot;); memberNames.add(&quot;Salman&quot;); memberNames.add(&quot;Yana&quot;); memberNames.add(&quot;Lokesh&quot;); Stream.filter()Filter accepts a predicate to filter all elements of the stream. This operation is intermediate which enables us to call another stream operation (e.g. forEach) on the result. 过滤流获取我们需要的数据 memberNames.stream().filter((s) -&gt; s.startsWith(&quot;A&quot;)) .forEach(System.out::println); Stream.distinct()函数原型为Stream&lt;T&gt; distinct()，作用是返回一个去除重复元素之后的Stream Stream&lt;String&gt; stream= Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;, &quot;too&quot;); stream.distinct() .forEach(str -&gt; System.out.println(str)); Stream.map()The intermediate operation map converts each element into another object via the given function 映射流的每个元素进行转换等操作 memberNames.stream().filter((s) -&gt; s.startsWith(&quot;A&quot;)) .map(String::toUpperCase) .forEach(System.out::println); Stream.flatMap函数原型为&lt;R&gt; Stream&lt;R&gt; flatMap(Function&lt;? super T,? extends Stream&lt;? extends R&gt;&gt; mapper)，作用是对每个元素执行mapper指定的操作，并用所有mapper返回的Stream中的元素组成一个新的Stream作为最终返回结果。说起来太拗口，通俗的讲flatMap()的作用就相当于把原stream中的所有元素都”摊平”之后组成的Stream，转换前后元素的个数和类型都可能会改变。 Stream&lt;List&lt;Integer&gt;&gt; stream = Stream.of(Arrays.asList(1,2), Arrays.asList(3, 4, 5)); stream.flatMap(list -&gt; list.stream()) .forEach(i -&gt; System.out.println(i)); Stream.sorted()Sorted is an intermediate operation which returns a sorted view of the stream. The elements are sorted in natural order unless you pass a custom Comparator. 对流的元素进行排序，除非传递自定义比较器，否则元素按自然顺序排序。 注意，流排序只是创建已排序的流视图，不改变原本集合的顺序。 memberNames.stream().sorted() .map(String::toUpperCase) .forEach(System.out::println); Terminal operationsTerminal operations return a result of a certain type instead of again a Stream. 终端流返回特定类型的结果，表示流操作完成。 Stream.forEach()This method helps in iterating over all elements of a stream and perform some operation on each of them. The operation is passed as lambda expression parameter. 遍历流的所有元素并对每个元素执行某些操作。作为lambda表达式参数传递。 memberNames.forEach(System.out::println); Stream.match()Various matching operations can be used to check whether a certain predicate matches the stream. All of those operations are terminal and return a boolean result. 返回布尔值，流匹配 boolean matchedResult = memberNames.stream() .anyMatch((s) -&gt; s.startsWith(&quot;A&quot;)); System.out.println(matchedResult); matchedResult = memberNames.stream() .allMatch((s) -&gt; s.startsWith(&quot;A&quot;)); System.out.println(matchedResult); matchedResult = memberNames.stream() .noneMatch((s) -&gt; s.startsWith(&quot;A&quot;)); System.out.println(matchedResult); Stream.count()Count is a terminal operation returning the number of elements in the stream as a long. 返回流元素的数量 long totalMatched = memberNames.stream() .filter((s) -&gt; s.startsWith(&quot;A&quot;)) .count(); System.out.println(totalMatched); Stream.reduce()This terminal operation performs a reduction on the elements of the stream with the given function. The result is an Optional holding the reduced value. reduce操作可以实现从一组元素中生成一个值，sum()、max()、min()、count()等都是reduce操作，将他们单独设为函数只是因为常用。reduce()的方法定义有三种重写形式： Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator) T reduce(T identity, BinaryOperator&lt;T&gt; accumulator) &lt;U&gt; U reduce(U identity, BiFunction&lt;U,? super T,U&gt; accumulator, BinaryOperator&lt;U&gt; combiner) 虽然函数定义越来越长，但语义不曾改变，多的参数只是为了指明初始值（参数identity），或者是指定并行执行时多个部分结果的合并方式（参数combiner）。reduce()最常用的场景就是从一堆值中生成一个值。用这么复杂的函数去求一个最大或最小值，你是不是觉得设计者有病。其实不然，因为“大”和“小”或者“求和”有时会有不同的语义。 需求：从一组单词中找出最长的单词。这里“大”的含义就是“长”。 // 找出最长的单词 Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;); Optional&lt;String&gt; longest = stream.reduce((s1, s2) -&gt; s1.length()&gt;=s2.length() ? s1 : s2); //Optional&lt;String&gt; longest = stream.max((s1, s2) -&gt; s1.length()-s2.length()); System.out.println(longest.get()); 上述代码会选出最长的单词love，其中Optional是（一个）值的容器，使用它可以避免null值的麻烦。当然可以使用Stream.max(Comparator&lt;? super T&gt; comparator)方法来达到同等效果，但reduce()自有其存在的理由。 需求：求出一组单词的长度之和。这是个“求和”操作，操作对象输入类型是String，而结果类型是Integer。 // 求单词长度之和 Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;); Integer lengthSum = stream.reduce(0, // 初始值 // (1) (sum, str) -&gt; sum+str.length(), // 累加器 // (2) (a, b) -&gt; a+b); // 部分和拼接器，并行执行时才会用到 // (3) // int lengthSum = stream.mapToInt(str -&gt; str.length()).sum(); System.out.println(lengthSum); 上述代码标号(2)处将i. 字符串映射成长度，ii. 并和当前累加和相加。这显然是两步操作，使用reduce()函数将这两步合二为一，更有助于提升性能。如果想要使用map()和sum()组合来达到上述目的，也是可以的。 Boxed Stream采用reduce进行数值操作会涉及到基本数值类型和引用数值类型之间的装箱、拆箱操作，因此效率较低。 当流操作为纯数值操作时，使用数值流能获得较高的效率。 将普通流转换成数值流 StreamAPI提供了三种数值流：IntStream、DoubleStream、LongStream，也提供了将普通流转换成数值流的三种方法：mapToInt、mapToDouble、mapToLong。 如，将Person中的age转换成数值流： IntStream stream = list.stream().mapToInt(Person::getAge); 数值计算 每种数值流都提供了数值计算函数，如max、min、sum等。如，找出最大的年龄： OptionalInt maxAge = list.stream() .mapToInt(Person::getAge) .max(); 由于数值流可能为空，并且给空的数值流计算最大值是没有意义的，因此max函数返回OptionalInt，它是Optional的一个子类，能够判断流是否为空，并对流为空的情况作相应的处理。 此外，mapToInt、mapToDouble、mapToLong进行数值操作后的返回结果分别为：OptionalInt、OptionalDouble、OptionalLong reduce()擅长的是生成一个值，如果想要从Stream生成一个集合或者Map等复杂的对象该怎么办呢？终极武器collect()横空出世！ Stream.collect()Collectors 类的静态工厂方法 工厂方法 返回类型 用途 示例 toList List&lt;T&gt; 把流中所有项目收集到一个 List List&lt;Project&gt; projects = projectStream.collect(toList()); toSet Set&lt;T&gt; 把流中所有项目收集到一个 Set，删除重复项 Set&lt;Project&gt; projects = projectStream.collect(toSet()); toCollection Collection&lt;T&gt; 把流中所有项目收集到给定的供应源创建的集合 Collection&lt;Project&gt; projects = projectStream.collect(toCollection(), ArrayList::new); counting Long 计算流中元素的个数 long howManyProjects = projectStream.collect(counting()); summingInt Integer 对流中项目的一个整数属性求和 int totalStars = projectStream.collect(summingInt(Project::getStars)); averagingInt Double 计算流中项目 Integer 属性的平均值 double avgStars = projectStream.collect(averagingInt(Project::getStars)); summarizingInt IntSummaryStatistics 收集关于流中项目 Integer 属性的统计值，例如最大、最小、 总和与平均值 IntSummaryStatistics projectStatistics = projectStream.collect(summarizingInt(Project::getStars)); joining String 连接对流中每个项目调用 toString 方法所生成的字符串 String shortProject = projectStream.map(Project::getName).collect(joining(&quot;, &quot;)); maxBy Optional&lt;T&gt; 按照给定比较器选出的最大元素的 Optional， 或如果流为空则为 Optional.empty() Optional&lt;Project&gt; fattest = projectStream.collect(maxBy(comparingInt(Project::getStars))); minBy Optional&lt;T&gt; 按照给定比较器选出的最小元素的 Optional， 或如果流为空则为 Optional.empty() Optional&lt;Project&gt; fattest = projectStream.collect(minBy(comparingInt(Project::getStars))); reducing 归约操作产生的类型 从一个作为累加器的初始值开始，利用 BinaryOperator 与流中的元素逐个结合，从而将流归约为单个值 int totalStars = projectStream.collect(reducing(0, Project::getStars, Integer::sum)); collectingAndThen 转换函数返回的类型 包含另一个收集器，对其结果应用转换函数 int howManyProjects = projectStream.collect(collectingAndThen(toList(), List::size)); groupingBy Map&lt;K, List&lt;T&gt;&gt; 根据项目的一个属性的值对流中的项目作问组，并将属性值作 为结果 Map 的键 Map&lt;String,List&lt;Project&gt;&gt; projectByLanguage = projectStream.collect(groupingBy(Project::getLanguage)); partitioningBy Map&lt;Boolean,List&lt;T&gt;&gt; 根据对流中每个项目应用断言的结果来对项目进行分区 Map&lt;Boolean,List&lt;Project&gt;&gt; vegetarianDishes = projectStream.collect(partitioningBy(Project::isVegetarian)); collect() method used to recieve elements from a sream and store them in a collection and metioned in parameter funcion. collect ( )方法，用于从Stream接收元素，并将它们存储在集合中，并在参数函数中进行赋值。 List&lt;String&gt; memNamesInUppercase = memberNames.stream().sorted() .map(String::toUpperCase) .collect(Collectors.toList()); System.out.print(memNamesInUppercase); 不夸张的讲，如果你发现某个功能在Stream接口中没找到，十有八九可以通过collect()方法实现。collect()是Stream接口方法中最灵活的一个。 // 将Stream转换成容器或Map Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;); List&lt;String&gt; list = stream.collect(Collectors.toList()); // (1) // Set&lt;String&gt; set = stream.collect(Collectors.toSet()); // (2) // Map&lt;String, Integer&gt; map = stream.collect(Collectors.toMap(Function.identity(), String::length)); // (3) 上述代码分别列举了如何将Stream转换成List、Set和Map。 Collectors.toMap() internally uses Map.merge() to add mappings to the map. Map.merge() is spec'd not to allow null values, regardless of whether the underlying Map supports null values. This could probably use some clarification in the Collectors.toMap() specifications. 前面已经说过Stream背后依赖于某种数据源，数据源可以是数组、容器等，但不能是Map。反过来从Stream生成Map是可以的，但我们要想清楚Map的key和value分别代表什么，根本原因是我们要想清楚要干什么。通常在三种情况下collect()的结果会是Map： 使用Collectors.toMap()生成的收集器，用户需要指定如何生成Map的key和value。 使用Collectors.partitioningBy()生成的收集器，对元素进行二分区操作时用到。 使用Collectors.groupingBy()生成的收集器，对元素做group操作时用到。 情况1：使用toMap()生成的收集器，这种情况是最直接的，前面例子中已提到，这是和Collectors.toCollection()并列的方法。如下代码展示将学生列表转换成由&lt;学生，GPA&gt;组成的Map。非常直观，无需多言。 // 使用toMap()统计学生GPA Map&lt;Student, Double&gt; studentToGPA = students.stream().collect(Collectors.toMap(Function.identity(),// 如何生成key student -&gt; computeGPA(student)));// 如何生成value 情况2：使用partitioningBy()生成的收集器，这种情况适用于将Stream中的元素依据某个二值逻辑（满足条件，或不满足）分成互补相交的两部分，比如男女性别、成绩及格与否等。下列代码展示将学生分成成绩及格或不及格的两部分。 // Partition students into passing and failing Map&lt;Boolean, List&lt;Student&gt;&gt; passingFailing = students.stream() .collect(Collectors.partitioningBy(s -&gt; s.getGrade() &gt;= PASS_THRESHOLD)); 情况3：使用groupingBy()生成的收集器，这是比较灵活的一种情况。跟SQL中的group by语句类似，这里的groupingBy()也是按照某个属性对数据进行分组，属性相同的元素会被对应到Map的同一个key上。下列代码展示将员工按照部门进行分组： // Group employees by department Map&lt;Department, List&lt;Employee&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment)); 以上只是分组的最基本用法，有些时候仅仅分组是不够的。在SQL中使用group by是为了协助其他查询，比如1. 先将员工按照部门分组，2. 然后统计每个部门员工的人数。Java类库设计者也考虑到了这种情况，增强版的groupingBy()能够满足这种需求。增强版的groupingBy()允许我们对元素分组之后再执行某种运算，比如求和、计数、平均值、类型转换等。这种先将元素分组的收集器叫做上游收集器，之后执行其他运算的收集器叫做下游收集器(downstream Collector)。 // 使用下游收集器统计每个部门的人数 Map&lt;Department, Integer&gt; totalByDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, Collectors.counting()));// 下游收集器 上面代码的逻辑是不是越看越像SQL？高度非结构化。还有更狠的，下游收集器还可以包含更下游的收集器，这绝不是为了炫技而增加的把戏，而是实际场景需要。考虑将员工按照部门分组的场景，如果我们想得到每个员工的名字（字符串），而不是一个个Employee对象，可通过如下方式做到： // 按照部门对员工分布组，并只保留员工的名字 Map&lt;Department, List&lt;String&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, Collectors.mapping(Employee::getName,// 下游收集器 Collectors.toList())));// 更下游的收集器 字符串拼接时使用Collectors.joining()生成的收集器，从此告别for循环。Collectors.joining()方法有三种重写形式，分别对应三种不同的拼接方式。无需多言，代码过目难忘。 // 使用Collectors.joining()拼接字符串 Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;); //String joined = stream.collect(Collectors.joining());// &quot;Iloveyou&quot; //String joined = stream.collect(Collectors.joining(&quot;,&quot;));// &quot;I,love,you&quot; String joined = stream.collect(Collectors.joining(&quot;,&quot;, &quot;{&quot;, &quot;}&quot;));// &quot;{I,love,you}&quot; 了可以使用Collectors工具类已经封装好的收集器，我们还可以自定义收集器，或者直接调用collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R,? super T&gt; accumulator, BiConsumer&lt;R,R&gt; combiner)方法，收集任何形式你想要的信息。不过Collectors工具类应该能满足我们的绝大部分需求，手动实现之间请先看看文档。 Stream short-circuit operations尽管流操作是在满足谓词的集合中的所有元素上执行的，但是在迭代过程中每当遇到匹配的元素时，通常都希望中断该操作。在外部迭代中，您将使用if-else块。在内部迭代中，有一些特定的方法可以用于此目的。 // anyMatch() -&gt; 一旦条件 满足 predicate ，则返回true。它将不再处理任何元素。 boolean matched = memberNames.stream() .anyMatch((s) -&gt; s.startsWith(&quot;A&quot;)); System.out.println(matched); // findFirst() -&gt; 它将从流返回第一个元素，然后不再处理任何元素。 String firstMatchedName = memberNames.stream() .filter((s) -&gt; s.startsWith(&quot;L&quot;)) .findFirst().get(); System.out.println(firstMatchedName); Streams pipeline这里我们来阐述一下，Streams 流水线工作原理。 中间操作怎么保存跟记录首先，我们上面介绍了Streams的很多中间操作，那么这些中间操作是如果保存跟记录呢，很多Stream操作会需要一个回调函数（Lambda表达式），因此一个完整的操作是&lt;数据来源，操作，回调函数*&gt;构成的三元组。Stream中使用Stage的概念来描述一个完整的操作，并用某种实例化后的PipelineHelper*来代表Stage，将具有先后顺序的各个Stage连到一起，就构成了整个流水线。跟Stream相关类和接口的继承关系图示。 还有IntPipeline, LongPipeline, DoublePipeline没在图中画出，这三个类专门为三种基本类型（不是包装类型）而定制的，跟ReferencePipeline是并列关系。图中Head用于表示第一个Stage，即调用调用诸如Collection.stream()方法产生的Stage，很显然这个Stage里不包含任何操作；StatelessOp和StatefulOp分别表示无状态和有状态的Stage，对应于无状态和有状态的中间操作。 Stream流水线组织结构示意图如下： 图中通过Collection.stream()方法得到Head也就是stage0，紧接着调用一系列的中间操作，不断产生新的Stream。这些Stream对象以双向链表的形式组织在一起，构成整个流水线，由于每个Stage都记录了前一个Stage和本次的操作以及回调函数，依靠这种结构就能建立起对数据源的所有操作。这就是Stream记录操作的方式。 中间操作怎么叠加以上只是解决了操作记录的问题，要想让流水线起到应有的作用我们需要一种将所有操作叠加到一起的方案。你可能会觉得这很简单，只需要从流水线的head开始依次执行每一步的操作（包括回调函数）就行了。这听起来似乎是可行的，但是你忽略了前面的Stage并不知道后面Stage到底执行了哪种操作，以及回调函数是哪种形式。换句话说，只有当前Stage本身才知道该如何执行自己包含的动作。这就需要有某种协议来协调相邻Stage之间的调用关系。 这种协议由Sink接口完成，Sink接口包含的方法如下表所示： 方法名 作用 void begin(long size) 开始遍历元素之前调用该方法，通知Sink做好准备。 void end() 所有元素遍历完成之后调用，通知Sink没有更多的元素了。 boolean cancellationRequested() 是否可以结束操作，可以让短路操作尽早结束。 void accept(T t) 遍历元素时调用，接受一个待处理元素，并对元素进行处理。Stage把自己包含的操作和回调方法封装到该方法里，前一个Stage只需要调用当前Stage.accept(T t)方法就行了。 有了上面的协议，相邻Stage之间调用就很方便了，每个Stage都会将自己的操作封装到一个Sink里，前一个Stage只需调用后一个Stage的accept()方法即可，并不需要知道其内部是如何处理的。当然对于有状态的操作，Sink的begin()和end()方法也是必须实现的。比如Stream.sorted()是一个有状态的中间操作，其对应的Sink.begin()方法可能创建一个乘放结果的容器，而accept()方法负责将元素添加到该容器，最后end()负责对容器进行排序。对于短路操作，Sink.cancellationRequested()也是必须实现的，比如Stream.findFirst()是短路操作，只要找到一个元素，cancellationRequested()就应该返回true，以便调用者尽快结束查找。Sink的四个接口方法常常相互协作，共同完成计算任务。实际上Stream API内部实现的的本质，就是如何重载Sink的这四个接口方法。 有了Sink对操作的包装，Stage之间的调用问题就解决了，执行时只需要从流水线的head开始对数据源依次调用每个Stage对应的Sink.{begin(), accept(), cancellationRequested(), end()}方法就可以了。一种可能的Sink.accept()方法流程是这样的： void accept(U u){ 1. 使用当前Sink包装的回调函数处理u 2. 将处理结果传递给流水线下游的Sink } Sink接口的其他几个方法也是按照这种[处理-&gt;转发]的模型实现。下面我们结合具体例子看看Stream的中间操作是如何将自身的操作包装成Sink以及Sink是如何将处理结果转发给下一个Sink的。先看Stream.map()方法： // Stream.map()，调用该方法将产生一个新的Stream public final &lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super P_OUT, ? extends R&gt; mapper) { ... return new StatelessOp&lt;P_OUT, R&gt;(this, StreamShape.REFERENCE, StreamOpFlag.NOT_SORTED | StreamOpFlag.NOT_DISTINCT) { @Override /*opWripSink()方法返回由回调函数包装而成Sink*/ Sink&lt;P_OUT&gt; opWrapSink(int flags, Sink&lt;R&gt; downstream) { return new Sink.ChainedReference&lt;P_OUT, R&gt;(downstream) { @Override public void accept(P_OUT u) { R r = mapper.apply(u);// 1. 使用当前Sink包装的回调函数mapper处理u downstream.accept(r);// 2. 将处理结果传递给流水线下游的Sink } }; } }; } 上述代码看似复杂，其实逻辑很简单，就是将回调函数mapper包装到一个Sink当中。由于Stream.map()是一个无状态的中间操作，所以map()方法返回了一个StatelessOp内部类对象（一个新的Stream），调用这个新Stream的opWripSink()方法将得到一个包装了当前回调函数的Sink。 再来看一个复杂一点的例子。Stream.sorted()方法将对Stream中的元素进行排序，显然这是一个有状态的中间操作，因为读取所有元素之前是没法得到最终顺序的。抛开模板代码直接进入问题本质，sorted()方法是如何将操作封装成Sink的呢？sorted()一种可能封装的Sink代码如下： // Stream.sort()方法用到的Sink实现 class RefSortingSink&lt;T&gt; extends AbstractRefSortingSink&lt;T&gt; { private ArrayList&lt;T&gt; list;// 存放用于排序的元素 RefSortingSink(Sink&lt;? super T&gt; downstream, Comparator&lt;? super T&gt; comparator) { super(downstream, comparator); } @Override public void begin(long size) { ... // 创建一个存放排序元素的列表 list = (size &gt;= 0) ? new ArrayList&lt;T&gt;((int) size) : new ArrayList&lt;T&gt;(); } @Override public void end() { list.sort(comparator);// 只有元素全部接收之后才能开始排序 downstream.begin(list.size()); if (!cancellationWasRequested) {// 下游Sink不包含短路操作 list.forEach(downstream::accept);// 2. 将处理结果传递给流水线下游的Sink } else {// 下游Sink包含短路操作 for (T t : list) {// 每次都调用cancellationRequested()询问是否可以结束处理。 if (downstream.cancellationRequested()) break; downstream.accept(t);// 2. 将处理结果传递给流水线下游的Sink } } downstream.end(); list = null; } @Override public void accept(T t) { list.add(t);// 1. 使用当前Sink包装动作处理t，只是简单的将元素添加到中间列表当中 } } 上述代码完美的展现了Sink的四个接口方法是如何协同工作的： 首先begin()方法告诉Sink参与排序的元素个数，方便确定中间结果容器的的大小； 之后通过accept()方法将元素添加到中间结果当中，最终执行时调用者会不断调用该方法，直到遍历所有元素；一个 最后end()方法告诉Sink所有元素遍历完毕，启动排序步骤，排序完成后将结果传递给下游的Sink； 如果下游的Sink是短路操作，将结果传递给下游时不断询问下游cancellationRequested()是否可以结束处理。 操作叠加后如何执行Sink完美封装了Stream每一步操作，并给出了[处理-&gt;转发]的模式来叠加操作。这一连串的齿轮已经咬合，就差最后一步拨动齿轮启动执行。是什么启动这一连串的操作呢？也许你已经想到了启动的原始动力就是结束操作(Terminal Operation)，一旦调用某个结束操作，就会触发整个流水线的执行。 结束操作之后不能再有别的操作，所以结束操作不会创建新的流水线阶段(Stage)，直观的说就是流水线的链表不会在往后延伸了。结束操作会创建一个包装了自己操作的Sink，这也是流水线中最后一个Sink，这个Sink只需要处理数据而不需要将结果传递给下游的Sink（因为没有下游）。对于Sink的[处理-&gt;转发]模型，结束操作的Sink就是调用链的出口。 我们再来考察一下上游的Sink是如何找到下游Sink的。一种可选的方案是在PipelineHelper中设置一个Sink字段，在流水线中找到下游Stage并访问Sink字段即可。但Stream类库的设计者没有这么做，而是设置了一个Sink AbstractPipeline.opWrapSink(int flags, Sink downstream)方法来得到Sink，该方法的作用是返回一个新的包含了当前Stage代表的操作以及能够将结果传递给downstream的Sink对象。为什么要产生一个新对象而不是返回一个Sink字段？这是因为使用opWrapSink()可以将当前操作与下游Sink（上文中的downstream参数）结合成新Sink。试想只要从流水线的最后一个Stage开始，不断调用上一个Stage的opWrapSink()方法直到最开始（不包括stage0，因为stage0代表数据源，不包含操作），就可以得到一个代表了流水线上所有操作的Sink，用代码表示就是这样： // AbstractPipeline.wrapSink() // 从下游向上游不断包装Sink。如果最初传入的sink代表结束操作， // 函数返回时就可以得到一个代表了流水线上所有操作的Sink。 final &lt;P_IN&gt; Sink&lt;P_IN&gt; wrapSink(Sink&lt;E_OUT&gt; sink) { ... for (AbstractPipeline p=AbstractPipeline.this; p.depth &gt; 0; p=p.previousStage) { sink = p.opWrapSink(p.previousStage.combinedFlags, sink); } return (Sink&lt;P_IN&gt;) sink; } 现在流水线上从开始到结束的所有的操作都被包装到了一个Sink里，执行这个Sink就相当于执行整个流水线，执行Sink的代码如下： // AbstractPipeline.copyInto(), 对spliterator代表的数据执行wrappedSink代表的操作。 final &lt;P_IN&gt; void copyInto(Sink&lt;P_IN&gt; wrappedSink, Spliterator&lt;P_IN&gt; spliterator) { ... if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) { wrappedSink.begin(spliterator.getExactSizeIfKnown());// 通知开始遍历 spliterator.forEachRemaining(wrappedSink);// 迭代 wrappedSink.end();// 通知遍历结束 } ... } 上述代码首先调用wrappedSink.begin()方法告诉Sink数据即将到来，然后调用spliterator.forEachRemaining()方法对数据进行迭代（Spliterator是容器的一种迭代器，参阅），最后调用wrappedSink.end()方法通知Sink数据处理结束。逻辑如此清晰。 执行后的结果怎么保存最后一个问题是流水线上所有操作都执行后，用户所需要的结果（如果有）在哪里？首先要说明的是不是所有的Stream结束操作都需要返回结果，有些操作只是为了使用其副作用(Side-effects)，比如使用Stream.forEach()方法将结果打印出来就是常见的使用副作用的场景（事实上，除了打印之外其他场景都应避免使用副作用），对于真正需要返回结果的结束操作结果存在哪里呢？ 特别说明：副作用不应该被滥用，也许你会觉得在Stream.forEach()里进行元素收集是个不错的选择，就像下面代码中那样，但遗憾的是这样使用的正确性和效率都无法保证，因为Stream可能会并行执行。大多数使用副作用的地方都可以使用归约操作更安全和有效的完成。 // 错误的收集方式 ArrayList&lt;String&gt; results = new ArrayList&lt;&gt;(); stream.filter(s -&gt; pattern.matcher(s).matches()) .forEach(s -&gt; results.add(s)); // Unnecessary use of side-effects! // 正确的收集方式 List&lt;String&gt;results = stream.filter(s -&gt; pattern.matcher(s).matches()) .collect(Collectors.toList()); // No side-effects! 回到流水线执行结果的问题上来，需要返回结果的流水线结果存在哪里呢？这要分不同的情况讨论，下表给出了各种有返回结果的Stream结束操作。 返回类型 对应的结束操作 boolean anyMatch() allMatch() noneMatch() Optional findFirst() findAny() 归约结果 reduce() collect() 数组 toArray() 对于表中返回boolean或者Optional的操作（Optional是存放 一个 值的容器）的操作，由于值返回一个值，只需要在对应的Sink中记录这个值，等到执行结束时返回就可以了。 对于归约操作，最终结果放在用户调用时指定的容器中（容器类型通过收集器指定）。collect(), reduce(), max(), min()都是归约操作，虽然max()和min()也是返回一个Optional，但事实上底层是通过调用reduce()方法实现的。 对于返回是数组的情况，毫无疑问的结果会放在数组当中。这么说当然是对的，但在最终返回数组之前，结果其实是存储在一种叫做Node的数据结构中的。Node是一种多叉树结构，元素存储在树的叶子当中，并且一个叶子节点可以存放多个元素。这样做是为了并行执行方便。 Parallelism in Java Steam并行流 List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); for(int i = 1; i&lt; 10; i++){ list.add(i); } //Here creating a parallel stream Stream&lt;Integer&gt; stream = list.parallelStream(); Integer[] evenNumbersArr = stream.filter(i -&gt; i%2 == 0).toArray(Integer[]::new); System.out.print(evenNumbersArr); ConcurrentThread 和 Runnable所有的现代操作系统都通过进程和线程来支持并发。进程是通常彼此独立运行的程序的实例，比如，如果你启动了一个Java程序，操作系统产生一个新的进程，与其他程序一起并行执行。 在这些进程的内部，我们使用线程并发执行代码，因此，我们可以最大限度的利用CPU可用的核心（core）。 Java从JDK1.0开始执行线程。在开始一个新的线程之前，你必须指定由这个线程执行的代码，通常称为task。这可以通过实现Runnable——一个定义了一个无返回值无参数的 run() 方法的函数接口。 线程池在执行一个异步任务或并发任务时，往往是通过直接 new Thread() 方法来创建新的线程，这样做弊端较多，更好的解决方案是合理地利用线程池，线程池的优势很明显，如下： 降低系统资源消耗，通过重用已存在的线程，降低线程创建和销毁造成的消耗； 提高系统响应速度，当有任务到达时，无需等待新线程的创建便能立即执行； 方便线程并发数的管控，线程若是无限制的创建，不仅会额外消耗大量系统资源，更是占用过多资源而阻塞系统或oom等状况，从而降低系统的稳定性。线程池能有效管控线程，统一分配、调优，提供资源使用率； 更强大的功能，线程池提供了定时、定期以及可控线程数等功能的线程池，使用方便简单。 线程池用法newCachedThreadPool创建一个可缓存的无界线程池，该方法无参数。当线程池中的线程空闲时间超过60s则会自动回收该线程，当任务超过线程池的线程数则创建新线程。线程池的大小上限为 Integer.MAX_VALUE，可看做是无限大。 public void cachedThreadPoolDemo(){ ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) { final int index = i; cachedThreadPool.execute(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()+&quot;, index=&quot;+index); } }); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } 运行结果： pool-1-thread-1, index=0 pool-1-thread-1, index=1 pool-1-thread-1, index=2 pool-1-thread-1, index=3 pool-1-thread-1, index=4 从运行结果可以看出，整个过程都在同一个线程pool-1-thread-1中运行，后面线程复用前面的线程。 newFixedThreadPool创建一个固定大小的线程池，该方法可指定线程池的固定大小，对于超出的线程会在 LinkedBlockingQueue 队列中等待。 public void fixedThreadPoolDemo(){ ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 6; i++) { final int index = i; fixedThreadPool.execute(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()+&quot;, index=&quot;+index); } }); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } 运行结果： pool-1-thread-1, index=0 pool-1-thread-2, index=1 pool-1-thread-3, index=2 pool-1-thread-1, index=3 pool-1-thread-2, index=4 pool-1-thread-3, index=5 从运行结果可以看出，线程池大小为3，每休眠1s后将任务提交给线程池的各个线程轮番交错地执行。线程池的大小设置，可参数 Runtime.getRuntime().availableProcessors()。 newSingleThreadExecutor创建只有一个线程的线程池，该方法无参数，所有任务都保存队列LinkedBlockingQueue中，等待唯一的单线程来执行任务，并保证所有任务按照指定顺序(FIFO或优先级)执行。 public void singleThreadExecutorDemo(){ ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 3; i++) { final int index = i; singleThreadExecutor.execute(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()+&quot;, index=&quot;+index); } }); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } 运行结果： pool-1-thread-1, index=0 pool-1-thread-1, index=1 pool-1-thread-1, index=2 从运行结果可以看出，所有任务都是在单一线程运行的。 newScheduledThreadPool创建一个可定时执行或周期执行任务的线程池，该方法可指定线程池的核心线程个数。 public void scheduledThreadPoolDemo(){ ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(3); //定时执行一次的任务，延迟1s后执行 scheduledThreadPool.schedule(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()+&quot;, delay 1s&quot;); } }, 1, TimeUnit.SECONDS); //周期性地执行任务，延迟2s后，每3s一次地周期性执行任务 scheduledThreadPool.scheduleAtFixedRate(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()+&quot;, every 3s&quot;); } }, 2, 3, TimeUnit.SECONDS); } 运行结果： pool-1-thread-1, delay 1s pool-1-thread-1, every 3s pool-1-thread-2, every 3s pool-1-thread-2, every 3s ... schedule(Runnable command, long delay, TimeUnit unit): 延迟一定时间后执行 Runnable 任务； schedule(Callable callable, long delay, TimeUnit unit): 延迟一定时间后执行 Callable 任务； scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit): 延迟一定时间后，以间隔period时间的频率周期性地执行任务； scheduleWithFixedDelay(Runnable command, long initialDelay, long delay,TimeUnit unit): 与 scheduleAtFixedRate() 方法很类似， 但是不同的是scheduleWithFixedDelay()方法的周期时间间隔是以上一个任务执行结束到下一个任务开始执行的间隔， 而scheduleAtFixedRate()方法的周期时间间隔是以上一个任务开始执行到下一个任务开始执行的间隔，也就是这一些任务系列的触发时间都是可预知的。 ScheduledExecutorService 功能强大，对于定时执行的任务，建议多采用该方法。 方法对比 工厂方法 corePoolSize maximumPoolSize keepAliveTime workQueue newCachedThreadPool 0 Integer.MAX_VALUE 60sSynchronousQueue newFixedThreadPool nThreads nThreads 0 LinkedBlockingQueue newSingleThreadExecutor 1 1 0 LinkedBlockingQueue newScheduledThreadPool corePoolSize Integer.MAX_VALUE 0 DelayedWorkQueue 其他参数都相同，其中线程工厂的默认类为 DefaultThreadFactory，线程饱和的默认策略为 ThreadPoolExecutor.AbortPolicy。 简单使用 Lock 锁Java 5 中引入了新的锁机制——java.util.concurrent.locks 中的显式的互斥锁：Lock 接口，它提供了比 synchronized 更加广泛的锁定操作。 Lock 接口有 3 个实现它的类：ReentrantLock、ReetrantReadWriteLock.ReadLock 和 ReetrantReadWriteLock.WriteLock，即重入锁、读锁和写锁。 lock 必须被显式地创建、锁定和释放，为了可以使用更多的功能，一般用 ReentrantLock 为其实例化。为了保证锁最终一定会被释放（可能会有异常发生），要把互斥区放在 try 语句块内，并在 finally 语句块中释放锁，尤其当有 return 语句时，return 语句必须放在 try 字句中，以确保 unlock()不会过早发生，从而将数据暴露给第二个任务。因此，采用 lock 加锁和释放锁的一般形式如下： //默认使用非公平锁，如果要使用公平锁，需要传入参数true Lock lock = new ReentrantLock(); lock.lock(); try { // 更新对象的状态 // 捕获异常，必要时恢复到原来的不变约束 // 如果有return语句，放在这里 } finally { //锁必须在finally块中释放 lock.unlock(); } 可重入锁，也叫做递归锁，指的是同一线程外层函数获得锁之后，内层递归函数仍然有获取该锁的代码，但不受影响。 在JAVA环境下 ReentrantLock 和 synchronized 都是可重入锁。 ReentrantReadWriteLock读写锁：分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可。 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁；如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。 总之，读的时候上读锁，写的时候上写锁！ ReentrantReadWriteLock 会使用两把锁来解决问题，一个读锁，一个写锁 线程进入读锁的前提条件 没有其他线程的写锁 没有写请求或者有写请求，但调用线程和持有锁的线程是同一个 线程进入写锁的前提条件 没有其他线程的读锁 没有其他线程的写锁 StampedLockStampedLock 是 java 8 在 java.util.concurrent.locks 新增的一个API。 ReentrantReadWriteLock 在沒有任何读锁和写锁时，才可以取得写入锁，这可用于实现了悲观读取。 然而，如果读取很多，写入很少的情况下，使用 ReentrantReadWriteLock 可能会使写入线程遭遇饥饿问题，也就是写入线程无法竞争到锁定而一直处于等待状态。 StampedLock 有三种模式的锁，用于控制读取/写入访问，StampedLock 的状态由版本和模式组成。 锁获取操作返回一个用于展示和访问锁状态的票据（stamp）变量，它用相应的锁状态表示并控制访问，数字0表示没有写锁被授权访问。 在读锁上分为悲观锁和乐观锁，锁释放以及其他相关方法需要使用邮戳（stamps）变量作为参数，如果他们和当前锁状态不符则失败，这三种模式为： 写入：方法writeLock可能为了获取独占访问而阻塞当前线程，返回一个stamp变量，能够在unlockWrite方法中使用从而释放锁。也提供了tryWriteLock。 当锁被写模式所占有，没有读或者乐观的读操作能够成功。 读取：方法readLock可能为了获取非独占访问而阻塞当前线程，返回一个stamp变量，能够在unlockRead方法中用于释放锁。也提供了tryReadLock。 乐观读取：方法 tryOptimisticRead 返回一个非 0 邮戳变量，仅在当前锁没有以写入模式被持有。如果在获得stamp变量之后没有被写模式持有，方法validate将返回true。 这种模式可以被看做一种弱版本的读锁，可以被一个写入者在任何时间打断。乐观读取模式仅用于短时间读取操作时经常能够降低竞争和提高吞吐量。 悲观锁（Pessimistic Lock），顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 Java synchronized 就属于悲观锁的一种实现，每次线程要修改数据时都先获得锁，保证同一时刻只有一个线程能操作数据，其他线程则会被block。 乐观锁（Optimistic Lock），顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。 乐观锁适用于读多写少的应用场景，这样可以提高吞吐量。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 AtomicIntegerJDK1.5之后的java.util.concurrent.atomic包里，多了一批原子处理类。 AtomicBoolean、AtomicInteger、AtomicLong、AtomicReference。 主要用于在高并发环境下的高效程序处理,来帮助我们简化同步处理. AtomicInteger，一个提供原子操作的Integer的类。 在Java语言中，++i和i++操作并不是线程安全的，在使用的时候，不可避免的会用到synchronized关键字。 而AtomicInteger则通过一种线程安全的加减操作接口。 public final int get() //获取当前的值 public final int getAndSet(int newValue)//获取当前的值，并设置新的值 public final int getAndIncrement() //获取当前的值，并自增 public final int getAndDecrement() //获取当前的值，并自减 public final int getAndAdd(int delta) //获取当前的值，并加上预期的值 LongAccumulatorLongAdder 是jdk1.8提供的累加器，基于 Striped64 实现。 它常用于状态采集、统计等场景。 AtomicLong也可以用于这种场景，但在线程竞争激烈的情况下，LongAdder要比AtomicLong拥有更高的吞吐量，但会耗费更多的内存空间。 LongAccumulator 和 LongAdder 类似，也基于Striped64实现。但要比LongAdder更加灵活(要传入一个函数接口)， LongAdder相当于是LongAccumulator的一种特例。 SemaphoreSemaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。 很多年以来，我都觉得从字面上很难理解Semaphore所表达的含义，只能把它比作是控制流量的红绿灯，比如XX马路要限制流量，只允许同时有一百辆车在这条路上行使， 其他的都必须在路口等待，所以前一百辆车会看到绿灯，可以开进这条马路，后面的车会看到红灯，不能驶入XX马路， 但是如果前一百辆中有五辆车已经离开了XX马路，那么后面就允许有5辆车驶入马路，这个例子里说的车就是线程，驶入马路就表示线程在执行， 离开马路就表示线程执行完成，看见红灯就表示线程被阻塞，不能执行。 应用场景 Semaphore可以用于做流量控制，特别公用资源有限的应用场景，比如数据库连接。 假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发的读取， 但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个， 这时我们必须控制只有十个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。 这个时候，我们就可以使用Semaphore来做流控。 Time APIZoneIdJava 8中的时区操作被很大程度上简化了，新的时区类 java.time.ZoneId 是原有的 java.util.TimeZone 类的替代品。 ZoneId对象可以通过 ZoneId.of() 方法创建，也可以通过 ZoneId.systemDefault() 获取系统默认时区： ZoneId shanghaiZoneId = ZoneId.of(&quot;Asia/Shanghai&quot;); ZoneId systemZoneId = ZoneId.systemDefault(); of() 方法接收一个“区域/城市”的字符串作为参数，你可以通过 getAvailableZoneIds() 方法获取所有合法的“区域/城市”字符串： Set&lt;String&gt; zoneIds = ZoneId.getAvailableZoneIds(); 对于老的时区类 TimeZone，Java 8也提供了转化方法： ZoneId oldToNewZoneId = TimeZone.getDefault().toZoneId(); 有了 ZoneId，我们就可以将一个 LocalDate、LocalTime 或 LocalDateTime 对象转化为 ZonedDateTime 对象： LocalDateTime localDateTime = LocalDateTime.now(); ZonedDateTime zonedDateTime = ZonedDateTime.of(localDateTime, shanghaiZoneId); ZonedDateTime 对象由两部分构成，LocalDateTime 和 ZoneId，其中 2018-03-03T15:26:56.147 部分为 LocalDateTime，+08:00[Asia/Shanghai] 部分为ZoneId。 另一种表示时区的方式是使用 ZoneOffset，它是以当前时间和 世界标准时间（UTC）/格林威治时间（GMT） 的偏差来计算，例如： ZoneOffset zoneOffset = ZoneOffset.of(&quot;+09:00&quot;); LocalDateTime localDateTime = LocalDateTime.now(); OffsetDateTime offsetDateTime = OffsetDateTime.of(localDateTime, zoneOffset); InstantInstant类在Java日期与时间功能中，表示了时间线上一个确切的点，定义为距离初始时间的时间差（初始时间为GMT 1970年1月1日00:00）经测量一天有86400秒，从初始时间开始不断向前移动。 创建一个Instant实例 你可以通过Instant类的工厂方法创建一个Instant实例，例如你可以调用instant.now()来创建一个确切的表达当前时间的Instant对象： Instant now = Instant.now(); 另外也有一些其它方法能创建Instant，具体请查阅Java官方文档。 访问Instant的时间 一个Instant对象里有两个域：距离初始时间的秒钟数、在当前一秒内的第几纳秒，他们的组合表达了当前时间点。你可以通过以下两个方法得到它们的值： long seconds = getEpochSecond() int nanos = getNano() Instant的计算 Instant类有一些方法，可以用于获得另一Instant的值，例如： plusSeconds() plusMillis() plusNanos() minusSeconds() minusMillis() minusNanos() 我下面将向你展示两个例子，来说明这些方法如何使用： Instant now = Instant.now(); Instant later = now.plusSeconds(3); Instant earlier = now.minusSeconds(3); 第一行获得了一个Instant对象，表示当前时间。第二行创建了一个Instant表示三秒后，第三行创建了一个Instant表示三秒前。 seconds 表示从 1970-01-01 00:00:00 开始到现在的秒数，nanos 表示纳秒部分（nanos的值不会超过999,999,999） ClockClock类提供了访问当前日期和时间的方法，Clock是时区敏感的，可以用来取代 System.currentTimeMillis() 来获取当前的微秒数。 某一个特定的时间点也可以使用Instant类来表示，Instant 类也可以用来创建老的 java.util.Date 对象。 Clock clock = Clock.systemDefaultZone(); long millis = clock.millis(); Instant instant = clock.instant(); Date legacyDate = Date.from(instant); // legacy java.util.Date LocalDateLocalDate类是Java 8中日期时间功能里表示一个本地日期的类，它的日期是无时区属性的。 可以用来表示生日、节假日期等等。这个类用于表示一个确切的日期，而不是这个日期所在的时间（如java.util.Date中的2000.01.01表示的实际是这一天的00:00这个瞬间）。 LocalDate类位于java.time包下，名叫java.time.LocalDate，创建出来的实例也是不可变对象，所以涉及它的计算方法将返回一个新的LocalDate。 创建一个LocalDate实例 我们有多种方式可以创建出 LocalDate 实例。第一种方法是使用 now() 方法获得值为今天当日的 LocalDate 对象： LocalDate localDate = LocalDate.now(); 另一种方法是使用年月日信息构造出LocalDate对象： LocalDate localDate2 = LocalDate.of(2018, 3, 3); LocalDate 的 of() 方法创建出一个指定年月日的日期，并且没有时区信息。 访问日期信息 可以用如下方法访问LocalDate中的日期信息： int year = localDate.getYear(); Month month = localDate.getMonth(); int dayOfMonth = localDate.getDayOfMonth(); int dayOfYear = localDate.getDayOfYear(); DayOfWeek dayOfWeek = localDate.getDayOfWeek(); 可以注意到getMonth()与getDayOfWeek()方法返回了一个枚举类型代替一个int。你可以通过枚举类型中的getValue()来获得信息。 LocalDate计算 你可以进行一堆简单的日期计算，只要使用如下的方法： plusDays() plusWeeks() plusMonths() plusYears() minusDays() minusWeeks() minusMonths() minusYears() 以下举几个使用的例子来帮助理解使用： LocalDate d = LocalDate.of(2018, 3, 5); LocalDate d1 = localDate.plusYears(3); LocalDate d2 = localDate.minusYears(3); 第一行创建出一个新的LocalDate对象d，表示2018.3.5。 第二行创建了值等于d日期3年后的LocalDate对象，第三行也是一样，只是值改为d日期的三年前。 LocalTimeLocalTime类是Java 8中日期时间功能里表示一整天中某个时间点的类，它的时间是无时区属性的（早上10点等等）。比如你需要描述学校几点开学，这个时间不涉及在什么城市，这个描述是对任何国家城市都适用的，此时使用无时区的LocalTime就足够了。 LocalTime类的对象也是不可变的，所以计算方法会返回一个新的LocalTime实例。 创建一个LocatTime实例 有多种方式可以新建LocalTime实例。比如使用当前时间作为值新建对象： LocalTime localTime = LocalTime.now(); 另一种方式是使用指定的时分秒和纳秒来新建对象： LocalTime localTime2 = LocalTime.of(21, 30, 59, 11001); 也有另一种版本的 of() 方法只需要小时分钟两项，或时分秒三项值作为参数。 访问LocalTime对象的时间 你可以通过这些方法访问其时、分、秒、纳秒： getHour() getMinute() getSecond() getNano() LocalTime的计算 LocalTime类包含一系列方法，能帮你完成时间计算： plusHours() plusMinutes() plusSeconds() plusNanos() minusHours() minusMinutes() minusSeconds() minusNanos() 以下举一个例子： LocalTime localTime2 = LocalTime.of(21, 30, 59, 11001); LocalTime localTimeLater = localTime.plusHours(3); LocalTime localTimeEarlier = localTime.minusHours(3); 第一行新建一个LocalTime实例，表示21:30:50的第11001纳秒。 第二行新建了一个LocalTime实例表示这个时间的三小时后，第三行表示三小时前。 LocalTime类是Java 8中日期时间功能里表示一整天中某个时间点的类，它的时间是无时区属性的（早上10点等等）。比如你需要描述学校几点开学，这个时间不涉及在什么城市，这个描述是对任何国家城市都适用的，此时使用无时区的LocalTime就足够了。 LocalTime类的对象也是不可变的，所以计算方法会返回一个新的LocalTime实例。 LocalDateTimeLocalDateTime类是Java 8中日期时间功能里，用于表示当地的日期与时间的类，它的值是无时区属性的。你可以将其视为Java 8中LocalDate与LocalTime两个类的结合。 LocalDateTime类的值是不可变的，所以其计算方法会返回一个新的LocalDateTime实例。 创建一个LocatDateTime实例 可以通过LocalDateTime的静态工厂方法来创建LocalDateTime实例。以下举例使用 now() 方法创建： LocalDateTime localDateTime = LocalDateTime.now(); 另一种方式是使用指定的年月日、时分秒、纳秒来新建对象： LocalDateTime localDateTime2 = LocalDateTime.of(2018, 11, 26, 13, 55, 36, 123); 访问LocalDateTime对象的时间 你可以通过这些方法访问其日期时间： getYear() getMonth() getDayOfMonth() getDayOfWeek() getDayOfYear() getHour() getMinute() getSecond() getNano() 这些方法中有一些返回int有一些返回枚举类型，你可以通过枚举类型中的 getValue() 方法来获得int值。 LocalDateTime的计算 LocalDateTime 类包含一系列方法，能帮你完成时间计算： plusYears() plusMonths() plusDays() plusHours() plusMinutes() plusSeconds() plusNanos() minusYears() minusMonths() minusDays() minusHours() minusMinutes() minusSeconds() minusNanos() 以下举一个例子： LocalDateTime localDateTime = LocalDateTime.now(); LocalDateTime localDateTime1 = localDateTime.plusYears(3); LocalDateTime localDateTime2 = localDateTime.minusYears(3); 第一行新建一个LocalDateTime实例表示当前这个时间。 第二行新建了一个LocalDateTime实例表示三年后。 第三行也新建了一个LocalDateTime实例表示三小时前。 ZonedDateTimeZonedDateTime类是Java 8中日期时间功能里，用于表示带时区的日期与时间信息的类。可以用于表示一个真实事件的开始时间，如某火箭升空时间等等。 ZonedDateTime 类的值是不可变的，所以其计算方法会返回一个新的ZonedDateTime 实例。 创建一个ZonedDateTime实例 有多种方式可以新建ZonedDateTime实例。比如使用当前时间作为值新建对象： ZonedDateTime dateTime = ZonedDateTime.now(); 另一种方式是使用指定的年月日、时分秒、纳秒以及时区ID来新建对象： ZoneId zoneId = ZoneId.of(&quot;UTC+1&quot;); ZonedDateTime dateTime2 = ZonedDateTime.of(2015, 11, 30, 23, 45, 59, 1234, zoneId); 访问ZonedDateTime对象的时间 你可以通过这些方法访问其日期时间： getYear() getMonth() getDayOfMonth() getDayOfWeek() getDayOfYear() getHour() getMinute() getSecond() getNano() 这些方法中有一些返回int有一些返回枚举类型，但可以通过枚举类型中的getValue()方法来获得int值。 ZonedDateTime的计算 ZonedDateTime类包含一系列方法，能帮你完成时间计算： plusYears() plusMonths() plusDays() plusHours() plusMinutes() plusSeconds() plusNanos() minusYears() minusMonths() minusDays() minusHours() minusMinutes() minusSeconds() minusNanos() 但注意计算时，若不巧跨越了夏令时（会补一小时或减一小时），可能得不到希望的结果。一个替代的正确做法是使用Period： ZonedDateTime zoneDateTime = previousDateTime.plus(Period.ofDays(3)); 时区 时区是用ZoneId类表示的，你可以使用ZoneId.now()或ZoneId.of(“xxx”)来实例化： ZoneId zoneId = ZoneId.of(&quot;UTC+1&quot;); 传给 of() 方法的参数是时区的ID，如“UTC+1”指距离UTC（格林威治时间）有一小时的时差，你可以使用你想要的时差来表示ZoneId（如+1与-5等等） 你也可以使用另一种方式表示zone id，即使用地区名字，也是可以的： ZoneId zoneId2 = ZoneId.of(&quot;Europe/Copenhagen&quot;); ZoneId zoneId3 = ZoneId.of(&quot;Europe/Paris&quot;); DateTimeFormatterDateTimeFormatter类是Java 8中日期时间功能里，用于解析和格式化日期时间的类，位于 java.time.format 包下。 预定义的DateTimeFormatter实例 DateTimeFormatter类包含一系列预定义（常量）的实例，可以解析和格式化一些标准时间格式。这将让你免除麻烦的时间格式定义，类中包含如下预定义的实例： BASIC_ISO_DATE ISO_LOCAL_DATE ISO_LOCAL_TIME ISO_LOCAL_DATE_TIME ISO_OFFSET_DATE ISO_OFFSET_TIME ISO_OFFSET_DATE_TIME ISO_ZONED_DATE_TIME ISO_INSTANT ISO_DATE ISO_TIME ISO_DATE_TIME ISO_ORDINAL_TIME ISO_WEEK_DATE RFC_1123_DATE_TIME 每个预定义的DateTimeFormatter实例都有不同的日期格式，我就不解释全部的了。具体的可以查阅Java官方文档，但我在这篇的后续中会解释其中几个，以方便理解。 它的格式化日期 当你获取一个DateTimeFormatter实例后，就可以用format()方便来将一个日期格式化为某种字符串，例如： DateTimeFormatter formatter = DateTimeFormatter.BASIC_ISO_DATE; String formattedDate = formatter.format(LocalDate.now()); System.out.println(formattedDate); 这个样例把LocalDate对象格式化了，并输出20150703，这个输出表示现在2018年，3月5日。 再举一个关于ZonedDateTime的例子： DateTimeFormatter formatter = DateTimeFormatter.BASIC_ISO_DATE; String formattedZonedDate = formatter.format(ZonedDateTime.now()); System.out.println(&quot;formattedZonedDate = &quot; + formattedZonedDate); 这个例子会输出：20180305+0800 表示今年2018年，3月5日，位于UTC+8时区。 Duration一个Duration对象表示两个Instant间的一段时间，是在Java 8中加入的新功能。 一个Duration实例是不可变的，当创建出对象后就不能改变它的值了。你只能通过Duration的计算方法，来创建出一个新的Durtaion对象。你会在之后的教程中见到的。 创建Duration实例 使用 Duration 类的工厂方法来创建一个 Duration 对象，以下是一个使用 between() 的例子： Instant first = Instant.now(); // wait some time while something happens Instant second = Instant.now(); Duration duration = Duration.between(first, second); 访问Duration的时间 一个Duration对象里有两个域：纳秒值（小于一秒的部分），秒钟值（一共有几秒），他们的组合表达了时间长度。注意屯使用System.getCurrentTimeMillis()时不同，Duration不包含毫秒这个属性。 你可以通过以下两个方法得到它们的值： long seconds = getSeconds() int nanos = getNano() 你也可以转换整个时间到其它单位如纳秒、分钟、小时、天： toNanos() toMillis() toMinutes() toHours() toDays() 举例而言：toNanos() 与 getNano() 不同，toNanos() 获得的是 Duration 整个时间共有多少纳秒， 而 getNano() 只是获得这段时间中小于一秒的部分。 你也许会问，为什么没有 toSeconds() 方法，因为已经有 getSeconds() 这个方法能达到同样的功能了。 Duration计算 Duration类包含一系列的计算方法： plusNanos() plusMillis() plusSeconds() plusMinutes() plusHours() plusDays() minusNanos() minusMillis() minusSeconds() minusMinutes() minusHours() minusDays() 这些方法所做的事都是相似的，我在这儿也不展示内部实现细节了，就展示一个加减的例子吧： Duration start = ... //obtain a start duration Duration added = start.plusDays(3); Duration subtracted = start.minusDays(3); 第一行创建了一个Duration对象叫start，具体怎么创建可以参考前面的代码。 第二三行样例创建了两个新的Duration，通过调用start的加减操作，使得added对象表示的时间比start多三天，而substracted则少三天。 所有的计算方法都会返回一个新的Duration，以保证Duration的不可变属性。 long days = duration.toDays(); // 这段时间的总天数 long hours = duration.toHours(); // 这段时间的小时数 long minutes = duration.toMinutes(); // 这段时间的分钟数 long seconds = duration.getSeconds(); // 这段时间的秒数 long milliSeconds = duration.toMillis(); // 这段时间的毫秒数 long nanoSeconds = duration.toNanos(); // 这段时间的纳秒数 其他操作增加和减少日期 Java 8中的日期/时间类都是不可变的，这是为了保证线程安全。当然，新的日期/时间类也提供了方法用于创建对象的可变版本，比如增加一天或者减少一天： LocalDate date = LocalDate.of(2017, 1, 5); // 2017-01-05 LocalDate date1 = date.withYear(2016); // 修改为 2016-01-05 LocalDate date2 = date.withMonth(2); // 修改为 2017-02-05 LocalDate date3 = date.withDayOfMonth(1); // 修改为 2017-01-01 LocalDate date4 = date.plusYears(1); // 增加一年 2018-01-05 LocalDate date5 = date.minusMonths(2); // 减少两个月 2016-11-05 LocalDate date6 = date.plus(5, ChronoUnit.DAYS); // 增加5天 2017-01-10 上面例子中对于日期的操作比较简单，但是有些时候我们要面临更复杂的时间操作，比如将时间调到下一个工作日， 或者是下个月的最后一天，这时候我们可以使用 with() 方法的另一个重载方法，它接收一个TemporalAdjuster参数， 可以使我们更加灵活的调整日期： LocalDate date7 = date.with(nextOrSame(DayOfWeek.SUNDAY)); // 返回下一个距离当前时间最近的星期日 LocalDate date9 = date.with(lastInMonth(DayOfWeek.SATURDAY)); // 返回本月最后一个星期六 要使上面的代码正确编译，你需要使用静态导入 TemporalAdjusters 对象： import static java.time.temporal.TemporalAdjusters.*; TemporalAdjusters 类中包含了很多静态方法可以直接使用，下面的表格列出了一些方法： 方法名 描述 dayOfWeekInMonth 返回同一个月中每周的第几天 firstDayOfMonth 返回当月的第一天 firstDayOfNextMonth 返回下月的第一天 firstDayOfNextYear 返回下一年的第一天 firstDayOfYear 返回本年的第一天 firstInMonth 返回同一个月中第一个星期几 lastDayOfMonth 返回当月的最后一天 lastDayOfNextMonth 返回下月的最后一天 lastDayOfNextYear 返回下一年的最后一天 lastDayOfYear 返回本年的最后一天 lastInMonth 返回同一个月中最后一个星期几 next / previous 返回后一个/前一个给定的星期几 nextOrSame / previousOrSame 返回后一个/前一个给定的星期几，如果这个值满足条件，直接返回 如果上面表格中列出的方法不能满足你的需求，你还可以创建自定义的 TemporalAdjuster 接口的实现，TemporalAdjuster 也是一个函数式接口，所以我们可以使用Lambda表达式： @FunctionalInterface public interface TemporalAdjuster { Temporal adjustInto(Temporal temporal); } 比如给定一个日期，计算该日期的下一个工作日（不包括星期六和星期天）： LocalDate date = LocalDate.of(2017, 1, 5); date.with(temporal -&gt; { // 当前日期 DayOfWeek dayOfWeek = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK)); // 正常情况下，每次增加一天 int dayToAdd = 1; // 如果是星期五，增加三天 if (dayOfWeek == DayOfWeek.FRIDAY) { dayToAdd = 3; } // 如果是星期六，增加两天 if (dayOfWeek == DayOfWeek.SATURDAY) { dayToAdd = 2; } return temporal.plus(dayToAdd, ChronoUnit.DAYS); }); 其他历法Java中使用的历法是ISO 8601日历系统，它是世界民用历法，也就是我们所说的公历。平年有365天，闰年是366天。闰年的定义是：非世纪年，能被4整除；世纪年能被400整除。为了计算的一致性，公元1年的前一年被当做公元0年，以此类推。 此外Java 8还提供了4套其他历法（很奇怪为什么没有汉族人使用的农历），每套历法都包含一个日期类，分别是： ThaiBuddhistDate：泰国佛教历 MinguoDate：中华民国历 JapaneseDate：日本历 HijrahDate：伊斯兰历 每个日期类都继承 ChronoLocalDate 类，所以可以在不知道具体历法的情况下也可以操作。不过这些历法一般不常用，除非是有某些特殊需求情况下才会使用。 这些不同的历法也可以用于向公历转换： LocalDate date = LocalDate.now(); JapaneseDate jpDate = JapaneseDate.from(date); 由于它们都继承ChronoLocalDate类，所以在不知道具体历法情况下，可以通过ChronoLocalDate类操作日期： Chronology jpChronology = Chronology.ofLocale(Locale.JAPANESE); ChronoLocalDate jpChronoLocalDate = jpChronology.dateNow(); 我们在开发过程中应该尽量避免使用 ChronoLocalDate，尽量用与历法无关的方式操作时间，因为不同的历法计算日期的方式不一样， 比如开发者会在程序中做一些假设，假设一年中有12个月，如果是中国农历中包含了闰月，一年有可能是13个月， 但开发者认为是12个月，多出来的一个月属于明年的。 再比如假设年份是累加的，过了一年就在原来的年份上加一，但日本天皇在换代之后需要重新纪年，所以过了一年年份可能会从1开始计算。 在实际开发过程中建议使用 LocalDate，包括存储、操作、业务规则的解读；除非需要将程序的输入或者输出本地化， 这时可以使用 ChronoLocalDate 类。 Nashorn个人感觉用的不是很多，不感兴趣的可以直接略过。 原文地址 使用 NashronNashorn JavaScript引擎可以在Java代码中编程调用，也可以通过命令行工具jjs使用，它在$JAVA_HOME/bin中。如果打算使用jjs，你可能希望设置符号链接来简化访问： $ cd /usr/bin $ ln -s $JAVA_HOME/bin/jjs jjs $ jjs jjs&gt; print('Hello World'); 这个教程专注于在Java代码中调用Nashron，所以让我们先跳过jjs。Java代码中简单的HelloWorld 如下所示： ScriptEngine engine = new ScriptEngineManager().getEngineByName(&quot;nashorn&quot;); engine.eval(&quot;print('Hello World!');&quot;); 为了在Java中执行JavaScript，你首先要通过javax.script包创建脚本引擎。这个包已经在Rhino（来源于Mozilla、Java中的遗留JS引擎）中使用了。 JavaScript代码既可以通过传递JavaScript代码字符串，也可以传递指向你的JS脚本文件的FileReader来执行： ScriptEngine engine = new ScriptEngineManager().getEngineByName(&quot;nashorn&quot;); engine.eval(new FileReader(&quot;script.js&quot;)); Nashorn JavaScript基于ECMAScript 5.1，但是它的后续版本会对ES6提供支持： Nashorn的当前策略遵循ECMAScript规范。当我们在JDK8中发布它时，它将基于ECMAScript 5.1。Nashorn未来的主要发布基于ECMAScript 6。 Nashorn定义了大量对ECMAScript标准的语言和API扩展。但是首先让我们看一看Java和JavaScript代码如何交互。 在Java中调用JavaScript函数Nashorn 支持从Java代码中直接调用定义在脚本文件中的JavaScript函数。你可以将Java对象传递为函数参数，并且从函数返回数据来调用Java方法。 下面的JavaScript函数稍后会在Java端调用： var fun1 = function(name) { print('Hi there from Javascript, ' + name); return &quot;greetings from javascript&quot;; }; var fun2 = function (object) { print(&quot;JS Class Definition: &quot; + Object.prototype.toString.call(object)); }; 为了调用函数，你首先需要将脚本引擎转换为Invocable。Invocable接口由NashornScriptEngine实现，并且定义了invokeFunction方法来调用指定名称的JavaScript函数。 ScriptEngine engine = new ScriptEngineManager().getEngineByName(&quot;nashorn&quot;); engine.eval(new FileReader(&quot;script.js&quot;)); Invocable invocable = (Invocable) engine; Object result = invocable.invokeFunction(&quot;fun1&quot;, &quot;Peter Parker&quot;); System.out.println(result); System.out.println(result.getClass()); // Hi there from Javascript, Peter Parker // greetings from javascript // class java.lang.String 执行这段代码会在控制台产生三行结果。调用函数print将结果输出到System.out，所以我们会首先看到JavaScript输出。 现在让我们通过传入任意Java对象来调用第二个函数： invocable.invokeFunction(&quot;fun2&quot;, new Date()); // [object java.util.Date] invocable.invokeFunction(&quot;fun2&quot;, LocalDateTime.now()); // [object java.time.LocalDateTime] invocable.invokeFunction(&quot;fun2&quot;, new Person()); // [object com.winterbe.java8.Person] Java对象在传入时不会在JavaScript端损失任何类型信息。由于脚本在JVM上原生运行，我们可以在Nashron上使用Java API或外部库的全部功能。 在JavaScript中调用Java方法在JavaScript中调用Java方法十分容易。我们首先需要定义一个Java静态方法。 static String fun1(String name) { System.out.format(&quot;Hi there from Java, %s&quot;, name); return &quot;greetings from java&quot;; } Java类可以通过Java.typeAPI扩展在JavaScript中引用。它就和Java代码中的import类似。只要定义了Java类型，我们就可以自然地调用静态方法fun1()，然后像sout打印信息。由于方法是静态的，我们不需要首先创建实例。 var MyJavaClass = Java.type('my.package.MyJavaClass'); var result = MyJavaClass.fun1('John Doe'); print(result); // Hi there from Java, John Doe // greetings from java 在使用JavaScript原生类型调用Java方法时，Nashorn 如何处理类型转换？让我们通过简单的例子来弄清楚。 下面的Java方法简单打印了方法参数的实际类型： static void fun2(Object object) { System.out.println(object.getClass()); } 为了理解背后如何处理类型转换，我们使用不同的JavaScript类型来调用这个方法： MyJavaClass.fun2(123); // class java.lang.Integer MyJavaClass.fun2(49.99); // class java.lang.Double MyJavaClass.fun2(true); // class java.lang.Boolean MyJavaClass.fun2(&quot;hi there&quot;) // class java.lang.String MyJavaClass.fun2(new Number(23)); // class jdk.nashorn.internal.objects.NativeNumber MyJavaClass.fun2(new Date()); // class jdk.nashorn.internal.objects.NativeDate MyJavaClass.fun2(new RegExp()); // class jdk.nashorn.internal.objects.NativeRegExp MyJavaClass.fun2({foo: 'bar'}); // class jdk.nashorn.internal.scripts.JO4 JavaScript原始类型转换为合适的Java包装类，而JavaScript原生对象会使用内部的适配器类来表示。要记住jdk.nashorn.internal中的类可能会有所变化，所以不应该在客户端面向这些类来编程。 任何标记为“内部”的东西都可能会从你那里发生改变。 ScriptObjectMirror在向Java传递原生JavaScript对象时，你可以使用ScriptObjectMirror类，它实际上是底层JavaScript对象的Java表示。ScriptObjectMirror实现了Map接口，位于jdk.nashorn.api中。这个包中的类可以用于客户端代码。 下面的例子将参数类型从Object改为ScriptObjectMirror，所以我们可以从传入的JavaScript对象中获得一些信息。 static void fun3(ScriptObjectMirror mirror) { System.out.println(mirror.getClassName() + &quot;: &quot; + Arrays.toString(mirror.getOwnKeys(true))); } 当向这个方法传递对象（哈希表）时，在Java端可以访问其属性： MyJavaClass.fun3({ foo: 'bar', bar: 'foo' }); // Object: [foo, bar] 我们也可以在Java中调用JavaScript的成员函数。让我们首先定义JavaScript Person类型，带有属性firstName 和 lastName，以及方法getFullName。 function Person(firstName, lastName) { this.firstName = firstName; this.lastName = lastName; this.getFullName = function() { return this.firstName + &quot; &quot; + this.lastName; } } JavaScript方法getFullName可以通过callMember()在ScriptObjectMirror上调用。 static void fun4(ScriptObjectMirror person) { System.out.println(&quot;Full Name is: &quot; + person.callMember(&quot;getFullName&quot;)); } 当向Java方法传递新的Person时，我们会在控制台看到预期的结果： var person1 = new Person(&quot;Peter&quot;, &quot;Parker&quot;); MyJavaClass.fun4(person1); // Full Name is: Peter Parker 语言扩展Nashorn定义了多种对ECMAScript标准的语言和API扩展。让我们看一看最新的特性： 类型数组JavaScript的原生数组是无类型的。Nashron允许你在JavaScript中使用Java的类型数组： var IntArray = Java.type(&quot;int[]&quot;); var array = new IntArray(5); array[0] = 5; array[1] = 4; array[2] = 3; array[3] = 2; array[4] = 1; try { array[5] = 23; } catch (e) { print(e.message); // Array index out of range: 5 } array[0] = &quot;17&quot;; print(array[0]); // 17 array[0] = &quot;wrong type&quot;; print(array[0]); // 0 array[0] = &quot;17.3&quot;; print(array[0]); // 17 int[]数组就像真实的Java整数数组那样。但是此外，在我们试图向数组添加非整数时，Nashron在背后执行了一些隐式的转换。字符串会自动转换为整数，这十分便利。 集合和范围遍历我们可以使用任何Java集合，而避免使用数组瞎折腾。首先需要通过Java.type定义Java类型，之后创建新的实例。 var ArrayList = Java.type('java.util.ArrayList'); var list = new ArrayList(); list.add('a'); list.add('b'); list.add('c'); for each (var el in list) print(el); // a, b, c 为了迭代集合和数组，Nashron引入了for each语句。它就像Java的范围遍历那样工作。 下面是另一个集合的范围遍历示例，使用HashMap： var map = new java.util.HashMap(); map.put('foo', 'val1'); map.put('bar', 'val2'); for each (var e in map.keySet()) print(e); // foo, bar for each (var e in map.values()) print(e); // val1, val2 Lambda表达式和数据流每个人都热爱lambda和数据流 — Nashron也一样！虽然ECMAScript 5.1没有Java8 lmbda表达式的简化箭头语法，我们可以在任何接受lambda表达式的地方使用函数字面值。 var list2 = new java.util.ArrayList(); list2.add(&quot;ddd2&quot;); list2.add(&quot;aaa2&quot;); list2.add(&quot;bbb1&quot;); list2.add(&quot;aaa1&quot;); list2.add(&quot;bbb3&quot;); list2.add(&quot;ccc&quot;); list2.add(&quot;bbb2&quot;); list2.add(&quot;ddd1&quot;); list2 .stream() .filter(function(el) { return el.startsWith(&quot;aaa&quot;); }) .sorted() .forEach(function(el) { print(el); }); // aaa1, aaa2 类的继承Java类型可以由Java.extend轻易扩展。就像你在下面的例子中看到的那样，你甚至可以在你的脚本中创建多线程的代码： var Runnable = Java.type('java.lang.Runnable'); var Printer = Java.extend(Runnable, { run: function() { print('printed from a separate thread'); } }); var Thread = Java.type('java.lang.Thread'); new Thread(new Printer()).start(); new Thread(function() { print('printed from another thread'); }).start(); // printed from a separate thread // printed from another thread 参数重载方法和函数可以通过点运算符或方括号运算符来调用： var System = Java.type('java.lang.System'); System.out.println(10); // 10 System.out[&quot;println&quot;](11.0); // 11.0 System.out[&quot;println(double)&quot;](12); // 12.0 当使用重载参数调用方法时，传递可选参数类型println(double)会指定所调用的具体方法。 Java Beans你可以简单地使用属性名称来向Java Beans获取或设置值，不需要显式调用读写器： var Date = Java.type('java.util.Date'); var date = new Date(); date.year += 1900; print(date.year); // 2014 函数字面值对于简单的单行函数，我们可以去掉花括号： function sqr(x) x * x; print(sqr(3)); // 9 属性绑定两个不同对象的属性可以绑定到一起： var o1 = {}; var o2 = { foo: 'bar'}; Object.bindProperties(o1, o2); print(o1.foo); // bar o1.foo = 'BAM'; print(o2.foo); // BAM 字符串去空白我喜欢去掉空白的字符串： print(&quot; hehe&quot;.trimLeft()); // hehe print(&quot;hehe &quot;.trimRight() + &quot;he&quot;); // hehehe 位置以防你忘了自己在哪里： print(__FILE__, __LINE__, __DIR__); 导入作用域有时一次导入多个Java包会很方便。我们可以使用JavaImporter类，和with语句一起使用。所有被导入包的类文件都可以在with语句的局部域中访问到。 var imports = new JavaImporter(java.io, java.lang); with (imports) { var file = new File(__FILE__); System.out.println(file.getAbsolutePath()); // /path/to/my/script.js } 数组转换一些类似java.util的包可以不使用java.type或JavaImporter直接访问： var list = new java.util.ArrayList(); list.add(&quot;s1&quot;); list.add(&quot;s2&quot;); list.add(&quot;s3&quot;); 下面的代码将Java列表转换为JavaScript原生数组： var jsArray = Java.from(list); print(jsArray); // s1,s2,s3 print(Object.prototype.toString.call(jsArray)); // [object Array] 下面的代码执行相反操作： var javaArray = Java.to([3, 5, 7, 11], &quot;int[]&quot;); 访问超类在JavaScript中访问被覆盖的成员通常比较困难，因为Java的super关键字在ECMAScript中并不存在。幸运的是，Nashron有一套补救措施。 首先我们需要在Java代码中定义超类： class SuperRunner implements Runnable { @Override public void run() { System.out.println(&quot;super run&quot;); } } 下面我在JavaScript中覆盖了SuperRunner。要注意创建新的Runner实例时的Nashron语法：覆盖成员的语法取自Java的匿名对象。 var SuperRunner = Java.type('com.winterbe.java8.SuperRunner'); var Runner = Java.extend(SuperRunner); var runner = new Runner() { run: function() { Java.super(runner).run(); print('on my run'); } } runner.run(); // super run // on my run 我们通过Java.super()扩展调用了被覆盖的SuperRunner.run()方法。 加载脚本在JavaScript中加载额外的脚本文件非常方便。我们可以使用load函数加载本地或远程脚本。 我在我的Web前端中大量使用Underscore.js，所以让我们在Nashron中复用它： load('http://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.6.0/underscore-min.js'); var odds = _.filter([1, 2, 3, 4, 5, 6], function (num) { return num % 2 == 1; }); print(odds); // 1, 3, 5 外部脚本会在相同JavaScript上下文中被执行，所以我们可以直接访问underscore 的对象。要记住当变量名称互相冲突时，脚本的加载可能会使你的代码崩溃。 这一问题可以通过把脚本文件加载到新的全局上下文来绕过： loadWithNewGlobal('script.js'); 命令行脚本如果你对编写命令行（shell）脚本感兴趣，来试一试Nake吧。Nake是一个Java 8 Nashron的简化构建工具。你只需要在项目特定的Nakefile中定义任务，之后通过在命令行键入nake -- myTask来执行这些任务。任务编写为JavaScript，并且在Nashron的脚本模式下运行，所以你可以使用你的终端、JDK8 API和任意Java库的全部功能。 对Java开发者来说，编写命令行脚本是前所未有的简单… MiscOptional 方法 描述 empty 返回一个空的 Optional 实例 filter 如果值存在并且满足提供的断言， 就返回包含该值的 Optional 对象；否则返回一个空的 Optional 对象 map 如果值存在，就对该值执行提供的 mapping 函数调用 flatMap 如果值存在，就对该值执行提供的 mapping 函数调用，返回一个 Optional 类型的值，否则就返 回一个空的 Optional 对象 get 如果该值存在，将该值用 Optional 封装返回，否则抛出一个 NoSuchElementException 异常 ifPresent 如果值存在，就执行使用该值的方法调用，否则什么也不做 isPresent 如果值存在就返回 true，否则返回 false of 将指定值用 Optional 封装之后返回，如果该值为 null，则抛出一个 NullPointerException 异常 ofNullable 将指定值用 Optional 封装之后返回，如果该值为 null，则返回一个空的 Optional 对象 orElse 如果有值则将其返回，否则返回一个默认值 orElseGet 如果有值则将其返回，否则返回一个由指定的 Supplier 接口生成的值 orElseThrow 如果有值则将其返回，否则抛出一个由指定的 Supplier 接口生成的异常 Optional 可以很优雅地避免了 NullPointerException ，这里我们简单举个例子， ptional&lt;String&gt; optional = Optional.of(&quot;bam&quot;); optional.isPresent();// true optional.get(); // &quot;bam&quot; optional.orElse(&quot;fallback&quot;); // &quot;bam&quot; optional.ifPresent((s) -&gt; System.out.println(s.charAt(0))); // &quot;b&quot; Base64// Encoding a string to base 64 Base64.Encoder encoder = Base64.getEncoder(); String normalString = &quot;username:password&quot;; String encodedString = encoder.encodeToString( normalString.getBytes(StandardCharsets.UTF_8) ); // Decoding a base 64 encoded string String encodedString = &quot;dXNlcm5hbWU6cGFzc3dvcmQ=&quot;; Base64.Decoder decoder = Base64.getDecoder(); byte[] decodedByteArray = decoder.decode(encodedString); //Verify the decoded string System.out.println(new String(decodedByteArray)); // Wrap to a base 64 encoded output stream Path originalPath = Paths.get(&quot;c:/temp&quot;, &quot;mail.txt&quot;); Path targetPath = Paths.get(&quot;c:/temp&quot;, &quot;encoded.txt&quot;); Base64.Encoder mimeEncoder = Base64.getMimeEncoder(); try(OutputStream output = Files.newOutputStream(targetPath)){ //Copy the encoded file content to target file Files.copy(originalPath, mimeEncoder.wrap(output)); //Or simply use the encoded output stream OutputStream encodedStrem = mimeEncoder.wrap(output); } Annotation原文链接 Java 8在两个方面对注解机制进行了改进，分别为: 你现在可以定义重复注解 你可以为任何目标添加注解 Java中的注解是一种对程序元素进行配置，提供附加信息的机制。 重复注解之前版本的Java禁止对同样的注解类型声明多次。由于这个原因，下面的第二句代码是无效的。 @interface Author { String name(); } @Author(name=&quot;Raoul&quot;) @Author(name=&quot;Mario&quot;) @Author(name=&quot;Alan&quot;) class Book{ } Java程序员经常通过一些惯用法绕过这一限制。例如可以声明一个新的注解，它包含了你希望重复的注解数组。这种方法的形式如下: @interface Author { String name(); } @interface Authors { Author[] value(); } @Authors( { @Author(name=&quot;Raoul&quot;), @Author(name=&quot;Mario&quot;) , @Author(name=&quot;Alan&quot;) } ) class Book{} Book类的嵌套注解相当难看。这就是Java 8想要从根本上移除这一限制的原因，去掉这一限制后，代码的可读性会好很多。 现在，如果你的配置允许重复注解，你可以毫无顾虑地一次声明 多个同一种类型的注解。它目前还不是默认行为，你需要显式地要求进行重复注解。 创建一个重复注解 如果一个注解在设计之初就是可重复的，你可以直接使用它。但是，如果你提供的注解是为用户提供的，那么就需要做一些工作，说明该注解可以重复。下面是你需要执行的两个步骤: @Repeatable(Authors.class) @interface Author { String name(); } @interface Authors { Author[] value(); } 完成了这样的定义之后，Book类可以通过多个@Author注解进行注释，如下所示: @Author(name=&quot;Raoul&quot;) @Author(name=&quot;Mario&quot;) @Author(name=&quot;Alan&quot;) class Book{ } 编译时，Book会被认为使用了 @Authors({@Author(name=&quot;Raoul&quot;), @Author(name =”Mario”), @Author(name=”Alan”)}) 这样的形式进行了注解，所以，你可以把这种新的机 制看成是一种语法糖，它提供了Java程序员之前利用的惯用法类似的功能。为了确保与反射方法 在行为上的一致性，注解会被封装到一个容器中。Java API中的getAnnotation(Class annotation-Class)方法会为注解元素返回类型为T的注解。如果实际情况有多个类型为T的注解，该方法的返回到底是哪一个呢? 类Class提供了一个新的getAnnotationsByType 方法，它可以帮助我们更好地使用重复注解。比如，你可以像下面这样打印输出Book类的所有Author注解: public static void main(String[] args) { Author[] authors = Book.class.getAnnotationsByType(Author.class); //java8提供的循环及lambda表达式 Arrays.asList(authors).forEach(a -&gt; { System.out.println(a.name()); } ); } 类型注解从Java 8开始，注解已经能应用于任何目标。这其中包括new操作符、类型转换、instanceof检查、泛型类型参数，以及implements和throws子句。 这里，我们举了一个例子，这个例子中 类型为String的变量name不能为空，所以我们使用了@NonNull对其进行注解: @NonNull String name = person.getName(); 类似地，你可以对列表中的元素类型进行注解: List&lt;@NonNull Car&gt; cars = new ArrayList&lt;&gt;(); 利用好对类型的注解非常有利于我们对程序进行分析。这两个例子中，通过这一工具我们可以确保getName不返回空，cars列表中的元素总是非空值。这会 极大地帮助你减少代码中不期而至的错误。 Java 8并未提供官方的注解或者一种工具能以开箱即用的方式使用它们。它仅仅提供了一种功能，你使用它可以对不同的类型添加注解。 泛型类型推断Java 8对泛型参数的推断进行了增强。相信你对Java 8之前版本中的类型推断已经比较熟了。 比如，Java中的方法emptyList方法定义如下: static &lt;T&gt; List&lt;T&gt; emptyList(); emptyList方法使用了类型参数T进行参数化。你可以像下面这样为该类型参数提供一个显式的类型进行函数调用: List&lt;Car&gt; cars = Collections.&lt;Car&gt;emptyList(); 不过Java也可以推断泛型参数的类型。上面的代码和下面这段代码是等价的: List&lt;Car&gt; cars = Collections.emptyList(); Java 8出现之前，这种推断机制依赖于程序的上下文(即目标类型)，具有一定的局限性。 Java 8中，目标类型包括向方法传递的参数，因此你不再需要提供显式的泛型参数 RegexConvert Regex to Predicatelong count = Stream.of(&quot;bob@gmail.com&quot;, &quot;alice@hotmail.com&quot;) .filter(Pattern.compile(&quot;.*@gmail\\\\.com&quot;).asPredicate()) .count(); System.out.println(count); Using Regex using Pattern.matcher()Pattern pattern = Pattern.compile(&quot;^(.+)@example.com$&quot;); // Input list List&lt;String&gt; emails = Arrays.asList(&quot;alex@example.com&quot;, &quot;bob@yahoo.com&quot;, &quot;cat@google.com&quot;, &quot;david@example.com&quot;); for(String email : emails) { Matcher matcher = pattern.matcher(email); if(matcher.matches()) { System.out.println(email); } } FileReadRead file line by line – Java 8 Stream Path path = Paths.get(&quot;c:/temp&quot;, &quot;data.txt&quot;); //The stream hence file will also be closed here try(Stream&lt;String&gt; lines = Files.lines(path)) { Optional&lt;String&gt; hasPassword = lines.filter(s -&gt; s.contains(&quot;password&quot;)).findFirst(); if(hasPassword.isPresent()){ System.out.println(hasPassword.get()); } } // or Path path = Paths.get(&quot;c:/temp&quot;, &quot;data.txt&quot;); // When filteredLines is closed, it closes underlying stream as well as underlying file. try(Stream&lt;String&gt; filteredLines = Files.lines(path).filter(s -&gt; s.contains(&quot;password&quot;))) { Optional&lt;String&gt; hasPassword = filteredLines.findFirst(); if(hasPassword.isPresent()){ System.out.println(hasPassword.get()); } } Read file line by line – FileReaderTill java 7, you could read a file using FileReader in various ways. There may be other effective and better variations of this code but that is not the man point of this post. I am giving just as reminder. File file = new File(&quot;c:/temp/data.txt&quot;); FileReader fr = new FileReader(file); BufferedReader br = new BufferedReader(fr); String line; while((line = br.readLine()) != null) { if(line.contains(&quot;password&quot;)){ System.out.println(line); } } br.close(); fr.close(); WriteJava 8 write to file using BufferedWriterBufferedWriter is used to write text to a character or byte stream. Before printing the characters, it stores the characters in buffer and print in bunches. Without buffering, each invocation of a print() method would cause characters to be converted into bytes that would then be written immediately to the file, which can be very inefficient. Java program to write content to file using Java 8 APIs is – //Get the file reference Path path = Paths.get(&quot;c:/output.txt&quot;); //Use try-with-resource to get auto-closeable writer instance try (BufferedWriter writer = Files.newBufferedWriter(path)) { writer.write(&quot;Hello World !!&quot;); } Write to file using Files.write()Using Files.write() method is also pretty much clean code. String content = &quot;Hello World !!&quot;; Files.write(Paths.get(&quot;c:/output.txt&quot;), content.getBytes()); 相关链接java8-tutorial howtodoinjava java8 JavaLambdaInternals collection-pipeline learn-java8 java8官网笔记教程 示例代码","link":"/2021/09/10/JAVA8/"},{"title":"Java 开发基础规范（初稿）","text":"本文初衷 以本篇为引，获取到有识之士的一些意见或是看法，促进成长！ 重要说明 2017-01：阿里公开了他们自己的规范，写得还是很合理的，也很清晰，重点推荐。 在 Google 里面搜索：阿里巴巴 JAVA 开发手册 命名、规范Java 相关命名、规范 命名： Java 类名命名（用名词性单词组合） 普通类名：首字母大写，需要两个、多个单词表达的，使用大驼峰命名法进行命名，eg：CategoryService 抽象类名：在普通类名的基础上对其命名后加上 Abstract，eg：CategoryAbstract 自定义异常类名：在普通类名的基础上对其命名后加上 Exception，eg：CategoryException 队列类名：在普通类名的基础上对其命名后加上 Queue，eg：CategoryQueue 后台任务类名：在普通类名的基础上对其命名后加上 Task 或 Job，eg：CategoryTask、CategoryJob Servlet 类名：在普通类名的基础上对其命名后加上 Servlet，eg：CategoryServlet Filter 类名：在普通类名的基础上对其命名后加上 Filter，eg：CategoryFilter 工厂类名：在普通类名的基础上对其命名后加上 Factory，eg：CategoryFactory 工具类名：在普通类名的基础上对其命名后加上 Util，eg：CategoryUtil 测试类名：在普通类名的基础上对其命名后加上 Test，eg：CategoryServiceTest 数据库访问层接口类名：在普通类名的基础上对其命名后加上 Dao，eg：CategoryDao 数据库访问层实现类名：在普通类名的基础上对其命名后加上 DaoImpl，eg：CategoryDaoImpl 业务层接口类名：在普通类名的基础上对其命名后加上 Service，eg：CategoryService 业务层实现类名：在普通类名的基础上对其命名后加上 ServiceImpl，eg：CategoryServiceImpl 控制层类名：在普通类名的基础上对其命名后加上 Controller，eg：CategoryController、CategoryAction、CategoryActivity 对象扩展类名：在普通类名的基础上对其命名后加上 VO，eg：CategoryVO(Value Object)、CategoryDTO(Data Transfer Object)、CategoryPOJO(plain ordinary java object) 常量名：全部字母大写，有多个单词用下划线分隔，eg：MY_AGE 常规变量名：首字母小写，需要两个、多个单词表达的，使用小驼峰命名法进行命名，eg：categoryName 复数变量名：首字母小写，需要两个、多个单词表达的，使用小驼峰命名法进行命名，eg： List：categoryList Map：categoryMap Set：categorySet package 名：所有单词全部小写，即使有多个单词组成，且不能使用下划线连接，或是其他任意字符连接，eg：googlebook 方法参数名：首字母小写，需要两个、多个单词表达的，使用小驼峰命名法进行命名，eg：categoryName 方法命名（用动词性单词开头）： 数据库访问层方法名 saveCategory() deleteCategoryByObject() deleteCategoryById() updateCategoryByObject() updateCategoryById() findCategoryList() findCategory() 业务层方法名 saveCategory() deleteCategoryByObject() deleteCategoryById() updateCategoryByObject() updateCategoryById() findCategoryList() findCategory() initCategory() openConnection() closeConnection() writeFile() readFile() 视图层（JSP、FreeMarker 等）： categoryList categoryAdd categoryUpdate categoryEdit categoryDetail categoryTree 规范： 当一个类有多个构造函数，或是多个同名方法，这些函数 / 方法应该按顺序出现在一起，中间不要放进其它函数 / 方法 导入包的时候，import 后面不要使用通配符 * 来代替有些包的导入 大括号与 if, else, for, do, while 语句一起使用，即使只有一条语句(或是空)，也应该把大括号写上 不要使用组合声明，比如 int a, b; 需要时才声明，并尽快进行初始化 注解紧跟在文档块后面，应用于类、方法和构造函数，一个注解独占一行 注释： 块注释 /* logger.info(&quot;---------开始---------&quot;); SubmitOrderInfo submitOrderInfo = getSubmitOrderInfo(orderId); */ 行注释，只用来注释 //ResultInfo resultInfo = orderService.orderStateUpdate(voucherNo); 行注释，用来解释 private int categoryId = 1; // 1 是顶级分类的 ID Mysql 相关命名、规范 表名：全部小写，需要两个、多个单词表达的使用下划线隔开，eg：prd_category 字段名：全部小写，需要两个、多个单词表达的使用下划线隔开，eg：category_name 注释： 行注释 # 下面内容需要先执行 -- 下面内容需要先执行 块注释 /* 下面内容需要先执行 需要注意的是：分类的 ID 需要先检查 */ 程序 SQL 补丁文件命名，eg： 20160306-update-更新所有会员密码 20160312-delete-删除指定会员密码 20160313-insert-新增会员数据 20160315-alter-更新会员邮箱字段长度 编码 数据源连接：jdbc:mysql://localhost:3306/youshop?characterEncoding=utf-8 Java 文件编码：UTF-8 XML 文件编码：UTF-8 Properties 文件编码：UTF-8 Mysql 字符集：UTF-8 其他 Tab 缩进为 4 个空格，使用 IntelliJ IDEA 标准格式化即可 TODO 标记必须使用个人自定义 TODO，不能使用公共的 SVN、Git 提交必须有 Commit Message 资料 https://github.com/google/styleguide http://www.cnblogs.com/lanxuezaipiao/p/3534447.html 感谢 感谢 Lindp 提供意见","link":"/2016/03/15/Java-Style/"},{"title":"JS逆向反调试和反反调试","text":"写在最前面本文转载于CSDN大佬: @花爷已获得其本人允许 根据《中华人民共和国著作权法》规定 1、已在报刊上刊登或者网络上传播的作品，除著作权人声明或者上载该作品的网络服务提供者受著作权人的委托声明不得转载、摘编的以外，网站予以转载、摘编，并按有关规定支付报酬、注明出处的，不构成侵权。 2、为个人学习、研究或者欣赏，使用他人已经发表的作品而转载的不属于侵权，可以不经著作权人许可，不向其支付报酬，但应当指明作者姓名、作品名称，并且不得侵犯著作权人依照本法享有的其他权利。 切入JS逆向反调试现在调试JS各种反调，既然有反调，那我们就肯定有过这个反调试的方法。这里给大家推荐一个JS逆向练习平台。 JS逆向练习平台 1.我们这里讲的是第5题，它这里的反调试是不让你打开开发者人员工具。打开开发者人员工具，就自动返回主页面。 2.思路：a：它不让我打开开发者人员工具，肯定是在打开开发者人员工具之后它检测了什么玩意 b：.那他就是调用了浏览器内置的东西，我这个就解决方法是下页面事件监听断点，如图： 这里的意思：事件侦听器断点 event listener breakpoints事件突变 Dom mutation下面还有一些我就不翻译了，有兴趣可以去看看，翻译一下，小弟英语不好。下这个断点之后，跳转完页面，加载ok之后他就会断下来，如图，我们就可以得到这道题的答案了。 答案大佬打了一下马赛克，这边大佬不公布答案，大家可以尝试一下。 切入JS反反调试你千万别跟任何人谈任何事情。你只要一谈起，就会想念起每一个人来，我只知道我很想念我所谈到的每一个人。——Ｊ·Ｄ·塞林格《麦田里的守望者》 [JS逆向]过无限debugger调试在JS逆向过程当中，获取用发F12抓取XHR的时候，常常会发现网页不让我们打开F12开发人员工具。如果这个时候我们开启工具中禁止断点之后，虽然我们可以抓取xhr，但是这样我们无法调试代码部分了，开启了禁止断点之后，我们自己也无法在代码当中下断点了 需求在采集某些网站时，目标网站为了防止别人分析调试前端代码，采取了反调试措施。其中一种做法是当你按F12进入浏览器控制台后，浏览器会自动命中debugger断点，并且无限循环，导致无法调试。以食品药品监督管理总局数据查询网站为例。如下图: 按F12进入控制台 解决方法禁用浏览器断点点击图中按钮，之后将不会再命中任何断点。这种方法虽然可以防止无限循环命中debugger断点，但是也存在很大的缺陷，因为对于其他代码，我们还是需要断点调试功能的。所以这个方法仅限于静态分析。 利用中间人修改响应代码用Fiddler删除响应代码中的debugger即可达到目的实现的核心代码很简单:如下 FiddlerApplication.BeforeRequest += delegate(Fiddler,Session oS) { oS.bBufferResponse = true; } FiddlerApplication.BeforeResponse += (oS) =&gt; { oS.utilDecodeResponse(); oS.utilReplaceLnResponse(&quot;debugger&quot;, String.Empty); /* * Code 实在是找不到FiddlerCode的代码格式，只能用Python代替一下 * */ } 实际使用中发现,位于响应html页的debugger被删除了，但是仍然会弹出断点。分析页面得到，debugger断点位置一共有2处 第一处位于”http://qy1.sfda.gov.cn/datasearch/face3/dir.html&quot;debugger以明文形式存在,Fiddler删除的就是这部分。通过分析另一处debugger位置，发现debugger是通过eval去实现的，响应中并没有直接出现debugger字段，所以没有被替换掉。 在Console输入 &gt; _$uj() &lt;· &quot;eval&quot; &gt; _$dQ() &lt;· &quot;(function() {var a = new Date(); debugger; return new Date() - a &gt; 100;}())&quot; &gt; _ 代码经过强混淆，读者看到的函数名称是和我不一样的。 利用浏览器插件修改响应代码具体原理和使用Fiddler是相同的，通过浏览器插件将请求重定向以达到修改代码的目的。也存在相同的问题 手动替换代码既然修改响应结果无法满足需求，那只能从代码中寻找突破了。以本文的网站为例，查看debugger断点处的调用栈堆，找到调用位置。其实在上文中间人方式结尾处已经发现了。是通过eval去实现断点的。我们先构造一个空方法 将目标网站的方法偷梁换柱由于网站代码强混淆，所以函数名称会不一样。下面放个GIF图完美解决 但是注意不要刷新，页面刷新后需要重新替换。 傻瓜式技巧上文的几种方法，要么是存在缺陷，要么是步骤较为繁琐，我这边还有个压箱底的神技，不需要写任何代码，鼠标点点点就能够满足需求，为了避免伸手党，所以不放了。 总结 1-DebugPort2-KdDisableDebugger3-IsDebuggerPresent和CheckRemoteDebuggerPresent4-hook http://www.moguizuofang.com/bbs/thread-3235-1-1.html http://bbs.pediy.com/showthread.php?t=126802 http://bbs.pediy.com/showthread.php?t=129810 DebugPort是进程EPROCESS结构里的一个成员，指向了一个用于进程调试的对象，如果一个进程不在被调试的时候那么就是NULL，否则他是一个指针。该对象负责在调试器与被调进程之间进行调试事件传递，因此被称为调试端口。被调试程序的事件由这个端口发送到调试器进程的。 HOOK系统中一些与调试相关的函数，也可以防止被各种调试器调试。比如某款程序在内核中就HOOK了下面这些函数：NtOpenThread（）：防止调试器在程序内部创建线程NtOpenProcess（）：防止OD（OllyDbg）等调试工具在进程列表中看到KiAttachProcess（）：防止被附加上NtReadVirtualMemory（）：防止被读内存NtWriteVirtualMemory（）：防止内存被写KdReceivePacket（）：KDCOME.dll 中Com串口接收数据函数KdSendPacket（）：KDCOME.dll 中Com串口发送数据函数，可以HOOK这2个函数用来防止双机调试。 反反调试的思路也就出来了。针对清零DebugPort来防止调试的方法，可以通过对DebugPort内存地址下内存断点：ba w4 debugport_addr这样一旦有程序代码在修改DebugPort，就会被断下，从而找到对应的清零DebugPort的反调试代码，然后对这部分代码进行patch（用机器码0×90(nop)或者0xC3(ret)取代），从而让它失去作用，当然有的程序会对代码进行校验，一旦发现代码被篡改，就会采取保护措施，比如抛出异常或者退出程序。针对调用系统函数如KdDisableDebugger（）来检测调试器存在从而禁止被调试的方法，可以在对应的这些函数的地址下断点，然后对相关的代码进行patch，然后使该函数判断失效。比如：bp KdDisableDebugger、eb xxx针对通过HOOK系统函数来防止进程被调试的方法，可以直接将这些系统函数的钩子直接恢复，可以通过内核驱动程序或者借助一些ARK工具（比如Pchunter）就可以直接检测和恢复这些函数钩子。 总结 -2 在调试一些病毒程序的时候，可能会碰到一些反调试技术，也就是说，被调试的程序可以检测到自己是否被调试器附加了，如果探知自己正在被调试，肯定是有人试图反汇编啦之类的方法破解自己。为了了解如何破解反调试技术，首先我们来看看反调试技术。 一、Windows API方法 Win32提供了两个API, IsDebuggerPresent和CheckRemoteDebuggerPresent可以用来检测当前进程是否正在被调试，以IsDebuggerPresent函数为例，例子如下： BOOL ret = IsDebuggerPresent(); printf(&quot;ret = %d\\n&quot;, ret); 破解方法很简单，就是在系统里将这两个函数hook掉，让这两个函数一直返回false就可以了，网上有很多做hook API工作的工具，也有很多工具源代码是开放的，所以这里就不细谈了。 二、查询进程PEB的BeingDebugged标志位 当进程被调试器所附加的时候，操作系统会自动设置这个标志位，因此在程序里定期查询这个标志位就可以了，例子如下： bool PebIsDebuggedApproach() { char result = 0; __asm { // 进程的PEB地址放在fs这个寄存器位置上 mov eax, fs:[30h] // 查询BeingDebugged标志位 mov al, BYTE PTR [eax + 2] mov result, al } return result != 0; } 三、查询进程PEB的NtGlobal标志位 跟第二个方法一样，当进程被调试的时候，操作系统除了修改BeingDebugged这个标志位以外，还会修改其他几个地方，其中NtDll中一些控制堆（Heap）操作的函数的标志位就会被修改，因此也可以查询这个标志位，例子如下： bool PebNtGlobalFlagsApproach() { int result = 0; __asm { // 进程的PEB mov eax, fs:[30h] // 控制堆操作函数的工作方式的标志位 mov eax, [eax + 68h] // 操作系统会加上这些标志位FLG_HEAP_ENABLE_TAIL_CHECK, // FLG_HEAP_ENABLE_FREE_CHECK and FLG_HEAP_VALIDATE_PARAMETERS， // 它们的并集就是x70 // // 下面的代码相当于C/C++的 // eax = eax &amp; 0x70 and eax, 0x70 mov result, eax } return result != 0; } 四、查询进程堆的一些标志位 这个方法是第三个方法的变种，只要进程被调试，进程在堆上分配的内存，在分配的堆的头信息里，ForceFlags这个标志位会被修改，因此可以通过判断这个标志位的方式来反调试。因为进程可以有很多的堆，因此只要检查任意一个堆的头信息就可以了，所以这个方法貌似很强大，例子如下： bool HeapFlagsApproach() { int result = 0; __asm { // 进程的PEB mov eax, fs:[30h] // 进程的堆，我们随便访问了一个堆，下面是默认的堆 mov eax, [eax + 18h] // 检查ForceFlag标志位，在没有被调试的情况下应该是 mov eax, [eax + 10h] mov result, eax } return result != 0; } 五、使用NtQueryInformationProcess函数 NtQueryInformationProcess函数是一个未公开的API，它的第二个参数可以用来查询进程的调试端口。如果进程被调试，那么返回的端口值会是-1，否则就是其他的值。由于这个函数是一个未公开的函数，因此需要使用LoadLibrary和GetProceAddress的方法获取调用地址，示例代码如下： // 声明一个函数指针。 typedef NTSTATUS (WINAPI *NtQueryInformationProcessPtr)( HANDLE processHandle, PROCESSINFOCLASS processInformationClass, PVOID processInformation, ULONG processInformationLength, PULONG returnLength); bool NtQueryInformationProcessApproach() { int debugPort = 0; HMODULE hModule = LoadLibrary(TEXT(&quot;Ntdll.dll &quot;)); NtQueryInformationProcessPtr NtQueryInformationProcess = (NtQueryInformationProcessPtr)GetProcAddress(hModule, &quot;NtQueryInformationProcess&quot;); if ( NtQueryInformationProcess(GetCurrentProcess(), (PROCESSINFOCLASS)7, &amp;debugPort, sizeof(debugPort), NULL) ) printf(&quot;[ERROR NtQueryInformationProcessApproach] NtQueryInformationProcess failed\\n&quot;); else return debugPort == -1; return false; } 六、NtSetInformationThread方法 这个也是使用Windows的一个未公开函数的方法，你可以在当前线程里调用NtSetInformationThread，调用这个函数时，如果在第二个参数里指定0x11这个值（意思是ThreadHideFromDebugger），等于告诉操作系统，将所有附加的调试器统统取消掉。示例代码: // 声明一个函数指针。 typedef NTSTATUS (*NtSetInformationThreadPtr)(HANDLE threadHandle, THREADINFOCLASS threadInformationClass, PVOID threadInformation, ULONG threadInformationLength); void NtSetInformationThreadApproach() { HMODULE hModule = LoadLibrary(TEXT(&quot;ntdll.dll&quot;)); NtSetInformationThreadPtr NtSetInformationThread = (NtSetInformationThreadPtr)GetProcAddress(hModule, &quot;NtSetInformationThread&quot;); NtSetInformationThread(GetCurrentThread(), (THREADINFOCLASS)0x11, 0, 0); } 七、触发异常的方法 这个技术的原理是，首先，进程使用SetUnhandledExceptionFilter函数注册一个未处理异常处理函数A，如果进程没有被调试的话，那么触发一个未处理异常，会导致操作系统将控制权交给先前注册的函数A；而如果进程被调试的话，那么这个未处理异常会被调试器捕捉，这样我们的函数A就没有机会运行了。 这里有一个技巧，就是触发未处理异常的时候，如果跳转回原来代码继续执行，而不是让操作系统关闭进程。方案是在函数A里修改eip的值，因为在函数A的参数_EXCEPTION_POINTERS里，会保存当时触发异常的指令地址，所以在函数A里根据这个指令地址修改寄存器eip的值就可以了，示例代码如下： // 进程要注册的未处理异常处理程序A LONG WINAPI MyUnhandledExceptionFilter(struct _EXCEPTION_POINTERS *pei) { SetUnhandledExceptionFilter((LPTOP_LEVEL_EXCEPTION_FILTER) pei-&gt;ContextRecord-&gt;Eax); // 修改寄存器eip的值 pei-&gt;ContextRecord-&gt;Eip += 2; // 告诉操作系统，继续执行进程剩余的指令（指令保存在eip里），而不是关闭进程 return EXCEPTION_CONTINUE_EXECUTION; } bool UnhandledExceptionFilterApproach() { SetUnhandledExceptionFilter(MyUnhandledExceptionFilter); __asm { // 将eax清零 xor eax, eax // 触发一个除零异常 div eax } return false; } 八、调用DeleteFiber函数 如果给DeleteFiber函数传递一个无效的参数的话，DeleteFiber函数除了会抛出一个异常以外，还是将进程的LastError值设置为具体出错原因的代号。然而，如果进程正在被调试的话，这个LastError值会被修改，因此如果调试器绕过了第七步里讲的反调试技术的话，我们还可以通过验证LastError值是不是被修改过来检测调试器的存在，示例代码： bool DeleteFiberApproach() { char fib[1024] = {0}; // 会抛出一个异常并被调试器捕获 DeleteFiber(fib); // 0x57的意思是ERROR_INVALID_PARAMETER return (GetLastError() != 0x57); }","link":"/2021/01/26/JS%E5%8F%8D%E8%B0%83%E8%AF%95/"},{"title":"Linux服务器初始化","text":"当我们开始使用一个新的服务器的时候，首先一定要对服务器的登陆等做一些修改工作，笔者曾经就因为对服务器登陆安全没有重视，导致服务器数据全部丢失。接下来我们按照步骤，罗列出应该做的一些事情。 修改ssh端口号第一件事情： 修改ssh端口号： 之后加上一个端口比如说50000 vi /etc/ssh/sshd_config之后在port字段加上一个端口比如说50000，原来的端口号字段可能是被注释掉的，要先解除注释。 然后执行： service sshd restart 这个时候可能还要重新配置一下防火墙，开放50000端口，具体如何配置也可以参考这里的后半部分。但是目前，阿里云的服务器实测是不需要再配置防火墙的，但是需要去登陆到网页后台修改安全组。 之后就可以通过这样的方式登录了：(注意登录方式一定要写对) ssh root@115.29.102.81 -p 50000 创建用户这个时候我们还是用root进行操作，所以我们接下来要给自己创建一个账户，比如创建一个如下的用户： useradd xiaotao passwd xiaotao 可以用`ls -al /home/``查看一下账户 对创建的这个用户增加sudo权限： 相关配置文件/etc/sudoers中，但是这个文件是只读的，所以要更改一下权限 chmod u+w sudoers 然后进入这个文件在这里进行更改： root ALL=(ALL) ALL xiaotao ALL=(ALL) ALL 然后再改回权限： chmod u-w sudoers 注意一点，CentOS 7预设容许任何帐号透过ssh登入（也就是说自己根本不用改改，直接新建帐号登录即可），包括根和一般帐号，为了不受根帐号被黑客暴力入侵，我们必须禁止 root帐号的ssh功能，事实上root也没有必要ssh登入伺服器，因为只要使用su或sudo（当然需要输入root的密码）普通帐号便可以拥有root的权限。使用vim（或任何文本编辑器）开启的/ etc/ SSH/ sshd_config中，寻找： ＃PermitRootLogin yes 修改： PermitRootLogin no 配置公私钥加密登录这一步骤要切换到自己新建的用户，不能再用 root 用户了，否则可能无法正常登陆。 很多时候以上所说的还是不够安全，为了更加安全方便，我们采用公私钥对称加密登录，简单的讲做法就是再客户端生成一把私钥一把公钥，私钥是在客户端的，公钥上传到服务端，对称加密进行登录。 在客户端先进到这个目录： cd ~/.ssh 生成公钥和私钥（实际上如果之前有的话就不用重新生成了） ssh-keygen -t rsa 接下来把公钥上传到服务端 scp ~/.ssh/id_rsa.pub xiaotao@&lt;ssh_server_ip&gt;:~ 在服务端执行以下命令(如果没有相关的文件和文件夹要先进行创建，注意不要使用 sudo ) cat id_rsa.pub &gt;&gt; ～/.ssh/authorized_keys 配置服务器的/etc/ssh/sshd_config，下面是一些建议的配置： vim /etc/ssh/sshd_config # 禁用root账户登录，非必要，但为了安全性，请配置 PermitRootLogin no # 是否让 sshd 去检查用户家目录或相关档案的权限数据， # 这是为了担心使用者将某些重要档案的权限设错，可能会导致一些问题所致。 # 例如使用者的 ~.ssh/ 权限设错时，某些特殊情况下会不许用户登入 StrictModes no # 是否允许用户自行使用成对的密钥系统进行登入行为，仅针对 version 2。 # 至于自制的公钥数据就放置于用户家目录下的 .ssh/authorized_keys 内 RSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile %h/.ssh/authorized_keys #有了证书登录了，就禁用密码登录吧，安全要紧 PasswordAuthentication no 然后不要忘记 sudo service sshd restart 一般来讲，这样就算是成功了，我们可以在客户端尝试： ssh -i ~/.ssh/id_rsa remote_username@remote_ip 如果不行，可能是服务端或客户端相关 .ssh 文件权限不对，可以进行如下尝试： 服务端 chown -R 0700 ~/.ssh chown -R 0644 ~/.ssh/authorized_keys 客户端改一下 chmod 600 id_rsa","link":"/2018/04/11/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E5%92%8Cssh%E5%85%AC%E7%A7%81%E9%92%A5%E7%99%BB%E9%99%86/"},{"title":"一个Java程序员眼中的Mac OS（系列五：包管理工具）","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 帮助 Mac 后来者，减少他/她入门成本 先总结 有 Homebrew 配置，安装/维护一些开发包/组件会方便很多，提供开发者效率，仅此而已。 如果不是开发者，一般人就不用折腾这个，浪费时间 Homebrew 知识Homebrew 是什么 术语定义 Homebrew 官网：http://brew.sh/index_zh-cn.html 维基百科定义：https://weiji.ga/zh-hans/Homebrew 我的理解：类似 Ubuntu 的 apt-get，CentOS 的 yum。 同类常见技术 Fink MacPorts 同类技术比较： Homebrew 和 Fink、MacPort 相比有什么优势？ 学习前提/依赖 一点英文 一点 Unix/Linux 系统的思想 一点 shell 概念 为什么会出现 有些操作，命令行或者说脚本的方式效率是远高于 GUI 界面操作的，这个概念需要用过 Unix/Linux 做过开发的人会懂，特别是搞运维的。 如果你不理解，可以找一些运维的视频教程来看看，会有很多事情的处理都是搞脚本的做的。所以在维护一些开发包/组件的时候，懂一些包管理工具的话会帮你提高工作效率，仅此而已。 哪些人不喜欢它 不需要用到终端的用户 为什么学习它 方便安装开发包/组件，便于管理这些东西 我要怎么做 安装 先安装 Xcode command line tools： 打开终端，输入：xcode-select --install ，如果提示已经安装过了那就不用管了。 打开终端，复制该命令：ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 根据提示，按回车键 根据提示，输入当前用户的密码 终端中提示正在下载和安装 Homebrew，这个时间根据你网速的快慢来决定时间，反正我是很慢，还出现了下载速度 0kb 的状况，然后重新运行了一次就成功。 测试 打开终端，复制该命令：brew doctor 如果输出：Your system is ready to brew.，则表示安装成功。 卸载 打开终端，复制该命令：ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)&quot; 删除目录：sudo rm -rf /usr/local/Homebrew Homebrew 基本使用 安装指定软件包：brew install 软件包名称，安装过程的讲解可以看这篇文章：https://www.zybuluo.com/phper/note/87055 卸载指定软件包：brew uninstall 软件包名称 更新指定软件包：brew upgrade 软件包名称 搜索是否存在对应的软件包：brew search 软件包名称 查看对应软件包的信息：brew info 软件包名称 更新 Homebrew 在服务器端上的包目录：brew update 清理旧版本的包缓存时：brew cleanup 查看你安装过的包列表：brew list 更新 Homebrew 在服务器端上的包目录：brew update 查看那些已安装的程序需要更新：brew outdated 使用国内源 默认的源实在速度有够慢的 USTC 的源：https://lug.ustc.edu.cn/wiki/mirrors/help/brew.git 方法： cd &quot;$(brew --repo)&quot; git remote set-url origin git://mirrors.ustc.edu.cn/brew.git Proxychains4 为终端做代理 保证你本地有一个 socks5 到代理工具，不然下面的方法你无法使用。我这里的工具是：Shadowsocks 如果你不懂 Shadowsocks 相关，可以看：http://code.youmeek.com/2016/08/19/2016/08/VPS/ 安装 Proxychains4，输入命令：brew install proxychains-ng 修改配置文件：vim /usr/local/etc/proxychains.conf 在配置文件中找到：[ProxyList]（也就是第 111 行的地方），在其下面一行新增一条：socks5 127.0.0.1 1080 # my vps 测试：proxychains4 wget www.google.com，如果你能正常下载到 Google 页面，则表示成功了。以后只要在命令前面加个：proxychains4，即可。 修改终端配置，让命令更加简洁： 如果你是 zsh 终端，配置修改：vim ~/.zshrc，添加一行：alias pc='proxychains4' 如果你是 bash 终端，配置修改：vim ~/.bash_profile，添加一行：alias pc='proxychains4' 修改之后，以后要用 proxychains4 执行穿墙命令的话，那就可以这样写：pc wget google.com 资料整理 来自 Google 过程中的资料（真心感谢这些作者）： https://aaaaaashu.gitbooks.io/mac-dev-setup/content/Homebrew/index.html http://mac-osx-for-newbie-book.kejyun.com/software/SoftwareManageHomebrew.html http://www.cnblogs.com/TankXiao/p/3247113.html http://brew.sh/index_zh-cn.html https://www.zybuluo.com/phper/note/87055 http://www.udpwork.com/item/11775.html http://www.zhihu.com/question/22624898 http://wiki.jikexueyuan.com/project/mac-dev-setup/homebrew.html http://blog.devtang.com/2014/02/26/the-introduction-of-homebrew-and-brewcask/ 结束语 如果你需要它就你就好好学习，如果你的职业现在完全用不到，那就把这篇文章加收藏，有需要再打开，不希望你花时间多做一些没有太大意义的事情。","link":"/2016/11/27/Mac-Homebrew/"},{"title":"一个Java程序员眼中的Mac OS（系列七：Java 开发环境）","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 帮助 Mac 后来者，减少他/她入门成本 如果你不是 Java 开发者，本章对你没啥太大意义。 先总结 本篇文章没有细到一步一步截图的地步，需要有 Windows 下 Java 开发经验，以及 Linux 部署 Java 环境为基础。 其实 Java 相关的开发环境，不管是 Windows、Mac、Linux 其实本质都一样的，都是改路径，改系统变量，如果你还用 IntelliJ IDEA 这种 IDE，有些压根就不需要系统变量了。 各系统的路径差异说明： Windows 的路径结构是这样的：D:\\360Downloads\\HotFix Mac/Linux 的路径结构是这样的：/usr/local 没用过 Unix 系统的人会很不爽这种路径结构，其实嘛我觉得是 Windows 那种路径结构不好。 系统变量的更改位置，Mac/Linux 一般都是习惯在终端改，Windows 一般在 GUI，但是本质 Windows 也是可以在 cmd 改的，只是 Windows 的终端真的是太差劲了。 JDK 官网下载 JDK7：http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html 官网下载 JDK8：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html Java 开发环境理论上一般都是这个优先安装的。 安装过程和 Windows 没啥区别，都是下一步下一步，只是比 Windows 简单，连安装路径都不需要改而已，所以这里不截图了。 我这边不管是 Windows、Mac、Linux，只要开发环境，JAVA_HOME 我都是 JDK8，同时还装有 JDK6、JDK7，在使用 IntelliJ IDEA 的时候，我可以同时使用三个版本的 JDK。 JDK 的环境变量是要添加的，我这边可以贴一下。 在本系列前面的章节中我已经说明了，我这边是 Zsh 环境，所以我需要编辑这个配置文件：vim ~/.zshrc 如果你是 bash，你需要编辑的是这个：vim ~/.bash_profile 修改后之后刷新配置文件我是：source ~/.zshrc # JDK 1.8 JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk/Contents/Home JRE_HOME=$JAVA_HOME/jre PATH=$PATH:$JAVA_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME export JRE_HOME export PATH export CLASSPATH IntelliJ IDEA 官网下载：http://www.jetbrains.com/idea/ 最优秀的 IDE，没有之一，我所有的生产力硬件设备都是为了支持它而购买的，所以内存一定要够大。 下面的 Maven、Tomcat 都是依赖于 IntelliJ IDEA 运行的，所以本质上我只要搞定 IntelliJ IDEA，其他的 Java 开发环境 IntelliJ IDEA 都会帮我们解决。 关于 IntelliJ IDEA Mac 下安装/配置等相关，请看我写的这个系列，里面有详细说明：IntelliJ IDEA 简体中文专题教程 在 IntelliJ IDEA 有几个特别的地方我单独拿出来讲讲吧： 如果启动 Tomcat 的时候报：Permission denied，你则可以：打开终端，进入 Tomcat\\bin 目录，然后执行：chmod 777 *.sh 如果启动 Tomcat 之后，控制台乱码了，并且你确认你在 IntelliJ IDEA 的 Preferences 中设置的控制台字体是支持中文的，那你可以尝试下在 Tomcat VM 参数上加上：-Dfile.encoding=UTF-8 Git 的路径配置：Preferences -- Version Control -- Git -- Path to Git executable 的值是：/usr/local/git/bin/git 如果你已经看过前面的：一个Java程序员眼中的Mac OS（系列六：终端方案iTerm2 + Zsh），假设你也已经安装了 zsh 那你的 IntelliJ IDEA 终端路径可以改成 zsh 的，配置方法在 Preferences -- Tools -- Terminal -- Shell path 的值改为是：/bin/zsh IntelliJ IDEA 在 Mac 下的配置文件保存路径 下面内容中：XXXXXX，表示 IntelliJ IDEA 的版本号，IntelliJ IDEA 的配置目录是跟版本号有关系的。 /Users/你的用户名/Library/Application Support/IntelliJIdeaXXXXXX，用于保存安装的插件 /Users/你的用户名/Library/Caches/IntelliJIdeaXXXXXX，用于保存缓存、日志、以及本地的版本控制信息（local history 这个功能） /Users/你的用户名/Library/Preferences/IntelliJIdeaXXXXXX，用于保存你的个人配置、授权文件，等价于 Windows 下的 config 目录 Maven 官网下载：http://maven.apache.org/download.cgi Maven 是绿色版的，任何系统都适用。 安装方式和 Windows、Linux 没啥本质区别，都是把 zip 文件夹解压，然后新增几个系统变量，修改 Maven 配置文件参数。 如果你不懂 Maven 相关知识可以查看我过去写的这篇文章：构建工具-Maven-相关知识-整理专题 我是把 Maven 解压后，直接把 Windows 的 settings.xml 复制过来，修改下该文件本地仓库的路径，其他没啥可以改的了。 然后本地仓库的那些依赖包是直接从 Windows 下拷贝过来的，这个是任何系统下都兼容的，不需要额外处理。 最后再用 IntelliJ IDEA 对 Maven 的配置路径重新做了修改。 以上这些点都需要你对 Maven 和 IntelliJ IDEA 有了解，对于这两个东西我也在本文章都贴了相关的文章链接，我这里不多说了，学习总是需要花时间的。 Maven 的环境变量是要添加的，我这边可以贴一下： MAVEN_HOME=/Users/youmeek/my_software/work_software/maven3.3.9 PATH=$PATH:$MAVEN_HOME/bin export MAVEN_HOME export PATH Tomcat 官网下载 Tomcat 7：http://tomcat.apache.org/download-70.cgi 官网下载 Tomcat 8：http://tomcat.apache.org/download-80.cgi Tomcat 在 Windows 下虽然有安装版本，但是一般开发环境我们都不会下载安装版本的，所以假设你也是下载 zip 的压缩版本，这个版本任何系统都是通用的。 因为是开发环境，所以不需要配置 CATALINA_HOME 变量，直接用 IntelliJ IDEA 指向 Tomcat 的解压目录即可，如果不懂，还是看我本文上面贴的 IntelliJ IDEA 系列教程地址。 MySQL 官网下载 MySQL 5.6：http://dev.mysql.com/downloads/mysql/5.6.html#downloads 官网下载 MySQL 5.7：http://dev.mysql.com/downloads/mysql/ MySQL 官网提供的 Mac 系统的安装包，是下一步下一步安装类型的，没啥难度，大家自己试一下。 有几个点需要注意的是： 如何重置 root 密码： 打开：系统偏好设置 -- 底部的 MySQL -- 点击：Stop MySQL Server，根据提示输入你的 Mac 用户密码。 打开终端，输入命令：sudo /usr/local/mysql/bin/mysqld_safe --skip-grant-tables，根据提示输入你的 Mac 用户密码，然后这个终端就这样放着，别动 再打开一个新的终端，输入命令：sudo /usr/local/mysql/bin/mysql -u root，根据提示输入你的 Mac 用户密码，密码如果无误的话，此时就进入：mysql &gt; 这种状态下。 在：mysql &gt; 这种状态下输入命令：UPDATE user SET authentication_string=PASSWORD('123456') WHERE User='root';FLUSH PRIVILEGES;，我把密码重置为：123456 了。 MySQL 配置文件设置 Mac 下的 MySQL 默认是没有 my.ini 或是 my.cnf 文件的，需要我们自己复制一个出来。 通过终端进入这个目录：cd /usr/local/mysql/support-files/，从该目录下随便找一个 .cnf 的文件，复制命名为：my.cnf，然后按照 MySQL 的配置规则配置这个文件。 然后把这个 my.cnf 的文件复制到 /etc 目录下 重启 MySQL 服务即可 Git 官网下载：http://git-scm.com/download/mac 安装过程和 Windows 没啥区别，都是下一步下一步。 IntelliJ IDEA 对 Git 的支持很好，也不需要额外配置什么，IntelliJ IDEA 的 Git 操作都很便捷强烈使用 IntelliJ IDEA 作为 Git 的 GUI 操作工具。 结束语 感谢 JetBrains 这样的公司存在，让我省去很多麻烦。","link":"/2016/11/30/Mac-Java/"},{"title":"一个Java程序员眼中的Mac OS（系列六：终端方案iTerm2 + Zsh）","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 帮助 Mac 后来者，减少他/她入门成本 如果你不是后台开发者，一般不需要用到这个东西，可以不用学的。如果你非要学，那你可以认为你现在看到的东西和在 Linux 上看到的没啥本质的区别，做好这个准备，对你很重要。 先总结 iTerm2 比 Mac 默认的 Terminal 终端好用，配合 Zsh 确实更加得体 牢记： 装了 zsh 之后，修改终端配置就变成了：vim ~/.zshrc，而不是：vim ~/.bash_profile，所以以后看到别人的文章中需要：vim ~/.bash_profile，那你自己要变通思想过来。 同时更新修改后的配置文件也从：source ~/.bash_profile，变成了：source ~/.zshrc，当然还有其他取取巧方式，这里不谈。 iTerm2 知识iTerm2 是什么 术语定义 iTerm2 官网：http://iterm2.com/ wiki 介绍：https://en.wikipedia.org/wiki/ITerm2 iTerm2 作者意思：Mac 的默认终端 Terminal 太难用了，我们开发一个新的终端来代替它吧。 同类常见技术 Terminal 学习前提/依赖 一点英文 一点 Unix/Linux 系统的思想 一点 Shell 概念 为什么会出现 有些操作，命令行或者说脚本的方式效率是远高于 GUI 界面操作的，这个概念需要用过 Unix/Linux 做过开发的人会懂，特别是搞运维的。如果你不理解，可以找一些运维的视频教程来看看，会有很多事情的处理都是搞脚本的做的。 哪些人不喜欢 iTerm2 设计师？ 前端开发者？可能真正的好前端开发者也是会经常用终端的，因为 node.js 的 npm 就有很多命令。 不喜欢学习的，因为这里面涉及到很多 Unix/Linux 系统的知识点，很枯燥，而且很多快捷键需要背，需要花很多精力。 为什么学习 iTerm2 作为后端开发者必须学会的一个技能，不管是为了简化安装一些软件或是处理一些事情，还有工作中的后端程序的软件部署，都会跟 shell 打交道。 安装 iTerm2 在安装之前先说下前提，你的 Mac 必须装有：Homebrew，等下 zsh 要用到。 如果你不知道 Homebrew 是做什么，可以查看我写的另外一篇文章：一个Java程序员眼中的Mac OS（系列五：包管理工具） 下载 iTerm 2 当前时间（2016-10-31）最新版为：3.0.10 下载地址，官网：https://iterm2.com/ 安装 iTerm 2 官网下载下来是一个 zip 压缩包，解压出来有一个 .app 文件，双击运行即可安装，或是拖到应用程序里面。 更改配色方案 目前大家喜欢设置的配色方案为 solarized，iTerm2 默认是有带的，如果没有则访问：https://github.com/altercation/solarized 在项目中找到 solarized/iterm2-colors-solarized 目录，下面有两个文件：Solarized Dark.itermcolors 和 Solarized Light.itermcolors，双击这两个文件就可以把配置文件导入到 iTerm 里了。 更改后的配色最终效果如下图：已经截图了。同时还要再切换到 Text 标签，把 Draw bold text in bold font 的勾去掉。 iTerm2 软件特色 智能选中 在 iTerm2 中，连续双击选中，连续三击选中整行，连续四击智能选中（智能规则可配置），可以识别网址，引号引起的字符串，邮箱地址等。 在 iTerm2 中，选中即复制。即任何选中状态的字符串都被放到了系统剪切板中。 Hotkey Window (快速调出窗口) 这个非常好用，默认是没有设置，需要自己设置下。 实际使用时我们经常会遇到这种场景：有时候只是执行几行命令，然后就不再使用它。可是我们还是必须要打开终端，使用完成后关闭它。但是用 iTerm2 这个功能只要按快捷键，出来虚化的终端，输入命令，然后再把光标放在其他地方自动就消息了。 设置和效果如下图： iTerm2 常用快捷键 这篇文章配了很多图，如果你想更加具体地了解可以看这篇文章，我不想截图了：http://swiftcafe.io/2015/07/25/iterm/ 快捷键 介绍 输入的命令开头字符 + Command + ; 根据输入的前缀历史记录自动补全 Command + ; 根据历史记录自动补全 Command + [ 或 command + ] 切换屏幕 Command + enter 进入全屏模式，再按一次返回 Command + 鼠标单击 可以打开文件，文件夹和链接（iTerm2 是可以对显示的内容进行点击的哦） Command + n 新建新的 Window 窗口 Command + t 新建标签页 Command + w 关闭当前标签或是窗口 Command + d 竖直分屏 Command + r 清屏 Command + / 按完之后，整个屏幕变成白茫茫的，而光标位置是一个小圆圈清除显示出来 Command + 方向键 切换标签页 Command + 数字 切换到指定数字标签页 Command + f 查找，所查找的内容会被自动复制 ,输入查找的部分字符，找到匹配的值按 tab，即可复制，带有补全功能 Command + option + e 全屏并排展示所有已经打开的标签页，带有可以搜索。 Command + Option + b 历史回放，i类似视频录像的东西，有记录你最近时间内的操作。有一个类似播放器的进度条可以拖动查看你做了什么。存放内容设置（Preferences -&gt; Genernal -&gt; Instant Replay）。 Command + Option + 数字 切换 Window 窗口 Command + shift + d 水平分屏 Command + shift + h 查看剪贴板历史，在光标位置下方会出现一列你输入过的历史记录 Command + Shift + m 可以保存当前位置，之后可以按Command + Shift + j跳回这个位置。 Command + shift + alt + w 关闭所有窗口 Control + u 清空当前行，无论光标在什么位置 Control + a 移动到行首 Control + e 移动到行尾 Control + f 向前移动，相当于方向键右 Control + b 向后移动，相当于方向键左 Control + p 上一条命令，相当于方向键上 Control + n 下一条命令，相当于方向键下 Control + r 搜索历史命令 Control + y 召回最近用命令删除的文字 Control + h 删除光标之前的字符 Control + d 删除光标所在位置的字符 Control + w 删除光标之前的单词 Control + k 删除从光标到行尾的内容 Control + c 结束当前状态，另起一行 Control + t 交换光标和之前的字符 安装 Zsh + oh-my-Zsh Zsh 官网：https://www.zsh.org/ oh-my-Zsh 官网：http://ohmyz.sh/ 先说下：Zsh 和 oh-my-Zsh 的关系 Zsh 是 Shell 中的一种，什么 Shell 你可以再搜索下，简单粗暴讲就是一个：命令解释器，你输入什么命令，它就执行什么，这个东西再 Unix 世界还有其他几个。 由于 Zsh 配置门槛有点高，或者说需要专门花时间去了解 Zsh 才能配置好一个好用的 Zsh，也因为这样，用户也就相对少了。 直到有一天 oh-my-Zsh 的作者诞生，他想要整理出一个配置框架出来，让大家直接使用他的这个公认最好的 Zsh 配置，省去繁琐的配置过程。所以，oh-my-Zsh 就诞生了，它只是会了让你减少 Zsh 的配置，然后又可以好好享受 Zsh 这个 Shell。 Mac 和一般 Linux 默认的 shell 是 bash，一般人都觉得不好用，我作为一般人，也喜欢 Zsh，所以这里就用 Zsh。 为了简化配置 Zsh 过程，我们这里选择 oh-my-Zsh 这个配置库，这是目前大家公认好用的配置。 打开终端，先安装 git（已经安装的跳过该步骤），输入命令：brew install git 打开终端，安装 wget 工具，输入命令：brew install wget 打开终端，安装 Zsh：brew install Zsh 打开终端，安装 oh-my-Zsh：sh -c &quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-Zsh/master/tools/install.sh -O -)&quot; 下载完后，会提示你输入当前登录系统的用户密码，输入完成之后就会从 bash 切换到 Zsh，如果你没有输入密码直接跳过了，可以运行该命令进行手动切换：chsh -s /bin/Zsh 你当前系统用户名 切换完成之后，关掉终端，重新打开终端即可 如果你需要修改 oh-my-Zsh 的主题，和安装 Zsh 插件，具体可以看我过去整理的这篇文章：Zsh 入门 Zsh 软件特色 不区分大小写智能提示。我是不喜欢大小写区分的那种人，所以用了 zsh 之后，经常按 Tab 进行提示。 此外按下 tab 键显示出所有待选项后，再按一次 tab 键，即进入选择模式，进入选择模式后，按 tab 切向下一个选项，按 shift + tab 键切向上一个选项，ctrl+f/b/n/p 可以向前后左右切换。 kill + 空格键 + Tab键，列出运行的进程，要啥哪个进程不需要再知道 PID 了，当然了 zsh，提供了让你知道 PID 的方法： 比如输入：kill vim，再按下 tab，会变成：kill 5643 ls **/*，分层级地列出当前目录下所有文件及目录，并递归目录 ls *.png 查找当前目录下所有 png 文件 ls **/*.png 递归查找 zsh 的目录跳转很智能，你无需输入 cd 就可直接输入路径即可。比如：.. 表示后退一级目录，../../ 表示后退两级，依次类推。 在命令窗口中输入：d，将列出当前 session 访问过的所有目录，再按提示的数字即可进入相应目录。 给 man 命令增加结果高亮显示： 编辑配置文件：vim ~/.zshrc，增加下面内容： # man context highlight export LESS_TERMCAP_mb=$'\\E[01;31m' # begin blinking export LESS_TERMCAP_md=$'\\E[01;38;5;74m' # begin bold export LESS_TERMCAP_me=$'\\E[0m' # end mode export LESS_TERMCAP_se=$'\\E[0m' # end standout-mode export LESS_TERMCAP_so=$'\\E[38;5;246m' # begin standout-mode - info box export LESS_TERMCAP_ue=$'\\E[0m' # end underline export LESS_TERMCAP_us=$'\\E[04;38;5;146m' # begin underline 刷新配置文件：source ~/.zshrc，重新查看 man 的命令就可以有高亮了。 关于搭配上 tmux 这个我觉得不是人人都需要的东西，如果经常用终端，或是运维人员可以考虑学这个东西，我的资料也是网上找的，你们可以自己找一下。 资料整理 来自 Google 过程中的资料（真心感谢这些作者）： Mac 终端命令大全 http://wiki.jikexueyuan.com/project/mac-dev-setup/iterm.html http://wulfric.me/2015/08/iterm2/ http://yanghui.name/blog/2015/07/19/make-all-command-through-proxy/ https://segmentfault.com/a/1190000003001555 http://www.wklken.me/posts/2015/08/06/linux-tmux.html http://www.dreamxu.com/mac-terminal/ http://zhaozhiming.github.io/blog/2015/11/22/save-and-restore-your-tmux/ http://cenalulu.github.io/linux/tmux/ http://blog.csdn.net/gatieme/article/details/49301037 http://blog.jobbole.com/87278/ http://wulfric.me/2015/08/zsh/ http://hujiandong.com/2016/09/11/iterm2/ http://www.jianshu.com/p/68ef9d2e1653 http://swiftcafe.io/2015/07/25/iterm/ 结束语 如果你需要它就你就好好学习，如果你的职业现在完全用不到，那就把这篇文章加收藏，有需要再打开，不希望你花时间多做一些没有太大意义的事情。","link":"/2016/11/29/Mac-iTerm2/"},{"title":"一个 Java 程序员眼中的 Mac OS（系列一：总纲领）","text":"系列教程总结 本系列有 **7 大篇，N 多小篇 **，7 大篇目前已经都整理完成，分别是： 一个 Java 程序员眼中的 Mac OS（系列二：系统使用） 一个 Java 程序员眼中的 Mac OS（系列三：常用快捷键） 一个 Java 程序员眼中的 Mac OS（系列四：常用软件） 一个 Java 程序员眼中的 Mac OS（系列五：包管理工具） 一个 Java 程序员眼中的 Mac OS（系列六：终端方案 iTerm2 + Zsh） 一个 Java 程序员眼中的 Mac OS（系列七：Java 开发环境） 一个 Java 程序员眼中的 Mac OS（系列八：外设 / 配件介绍） 我喜欢纲领性的文章，不喜欢一篇里面太长。 在 6 大篇里面会是类似提纲一样的东西，里面布满标题和链接，跳转到我新开通的简书小号中，简书里面有对应标题讲解的详细内容。 我个人觉得这样学起东西来更加系统和有规律，也方便别人查询。 本教程使用环境 设备硬件：2015 款 Retina MacBook Pro，i7，16G，256G。 Mac OS：macOS Sierra，10.12.1 我不是果粉，也不是软粉，也不是 Linux 粉，我只会站在效率上考虑问题，不计代价的考虑效率，所以对于此系列的相关文章沟通，我希望我们是建议在以一个效率为核心的基础上进行。 我目前生活中开发，主力机还是台式机的 Windows 系统，我这个屏幕分辨率大，CPU 强悍，内存足够，SSD + 机械容量够装，所以如果在家开发我会选择 Windows 系统，但是不排除以后我适应了 Mac OS 以后，专门装黑苹果使用。 如果专门写东西，出门，浏览网页等等非开发、非游戏事情我会选择 Retina MacBook Pro，它小巧，屏幕清晰，软件友好，我坐着用不会那么累。 Mac OS 使用感受总结 我现在同时具备了三种类型的系统使用习惯：Windows、Mac、Linux，所以我想我现在多少有话语权来推荐这三个系统了。 为了更适应大众，更适应效率，对比这三个系统的前提是：不考虑钱和职业的情况下。 这三个系统里面没有所有方面都最好的，因为都是有侧重点和自己的定位的。 Linux 是最简单划分的：Linux 最适合服务器部署，不适合桌面，所以只要你经常跟桌面打交道的都不建议。 Windows 和 Mac 倾向于普通用户，适用于桌面用户，如果要从这两个里面挑一个推荐给大家的话，我会这样分情况。 1.如果使用的对象是小孩，是他的第一台电脑的话，我会选择 Mac。里面英文软件多，屏幕好，最重要的是软件生态圈中有很多在维护的好软件和小软件，软件生态圈并不是完全依赖大公司或是苹果本身。 在这里也强调下，苹果所维护的收费软件生态圈确实比 Windows 好很多，那些开发者能有收入，他们才会继续进行维护。而对于中国的使用者来讲，好的英文软件多了，会间接促进他学好英文，沟通外面世界。所以我也发现为什么那些很早以前玩 Mac 的，说自己是果粉的英文都还不错，我觉得这个是有一点作用的。 2.如果被推荐的对方是成年人，那我又会细分为下面两种： 2.1.如果这个成年人会愿意花时间学习，并且有英文的一些底子，不反对英文，那我会推荐 Mac，因为 Mac 有很多优秀的软件可以增加效率的，而这些很多都是英文软件，我后面都会来一一推荐，并且硬件设备也一直处于世界最前沿的。 2.2.如果这个成年人不喜欢学习新东西，只是平时回家就是玩玩电脑游戏，看看视频聊聊天刷刷微博看看朋友圈什么的，我会推荐 Windows，Mac 在娱乐这条路上不是 Windows 的对手，微软有 XBOX 做后盾。 Retina MacBook Pro 笔记本总结 优点： 轻便，性能不差，待机长，适合出门，也因为你轻便所以在家经常抱到床上或是坐在椅子上直接就放在大腿上了。 两测喇叭清澈，音乐人适合。 视网膜的显示屏没什么可以挑剔。 系统字体渲染确实很棒，很清晰 触摸板好用，非常好用 系统备份功能强大 收费软件生态圈比 Windows 好很多，原因前面说了。 Unix 系统，对于懂 Linux 部署环境的 Java 开发者来讲是很友好。 如果你是 iPhone 手机用户，同时有开启 iCloud 的话，那有些数据同步上也是很方便的，比如我常用的备忘录、提醒事项，同时手机使用的 WIFI 密码，笔记本也会自己记住等等这类细节。 很多软件都没有中文版，对日常英文的回顾是有帮助的。 缺点： 贵，真心贵 在 Mac 下，那些国外软件反而都很好，反而是很多国内软件很糟糕，不管是有道词典、QQ、搜狗输入法、为知笔记、百度云盘等等，都做得比 Windows 差，很多设置、功能都去掉了。 软件设置少你可以叫做简洁，但是我也可以叫做功能简单，有些人用不到这些设置，但是对于我这类喜欢设置很多习惯的人来讲，我不觉得这样是简洁。我不知道是不是苹果没给权限还是什么的，反正我是非常不满意的。 Mac 机子购买建议 不推荐没有视网膜屏的设备，苹果就这个视网膜屏幕最让人欲罢不能。 优先根据 职业 来划分情况： 如果你是开发者、设计师、视频编辑、音乐编辑等 IT 相关职业者，那你的预算必须在 1W，必须选择 Retina MacBook Pro 系列，不然怕是扛不住你的日夜虐待的。 如果你是非IT职业者，平时也生活所用，不会有太多大型软件运行，那你的预算也必须在 1W，你可以考虑入手 2016 款 MacBook，这个平时使用的，而且待机又长，很适合出门轻度使用者。 作为开发者，如果你初期经费不够的，预算小于 1W，不建议你买 Mac 的任何产品，那些低于 1W 的 Mac 产品不会让你有多大的效率进步的，当然了，前提是你也确实对 Windows 也足够了解。 如果你经费在 1W 左右，那可以大胆尝试下 Retina MacBook Pro 不管是 2015 年款的还是最新的 2016 款。Mac OS 上其实也很多破解软件的，而且安装起来也很简单的，所以不会影响你工作效率。当然了，前提还是你要花时间去找资料学习下。 如果你已经进入一个比较好的后台开发状态，那我建议你手头有一台顶配的 Windows 台式机，一台 Retina MacBook Pro 笔记本。预计这需要花费 2W ~ 3W 左右，你可以分阶段来。 如果你非常着迷 Mac，那就一台顶配 Intel 台式机用来装黑苹果，一台 Retina MacBook Pro。 结束语 买 Mac 设备装双系统我觉得没必要，如果你就一台机，那我就只建议你专心用 Mac OS 或专心用 Windows，如果只是时不时用到 Windows 那就装个虚拟机。如果只习惯 Windows，那就专心买 Dell XPS，Surface Book。 如果你打算认真从事开发行业，那就等手里有钱之后，按我刚刚说的，笔记本用 Retina MacBook Pro，台式机组装用 Windows 或 黑苹果。我是三个系统都喜欢的，所以我三个系统也同时都使用。 下期预告：一个 Java 程序员眼中的 Mac OS（系列二：Mac OS 系统细节设置）","link":"/2016/11/05/Mac-introduction/"},{"title":"一个Java程序员眼中的Mac OS（系列三：常用快捷键）","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 帮助 Mac 后来者，减少他/她入门成本 先总结 不管哪个系统，快捷键都很多，Mac 也不少。 对于 Windows 转过来的人，下面的符号是最需要搞懂的，说句良心话，我讨厌这个符号，因为每次看到这些符号我的脑袋也是把他们转换成对应的英文单词，还为什么有些人不直接写单词就好了? Mac 特殊按键讲解 Mac 系统的功能按键跟 Windows 还是有点差别，需要做一下特殊记忆。 ⌘ == Command ⇧ == Shift ⇪ == Caps Lock ⌥ == Option ⌃ == Control ↩ == Return/Enter ⌫ == Delete ⌦ == 向前删除键（Fn+Delete） ↑ == 上箭头 ↓ == 下箭头 ← == 左箭头 → == 右箭头 ⇞ == Page Up（Fn+↑） ⇟ == Page Down（Fn+↓） Home == Fn + ← End == Fn + → ⇥ == 右制表符（Tab键） ⇤ == 左制表符（Shift+Tab） ⎋ == Escape (Esc) ⏏ == 电源开关键 不同描述法词汇 app 指的是一个应用程序 窗口指的是一个 app 里面可以多开的窗口。一个 app 是可以打开多个窗口的。 必备快捷键普通 app / 系统 共有快捷键 快捷键 介绍 电源按钮 轻点可打开 Mac 或将 Mac 从睡眠状态唤醒。 当 Mac 处于唤醒状态时，按住此按钮 1.5 秒钟会显示一个对话框，询问您是要重新启动、睡眠还是关机。如果您不想等待 1.5 秒钟，请按下 Control + 电源按钮。如果按住此按钮 5 秒钟会强制 Mac 关机。 Delete 文本编辑中：向前删除 Fn + Delete 文本编辑中：向后删除 Control + 空格 切换输入法 Control + Shift + 电源按钮 将显示器置于睡眠状态 Command + H 隐藏最前面的 app 的窗口 Command + M 将最前面的窗口最小化至 Dock Command + S 保存 Command + W 关闭最前面的窗口。 Command + Q 退出当前使用的 app Command + A 选择全部 Command + F 打开“查找”窗口 Command + G 再次查找：查找之前所找到项目出现的下一个位置。要查找出现的上一个位置，请按 Command + Shift + G Command + X 剪切 Command + C 复制 Command + V 粘贴 Command + Z 撤销 Command + Tab 切换 app Command + Delete 删除文件 Command + 空格键 Spotlight：显示或隐藏 Spotlight 搜索栏。要从 Finder 窗口执行 Spotlight 搜索，请按 Command–Option–空格键 Command + 上方向键 跳转到页头 Command + 下方向键 跳转到页尾 Command + 左方向键 跳转当前行头 Command + 右方向键 跳转当前行尾 Command + 鼠标单击 间隔多选，类 Win 下的：Ctrl + 鼠标单击 Command + 逗号 偏好设置：打开最前面的 app 的偏好设置 Command + Shift + 3 截图整个桌面图片保存到桌面，默认是 PNG 格式 Command + Shift + 4 截图区域图片保存到桌面，默认是 PNG 格式 Command + Shift + Y 对选中的文字生成便签 Command + Shift + Q 注销您的 macOS 用户帐户。系统将提示您确认 Command + Shift + 波浪号 (~) 切换窗口：切换到最前端应用中下一个最近使用的窗口 Command + Shift + 点号 显示隐藏文件夹/文件，再按一次则隐藏 Command + Control + 空格键 显示“字符显示程序”弹出窗口，可以插入表情 Command + Control + 电源按钮 强制 Mac 重新启动 Command + Option + H 置顶当前焦点所在的这个窗口，隐藏后面的其他所有窗口。这个很有用的，方便使用桌面的内容 Command + Option + W 关闭当前 app 的所有窗口，请按 Command-Option-W Command + Option + M 最小化最前面的 app 的所有窗口 Command + Option + Esc 弹出强制退出管理界面。或者，按住 Command-Shift-Option-Esc 3 秒钟来仅强制最前面的 app 退出 Command + Option + Shift + Q 立即注销您的 macOS 用户帐户，且系统不提示您确认。 Command + Option + Control + 电源按钮 退出所有 app，然后关闭 Mac。如果任何打开的文稿有未存储的更改，系统将询问您是否要存储这些更改 Finder 文件管理器快捷键 快捷键 介绍 Command + 1 以图标方式显示 Finder 窗口中的项目 Command + 2 以列表方式显示 Finder 窗口中的项目 Command + 3 以分栏方式显示 Finder 窗口中的项目 Command + 4 以 Cover Flow 方式显示 Finder 窗口中的项目 Command + D 复制所选文件 Command + E 推出所选磁盘或宗卷 Command + F 在 Finder 窗口中开始 Spotlight 搜索 Command + I 显示所选文件的“显示简介”窗口 Command + N 新建文件夹 Command + N 打开一个新的 Finder 窗口 Command + J 调出“显示”选项 Command + Delete 将所选项移到废纸篓 Command + 上箭头 打开包含当前文件夹的文件夹 Command + 下箭头 打开所选项 Command + 左中括号 [ 前往上一文件夹 Command + 右中括号 ] 前往下一文件夹 Command + 调高亮度键 开启或关闭目标显示器模式 Command + 调低亮度键 当 Mac 连接到多个显示器时打开或关闭显示器镜像功能 Command + 鼠标单击 在单独标签或窗口中打开文件夹 Command + 斜线 (/) 隐藏或显示 Finder 窗口中的状态栏 Command + Shift + C 打开“电脑”窗口 Command + Shift + D 打开“桌面”文件夹 Command + Shift + F 打开“我的所有文件”窗口 Command + Shift + G 打开“前往文件夹”窗口 Command + Shift + H 打开当前 macOS 用户帐户的个人文件夹 Command + Shift + I 打开 iCloud Drive Command + Shift + L 打开“下载”文件夹 Command + Shift + O 打开“文稿”文件夹 Command + Shift + U 打开“实用工具”文件夹。 Command + Shift + N 新建文件夹 Command + Shift + T 显示或隐藏 Finder 标签 Command + Shift + Delete 清空废纸篓 Command + Shift + Control + T 将所选的 Finder 项目添加到 Dock（OS X Mavericks 或更高版本） Command + Option + D 显示或隐藏 Dock。即使您未打开 Finder，此快捷键通常也有效 Command + Option + P 隐藏或显示 Finder 窗口中的路径栏 Command + Option + S 隐藏或显示 Finder 窗口中的边栏 Command + Option + N 新建智能文件夹 Command + Option + V 移动：将剪贴板中的文件从其原始位置移动到当前位置 Command + Control + T 将所选项添加到边栏（OS X Mavericks 或更高版本） Command + Control + 上箭头 在新窗口中打开包含当前文件夹的文件夹 鼠标选中文件拖动，并按住 Option 键 拷贝当前文件到拖动后的文件夹 在启动期间按住的快捷键 快捷键 介绍 C 从可引导的 CD、DVD 或 USB 闪存驱动器启动 Shift 以安全模式启动 Option 启动进入启动管理器 Command + R 从 OS X 恢复功能启动 Command + S 以单用户模式启动 资料整理 来自 Google 过程中的资料（真心感谢这些作者）： https://support.apple.com/zh-cn/HT201236 http://www.jianshu.com/p/700a002e2e47 https://support.apple.com/zh-cn/HT201255 https://support.apple.com/kb/PH21534?locale=zh_CN&amp;viewlocale=zh_CN https://support.apple.com/zh-cn/HT201586 https://support.apple.com/zh-cn/HT204436 结束语 我懂背快捷键是个麻烦事，但是你不背，你怎么知道有这些东西？ 整个系列会在以后不断地完善，请关注这个系列教程，系列入口有：YouMeek 博客，YouMeek 公众号。","link":"/2016/11/21/Mac-keymap/"},{"title":"一个Java程序员眼中的Mac OS（系列八：外设&#x2F;配件介绍）","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 帮助 Mac 后来者，减少他/她入门成本 先总结 量力而行，确认你自己是必须要这个东西再决定购买。 贵，真贵，特别贵 各类外设/配件 官网配件地址：http://www.apple.com/cn/shop/mac/mac-accessories 各类转接线 基础内容须知： Thunderbolt 3，USB-C，Type-C，这三个东西你可以理解为都是同一个样子的接口，别管它那么多叫法。 2016 款的 MacBook Pro 的接口是：Thunderbolt 3 (USB-C) 2015 款的 MacBook Pro 的接口是：Thunderbolt 2 我原本整理了一堆的配件出来的，但是整着整着就不爽了，苹果实在够坑爹的，在迭代过程中各种完全不同的标准，真是让人不开心，这些配件还贵。大家自己看官网的那些线缆配件吧，左侧有筛选项的。 官网：电源与线缆 我这边的 2015 款 MacBook Pro 电源适配器，真贵：Apple 85W MagSafe 2 电源适配器（适用于配备 Retina 显示屏的 MacBook Pro） 触摸板 MacBook 笔记本的触摸板确实比一般笔记本好用很多，所以台式机有需要用这个的倒是也可以建议买个。 Magic Trackpad 鼠标 虽然没有用过苹果这个鼠标，但是就一个字：贵，建议还是用普通的蓝牙鼠标吧。 Magic Mouse 蓝牙鼠标 键盘 默认的键盘还可以，但是如果长久用，并且不经常带出去，可以考虑买个我上次主力推荐的：ikbc f 时光机系列 @YouMeek主推的机械键盘ikbc f 时光机系列 硬盘盒 我主推这个牌子：奥睿科 奥睿科 硬盘盒 外置光驱 光驱这东西还是早点淘汰吧，确实有点烦人了在如今这个时代。 USB 外置光驱 散热器 MacBook Pro 在运行大型软件确实会发热很快，底部会很烫，所以有需要的人还是可以考虑一下散热器的。 mStand 支架 内胆包 如果你经常背着笔记本出门，那最好买一个内胆包，起到一个防震，防碰撞的作用。 Incase 内胆包 Mac 内胆包 USB 扩展 先看下你笔记本是不是有 USB-C 的接口。 USB 扩展 Type-c 扩展 资料整理 来自 Google 过程中的资料（真心感谢作者）： https://github.com/hzlzh/Best-App/blob/master/Best-Accessories-Apple.md 结束语 Apple 是个坑爹货。","link":"/2016/12/01/Mac-peripheral/"},{"title":"一个Java程序员眼中的Mac OS（系列二：系统使用）","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 帮助 Mac 后来者，减少他/她入门成本 先总结 Mac 系统你值得拥有。 本文所有的链接都是指向我写在简书上的文章，这里是做章节目录，方便你查阅。 教程环境 硬件：2015 款 MacBook Pro 系统：macOS Sierra 10.12.1 语言：简体中文 Mac 必懂概念 Mac 没有 我的电脑，有 Finder Mac 没有 控制面板，有 系统偏好设置 Mac 没有 回收站，有 废纸篓 Mac 的常用压缩格式 dmg 文件，类似 Windows 的 ISO 文件格式 认识 Mission Control 的概念 认识 Launchpad 的概念 认识 Mac 的工具栏位置 认识 Mac 的 Spotlight 全能搜索工具 系统功能点 如何连接有线网络/WiFi网络 查看本地 IP 地址 改变鼠标/触摸板滚轮滑动方向 触摸板的使用 修改F区键盘键为常规F1~F12键效果 调整鼠标大小 调整音量 调整屏幕亮度 修改无操作多少分钟后自动关闭屏幕 修改壁纸 如何修改分辨率 设置桌面四边角触摸事件 设置外置鼠标多键控制 如何查看/显示隐藏文件/文件夹 新建记事本 如何删除文件 如何给文件/文件夹重命名 如何复制/剪切/粘贴文件 修改安全性，允许任何来源的软件都可以安装 如何退出/推出U盘 如何锁屏 如何更新系统/官方应用 Mac 和 Windows 之间如何共享文件 强制结束应用 活动监视器，查看正在运行的软件情况 多桌面使用/切换 使用自带的定时关机 系统备份和还原 设置某个文件默认打开方式 设置某个文件类型默认打开方式 Mac 软件下载站推荐 压缩/解压文件 如何安装/卸载软件 把软件图标放送到Dock栏上 中文输入法的使用 如何高效地进行窗口管理 如何截图 调整 Launchpad 应用图标大小/软件图标合并 设置开机自启动运行某些软件 多开 QQ 如何录制视频 如何安装字体 如何关闭自动检查更新 硬盘维护/格式化硬盘 外接显示器设置 启用/禁用root-修改root密码 结束语 整个系列会在以后不断地完善，请关注这个系列教程，系列入口有：YouMeek 博客，YouMeek 公众号。","link":"/2016/11/20/Mac-settings/"},{"title":"一个Java程序员眼中的Mac OS（系列四：常用软件）","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 帮助 Mac 后来者，减少他/她入门成本 先总结 一个好的软件是帮你提高工作效率的最有利方法之一 用盗版是不对的 用盗版是不对的 用盗版是不对的 但是，没钱，等限免或是降价的时候大家在用力入手吧，有些网站会提供这类信息，大家可以关注下。 呃，其实推荐列表不在这里 我已经把软件整理在 YouMeek 导航，你走到哪里都不需要担心，里面就有一切。 YouMeek 导航 感谢 xclient 的站长，虽然我不认识你，但是他是所有 mac 下载站中最靠谱的，所以导航中下载地址都指向他那边了。 结束语 软件很重要！ 软件很重要！ 软件很重要！ 整个系列会在以后不断地完善，请关注这个系列教程，系列入口有：YouMeek 博客，YouMeek 公众号。","link":"/2016/11/24/Mac-software/"},{"title":"构建工具-Maven-相关知识-整理专题","text":"本文初衷 整理自己脑袋中、收藏中的那些资料，来一次清空，让自己重新开始。 整理这篇的起点是本人已经会使用 Maven，并且已经使用了一年多，所以我个人觉得这篇文章对完全不懂 Maven 来讲是有压力的，但是对于刚刚入门 Maven 的人是有帮助的。 如果你认为一篇文章就可以让你完全了解 Maven，那你是在鄙视官网帮助文档书写者。 以此篇为引，希望可以得到你的建议，我只想成长，真心感谢!（鞠躬） 先总结 如果你是学习 Java 或是说 JVM 语言相关的内容的话，在实际使用中有一个东西你是绕不过去的，构建工具。等你到企业还有一个东西你也绕不过去，持续集成。 在说持续集成前，先简单地解释两个概念：集群、分布式 应用集群：同样的一套程序/代码，放在一批服务器上，每台服务器上的代码一样。 应用分布式：不同的组件代码，放在一批服务器上，不同的服务器放不同模块的代码。 在大公司，现在的项目基本都是分布式的，而要做到分布式那就得尽可能地分层、分割、分布。也因为这样，一个项目一般都是由不同模块组合成的。公司里在不同的地区或是部门做不同的模块，尽量减少部门与部门、地区与地区模块的耦合度，也就是降低必要的联系，让他们尽可能的能独立开发、测试。 这样的拆分，对一个项目的好处是： 分布式架构：具有高性能、高可用、可伸缩、可扩展等优点 公司成本会降低，类似阿里的去 IOE 效率会提高 容错能力更强 灵活性更高 举一个两者简单的对比例子 应用分布式 一个采用分布式架构的电商，在做抢购的特殊时候，压力特别的大的部分应该是：购物车、订单、库存、日志等这些跟购物有关的模块，那既然这几个模块压力大，那我们就在抢购前多部署几套跟购物业务相关的模块到服务器上，此时要求这类服务器性能只要能承载对应的模块即可。其他比如：资讯、客服等无压力模块就原样部署即可，无需变动。 应用集群 一个采用应用集群架构的电商，在做抢购的特殊时候，为了抗住压力，必须把整个应用一套一套地部署到新服务器上，此时就要求服务器性能要好，能承载整个应用。 对比总结：降低成本 扩展内容 在未来容器虚拟化（以 Docker 为主）的情况下，模块化的组件更容易部署到这些容器上面，也就很容易发生这样的事情：一台服务器部署非常多模块，成本就会降得更低。 我们已经知道了分布式效益更好，我们也知道分布式的系统都是需要拆分的，对项目进行拆分，把一个大项目拆分成很多小模块项目，然后大家彼此依赖或通信。此时问题来了：如何高效地依赖。 高效地依赖解决办法是：自动化的构建 + 持续集成。 在目前 Java 界，最常用的构建工具就是：Maven 在多模块的项目中，还是以一个电商项目为例，购物车模块肯定是会依赖 core 模块、Parent 模块等，而这些模块的开发者在不同城市或是不同部门。在协同开发中，不可能每次他们一有更新就得专门安排一个人来交付依赖，这种方式效率是非常低的。 今天整理这个 Maven 材料其实是为了后面整理持续集成做的准备的，大家必须有这个基础才能说后面的持续集成，后续的持续集成会涉及到：TeamCity、Jenkins、Hudson Maven 知识Maven 是什么 术语定义 Maven 官网：http://maven.apache.org/ Maven 官网对自己的定义：http://maven.apache.org/what-is-maven.html 百度百科定义：http://baike.baidu.com/view/336103.htm 维基百科定义：https://zh.wikipedia.org/wiki/Apache_Maven 在 Wiki 上还需要注意如下，这些有助于你站在更加宏观的角度看待它，但是可能需要积累： 参见 补充阅读 参考资料 外部链接 它的历史 Google 搜索：Maven History 搜索结果： 历史介绍：http://maven.apache.org/background/history-of-maven.html 创始人：jason van zyl 创始人现在：http://takari.io/ Google 搜索：Maven 区别、Maven difference 搜索结果： 人们在关注： gradle maven区别 ant maven区别 ivy maven区别 maven maven2区别 通过这个搜索结果我们知道，现阶段我们要的是 Maven 3： Maven实战（十）——Maven 3，是时候升级了 六年等一回 Maven 3的10大新特性详解 同类常见技术（按技术出现时间正序） Ant Gradle 同类技术比较： Google 搜索：Ant Maven Gradle 搜索结果： Java构建工具：Ant vs Maven vs Gradle Maven和Gradle对比 学习前提/依赖 要有 Java 基础相关（如果你完全没学过 Java，建议跳过，不适合你） 最好有 Java Web 相关知识 不需要会 Ant 或是 Maven 早期版本的内容 为什么会出现 Google 搜索：（这些一般都是一些故事，你自己来判断，别人的坎坷是你成长的基石） 关键字：为什么用 maven 关键字：why use maven 关键字：What does Maven do 关键字：Why do we need Maven 关键字：Why should we use Maven 哪些人不喜欢它 Google 搜索：（这些一般都是一些故事，你自己来判断，别人的坎坷是你成长的基石） 关键字：不用 maven 关键字：Why I Don't Use Maven 为什么学习它 构建工具是 Java Web 开发者绕不过去的一道坎 我要怎么做（按优先级从高到低排序） 看教程 官网快速入门文档 在官网中查看带有下面几个关键字的链接： Getting Started Quick Start Getting Started Guides usage page Tutorials Guides Development Guides Documentation Docs Screencasts Maven 主页上得到字眼有： documentation index 在子页面我们得到： Getting Started in 5 Minutes Getting Started in 30 Minutes 在极客学院搜索对应的教学视频（我是年 VIP） 极客学院对 Maven 的讲解比较到位，从初级到中级都涵盖（需要 VIP 权限）： Maven 概述及安装，包含下面内容： Maven 概述及安装 在 Mac 电脑上安装及配置 Maven 在 Windows 电脑上安装及配置 Maven 在 Linux 电脑上安装及配置 Maven 地址：http://www.jikexueyuan.com/course/571.html Maven 核心概念讲解，包含下面内容： POM概述 插件与目标 项目的生命周期阶段 地址：http://www.jikexueyuan.com/course/866.html 在工具中使用 Maven，包含下面内容： 使用命令行工具构建一个 Maven 项目 使用 Eclipse 构建一个 Maven 项目 使用 IntelliJIDEA 构建一个 Maven 项目 地址：http://www.jikexueyuan.com/course/580_1.html?ss=1 使用 Maven 构建 Web 项目，包含下面内容： 创建一个Web项目 使用 Tomcat 插件运行 Web 项目 使用 Jetty 插件运行 Web 项目 添加 J2EE 依赖 创建 JSP 和 Servlet 在 Eclipse 中使用 Maven 构建 Web 项目 地址：http://www.jikexueyuan.com/course/908.html 地址：http://www.jikexueyuan.com/course/951.html 使用 Maven 构建多模块项目 多模块项目介绍 创建 helloweb 项目的骨架结构 将 helloweb 项目导入 Eclipse 使用 dependencyManagement 管理依赖 使用 pluginManagement 管理插件 定义项目属性及配置信息 完善 helloweb-entity 模块 完善 helloweb-core 模块 完善 helloweb-web 模块 使用 log4j 打印日志 使用 junit 进行单元测试 使用 guava 美化代码 地址：http://www.jikexueyuan.com/course/957.html 地址：http://www.jikexueyuan.com/course/964.html 地址：http://www.jikexueyuan.com/course/977.html 地址：http://www.jikexueyuan.com/course/989.html 极客学院上整理得很好的文字教程：http://wiki.jikexueyuan.com/project/maven/ 国外著名的教程网：http://www.tutorialspoint.com/maven/index.htm Google 搜索：Maven 视频 教程 百度云网盘 Google 搜索：Maven 视频 教程 简书-搜索相关内容：http://www.jianshu.com/ 知乎-搜索相关内容：http://www.zhihu.com/ Quora-搜索相关内容：https://www.quora.com/ 微博-搜索相关内容：http://weibo.com 公众号-搜索相关内容：http://weixin.sogou.com/ 开发者头条-搜索相关内容：http://toutiao.io/ 京东-图书：http://book.jd.com/ YouTube-搜索相关内容：http://youtube.com/ 自己写 Demo Maven 下载地址：http://maven.apache.org/download.cgi 此时（2016-03-10）最新版本为：Apache Maven 3.3.9 JDK 要求：Maven 3.3 要求 JDK 1.7 或是更新，其他版本无 操作系统没要求，官网原话：No minimum requirement. Start up scripts are included as shell scripts and Windows batch files 但是，按系统常见压缩格式，我个人建议： Windows 下载的文件：apache-maven-版本号-bin.zip 类 Unix 下载的文件：apache-maven-版本号-bin.tar.gz 我这里以 Maven 3.1 进行安装为例（Windows 系统）： 安装： 我的 Maven 解压目录发在 D 盘根目录下 新增系统变量：JAVA_HOME === C:\\Program Files\\Java\\jdk1.6.0_23 新增系统变量：M2_HOME === D:\\maven\\maven3.1.1 需要注意的是变量名就叫这个 M2_HOME，不要改其他的，因为 TeamCity 这类工具它会默认去找该变量一致的内容自动帮我们匹配构建环境的，所以我们就按官方约定来。 在系统变量 Path 中增加：;%JAVA_HOME%\\bin;%M2_HOME%\\bin 测试： 打开 cmd 输入：java -version，能显示 Java 版本信息即表示 JAVA_HOME 设置好了 输入：mvn –v，能显示 Maven 版本信息即表示 M2_HOME 设置好了 参考别人 Demo 通过上面的学习，我们知道，我们要学习别人的 Maven 配置，只要能看懂他们的 POM 文件配置即可，所以现在你需要做的是找一些开源项目，读懂他们的 POM Gtihub 搜索 Demo：https://github.com/search/advanced Git@OSC 搜索 Demo：http://git.oschina.net/ 项目场景模拟、提高 我现在所有的 Java 相关的项目都是 Maven 构建的 自己做持续集成的话，有 Nexus 做私有仓库 平时开发连接的是：开源中国 Maven 库： 使用技巧： http://maven.oschina.net/help.html http://my.oschina.net/huangyong/blog/180189 POM 依赖 jar 常去的查找地： 官网：http://search.maven.org/ 开源中国：http://maven.oschina.net/home.html Nexus 库：https://repository.sonatype.org/ MVNRepository：http://mvnrepository.com/ 遇到问题 官网 FAQ：https://maven.apache.org/general.html Google Stack Overflow：http://stackoverflow.com/ 资料整理 来自 Google 过程中的资料（真心感谢这些作者）： Maven重要概念及最佳实践 Maven 教程 Maven介绍，包括作用、核心概念、用法、常用命令、扩展及配置 7天学会Maven（第一天——了解 Maven） 7天学会Maven（第二天——Maven 标准目录结构） Maven 3 入门 – 安装与配置 Maven之pom中文详解 maven中的依赖机制简介 maven中的仓库简介 maven常见问题问答 maven scope含义的说明 Maven实战（九）——打包的技巧 Maven仓库汇总 Maven 的41种骨架功能介绍 IntelliJ IDEA 12创建Maven管理的Java Web项目（图解） 对maven私服配置的说明 过程细节 过去 2014 年里，基本上关于 Maven 的知识都是在 Google 上搜索出来的。 在 2015 年才看到极客学院上面有成套资料 结束语 Maven 也许开始要过时了，但是即使 Gradle 的时代要到来了，你会害怕吗？我想你不会的，因为你会学习知识的方法，更而且他们还差不多。","link":"/2016/03/09/Maven/"},{"title":"Node.js 的 TCP 链接管理","text":"在 Node.js 的微服务中，一般不同的服务模块我们会采用 TCP 进行通信，本文来简单谈一谈如何设计 TCP 服务的基础管理。 在具体设计上，本文参考了微服务框架 Seneca 所采用的通信方案 Seneca-transport，已经被实践所证明其可行性。 一提到 TCP 通信，我们肯定离不开 net 模块，事实上，借助 net 模块，我们也可以比较快速地完成一般的 TCP 通信的任务。 为了避免对基础的遗忘，我们还是先附上一个基本的 TCP 链接代码： //server.js: const net = require('net'); const server = net.createServer((socket) =&gt; { socket.write('goodbye\\n'); socket.on('data', (data) =&gt; { console.log('data:', data.toString()); socket.write('goodbye\\n'); }) }).on('error', (err) =&gt; { throw err; }); // grab an arbitrary unused port. server.listen(8024, () =&gt; { console.log('opened server on', server.address()); }); //client.js: const net = require('net'); const client = net.createConnection({ port: 8024 }, () =&gt; { //'connect' listener console.log('connected to server!'); client.write('world!\\r\\n'); setInterval(() =&gt; { client.write('world!\\r\\n'); }, 1000) }); client.on('data', (data) =&gt; { console.log(data.toString()); // client.end(); }); client.on('end', () =&gt; { console.log('disconnected from server'); }); 其实，上述已经是一个几乎最简单的客户端和服务端通信 Demo，但是并不能在实际项目中使用，首先我们需要审视，其离生产环境还差哪些内容： 以上要求 Server 端要在 Client 端之前启动，并且一旦因为一些错误导致 Server 端重启了并且这个时候 Client 端正好和 Server 端进行通信，那么肯定会 crash，所以，我们需要一个更为平滑兼容的方案。 以上 TCP 链接的 Server 部分，并没有对 connection 进行管理的能力，并且在在以上的例子中，双方都没有主动释放链接，也就是说，建立的是一个 TCP 长连接。 以上链接的处理数据能力有限，只能处理纯文本的内容，并且还有一定的风险性（你也许会说可以用 JSON 的序列化反序列化的方法来处理 JSON 数据，但是你别忘了 socket.on('data'... 很可能接收到的不是一个完整的 JSON，如果 JSON 较长，其可能只接收到一般的内容，这个时候如果直接 JSON.parse()) 很可能就会报错）。 以上三个问题，便是我们要解决的主要问题，如果你看过之后立刻知道该如何解决了，那么这篇文章可能你不需要看了，否则，我们可以一起继续探索解决方案。 使用 reconnect-corereconnect-core 是一个和协议无关的链接重试算法，其工作方式也比较简单，当你需要在 Client 端建立链接的时候，其流程是这样的： 调用事先传入的链接建立函数，如果这个时候返回成功了，即成功建立链接。 如果第一次建立链接失败了，那么再隔一段时间建立第二次，如果第二次还是失败，那么再隔一段更长的时间建立第三次，如果还是失败，那么再隔更长的一段时间……直到到达最大的尝试次数。 实际上关于尝试的时间间隔，也会有不同的策略，比较常用的是 Fibonacci 策略和 exponential 策略。 当然，关于策略的具体实现，reconnect-core 采用了一个 backoff 的库来管理，其可以支持 Fibonacci 策略和 exponential 策略以及更多的自定义策略。 对于上面提到的 DEMO 代码。我们给出 Client 端使用 reconnect-core 的一个实现： //client.js: const Reconnect = require('reconnect-core'); const net = require('net'); const Ndjson = require('ndjson'); const Connect = Reconnect(function() { var args = [].slice.call(arguments); return net.connect.apply(null, args) }); let connection = Connect(function(socket) { socket.write('world!\\r\\n'); socket.on('data', (msg) =&gt; { console.log('data', msg.toString()); }); socket.on('close', (msg) =&gt; { console.log('close', msg).toString(); connection.disconnect(); }); socket.on('end', () =&gt; { console.log('end'); }); }); connection.connect({ port: 8024 }); connection.on('reconnect', function () { console.log('on reconnect...') }); connection.on('error', function (err) { console.log('error:', err); }); connection.on('disconnect', function (err) { console.log('disconnect:', err); }); 采用 Reconnect 实际上相比之前是多了一层内容，我们在这里需要区分 connection 实例和 socket 句柄，并且附加正确的时间监听。 现在，我们就不用担心到底是先启动服务端还是先启动客户端了，另外，就算我们的服务端在启动之后由于某些错误关闭了一会，只要没超过最大时间（而这个也是可配置的），仍然不用担心客户端与其建立连接。 给 Server 端增加管理能力给 Server 端增加管理能力是一个比较必要的并且可以做成不同程度的，一般来说，最重要的功能则是及时清理链接，常用的做法是收到某条指令之后进行清理，或者到达一定时间之后定时清理。 这里我们可以增加一个功能，达到一定时间之后，自动清理所有链接： //server.js const net = require('net'); var connections = []; const server = net.createServer((socket) =&gt; { connections.push(socket); socket.write('goodbye\\n'); socket.on('data', (data) =&gt; { console.log('data:', data.toString()); socket.write('goodbye\\n'); }) }).on('error', (err) =&gt; { throw err; }); setTimeout(() =&gt; { console.log('clear connections'); connections.forEach((connection) =&gt; { connection.end('end') // connection.destory() }) }, 10000); // grab an arbitrary unused port. server.listen(8024, () =&gt; { console.log('opened server on', server.address()); }); 我们可以通过connection.end('end') 和 connection.destory() 来清理，一般来说，前者是正常情况下的关闭指令，需要 Client 端进行确认，而后者则是强制关闭，一般在出错的时候会这样调用。 使用 ndjson 来格式化数据ndjson 是一个比较方便的 JSON 序列化/反序列化库，相比于我们直接用 JSON，其好处主要体现在： 可以同时解析多个 JSON 对象，如果是一个文件流，即其可以包含多个 {}，但是要求则是每一个占据一行，其按行分割并且解析。 内部使用了 split2，好处就是其返回时可以保证该行的所有内容已经接受完毕，从而防止 ndjson 在序列化的时候出错。 关于 ndjson 的基本使用，可以根据上述链接查找文档，这里一般情况下，我们的使用方式如下（以下是一个 demo）： //server.js: const net = require('net'); var connections = []; const server = net.createServer((socket) =&gt; { connections.push(socket); socket.on('data', (data) =&gt; { console.log('data:', data.toString()); socket.write('{&quot;good&quot;: 1234}\\r\\n'); socket.write('{&quot;good&quot;: 4567}\\n\\n'); }) }).on('error', (err) =&gt; { throw err; }); // grab an arbitrary unused port. server.listen(8024, () =&gt; { console.log('opened server on', server.address()); }); //client.js: const Reconnect = require('reconnect-core'); const net = require('net'); const Ndjson = require('ndjson'); var Stream = require('stream'); const Connect = Reconnect(function() { var args = [].slice.call(arguments); return net.connect.apply(null, args) }); let connection = Connect(function(socket) { socket.write('world!\\r\\n'); var parser = Ndjson.parse(); var stringifier = Ndjson.stringify(); function yourhandler(){ var messager = new Stream.Duplex({ objectMode: true }); messager._read = function () { // console.log('data:', data); }; messager._write = function (data, enc, callback) { console.log(typeof data, data); // your handler return callback() }; return messager } socket // 链接句柄 .pipe(parser) .pipe(yourhandler()) .pipe(stringifier) .pipe(socket); socket.on('close', (msg) =&gt; { console.log('close', msg).toString(); connection.disconnect(); }); socket.on('end', (msg) =&gt; { console.log('end', msg); }); }); connection.connect({ port: 8024 }); connection.on('reconnect', function () { console.log('on reconnect...') }); connection.on('error', function (err) { console.log('error:', err); }); connection.on('disconnect', function (err) { console.log('disconnect:', err); }); 其中，用户具体的逻辑代码，可以是 yourhandler 函数 _write 里面的一部分，其接收的是一个一个处理好的对象。","link":"/2018/11/25/Node-js%E7%9A%84TCP%E9%93%BE%E6%8E%A5%E7%AE%A1%E7%90%86/"},{"title":"serviceWorker生命周期、请求代理与通信&#39;","text":"本文主要讲 serviceWorker 生命周期和挂载、卸载等问题，适合对 serviceWorker 的作用有所了解但是具体细节不是特别清楚的读者 以下所有分析基于 Chrome V63 serviceWorker的挂载先来一段代码感受serviceWorker注册: if ('serviceWorker' in navigator) { window.addEventListener('load', function () { navigator.serviceWorker.register('/sw.js', {scope: '/'}) .then(function (registration) { // 注册成功 console.log('ServiceWorker registration successful with scope: ', registration.scope); }) .catch(function (err) { // 注册失败:( console.log('ServiceWorker registration failed: ', err); }); }); } 通过上述代码，我们定义在/sw.js里的内容就会生效(对于当前页面之前没有 serviceWorker 的情况而言，我们注册的 serviceWorker 肯定会生效，如果当前页面已经有了我们之前注册的 serviceWorker，这个时候涉及到 serviceWorker的更新机制，下文详述) 如果我们在sw.js没有变化的情况下刷新这个页面，每次还是会有注册成功的回调以及相应的log输出，但是这个时候浏览器发现我们的 serviceWorker 并没有发生变化，并不会重置一遍 serviceWorker serviceWorker更新我们如果想更新一个 serviceWorker，根据我们的一般web开发策略，可能会想到以下几种策略： 仅变更文件名(比如把sw.js变成sw-v2.js或者加一个hash) 仅变更文件内容(仅仅更新sw.js的内容，文件名不变) 同时变更：同时执行以上两条 在这里，我可以很负责的告诉你，变更serviceWorker文件名绝对不是一个好的实践，浏览器判断 serviceWorker 是否相同基本和文件名没有关系，甚至有可能还会造成浏览器抛出404异常(因为找不到原来的文件名对应的文件了)。 所以我们只需要变更内容即可，实际上，我们每次打开或者刷新该页面，浏览器都会重新请求一遍 serviceWorker 的定义文件，如果发现文件内容和之前的不同了，这个时候: (下文中，我们使用“有关 tab”来表示受 serviceWorker 控制的页面，刷新均指普通刷新(F5/CommandR)并不指Hard Reload) 这个新的 serviceWorker 就会进入到一个 “waiting to activate” 的状态，并且只要我们不关闭这个网站的所有tab(更准确地说，是这个 serviceWorker 控制的所有页面)，新的 serviceWorker 始终不会进入替换原有的进入到 running 状态(就算我们只打开了一个有关 tab，直接刷新也不会让新的替换旧的)。 如果我们多次更新了 serviceWorker 并且没有关闭当前的 tab 页面，那么新的 serviceWorker 就会挤掉原先处于第二顺位(waiting to activate)的serviceWorker，变成waiting to activate状态 也就是说，我们只有关闭当前旧的 serviceWorker 控制的所有页面 的所有tab，之后浏览器才会把旧的 serviveWorker 移除掉，换成新的，再打开相应的页面就会使用新的了。 当然，也有一个特殊情况：如果我们在新的 serviceWorker 使用了self.skipWaiting();，像这样： self.addEventListener('install', function(event) { self.skipWaiting(); }); 这个时候，要分为以下两种情况： 如果当前我们只打开了一个有关 tab，这个时候，我们直接刷新，发现新的已经替换掉旧的了。 如果我们当前打开了若干有关 tab，这个时候，无论我们刷新多少次，新的也不会替换掉旧的，只有我们一个一个关掉tab(或者跳转走)只剩下最后一个了，这个时候刷新，会让新的替换旧的(也就是上一种情况) Chrome 的这种机制，防止了同一个页面先后被新旧两个不同的 serviceWorker 接管的情况出现。 手动更新虽然说，在页面每次进入的时候浏览器都会检查一遍 serviceWorker 是否更新，但如果我们想要手动更新 serviceWorker 也没有问题： navigator.serviceWorker.register(&quot;/sw.js&quot;).then(reg =&gt; { reg.update(); // 或者 一段时间之后更新 }); 这个时候如果 serviceWorker 变化了，那么会重新触发 install 执行一遍 install 的回调函数，如果没有变，就不会触发这个生命周期。 install 生命周期钩子我们一般会在 sw.js 中，添加install的回调，一般在回调中，我们会进行缓存处理操作，像这样： self.addEventListener('install', function(event) { console.log('[sw2] serviceWorker Installed successfully', event) event.waitUntil( caches.open('mysite-static-v1').then(function(cache) { return cache.addAll([ '/stylesheets/style.css', '/javascripts/common.39c462651d449a73b5bb.js', ]); }) ) } 如果我们新打开一个页面，如果之前有 serviceWorker，那么会触发install，如果之前没有， 那么在 serviceWorker 装载后会触发 install。 如果我们刷新页面，serviceWorker 和之前没有变化或者 serviceWorker 已经处在 waiting to activate，不会触发install，如果有变化，会触发install，但不会接管页面(上文中提到)。 activate 生命周期钩子activate 在什么时候被触发呢？ 如果当前页面没有 serviceworker ，那么会在 install 之后触发。 如果当前页面有 serviceWorker，并且有 serviceWorker更新，新的 serviceWorker 只会触发 install ，不会触发 activate 换句话说，当前变成 active 的 serviceWorker 才会被触发这个生命周期钩子 serviceWorker 代理请求serviceWorker 代理请求相对来说比较好理解，以下是一个很简单的例子： self.addEventListener('install', function(event) { console.log('[sw2] serviceWorker Installed successfully', event) event.waitUntil( caches.open('mysite-static-v1').then(function(cache) { return cache.addAll([ '/stylesheets/style.css', '/javascripts/common.39c462651d449a73b5bb.js', ]); }) ); }); self.addEventListener('fetch', function(event) { console.log('Handling fetch event for', event.request.url); // console.log('[sw2]fetch but do nothing') event.respondWith( // caches.match() will look for a cache entry in all of the caches available to the service worker. // It's an alternative to first opening a specific named cache and then matching on that. caches.match(event.request).then(function(response) { if (response) { console.log('Found response in cache:', response); return response; } console.log('No response found in cache. About to fetch from network...'); // event.request will always have the proper mode set ('cors, 'no-cors', etc.) so we don't // have to hardcode 'no-cors' like we do when fetch()ing in the install handler. return fetch(event.request).then(function(response) { console.log('Response from network is:', response); return response; }).catch(function(error) { // This catch() will handle exceptions thrown from the fetch() operation. // Note that a HTTP error response (e.g. 404) will NOT trigger an exception. // It will return a normal response object that has the appropriate error code set. console.error('Fetching failed:', error); throw error; }); }) ); }); 有两点要注意的： 我们如果这样代理了，哪怕没有 cache 命中，实际上也会在控制台写from serviceWorker，而那些真正由serviceWorker发出的请求也会显示，有一个齿轮图标，如下图： 第二点就是我们如果在 fetch 的 listener 里面 do nothing， 也不会导致这个请求直接假死掉的。 另外，通过上面的代码我们发现，实际上由于现在我们习惯给我们的文件资源加上 hash，所以我们基本上不可能手动输入需要缓存的文件列表，现在大多数情况下，我们都是借助 webpack 插件，完成这部分工作。 serviceWorker 和 页面之间的通信serviceWorker向页面发消息： sw.js: self.clients.matchAll().then(clients =&gt; { clients.forEach(client =&gt; { console.log('%c [sw message]', 'color:#00aa00', client) client.postMessage(&quot;This message is from serviceWorker&quot;) }) }) 主页面: navigator.serviceWorker.addEventListener('message', function (event) { console.log('[Main] receive from serviceWorker:', event.data, event) }); 当然，这里面是有坑的： 主界面的事件监听需要等serviceWorker注册完毕后，所以一般navigator.serviceWorker.register的回调到来之后再进行注册(或者延迟足够的时间)。 如果在主界面事件监听还没有注册成功的时候 serviceWorker 发送消息，自然是收不到的。如果我们把 serviceWorker 直接写在 install 的回调中，也是不能被正常收到的。 从页面向 serviceWorker 发送消息： 主页面: navigator.serviceWorker.controller &amp;&amp; navigator.serviceWorker.controller.postMessage('hello serviceWorker'); sw.js: self.addEventListener('message', function (event) { console.log(&quot;[sw from main]&quot;,event.data); // 输出：'sw.updatedone' }); 同样的，这也要求主界面的代码需要等到serviceWorker注册完毕后触发，另外还有一点值得注意， serviceWorker 的事件绑定代码要求主界面的serviceWorker已经注册完毕后才可以。 也就是说，如果当前页面没有该serviceWorker 第一次注册是不会收到主界面接收到的消息的。 记住，只有当前已经在 active 的 serviceWorker， 才能和主页面收发消息等。 以上就是和 serviceWorker 有关的一些内容，在下一篇文章中，我会对PWA 添加至主屏幕等功能进行总结","link":"/2018/02/11/PWA%E5%AE%9E%E8%B7%B5-serviceWorker%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E3%80%81%E8%AF%B7%E6%B1%82%E4%BB%A3%E7%90%86%E4%B8%8E%E9%80%9A%E4%BF%A1/"},{"title":"Python中的flask-todolist","text":"Flask 是一个使用 Python 语言编写的 Web 框架，它可以让你高效的编写 Web 程序。我最近用flask+vue搭建一个简单的todolist 项目示例来学习，主要是参考flask-tutorial，感兴趣的可以看看，示例代码 前言这个项目比较简单，就是用户登录，然后有一个todolist列表，可以简单的增删改，前端界面使用vue框架，所以关于flask template涉及不多，感兴趣的可以自己去学习下。本系列基于python3版本，所以命令跟python2可能有些许出入。 准备工作基础软件安装python， 编辑软件，一般文本软件软件即可，这个看个人习惯，我这边是用vscode 安装git，window用户推荐使用git bash 内置了很多linux命令 创建目录mkdir todo-list cd todo-list mkdir app serve 我这边项目里面创建两个目录app（vue前端页面，这个这里不多做介绍），serve（flask后端服务）， 虚拟环境cd serve # 安装虚拟环境 py -3 -m venv env # Windows or python3 -m venv env # Linux 和 macOS # 激活虚拟环境 env\\Scripts\\activate # Windows . env/bin/activate # Linux 或 macOS # 安装flask pip3 install flask env这个名字不固定，你也可以使用venv，记得.gitignore忽略掉这个目录。 在激活虚拟环境后，无论操作系统和 Python 版本，都可以统一使用 python 和 pip 命令来调用当前虚拟环境内的 Python 和 pip 程序/二进制文件。此时执行 python 或 pip 命令指向的程序和激活脚本在同一个目录下，在 Windows 下所在目录为 env\\Scripts\\，Linux 和 macOS 下所在目录为 env/bin/ Hello Flaskserve根目录下创建app.py # 创建app.py vim app.py # app.py内容 from flask import Flask app = Flask(__name__) @app.route('/') def hello(): return 'Welcome to My Watchlist!' # 启动 flask run 现在打开浏览器，访问 http://localhost:5000 即可访问我们的程序主页 程序发现机制如果你把上面的程序保存成其他的名字，比如 hello.py，接着执行 flask run 命令会返回一个错误提示。这是因为 Flask 默认会假设你把程序存储在名为 app.py 或 wsgi.py 的文件中。如果你使用了其他名称，就要设置系统环境变量 FLASK_APP 来告诉 Flask 你要启动哪个程序。 export FLASK_APP=hello.py # Linux 或 macOS $Env:FLASK_APP=hello.py # Window PowerShell set FLASK_APP=hello.py # Window CMD 管理环境变量为了不用每次打开新的终端会话都要设置环境变量，我们安装用来管理系统环境变量的 python-dotenv pip3 install python-dotenv 当 python-dotenv 安装后，Flask 会从项目根目录的 .flaskenv和 .env 文件读取环境变量并设置。 touch .env .flaskenv .flaskenv 用来存储 Flask 命令行系统相关的公开环境变量； .env 则用来存储敏感数据，不应该提交进Git仓库，我们把文件名 .env 添加到 .gitignore 文件的结尾（新建一行）来让 Git 忽略它。 开启调试模式： vim .flaskenv FLASK_ENV=development RoutingWeb的核心功能，这个后面经常用，有个印象即可。 Variable Rules@app.route('/user/&lt;username&gt;') def show_user_profile(username): # show the user profile for that user return 'User %s' % escape(username) @app.route('/post/&lt;int:post_id&gt;') def show_post(post_id): # show the post with the given id, the id is an integer return 'Post %d' % post_id @app.route('/path/&lt;path:subpath&gt;') def show_subpath(subpath): # show the subpath after /path/ return 'Subpath %s' % escape(subpath) 注意用户输入可能包含恶意代码，所以最好用escape进行转义处理 URL Building@app.route('/') def index(): return 'index' @app.route('/login', methods=['GET', 'POST']) def login(): return 'login' @app.route('/user/&lt;username&gt;') def profile(username): return '{}\\'s profile'.format(escape(username)) with app.test_request_context(): print(url_for('index')) print(url_for('login')) print(url_for('login', next='/')) print(url_for('profile', username='John Doe')) / /login /login?next=/ /user/John%20Doe Redirects and Errorsfrom flask import abort, redirect, url_for @app.route('/') def index(): return redirect(url_for('login')) @app.route('/login') def login(): abort(401) this_is_never_executed() from flask import render_template @app.errorhandler(404) def page_not_found(error): return render_template('page_not_found.html'), 404 Requestfrom flask import request @app.route('/login', methods=['POST', 'GET']) def login(): error = None if request.method == 'POST': if valid_login(request.form['username'], request.form['password']): return log_the_user_in(request.form['username']) else: error = 'Invalid username/password' # the code below is executed if the request method # was GET or the credentials were invalid return render_template('login.html', error=error) searchword = request.args.get('key', '') @app.route('/upload', methods=['GET', 'POST']) def upload_file(): if request.method == 'POST': f = request.files['the_file'] f.save('/var/www/uploads/' + secure_filename(f.filename)) Responsereturn stringreturn 'hello world' rerun htmlreturn '&lt;hr&gt;Hello World&lt;/hr&gt;' render templatereturn render_template('error.html'), 404 # or resp = make_response(render_template('error.html'), 404) resp.headers['X-Something'] = 'A value' return resp return json@app.route(&quot;/me&quot;) def me_api(): user = get_current_user() return { &quot;username&quot;: user.username, &quot;theme&quot;: user.theme, &quot;image&quot;: url_for(&quot;user_image&quot;, filename=user.image), } @app.route(&quot;/users&quot;) def users_api(): users = get_all_users() return jsonify([user.to_json() for user in users]) 数据库这边为了简单，使用Sqlite flask-sqlalchemy为了简化数据库操作，我们将使用 SQLAlchemy——一个 Python 数据库工具（ORM，即对象关系映射）。借助 SQLAlchemy，你可以通过定义 Python 类来表示数据库里的一张表（类属性表示表中的字段 / 列），通过对这个类进行各种操作来代替写 SQL 语句。 Flask 有大量的第三方扩展，这些扩展可以简化和第三方库的集成工作。我们下面将使用一个叫做 Flask-SQLAlchemy 的官方扩展来集成 SQLAlchemy。 pip3 install flask-sqlalchemy 大部分扩展都需要执行一个“初始化”操作。你需要导入扩展类，实例化并传入 Flask 程序实例： from flask_sqlalchemy import SQLAlchemy # 导入扩展类 app = Flask(__name__) db = SQLAlchemy(app) # 初始化扩展，传入程序实例 app 数据库URL为了设置 Flask、扩展或是我们程序本身的一些行为，我们需要设置和定义一些配置变量 Flask文档配置页面 Flask-SQLAlchemy 文档的配置页面 sqlite:////tmp/test.db mysql://username:password@server/db import os import sys from flask import Flask from flask_sqlalchemy import SQLAlchemy WIN = sys.platform.startswith('win') if WIN: # 如果是 Windows 系统，使用三个斜线 prefix = 'sqlite:///' else: # 否则使用四个斜线 prefix = 'sqlite:////' app = Flask(__name__) app.config['SQLALCHEMY_DATABASE_URI'] = prefix + os.path.join(app.root_path, 'data.db') app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False # 关闭对模型修改的监控 # 在扩展类实例化前加载配置 db = SQLAlchemy(app) 创建模型我们这边就只有两个模型，一个用户模型，一个代办项目模型 class User(db.Model, UserMixin): # 表名将会是 user id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(20)) password_hash = db.Column(db.String(128)) class TodoItem(db.Model): __tablename__ = 'todo_item' # 表名将会是 todo_item id = db.Column(db.Integer, primary_key=True) # 主键 title = db.Column(db.String(32)) # 标题 descs = db.Column(db.String(256)) # 描述 自定义命令注册命令，便于我们通过CLI对程序进行一些额外的数据处理，比如数据库建表，脚本初始化等 import click @app.cli.command() # 注册为命令 @click.option('--drop', is_flag=True, help='Create after drop.') # 设置选项 def initdb(drop): &quot;&quot;&quot;Initialize the database.&quot;&quot;&quot; if drop: # 判断是否输入了选项 db.drop_all() db.create_all() click.echo('Initialized database.') # 输出提示信息 flask initdb # 创建数据库 flask initdb --drop # 清空数据库 CURD创建from app import User, TodoItem # 导入模型类 &gt;&gt;&gt; user = User(username='wjc') # 创建一个 User 记录 &gt;&gt;&gt; ti1 = TodoItem(title='study') # 创建一个 TodoItem 记录 &gt;&gt;&gt; ti2 = TodoItem(title='game') # 再创建一个 TodoItem 记录 &gt;&gt;&gt; db.session.add(user) # 把新创建的记录添加到数据库会话 &gt;&gt;&gt; db.session.add(ti1) &gt;&gt;&gt; db.session.add(ti2) &gt;&gt;&gt; db.session.commit() # 提交数据库会话，只需要在最后调用一次即可 读取&lt;模型类&gt;.query.&lt;过滤方法（可选）&gt;.&lt;查询方法&gt; &gt;&gt;&gt; from app import TodoItem # 导入模型类 &gt;&gt;&gt; todoItem = TodoItem.query.first() # 获取 Movie 模型的第一个记录（返回模型类实例） &gt;&gt;&gt; todoItem.title # 对返回的模型类实例调用属性即可获取记录的各字段数据 'study' &gt;&gt;&gt; TodoItem.query.all() # 获取 TodoItem 模型的所有记录，返回包含多个模型类实例的列表 [&lt;TodoItem 1&gt;, &lt;TodoItem 2&gt;] &gt;&gt;&gt; TodoItem.query.count() # 获取 Movie 模型所有记录的数量 2 &gt;&gt;&gt; TodoItem.query.get(1) # 获取主键值为 1 的记录 &lt;TodoItem 1&gt; &gt;&gt;&gt; TodoItem.query.filter_by(title='game').first() # 获取 title 字段值为 game 的记录 &lt;TodoItem 2&gt; &gt;&gt;&gt; TodoItem.query.filter(TodoItem.title=='game').first() # 等同于上面的查询，但使用不同的过滤方法 &lt;TodoItem 2&gt; sqlalchemy query 更新&gt;&gt;&gt; todoItem = TodoItem.query.get(2) &gt;&gt;&gt; todoItem.title = 'play ball' # 直接对实例属性赋予新的值即可 &gt;&gt;&gt; todoItem.descs = '玩球' &gt;&gt;&gt; db.session.commit() # 注意仍然需要调用这一行来提交改动 删除&gt;&gt;&gt; todoItem = TodoItem.query.get(1) &gt;&gt;&gt; db.session.delete(todoItem) # 使用 db.session.delete() 方法删除记录，传入模型实例 &gt;&gt;&gt; db.session.commit() # 提交改动 Flask Marshmallow因为sqlalchemy查询出来的数据不能直接序列化，所以一般要转成dict，这边引入flask-marshmallow来处理 pip3 install marshmallow-sqlalchemy pip3 install flask-marshmallow 引入 from flask import Flask from flask_marshmallow import Marshmallow app = Flask(__name__) ma = Marshmallow(app) 定义 class TodoItemSchema(ma.SQLAlchemyAutoSchema): class Meta: model = TodoItem 使用 @app.route('/todoItems', methods=['GET']) def all(): todoItems = TodoItem.query.all() todoitems_schema = TodoItemSchema() return jsonify(result = todoitems_schema.dump(todoItems, many=True)) 用户认证密码存储Flask 的依赖 Werkzeug 内置了用于生成和验证密码散列值的函数，werkzeug.security.generate_password_hash() 用来为给定的密码生成密码散列值，而 werkzeug.security.check_password_hash() 则用来检查给定的散列值和密码是否对应 from werkzeug.security import generate_password_hash, check_password_hash class User(db.Model): id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(20)) username = db.Column(db.String(20)) # 用户名 password_hash = db.Column(db.String(128)) # 密码散列值 def set_password(self, password): # 用来设置密码的方法，接受密码作为参数 self.password_hash = generate_password_hash(password) # 将生成的密码保持到对应字段 def validate_password(self, password): # 用于验证密码的方法，接受密码作为参数 return check_password_hash(self.password_hash, password) # 返回布尔值 flask-jwt-extendedflask-jwt-extended pip3 install flask-jwt-extended from flask_jwt_extended import ( create_access_token, jwt_required, get_jwt_identity ) # 创建toekn access_token = create_access_token(identity=username) # 获取当前用户 current_user_name = get_jwt_identity() # 装饰器拦截接口 @app.route('/todoItem', methods=['POST']) @jwt_required def add(): todoItem = TodoItem(title = request.form['title'], descs = request.form['descs']) db.session.add(todoItem) db.session.commit() return utils.result(msg= 'Item added.') 代码结构代码结构调整，待定。。。 打包部署待定 相关链接flask-tutorial flask 1.1","link":"/2021/09/10/Python1/"},{"title":"Windows 10 如何运行红色警戒2","text":"ddraw.dll 补丁Win10 运行ra2的必须的插件补丁：https://github.com/ciraos/ts-ddraw。git clone下载过后，在 vs里面打开.sln文件，运行。不出意外的话，会编译出一个ddraw.dll文件，放到红警2或者尤里的复仇文件夹的根目录下，然后，启动游戏！ Win8 同理！ 游戏内分辨率&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;如果游戏内分辨率不对的话，就请看以下设置： Red Alert 2：（红色警戒2原版，什么？共和国之辉？）打开根目录的ra2.ini，找到[video]选项： [Video] VideoBackBuffer=no AllowHiResModes=yes AllowVRAMSidebar=no # 以下数字改为自己电脑的分辨率（分别对应宽、高）： ScreenWidth=1280 ScreenHeight=600 StretchMovies=no Yuri’s Revenge：（红色警戒2原版的官方资料片：尤里的复仇） &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;同理，打开根目录的ra2md.ini，找到[video]选项： [Video] VideoBackBuffer=no AllowHiResModes=yes AllowVRAMSidebar=no # 以下数字改为自己电脑的分辨率（分别对应宽、高）： ScreenWidth=1280 ScreenHeight=600 StretchMovies=no &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;保存，进游戏。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;另外，如果发现进游戏以后，不显示右侧建筑栏，请不要慌，请往下看！&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;打开电脑设置，定位到设置电脑分辨率的地方，然后查看缩放分辨率是不是100%。","link":"/2021/01/08/Play-RA2-in-WIN10/"},{"title":"Python中的Pandas","text":"pandas 是一种列存数据分析 API。它是用于处理和分析输入数据的强大工具，很多机器学习框架都支持将 pandas 数据结构作为输入。 虽然全方位介绍 pandas API 会占据很长篇幅，但它的核心概念非常简单，我们会在下文中进行说明。有关更完整的参考，请访问 pandas 文档网站，其中包含丰富的文档和教程资源。 基本概念首先安装一下 module，可以配置下pip源，或者 加参数-i提高下载速度 mkdir ~/.pip vim ~/.pip/pip.conf [global] index-url = https://mirrors.aliyun.com/pypi/simple pip3 install pandas -i https://mirrors.aliyun.com/pypi/simple pip3 install matplotlib -i https://mirrors.aliyun.com/pypi/simple # 如果需要绘制图表 pandas 中的主要数据结构被实现为以下两类： **DataFrame**，您可以将它想象成一个关系型数据表格，其中包含多个行和已命名的列。 **Series**，它是单一列。DataFrame 中包含一个或多个 Series，每个 Series 均有一个名称。 数据框架是用于数据操控的一种常用抽象实现形式。Spark 和 R 中也有类似的实现。 创建Series city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento']) population = pd.Series([852469, 1015785, 485199]) 创建DataFrame，通过Series pd.DataFrame({ 'City name': city_names, 'Population': population }) 更多时候，一般装载整个文件 california_housing_dataframe = pd.read_csv(&quot;https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv&quot;, sep=&quot;,&quot;) 当然，也可以通过复制表格内容 df = pd.read_clipboard() df.to_csv(&quot;some_data.csv&quot;) DataFrame 常用方法 # 显示统计信息 california_housing_dataframe.describe() # 显示前几个记录 california_housing_dataframe.head() # 绘制图表 california_housing_dataframe.hist('housing_median_age') 访问数据您可以使用熟悉的 Python dict/list 指令访问 DataFrame 数据： cities = pd.DataFrame({ 'City name': city_names, 'Population': population }) print(type(cities['City name'])) print(cities['City name']) print(type(cities['City name'][1])) print(cities['City name'][1]) 此外，pandas 针对高级索引和选择提供了极其丰富的 API（数量过多，此处无法逐一列出）。 操控数据您可以向 Series 应用 Python 的基本运算指令。例如： population / 1000 NumPy 是一种用于进行科学计算的常用工具包。pandas Series 可用作大多数 NumPy 函数的参数： import numpy as np np.log(population) 对于更复杂的单列转换，您可以使用 Series.apply。像 Python 映射函数一样，Series.apply 将以参数形式接受 lambda 函数，而该函数会应用于每个值。 下面的示例创建了一个指明 population 是否超过 100 万的新 Series： population.apply(lambda val: val &gt; 1000000) DataFrames 的修改方式也非常简单。例如，以下代码向现有 DataFrame 添加了两个 Series： cities['Area square miles'] = pd.Series([46.87, 176.53, 97.92]) cities['Population density'] = cities['Population'] / cities['Area square miles'] print(cities) 索引Series 和 DataFrame 对象也定义了 index 属性，该属性会向每个 Series 项或 DataFrame 行赋一个标识符值。 默认情况下，在构造时，pandas 会赋可反映源数据顺序的索引值。索引值在创建后是稳定的；也就是说，它们不会因为数据重新排序而发生改变。 print(city_names.index) 调用 DataFrame.reindex 以手动重新排列各行的顺序。例如，以下方式与按城市名称排序具有相同的效果： cities.reindex([2, 0, 1]) 重建索引是一种随机排列 DataFrame 的绝佳方式。在下面的示例中，我们会取用类似数组的索引，然后将其传递至 NumPy 的 random.permutation 函数，该函数会随机排列其值的位置。如果使用此重新随机排列的数组调用 reindex，会导致 DataFrame 行以同样的方式随机排列。 尝试多次运行以下单元格！ cities.reindex(np.random.permutation(cities.index)) 练习推荐使用 https://colab.research.google.com/ 练习，可以直接导入ipynb，练习库github上面有很多，这里不多赘述，底下相关链接也有列出。 相关链接colab intro to pandas user guide guipsamora/pandas_exercises","link":"/2021/09/10/Python2/"},{"title":"Maven 的 单模块&#x2F;多模块之Spring MVC+Spring+Mybatis项目讲解","text":"初衷 为了给一个叫做简的女孩子带来便利，让她更加方便学习 展示 IntelliJ IDEA 高度集成化的效果，降低 IntelliJ IDEA 入门时间 视频下载 单模块的 Spring MVC + Spring + Mybatis 讲解（基于 IntelliJ IDEA） 百度云盘：http://pan.baidu.com/s/1dEuxWh7 360 云盘（6d49）：https://yunpan.cn/cY444GphNgMe3 多模块的 Spring MVC + Spring + Mybatis 讲解（基于 IntelliJ IDEA） 百度云盘：http://pan.baidu.com/s/1hr0x6sc 360 云盘（e319）：https://yunpan.cn/cY4INmfJn8yvm 开发环境 JDK 7（理论上支持 JDK 6、JDK 7、JDK 8） Mysql 5.6 Maven 3.1.1 Tomcat 7 Git 2.7.0.2-64-bit IntelliJ IDEA 15.0.4 所有编码：UTF-8 演示内容 环境相关： Maven 环境说明：http://code.youmeek.com/2016/03/09/2016/03/Maven/ 我的 Maven 环境分享下载：http://pan.baidu.com/s/1bnPZU2b 建议你也跟我一样直接解压在 D 盘根目录，这样其他就不需要设置了 Git 环境的说明：http://code.youmeek.com/2016/02/28/2016/02/Hexo/ IntelliJ IDEA 基础教程系列：https://github.com/judasn/IntelliJ-IDEA-Tutorial IntelliJ IDEA 设置： Fork 单模块项目：https://github.com/judasn/Basic-Single-Module-SSM Fork 多模块项目：https://github.com/judasn/Basic-Multi-Module-SSM Checkout 项目并导入 IntelliJ IDEA Maven 设置 IntelliJ IDEA 文件编码设置 IntelliJ IDEA Mybatis 插件安装（该插件收费）：https://plugins.jetbrains.com/plugin/7293?pr= 项目设置： 项目 JDK 设置 项目 Facet 加入 Spring 配置 代码相关： 简单讲解 pom.xml 文件 用 IntelliJ IDEA 的 Database 初始化数据库 单元测试 启动 Tomcat 加上 Make Project 事件 访问 Controller 演示 Debug 讲解 Controller 中代码左侧的各个按钮效果 JSP 页面直接点击请求地址直接跳转到 Controller 静态资源映射特别提醒下，比如你做图片上传等等，如果你没有映射好可能都会遇到 404 查看 Druid 提供监控 演示用 Mybatis 插件自动生成代码 结束语 简，希望你有在好好学习，找到一个满意的工作","link":"/2016/03/22/Single-Module-SSM-Share/"},{"title":"持续集成TeamCity的安装和使用","text":"本文初衷 让大家了解持续集成（CI），以及入门了解 JetBrains 家的 TeamCity 的一些简单实用。 TeamCity 的一些复杂使用我暂时也不会，一样也是要看文档的，所以不管怎样你都要养成看官网文档的习惯。 TeamCity 和 Jenkins、Hudson 其实是非常一样的，基本流程都是差不多的，所以如果你会其他的几个 CI 工具的话，学习起来很快。 Docker 已经开始在引入到 CI、CD（持续交付）过程中，可以大大简化整体的过程，也许这是未来的一个方向，有兴趣的可以了解更多。 它是什么 官网定义（就一句话）：Powerful Continuous Integration out of the box 官网首页：https://www.jetbrains.com/teamcity/ 官网特性总结：https://www.jetbrains.com/teamcity/features/ 百度百科：http://baike.baidu.com/view/3703414.htm 官网文档：https://confluence.jetbrains.com/display/TCD9/TeamCity+Documentation 支持的平台、环境如下图（看不懂也没关系，只要知道它最友好的是 Java 开发即可）： 对上图的具体讲解可以看（很重要）：https://confluence.jetbrains.com/display/TCD9/Supported+Platforms+and+Environments 为什么会出现 TeamCity 的出现需要了解这个概念：持续集成（Continuous Integration） 百科定义：http://baike.baidu.com/view/5253255.htm 网络文章：http://www.ruanyifeng.com/blog/2015/09/continuous-integration.html 哪些人喜欢它 持续集成学习笔记－入门篇（1）持续集成基本概念 7 reasons why you should be using Continuous Integration What is CI and why use it? 哪些人不喜欢它 Google 不到结果，应该是没人不喜欢，只是有些人用不惯 为什么学习它 更好地保证项目质量 同类工具 Jenkins：http://jenkins-ci.org/ Travis CI：http://travis-ci.org/ Bamboo：http://www.atlassian.com/software/bamboo Hudson：http://hudson-ci.org/ QuickBuild：http://www.pmease.com/ 其他：http://www.oschina.net/project/tag/344/ci?lang=0&amp;os=0&amp;sort=view&amp;p=1 好的网络文章介绍： 持续集成工具的选择 TeamCity 入门 先来看一段官网的介绍视频 这个视频其实已经很清楚地说明了一个整理流程是怎样的，我今天只是做一个更加清晰的细节讲解而已 你需要穿越：https://www.youtube.com/watch?v=J-iYMMG6jmc#action=share TeamCity 安装部署（Linux 环境） 在我讲之前，如果你英文还可以，就到官网这里看下： Installation Quick Start 安装环境要求： JDK 1.7 以上，如果你要使用的是 2016 最新的 TeamCity 9.1 的话，JDK 官网推荐的 1.8 安装包下载：https://www.jetbrains.com/teamcity/download/#section=linux-version 开始安装（eg：TeamCity-9.1.6.tar.gz）： 解压压缩包（解压速度有点慢）：tar zxf TeamCity-9.1.6.tar.gz 解压完的目录结构讲解：https://confluence.jetbrains.com/display/TCD9/TeamCity+Home+Directory 下载的 tar.gz 的本质是已经里面捆绑了一个 Tomcat，所以如果你会 Tomcat 的话，有些东西你可以自己改的。 按我个人习惯，把解压缩的目录放在 usr 目录下：mv TeamCity/ /usr/program/ 进入解压目录：cd /usr/program/TeamCity/ 启动程序：/usr/program/TeamCity/bin/runAll.sh start 停止程序：/usr/program/TeamCity/bin/runAll.sh stop 启动需要点时间，最好能给它一两分钟吧 首次进入 假设我们已经启动了 TeamCity 访问（TeamCity 默认端口是：8111）：http://192.168.1.113:8111/ 如果访问不了，请先关闭防火墙：service iptables stop 你也可以选择把端口加入白名单中： sudo iptables -I INPUT -p tcp -m tcp --dport 8111 -j ACCEPT sudo /etc/rc.d/init.d/iptables save sudo service iptables restart 如果你要改变端口，找到下面这个 8111 位置：vim /usr/program/TeamCity/conf/server.xml &lt;Connector port=&quot;8111&quot; ... 在假设你已经可以访问的情况，我们开始进入 TeamCity 的设置向导： 如上图英文所示，TeamCity 的一些软件安装的配置、服务的配置默认都会放在：/root/.BuildServer 如果你要了解更多 TeamCity Data Directory 目录，你可以看：https://confluence.jetbrains.com/display/TCD9/TeamCity+Data+Directory 如上图英文所示，TeamCity 的一些构建历史、用户信息、构建结果等这类数据是需要放在关系型数据库上的，而默认它给我们内置了一个。 如果你要了解更多 TeamCity External Database，你可以看：https://confluence.jetbrains.com/display/TCD9/Setting+up+an+External+Database 首次使用，官网是建议使用默认的：Internal(HSQLDB)，这样我们无需在一开始使用的就考虑数据库迁移或安装的问题，我们只要好好感受 TeamCity 给我们的，等我们决定要使用了，后续再更换数据也是可以的。但是内置的有一个注意点：’TeamCity with the native MSSQL external database driver is not compatible with Oracle Java 6 Update 29, due to a bug in Java itself. You can use earlier or later versions of Oracle Java.’ 假设我们就选 Internal(HSQLDB) ，则在创建初始化数据库的过程稍微需要点时间，我这边是几分钟。 如上图所示，接受下协议 如上图所示，我们要创建一个顶级管理员账号，我个人习惯测试的账号是：admin，123456 如上图所示，安装完首次进来地址：http://192.168.1.113:8111/profile.html?tab=userGeneralSettings 我们可以完善一些管理员信息和基础配置信息，这些配置不配置都无所谓了，只是完善了可以更加好用而已 如果你有 SMTP 的邮箱，你可以来这里开启邮件通知功能：http://192.168.1.113:8111/admin/admin.html?item=email 如果你要开启通知功能那肯定下一步就是考虑通知内容的模板要如何设定：https://confluence.jetbrains.com/display/TCD9//Customizing+Notifications 模板存放路径在：/root/.BuildServer/config/_notifications，用的是 FreeMarker 的语法 项目的构建、管理 建议可以看下官网：https://confluence.jetbrains.com/display/TCD9/Configure+and+Run+Your+First+Build 现在让我们开始创建一个项目进行构建 项目管理地址：http://192.168.1.113:8111/admin/admin.html?item=projects 假设我现在有一个项目的结构是这样的： - Youshop-Parent，输出是 pom - Youshop-manage，输出是 pom - Youshop-pojo，输出 jar 我们现在以 Youshop-pojo 为例，让它自动构建并发布到 Nexus 中，其他项目道理是一样的，这里就不多说。 如上图，由于目前只要是公司的项目都应该是在版本控制的，所以这里我们选择：Create project from URL 如上图，我们可以看出 TeamCity 也支持 HTTP、SVN、Git 等链接方式。 输入你项目托管商的账号密码，我这里用的是 oschina 的。 账号、密码验证通过，现在可以给这个项目配置一个项目基本信息。 在从版本控制中下载文件和扫描文件 TeamCity 自动扫描到我是用 Maven 构建的项目，所以把 POM 文件找出来了，如果你一个项目有多种构建方式，有对应的配置文件的话，这里都会显示出来的。 我们勾选 Maven 前面的复选框，点击：Use Selected 由于我们的目标是构建完自动发布到 Nexus，所以我们的 Maven Goals 应该是：clean install deploy，这里我们应该点击：Edit，进行编辑。 如果你不懂 Maven Goals，那你需要学习下，这个很重要。 官网：http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html 如上图，这台服务器必须装有 Maven、JDK 如上图，Goals 我们的目标是 clean install deploy 如上图，Maven Home 我建议是自己自定义路径，这样肯定不会有问题。所以你服务器上的 Maven 安装路径是什么你就在这里填写上去。Maven 目前支持的最高版本是：3.2.5 下载 Maven 3.2.5：http://archive.apache.org/dist/maven/maven-3/3.2.5/binaries/ 如上图，Java Parameters 我建议也是自己自定义路径，别选择其他选项。 如上图，点击 run，开始手动构建该项目 如上图，我们看到简略的构建日志 如上 2 张图，我们看到详细的构建内容 如上图，当我们版本控制中有提交的时候，TeamCity 会识别到记录 如上图，我们可以看到提交的 Commit Message 信息。 如上图，右边红圈的三个按钮是用来处理这次提交的，常用的是第一次按钮，点击对此次版本进行构建 如上图，如果你要看所有的提交记录，可以在 Change Log 看到并且指定版本构建 如上图，如果在你不想要这个项目的时候可以进行删除 如上图，因为 Goals 里面有 deploy 命令，所以构建完成会发布到 Nexus 中，这样团队的人就可以用到最新的代码了 如上 gif 图演示，项目常去的几个配置地方就是这样些了 配置自动构建触发行为 官网提供的触发行为有：https://confluence.jetbrains.com/display/TCD9/Configuring+Build+Triggers 下面我们举例说常见的：VCS Trigger、Schedule Trigger 如上图，点击 Add new trigger 添加触发器 如上图，常见的触发器就这些了 如上图，配置好 VCS Trigger 效果是，当我们有代码提交的时候，TeamCity 检查到新版本之后自动构建，这个最常用 如上图，Schedule Trigger 的作用就是定时构建，除了常用的几个输入框设置定时外，TeamCity 还可以使用 Cron 语法进行设置 TeamCity 采用的 Cron 语法是 Quartz，具体你可以看：Quartz CronTrigger Tutorial 如果你不懂 Cron 语法那就算了，但是我想做 Java 这个应该要会的 集成 IntelliJ IDEA 安装 IntelliJ IDEA：https://confluence.jetbrains.com/display/TCD9/IntelliJ+Platform+Plugin 如上图，我们可以直接连上 TeamCity 服务器，这里的用户名密码是 TeamCity 的账号系统。 如上图，连上去的效果是这里会打钩 如上图，我们可以直接把别人提交的内容做 patch 直接用 IntelliJ IDEA 进行整合 还有其他很多结合玩法大家可以自己去尝试下 其他 TeamCity 的插件列表：https://confluence.jetbrains.com/display/TW/TeamCity+Plugins 使用外部数据库： 使用外部数据库：https://confluence.jetbrains.com/display/TCD9/Setting+up+an+External+Database 迁移到外部数据库：https://confluence.jetbrains.com/display/TCD9/Migrating+to+an+External+Database 数据备份：https://confluence.jetbrains.com/display/TCD9/TeamCity+Data+Backup 代码检查功能： https://confluence.jetbrains.com/display/TCD9/Code+Quality+Tools https://confluence.jetbrains.com/display/TCD9/Code+Quality+Tools#CodeQualityTools-IntelliJIDEA-poweredCodeAnalysisTools https://confluence.jetbrains.com/pages/viewpage.action?pageId=74847276","link":"/2016/03/23/TeamCity/"},{"title":"Rust初探:实现二叉树的增删与遍历","text":"Rust 简介实际上自己接触 Rust 的时间还是很有限的，这里也不会对 Rust 进行长篇大论地介绍，简单来说，Rust 是一个性能和 c++ 相近的系统级编程语言，同时，由于其所有权与变量生命周期等机制的设计，使其相对于 c++ 来说拥有内存安全的优势，几乎不会出现诸如悬垂指针、数组越界、段错误等问题，在微软、百度、字节跳动等公司均有所使用。 关于 Rust 的特性以及未来，知乎这个问题中的一些高赞回答以及相关的评论，非常值得一看。 本文会以二叉树这样一个具体的例子出发，来对 Rust 的一部分知识内容进行学习。 实现二叉树数据结构定义结构之前在 Javascript 等语言中，我们只要对对象有所了解，实现一个二叉树的数据结构是非常简单的事情，而在 Rust 中，可能对于新手来说仅仅是实现基本的数据结构就是一个比较脑壳疼的事情。 我们一般会写出类似这样的代码： struct Tree { value: i32, left: Tree, // 直接使用 Tree 是不行的 right: Tree } 自然不会通过 Rust 的编译检查，会报错例如：recursive type has infinite size，不过其同时给我们提供了解决方案，这里我们使用 Box&lt;T&gt; 指针。 另外，考虑到二叉树的左右子树可能为空，所以这里我们还需要增加一个 Option。 最终我们的二叉树数据结构定义如下： #[derive(Debug, Default)] struct Tree { value: i32, left: Option&lt;Box&lt;Tree&gt;&gt;, right: Option&lt;Box&lt;Tree&gt;&gt; } 实现基本的方法这里我们实现一些二叉树的基本的方法，作为上述结构体的方法，我们将实现以下方法： 获取二叉树节点的值（其实也可以没有这个方法）。 修改二叉树节点的值。 设置子树。 删除子树。 这里除了第一个，其余我们都需要传递 self 的可变引用，我们的实现如下： impl Tree { fn get_val(&amp;self) -&gt; i32 { return self.value; } fn set_val(&amp;mut self, val: i32) -&gt; i32 { self.value = val; return self.value; } fn insert(&amp;mut self, dir: &amp;String, val: Tree) { assert!(dir == &quot;left&quot; || dir == &quot;right&quot;); match dir.as_ref() { &quot;left&quot; =&gt; self.left = Some(Box::new(val)), &quot;right&quot; =&gt; self.right = Some(Box::new(val)), _ =&gt; { println!(&quot;Insert Error: only left and right supported&quot;); process::exit(1); } } } fn delete(&amp;mut self, dir: &amp;String) { assert!(dir == &quot;left&quot; || dir == &quot;right&quot;); match dir.as_ref() { &quot;left&quot; =&gt; self.left = None, &quot;right&quot; =&gt; self.right = None, _ =&gt; { println!(&quot;Insert Error: only left and right supported&quot;); process::exit(1); } } } } 遍历二叉树这里遍历二叉树我们作为一个单独的方法，而不是属性方法来实现，这样会更符合我们平时的业务场景，这里其实问题比较多的，我们先简易实现一个版本： fn traverse(tree: Tree) { println!(&quot;Node Value: {:?}&quot;, tree.value); if tree.left.is_some() { traverse(*tree.left.unwrap()); // 手动解引用 } if tree.right.is_some() { traverse(*tree.right.unwrap()); // 手动解引用 } } 如果我们测试一下这个版本，发现的确能够正常遍历的，但是实际上这有一个致命的问题： 这里采用的是所有权的移动，而不是不可变借用，这会导致我们的函数执行完后原来变量的所有权已经被移动了，换一种说法则是会消耗掉这个变量，这显然不是我们预期的。 虽然我们也可以在函数中返回 tree 的方式来最后再次移动所有权，但这样非常不便于实现，经过重构，我们采用了如下的方式实现： fn traverse(tree: &amp;Tree) { println!(&quot;Node Value: {:?}&quot;, tree.value); match tree.left { Some(ref x) =&gt; traverse(x), _ =&gt; {} } match tree.right { Some(ref x) =&gt; traverse(x), _ =&gt; {} } } 另外一个注意点则是由于 unwrap() 本身是一个消耗性操作，我们这里不能使用 unwrap，参考stackOverflow的提问1、stackOverflow的提问2。 我们最终的完整代码如下： use::std::process; use std::borrow::Borrow; #[derive(Debug, Default)] struct Tree { value: i32, left: Option&lt;Box&lt;Tree&gt;&gt;, right: Option&lt;Box&lt;Tree&gt;&gt; } impl Tree { fn get_val(&amp;self) -&gt; i32 { return self.value; } fn set_val(&amp;mut self, val: i32) -&gt; i32 { self.value = val; return self.value; } fn insert(&amp;mut self, dir: &amp;String, val: Tree) { assert!(dir == &quot;left&quot; || dir == &quot;right&quot;); match dir.as_ref() { &quot;left&quot; =&gt; self.left = Some(Box::new(val)), &quot;right&quot; =&gt; self.right = Some(Box::new(val)), _ =&gt; { println!(&quot;Insert Error: only left and right supported&quot;); process::exit(1); } } } fn delete(&amp;mut self, dir: &amp;String) { assert!(dir == &quot;left&quot; || dir == &quot;right&quot;); match dir.as_ref() { &quot;left&quot; =&gt; self.left = None, &quot;right&quot; =&gt; self.right = None, _ =&gt; { println!(&quot;Insert Error: only left and right supported&quot;); process::exit(1); } } } } // 原始的非消耗性遍历: // fn traverse(tree: &amp;Tree) { // println!(&quot;Node Value: {:?}&quot;, tree.value); // if tree.left.is_some() { // // cannot move out of borrowed content // // 首先 unwrap 是一个消耗性操作 // // 这是由于 unwrap 函数造成? as_ref 也不行 // traverse((tree.left.as_ref().map(|x| **x).unwrap()).borrow()); // } // // if tree.right.is_some() { // // // cannot move out of borrowed content // // traverse(tree.right.unwrap().borrow()); // // } // } // 非消耗性遍历 fn traverse(tree: &amp;Tree) { println!(&quot;Node Value: {:?}&quot;, tree.value); match tree.left { Some(ref x) =&gt; traverse(x), _ =&gt; {} } match tree.right { Some(ref x) =&gt; traverse(x), _ =&gt; {} } } // 消耗性遍历： // fn traverse(tree: Tree) { // println!(&quot;Node Value: {:?}&quot;, tree.value); // if tree.left.is_some() { // traverse(*tree.left.unwrap()); // 手动解引用 // } // if tree.right.is_some() { // traverse(*tree.right.unwrap()); // 手动解引用 // } // } fn main() { println!(&quot;begin rust tree test:&quot;); let mut tree = Tree { value : 12, ..Default::default() }; let mut left = Tree { value : 121, ..Default::default() }; tree.insert(&amp;String::from(&quot;left&quot;), left); let mut right = Tree { value : 122, ..Default::default() }; tree.insert(&amp;String::from(&quot;right&quot;), right); // tree.delete(&amp;String::from(&quot;right&quot;)); // println!(&quot;Tree val: {:?}&quot;, left.get_val()); 不能这样写，所有权已经被移动 traverse(&amp;tree); // traverse(tree); }","link":"/2019/09/07/Rust%E5%88%9D%E6%8E%A2-%E5%AE%9E%E7%8E%B0%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%A2%9E%E5%88%A0%E4%B8%8E%E9%81%8D%E5%8E%86/"},{"title":"VPS + Shadowsocks 可以是什么，做什么，如果使用（详细图文）","text":"本文初衷 帮助我弟弟，理解 VPS，理解服务器部署相关，最重要的是理解穿越这件事 帮助更多的开发者或是求知者，勇于求知，丰富自己的精神世界 以这篇文章作为回报，感谢鐡的指导 写、修改这篇文章大概花了差不多 5 个小时，如果连同过去的一些素材积累，差不多 7 个小时，希望能帮助你。 VPS 介绍它是什么 术语定义 维基百科定义：https://en.wikipedia.org/wiki/Virtual_private_server 百度百科定义：http://baike.baidu.com/item/VPS 简单地讲就是：服务器中的隔板房 本质：利用虚拟化技术，把一台实体服务器利用软件分割成多台虚拟化的服务器。 你可以简单粗暴地理解为：阿里云、腾讯云提供的那些服务器服务，本质都没啥区别，就是提供资源。 同类技术： 你可以用中文搜索：云主机 虚拟主机 VPS 你可以用英文搜索：Dedicated hosting VPS Virtual cloud Shared hosting 今天有看到这样一个标题顺便拿来做说明：linuxVPS基本命令，这个标题是不合理的。Linux 命令和 VPS 没啥关系，以后不要再犯这种错误了。 学习前提/依赖 英文单词好点 会点 Linux 命令，关于 Linux 知识我有整理过：https://github.com/judasn/Linux-Tutorial 懂一点代理相关的思维，不懂也没关系 知道外面世界和内部世界的差别，不知道也没关系 哪些人不喜欢它 懒人 为什么学习它 需要：Google 搭建博客 搭建个人私有云 放爬虫程序 做离线下载（注意经常别下盗版，外国要求这个很严），你看到很多人把 Youtube 视频转到国内优酷啥的，基本就是利用它的 服务器能做啥，它就能做啥，所以靠你想象力，也希望你能帮我想一下还有啥可以玩的，我这边 768M 内存感觉用不完 VPS 使用过程选择一个 VPS 提供商 目前在国内，使用的主流外国 VPS 厂商有这些： Linode，算是业界 Top，就是贵 Vultr，我现在用的，也是下文演示的 VPS 我的 Vultr 夏季特别推荐码 来自我朋友：鐡的 Vultr 夏季特别推荐码 使用这个注册我可以得到 30 美金，你可以得到 20 美金，这些钱提取不出来的，只能在里面消费。 DigitalOcean（跟 Vultr 模式差不多） BandwagonHost（俗称：搬瓦工） HostUs Amazon AWS VPS Vultr 注册账号 Vultr 我的 Vultr 夏季特别推荐码 来自我朋友：鐡的 Vultr 夏季特别推荐码 点击链接上面，注册的按钮就在官网页面右上角，你自己去注册吧 注册要点说明： vultr 是禁止用户重复注册账号的，即如果你的支付信息有2个账号在使用，那么你的账户会被后台关闭的。简单的说就是一个账户的支付信息比如paypal 账号是对应唯一的一个的，如果你再次使用这个paypal支付另外一个新注册的账号的话，那么账户就会被关闭。所以，重复的注册账号是不可取的，试用到期效果好续费即可。 来源：https://www.bandwagong.com/vultrvps/ Vultr 的一些特性介绍： Vultr 官网优点介绍集合：https://www.vultr.com/features/ 各个节点的下载速度测试：https://www.vultr.com/faq/#downloadspeedtests 各个节点当前的状态情况：https://www.vultr.com/status/ Vultr 收费模式 按每小时计算，比如官网套餐中： 5 美元一个月的机器配置，本质就是把 5 美元平摊到每个月里每个小时需要花多少金额。 也因为这个按时模式，所以你可以在 Vultr 上随便创建世界上不同地区节点的服务器，自己不喜欢的，速度不好的，都可以随便销毁。每次开通一个服务器，最低消费是 0.01 美金，所以本质上开通是需要成本的。 推荐你刚刚开始的时候可以自己多创建几个服务器，然后对比测试下，看看你当前的网络下，使用哪个地区节点速度更好。国内三大运营商走的路线是不同的，所有还是有差异的。 Vultr 账号充值 既然是服务器肯定是要钱的啦，不然别人没法活。 建议用 Paypal 支付，别用信用卡，不然后面取消绑定信用卡是个麻烦事，充值方法操作具体看下图。 如果你没 Paypal 账号，那就注册一个，这个是不需要穿越的：https://www.paypal.com 在 Paypal 上绑定一个全币卡信用卡，我不知道银联的国内单币卡可不可以，我猜想是不可以的。建议开发者平时还要准备一个全币卡，方便生活 Paypal 的购买流程跟常规银联的支付流程差不多，这里不多说 Vultr 上创建空白系统 或 一键搭建某些应用 Vultr 提供其他一些支持，比如提供专用的主机，存储类云（用的是机械硬盘，容量大）。支持单独开通 IPV6，开通自动备份，防 DDOS 攻击等等，当然了这些肯定是收费的。这些都跟新手没关系，如果你会了自己去勾选，这里不讲。 访问创建系统页面：https://my.vultr.com/deploy/ 创建空白系统： 第一步选择服务器所在地区，效果如下图： 目前，国内建议选洛杉矶（Los Angeles, California），其他我都试过了，包括日本，响应都不是最优的，包括鐡在上海的方案，基本也是倾向于洛杉矶的。 亚特兰大（Atlanta, Georgia）目前没有了，但是我测试了它公开的服务下载速度，发现是最快的，所以如果后面有亚特兰大的也建议开一个服务器，对比下，如果不错就换过来。 平时你还可以关注下：西雅图（Seattle, Washington），硅谷（Silicon Valley, California） 第二步选择服务器系统，效果如下图： 如果你会 Linux，你喜欢选 CentOS 或是 Ubuntu、Debian 我都是无所谓的，本质没啥区别，但是如果你不会，那就乖乖地跟着箭头来。 第三步选择服务器硬件情况，效果如下图： 如果你土豪，你选啥我都觉得没事，但是如果你跟我一样，主要是为了 Shadowsocks，那就选择图片上的红圈内容，最便宜，而最合适。 默认 Vultr 是选择第二个，10 美金一个月的套餐，所以你要注意点。 第四步开始自动部署系统，效果如下图： 页面下面剩下的选项跟你没关系，懂的人自己去考虑。新手只要点击：Deploy Now。 创建 Vultr 帮我们直接安装好的某个应用系统： 第一步同创建空白系统，这里不重复 第二步选择服务器应用，效果如下图： 如果你懂这些应用各代表什么意思，那就选。我用过 OpenVPN 效果是，部署完后在服务器详情页面下面会给我们一个 OpenVPN 服务地址、账号、密码，访问地址可以下载到一个专用的本地客户端，下载下来安装完成后，打开这个软件，输入账号密码即可连接。 第三步同创建空白系统，这里不重复 第四步同创建空白系统，这里不重复 在 Vultr 上销毁一个系统 访问我们的服务器列表页面：https://my.vultr.com/ 主要操作按钮如下： Server Details，查看该服务器相关详情，比如 SSH 的账号密码等 Server Stop，停止当前服务器，让服务器无法提供服务，费用可是照扣 Server Restart，重启服务器 Server Destroy，点击这个按钮即可销毁服务器，并且里面的数据全部跟着销毁，费用不会再扣 本地 SSH 连接到 VPS 系统 从这里开始就需要会一点 Linux 知识 点击上一步教学中提到的：Server Details，查看你自己的服务器 SSH 账号、密码，效果如下图： 把红框中的，IP 地址，用户名，密码，都记录下来，等下要用。端口是默认的 22。 下载 Xshell 进行 SSH 连接 这篇文章有使用 Xshell 说明：@Xshell+Xftp–在win下最喜欢的SSH终端仿真器/终端模拟器(介绍+下载) 把上面记下的：IP 地址，用户名，密码在 Xshell 里进行配置 判断 VPS 属于哪种虚拟化方案 常见的方案有：Xen、OpenVZ、Xen HVM、KVM 安装 virt-what 软件 wget http://people.redhat.com/~rjones/virt-what/files/virt-what-1.15.tar.gz tar zxvf virt-what-1.15.tar.gz cd virt-what-1.15/ ./configure make &amp;&amp; make install 运行命令：virt-what，脚本就会判断出当前环境所使用的虚拟技术。Vultr 的结果是：kvm 测试 VPS 性能 下面内容建立在你已经 SSH 连上服务器的基础上 测试 VPS 纯硬件性能 使用 UnixBench 测试机子性能： cd /opt wget --no-check-certificate https://github.com/teddysun/across/raw/master/unixbench.sh chmod +x unixbench.sh ./unixbench.sh，剩下就等结果，其他不用管了，执行的时间我这边大概是 30 min，所以还是有点长的。 我最后的结果是：System Benchmarks Index Score==1286.7，简单粗暴地讲，如果是 1 个 CPU 的机子，如果你的结果值低于 500，那就是比较垃圾的 VPS 了，优秀的应该在 1000 左右，八九百算是普通（别人说的）。 2016-12-11，我也购买了：DigitalOcean 旧金山每月 5 美金的机子，测试得到的分数：973.8。 测试我们当前位置到 VPS 所在地址之间的网络请求响应能力 线上 TraceRoute 工具： http://tool.chinaz.com/Tracert/ http://www.webkaka.com/tracert.aspx http://www.17ce.com/ 本地客户端工具：WinMTR 下载地址：http://winmtr.net/download-winmtr/ 扫描结果类似这样（实际地址我改动了）： |------------------------------------------------------------------------------------------| | WinMTR statistics | | Host - % | Sent | Recv | Best | Avrg | Wrst | Last | |------------------------------------------------|------|------|------|------|------|------| | 61.144.0.226 - 2 | 86 | 85 | 1 | 9 | 105 | 11 | | 183.56.31.85 - 0 | 90 | 90 | 1 | 9 | 74 | 5 | | 61.144.3.6 - 2 | 86 | 85 | 3 | 8 | 20 | 5 | | 202.97.33.194 - 17 | 54 | 45 | 0 | 7 | 24 | 10 | | 202.97.60.42 - 19 | 49 | 40 | 0 | 6 | 19 | 5 | | 202.97.58.134 - 4 | 78 | 75 | 175 | 180 | 193 | 179 | | 202.97.50.26 - 2 | 86 | 85 | 166 | 174 | 203 | 166 | | 218.30.54.182 - 6 | 74 | 70 | 263 | 267 | 278 | 267 | | 50.248.117.226 - 2 | 86 | 85 | 160 | 168 | 179 | 169 | | las-b4-link.telia.net - 12 | 62 | 55 | 272 | 277 | 382 | 277 | | 25.132.70.2.vultr.com - 0 | 90 | 90 | 173 | 179 | 201 | 181 | 在 CentOS 上搭建 Shadowsocks 服务器端 重要声明：即使你有 Shadowsocks，你也不一定能用。如果你的公司环境是有很强的内网拦截，或是各种屏蔽，你依旧还是可能使用不了的。如果是一般家用，基本不会出现问题。 Shadowsocks 中文名称：影梭？也有称作：小飞机，本质是：Socks 5 代理，也是一个代理工具。 这里安装 Shadowsocks 使用的是网络上的一键脚本，更多资料可以看： shadowsocks-libev 一键安装脚本（CentOS）：https://teddysun.com/357.html Shadowsocks-Python 版一键安装脚本（CentOS，Debian，Ubuntu）：https://teddysun.com/342.html Shadowsocks-go 一键安装脚本（CentOS，Debian，Ubuntu）：https://teddysun.com/392.html ShadowsocksR 一键安装脚本（CentOS，Debian，Ubuntu）：https://shadowsocks.be/9.html 我推荐使用：shadowsocks-libev 一键安装脚本 部署方法（新手请保证是 root 权限）： cd /opt ; wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-libev.sh chmod +x shadowsocks-libev.sh ./shadowsocks-libev.sh 2&gt;&amp;1 | tee shadowsocks-libev.log 接下来会有几个交互提示，需要你按要求完成，比如输入你要设置的端口、账号、密码等，具体看提示。脚本安装完成后，会将 shadowsocks-libev 自动加入开机自启动。 安装完成后效果是这样的： Congratulations, shadowsocks-libev install completed! Your Server IP:你自己的服务器IP Your Server Port:你自己设置的服务器端口 Your Password:你自己设置的密码 Your Local IP:127.0.0.1 Your Local Port:1080 Your Encryption Method:aes-256-cfb Welcome to visit:https://teddysun.com/357.html Enjoy it! 卸载 Shadowsocks： cd /opt ; ./shadowsocks-libev.sh uninstall 其他命令： 启动：/etc/init.d/shadowsocks start 停止：/etc/init.d/shadowsocks stop 重启：/etc/init.d/shadowsocks restart 查看状态：/etc/init.d/shadowsocks status Shadowsocks 客户端的介绍 因为是开源的，所有有很多，这里也感谢 Shadowsocks 的开源者：clowwindy Windows 客户端：https://github.com/shadowsocks/shadowsocks-windows/releases 百度云（密码：rlh1）：http://pan.baidu.com/s/1jHXGG1w 360 云盘（密码：30d3）：https://yunpan.cn/cMZLSPzTeUWJp Linux 客户端：https://github.com/shadowsocks/shadowsocks-gui OS X 客户端：https://github.com/shadowsocks/shadowsocks-iOS/wiki/Shadowsocks-for-OSX-Help iOS 客户端（在 App Store 中搜索下面名字）： 这类软件都很友好，配置都是很简单的，跟 PC 客户端类型，填上 SS 的相应信息即可。 Shadowrocket，收费，我正在用的 Surge，收费 Wingy，免费 Potatso，收费 A.BIG.T，收费 Android 客户端：https://github.com/shadowsocks/shadowsocks-android/releases 别人整理的客户端列表：https://shadowsocks.com/client.html 以 Windows 的 Shadowsocks 客户端为例进行说明： Windows 的 Shadowsocks 是一个绿色版软件 重要思维提醒： （重点）Shadowsocks 是一个代理工具，一启动该软件，即使你没有勾选：启用系统代理，也是同样可以用的，只是你需要利用浏览器扩展进行代理设置，本文下一个锚点会讲这个知识点 如果你想简单方便，不利用浏览器的扩展进行高级设置的话，那你也可以直接使用 Shadowsocks 自带功能，勾选：启用系统代理，然后在 系统代理模式 这个选项上选择对应模式 对于系统代理模式有两个选项模式： PAC 模式，我称作：自动模式。它有一个 PAC 文件，里面有一些网址的匹配规则，这些网址是历代国人整理出来的，帮你辨别一些有用网站需要使用它就自动代理。这里有一个衍生知识：GFWList 也因为有这样的一个 PAC 文件，所以你也可以自己添加规则，如果你会的话。当然了，如果你经常做这种事，那我建议你使用下面要讲的，配合浏览器扩展使用。 最新的 GFWList 地址：https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 全局模式，系统中所有支持 Socks 5 的软件都可以利用它代理，所以这里的要点是要用它代理必须是支持 Socks 5 也因为 Shadowsocks 这个特点，所以如果你要真正的全局代理，建议还是用 VPN 工具，比如 OpenVPN （重点）整体效果看下图 Gif：Gif 图片太大，点击单独打开 浏览器扩展的使用 Firefox 扩展 FoxyProxy Standard：https://addons.mozilla.org/zh-CN/firefox/addon/foxyproxy-standard/ （重点）配置方法如下图 Gif 演示：Gif 图片太大，点击单独打开 配置要点整理： 新建代理服务器 填写 Shadowsocks 默认的本地代理信息：主机或 IP 地址：127.0.0.1，端口：1080 选择 Socks 代理、Socks V5 工作模式选择：使用基于其预定模板的代理服务器 模式订阅增加 GFWList 地址：https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 快速添加功能的开启，这个是为了方便我们添加一些不在 GFWList 的站点进行代理的便捷操作。 Chrome 扩展 Proxy SwitchyOmega：https://chrome.google.com/webstore/detail/proxy-switchyomega/padekgcemlokbadohgkifijomclgjgif?hl=zh-CN （重点）配置方法如下图 Gif 演示：Gif 图片太大，点击单独打开 配置要点整理： 编辑 proxy 设置，填写 Shadowsocks 默认的本地代理信息：主机或 IP 地址：127.0.0.1，端口：1080，选择 Socks 代理、Socks V5 编辑 auto switch 设置 模式订阅增加 GFWList 地址：https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 规则列表规则选择：proxy 浏览器工作模式选择：auto switch 其他人文章参考：http://www.ihacksoft.com/chrome-switchyomega.html Shadowsocks 的同类 SpechtLite：https://github.com/zhuhaow/SpechtLite/releases ShadowsocksX：https://github.com/RobertYan/ShadowsocksX/releases ShadowsocksX-R：https://github.com/yichengchen/ShadowsocksX-R/releases 对 VPS 上的 Shadowsocks 进行加速 CentOS 6 下安装锐速 资料来源：https://github.com/91yun/serverspeeder 先确保虚拟化技术，Openvz 的机子无法安装：wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/code/master/vm_check.sh &amp;&amp; bash vm_check.sh 更改 CentOS 内核为 kernel-2.6.32-504.el6： 64 位系统： wget https://liujihong.com/download/linux/kernel-2.6.32-504.el6.x86_64.rpm rpm -ivh kernel-2.6.32-504.el6.x86_64.rpm --force 32 位系统： whttps://liujihong.com/download/linux/kernel-2.6.32-504.el6.i686.rpm rpm -ivh kernel-2.6.32-504.el6.i686.rpm --force 重启服务器：reboot 如果上面地址失效，可以查看这里：https://github.com/1265578519/kernel/tree/master/6.5 开始安装锐速：wget -N --no-check-certificate https://github.com/91yun/serverspeeder/raw/master/serverspeeder.sh &amp;&amp; bash serverspeeder.sh 全局代理 利用软件 Proxifier：https://www.proxifier.com/ 学习材料：http://www.jianshu.com/p/a84fc3d6bbe6 资料整理 来自 Google 过程中的资料（真心感谢这些作者）： http://www.laozuo.org/tag/vultr-vps https://www.bandwagong.com/vultrvps/ 结束语 不管你是不是开发者，不管你身在何处。请，多求知、求真。以上。","link":"/2016/08/19/VPS/"},{"title":"关于","text":"欢迎来到我的小站呀，很高兴遇见你！🤝 🏠 关于本站👨‍💻 博主是谁⛹ 兴趣爱好📬 联系我呀","link":"/2019/01/25/about/"},{"title":"物种起源（全英文）","text":"Primitive earthYou would think, there is a genetic molecule called DNA in each of our cells? So, is there any genetic molecule before DNA? My answer is: “Yes.” In ancient Earth, there are countless volcanoes on the sea floor. On both sides of the erupting crater are hot magma spewing out and the “deep sea black chimneys” produced by the instant solidification of the cold sea water. The size of the gap formed by these substances is exactly one. The cell is so big, how come you say it is so coincidental? They are organic compounds formed by hydration of sulfide in seawater and carbon dioxide in seawater. but! When we think about it carefully, we will find that the black smoke emitted by the “deep sea black chimney” is generally alkaline, but the sea water is acidic, and the strong acid-base reaction cannot bring about organic matter! However, the deep-sea black chimney cannot be composed of a single mineral! The water comes very violently, and it is very irregular. It is a flood. When the water comes in order, electricity can be generated. If there is a film between the acid and alkali to neutralize this strong reaction, then it becomes subtle, and it happens to form the black chimney minerals such as Say: “Iron, sulfur, nickel…” Such minerals can slowly and orderly release the strong stimulation produced by this acid and alkali, and produce organic matter. So far, the earliest appeared in the oceans of the primitive earth. A batch of “life” is such organic matter, nourishing the underwater world.but! This “life” can only be said to be “life”. From the theories given above, we can see that there are volcanic activity, organic matter, and “life” on the sea floor. These “life” are just rock gaps. Yes, you If you read it right, it is the rock gap. To put it simply, the rock gap is a cell. Here, you can imagine that there are countless black chimneys in the ocean of the primitive earth, and each chimney is filled with countless rock cells. However, since it is a primitive earth with submarine volcanoes, magma is definitely indispensable. The magma has a high temperature of 400 degrees Celsius, but the outside of the magma is cold sea water. The magma erupts from the crater and is instantly solidified to form black smoke. These rock cells have been given heat by magma. In the billions of years of sadness, they have synthesized various macromolecules. Finally, a special kind of rock cells have synthesized a special biological macromolecule RNA. RNA RNA, or ribonucleic acid, is a nucleic acid that is similar in structure to DNA but different in subtle ways. The cell uses RNA for a number of different tasks, one of which is called messenger RNA, or mRNA. And that is the nucleic acid information molecule that transfers information from the genome into proteins by translation. Another form of RNA is tRNA, or transfer RNA, and these are non-protein encoding RNA molecules that physically carry amino acids to the translation site that allows them to be assembled into chains of proteins in the process of translation.We all know what function the cell has, ah! Yes, split reproduction, RNA molecules also come to play this set, it will replicate itself! As a result, every RNA biological macromolecule begins to replicate itself, one produces 2, 2 produces 3, and 3 all things! In this way, RNA biological macromolecules keep replicating, and this rock cell has life! However, some mistakes occurred during the replication of some RNA macromolecules, causing the offspring to be different from themselves. This is the earliest mutation and inheritance. Slowly, every large RNA molecule will pass through the cracks in the rock to reach another rock cell, and then replicate and absorb their organic matter. In this way, day after day, year after year, the rock cell of this black chimney There is life! Slowly, from pyruvate (C3H4O3) to acetyl-CoA (CoA), from triphosphate triadenosine (APT) to nicotinamide adenine dinucleotide (NADH), an important organic molecule is Included in each life, DNA with good chemical stability finally replaced RNA as a carrier of genetic information, proteins with good catalytic properties were given the responsibility of manipulating biochemical reactions, and RNA controls every aspect of life An important part of this is that these small molecules control the most basic part of life, and in the next billions of years, it will evolve on this basis. But among so many cells, only one is our common ancestor-Luca (LUCA)…","link":"/2021/09/10/acid/"},{"title":"Butterfly添加全局吸底Aplayer教程","text":"以下文章只是教程如果遇到使用問題，请仔细查看插件文档，或者到插件那裏反饋 本文转载于butterfly作者 – Jerry，以获得其本人允许。 前言如果你想使用aplayer，很多人都會推薦安裝hexo-tag-aplayer這款插件。這款插件通過Hexo獨有的標籤外掛，我們可以很方便的寫入一些參數，插件就會幫我們生成對應的html。如果你只是使用一些簡單的功能，其實無需使用到這個插件，只需以html格式書寫就行，不用插件去轉換。 例如： 如果使用插件，在markdown中要這樣寫 {% meting \"000PeZCQ1i4XVs\" \"tencent\" \"artist\" \"theme:#3F51B5\" \"mutex:true\" \"preload:auto\" %} 其會被插件渲染為 &lt;div id=&quot;aplayer-uxAIfEUs&quot; class=&quot;aplayer aplayer-tag-marker meting-tag-marker&quot; data-id=&quot;000PeZCQ1i4XVs&quot; data-server=&quot;tencent&quot; data-type=&quot;artist&quot; data-mode=&quot;circulation&quot; data-autoplay=&quot;false&quot; data-mutex=&quot;true&quot; data-listmaxheight=&quot;340px&quot; data-preload=&quot;auto&quot; data-theme=&quot;#3F51B5&quot;&gt;&lt;/div&gt; 如果我們不想使用插件，就需要在markdown中用html的格式書寫，同時把主題配置文件中的aplayerInject開啟 &lt;div class=&quot;aplayer&quot; data-id=&quot;000PeZCQ1i4XVs&quot; data-server=&quot;tencent&quot; data-type=&quot;artist&quot; data-mutex=&quot;true&quot; data-preload=&quot;auto&quot; data-theme=&quot;#3F51B5&quot;&gt;&lt;/div&gt; 這樣我們就可以不用使用多一個插件，當然這種東西見仁見智，選自己喜歡的就行。 回到正題，這篇文章將教大家如何在Butterfly上使用全局吸底Aplayer 關閉 asset_inject此步驟適用於安裝了hexo-tag-aplayer插件的人 由於需要全局都插入aplayer和meting資源，為了防止插入重複的資源，需要把asset_inject設為false 在Hexo的配置文件中 aplayer: meting: true asset_inject: false 開啟主題的aplayerInject在主題的配置文件中，enable設為true和per_page設為true # Inject the css and script (aplayer/meting) aplayerInject: enable: true per_page: true 插入Aplayer html為了適配hexo-tag-aplayer，主題內置的Meting js 仍為1.2版本，並非最新的2.x版本。 Aplayer html 例子： &lt;div class=&quot;aplayer no-destroy&quot; data-id=&quot;000PeZCQ1i4XVs&quot; data-server=&quot;tencent&quot; data-type=&quot;artist&quot; data-fixed=&quot;true&quot; data-mini=&quot;true&quot; data-listFolded=&quot;false&quot; data-order=&quot;random&quot; data-preload=&quot;none&quot; data-autoplay=&quot;true&quot; muted&gt;&lt;/div&gt; 參數解釋 option default description data-id require song id / playlist id / album id / search keyword data-server require music platform: netease, tencent, kugou, xiami, baidu data-type require song, playlist, album, search, artist data-fixed false enable fixed mode data-mini false enable mini mode data-autoplay false audio autoplay data-theme #2980b9 main color data-loop all player loop play, values: ‘all’, ‘one’, ‘none’ data-order list player play order, values: ‘list’, ‘random’ data-preload auto values: ‘none’, ‘metadata’, ‘auto’ data-volume 0.7 default volume, notice that player will remember user setting, default volume will not work after user set volume themselves data-mutex true prevent to play multiple player at the same time, pause other players when this player start play data-lrctype 0 lyric type data-listfolded false indicate whether list should folded at first data-listmaxheight 340px list max height data-storagename metingjs localStorage key that store player setting require代表着這些參數是必須要使用的，其它的參數則可以根據自己需要配置。 配置全局吸底，data-fixed和data-mini也必須配置，配置為true 如果使用Pjax，則在class裏需添加no-destroy，這樣防止切換頁面時Aplayer被銷毀 把aplayer代碼插入到主題配置文件的inject.bottom去 inject: head: bottom: - &lt;div class=&quot;aplayer no-destroy&quot; data-id=&quot;000PeZCQ1i4XVs&quot; data-server=&quot;tencent&quot; data-type=&quot;artist&quot; data-fixed=&quot;true&quot; data-mini=&quot;true&quot; data-listFolded=&quot;false&quot; data-order=&quot;random&quot; data-preload=&quot;none&quot; data-autoplay=&quot;true&quot; muted&gt;&lt;/div&gt; 運行Hexo就可以看到網頁左下角出現了Aplayer 最後，如果你想切換頁面時，音樂不會中斷。請把主題配置文件的pjax設為true UI 調整按照上面的步驟設置完成后，瀏覽器左下角會出現Aplayer。打開文章頁面時，你會發現打開Toc目錄的按鈕被遮擋了。我們需要修改CSS來改變按鈕的位置。位置怎麽移動根據自己需求決定，這裏列出2種方法。 向上調整#toggle-sidebar { bottom: 80px } 在主題配置文件中，添加到inject去 inject: head: - '&lt;style type=&quot;text/css&quot;&gt;#toggle-sidebar {bottom: 80px}&lt;/style&gt;' 向右調整#toggle-sidebar { left: 100px } 在主題配置文件中，添加到inject去 inject: head: - '&lt;style type=&quot;text/css&quot;&gt;#toggle-sidebar {left:100px}&lt;/style&gt;'","link":"/2020/07/31/butterfly1/"},{"title":"docker","text":"Docker是一个开源的容器引擎，它可以帮助我们更快地交付应用。Docker可将应用程序和基础设施层隔离，并且能将基础设施当作程序一样进行管理。使用Docker，可更快地打包、测试以及部署应用程序，并可减少从编写到部署运行代码的周期。 准备工作官网有详细的安装教程，然后配置下加速器即可，我这边使用阿里云的docker镜像加速器。 基本命令镜像命令# 查询镜像 docker search nginx # 下载镜像 docker pull nginx # 列出镜像 docker images docker images java docker images java:8 docker images --digests docker images --filter &quot;dangling=true&quot; # 展示虚悬镜像 # 删除本地镜像 docker rmi hello-world docker rmi -f $(docker images) # 保存镜像 docker save busybox &gt; busybox.tar docker save --output busybox.tar busybox # 加载镜像 docker load &lt; busybox.tar.gz docker load --input fedora.tar # 构建镜像 docker build [OPTIONS] PATH | URL | - 容器命令新建并启动容器[重要]使用以下docker run 命令即可新建并启动一个容器。该命令是我们最常用的命令了，它有很多选项，下面笔者列举一些常用的选项。 ① -d选项：表示后台运行 ② -P选项：随机端口映射 ③ -p选项：指定端口映射，有以下四种格式。 ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort ④ –network选项：指定网络模式，该选项有以下可选参数： –network=bridge： 默认选项，表示连接到默认的网桥。 –network=host：容器使用宿主机的网络。 –network=container:NAME_or_ID：告诉Docker让新建的容器使用已有容器的网络配置。 –network=none：不配置该容器的网络，用户可自定义网络配置。 示例1： docker run java /bin/echo 'Hello World' 这样终端会打印Hello World的字样，跟在本地直接执行/bin/echo 'Hello World' 一样。 示例2： docker run -d -p 91:80 nginx 这样就能启动一个Nginx容器。在本例中，我们为docker run添加了两个参数，含义如下： -d # 后台运行-p 宿主机端口:容器端口 # 开放容器端口到宿主机端口 访问http://Docker宿主机IP:91/ TIPS 需要注意的是，使用docker run命令创建容器时，会先检查本地是否存在指定镜像。如果本地不存在该名称的镜像，Docker就会自动从Docker Hub下载镜像并启动一个Docker容器。 列出容器[重要]使用docker ps 命令即可列出运行中的容器。执行该命令后，可看到类似于如下的表格。 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES784fd3b294d7 nginx &quot;nginx -g 'daemon off&quot; 20 minutes ago Up 2 seconds 443/tcp, 0.0.0.0:91-&gt;80/tcp backstabbing_archimedes 如需列出所有容器（包括已停止的容器），可使用-a参数。 该表格包含了七列，含义如下： ① CONTAINER_ID：表示容器ID。 ② IMAGE：表示镜像名称。 ③ COMMAND：表示启动容器时运行的命令。 ④ CREATED：表示容器的创建时间。 ⑤ STATUS：表示容器运行的状态。Up表示运行中，Exited表示已停止。 ⑥ PORTS：表示容器对外的端口号。 ⑦ NAMES：表示容器名称。该名称默认由Docker自动生成，也可使用docker run命令的–name选项自行指定。 命令格式： docker ps [OPTIONS] 参数： Name, shorthand Default Description --all, -a false 列出所有容器，包括未运行的容器，默认只展示运行的容器 --filter, -f 根据条件过滤显示内容 --format 通过Go语言模板文件展示镜像 --last, -n -1 显示最近创建n个容器（包含所有状态） --latest, -l false 显示最近创建的容器（包含所有状态） --no-trunc false 不截断输出 --quiet, -q false 静默模式，只展示容器的编号 --size, -s false 显示总文件大小 示例： docker ps -n 5docker ps -a -q 停止容器[重要]使用docker stop 命令，即可停止容器。 命令格式： docker stop [OPTIONS] CONTAINER [CONTAINER...] 参数： Name, shorthand Default Description --time, -t 10 强制杀死容器前等待的时间，单位是秒 示例： docker stop 784fd3b294d7 其中784fd3b294d7 是容器ID，当然也可使用docker stop 容器名称 来停止指定容器。 强制停止容器[重要]可使用docker kill 命令停止一个或更多运行着的容器。 命令格式： docker kill [OPTIONS] CONTAINER [CONTAINER...] 参数： Name, shorthand Default Description --signal, -s KILL 向容器发送一个信号 例如： docker kill 784fd3b294d7 启动已停止的容器[重要]使用docker run 命令，即可新建并启动一个容器。对于已停止的容器，可使用docker start 命令来启动。 命令格式： docker start [OPTIONS] CONTAINER [CONTAINER...] 参数： Name, shorthand Default Description --attach, -a false 连接STDOUT/STDERR并转发信号 --checkpoint 从该检查点还原 --checkpoint-dir 使用自定义的检查点存储目录 --detach-keys 覆盖断开容器的关键顺序 --interactive, -i false 连接容器的STDIN 例如： docker start 784fd3b294d7 重启容器[重要]可使用docker restart 命令来重启容器。该命令实际上是先执行了docker stop 命令，然后执行了docker start 命令。 命令格式： docker restart [OPTIONS] CONTAINER [CONTAINER...] 参数： Name, shorthand Default Description --time, -t 10 关闭容器前等待的时间，单位是秒 进入容器[重要]某场景下，我们可能需要进入运行中的容器。 ① 使用docker attach 命令进入容器。 例如： docker attach 784fd3b294d7 很多场景下，使用docker attach 命令并不方便。当多个窗口同时attach到同一个容器时，所有窗口都会同步显示。同理，如果某个窗口发生阻塞，其他窗口也无法执行操作。 ② 使用nsenter 进入容器 nsenter工具包含在util-linux 2.23或更高版本中。为了连接到容器，我们需要找到容器第一个进程的PID，可通过以下命令获取： docker inspect --format &quot;{{.State.Pid}}&quot; $CONTAINER_ID 获得PID后，就可使用nsenter命令进入容器了： nsenter --target &quot;$PID&quot; --mount --uts --ipc --net --pid 下面给出一个完整的例子： [root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES784fd3b294d7 nginx &quot;nginx -g 'daemon off&quot; 55 minutes ago Up 3 minutes 443/tcp, 0.0.0.0:91-&gt;80/tcp backstabbing_archimedes[root@localhost ~]# docker inspect --format &quot;{{.State.Pid}}&quot; 784fd3b294d795492[root@localhost ~]# nsenter --target 95492 --mount --uts --ipc --net --pidroot@784fd3b294d7:/# 读者也可将以上两条命令封装成一个Shell，从而简化进入容器的过程。 ③ docker exec docker exec -it 容器id /bin/bash 删除容器[重要]使用docker rm 命令即可删除指定容器。 命令格式 docker rm [OPTIONS] CONTAINER [CONTAINER...] 参数： Name, shorthand Default Description --force, -f false 通过SIGKILL信号强制删除正在运行中的容器 --link, -l false 删除容器间的网络连接 --volumes, -v false 删除与容器关联的卷 例1：删除指定容器。 docker rm 784fd3b294d7 该命令只能删除已停止的容器，如需删除正在运行的容器，可使用-f参数。 例2：删除所有的容器。 docker rm -f $(docker ps -a -q) 导出容器将容器导出成一个压缩包文件。 命令格式： docker export [OPTIONS] CONTAINER 参数： Name, shorthand Default Description --output, -o 将内容写到文件而非STDOUT 示例： docker export red_panda &gt; latest.tardocker export --output=&quot;latest.tar&quot; red_panda 导入容器使用docker import 命令即可从归档文件导入内容并创建镜像。 命令格式： docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] 参数： Name, shorthand Default Description --change, -c 将Dockerfile指令应用到创建的镜像 --message, -m 为导入的镜像设置提交信息 示例： docker import nginx2.tar nginx Dockerfile基本指令ADD 复制文件ADD复制文件 格式为： ADD &lt;src&gt;... &lt;dest&gt; ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 从src目录复制文件到容器的dest。其中src可以是Dockerfile所在目录的相对路径，也可以是一个URL，还可以是一个压缩包。 除了要复制解压文件，一般不建议使用，使用RUN跟COPY命令就可以很好替代。 ADD microservice-discovery-eureka-0.0.1-SNAPSHOT.jar app.jar ARG 设置构建参数设置构建参数，类似于ENV。和ENV不同的是，ARG设置的是构建时的环境变量，在容器运行时是不会存在这些变量的。 格式为： ARG &lt;name&gt;[=&lt;default value&gt;] ARG user1=someuser CMD 容器启动命令用于为执行容器提供默认值。每个Dockerfile只有一个CMD命令，如果指定了多个CMD命令，那么只有最后一条会被执行，如果启动容器的时候指定了运行的命令，则会覆盖掉CMD指定的命令。 支持三种格式： CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (推荐使用，会解析成json数组，所以要记得要用双引号) CMD [&quot;param1&quot;,&quot;param2&quot;] (为ENTRYPOINT指令提供预设参数) CMD command param1 param2 (在shell中执行) 示例： CMD echo &quot;This is a test.&quot; | wc - COPY 复制文件复制文件，格式为： COPY &lt;src&gt;... &lt;dest&gt; COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 复制本地端的src到容器的dest。COPY指令和ADD指令类似，COPY不支持URL和压缩包。 ENTRYPOINT 入口点格式为： ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT command param1 param2 ENTRYPOINT和CMD指令的目的一样，都是指定Docker容器启动时执行的命令，可多次设置，但只有最后一个有效。ENTRYPOINT不可被重写覆盖。 ENTRYPOINT、CMD区别：http://blog.csdn.net/newjueqi/article/details/51355510 ENV 设置环境变量用于设置环境变量，格式为： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key&gt;=&lt;value&gt; ... 示例： ENV JAVA_HOME /path/to/java EXPOSE 声明暴露的端口用于声明在运行时容器提供服务的端口，格式为： EXPOSE &lt;port&gt; [&lt;port&gt;...] 需要注意的是，这只是一个声明，运行时并不会因为该声明就打开相应端口。该指令的作用主要是帮助镜像使用者理解该镜像服务的守护端口；其次是当运行时使用随机映射时，会自动映射EXPOSE的端口。示例： # 声明暴露一个端口示例 EXPOSE port1 # 相应的运行容器使用的命令 docker run -p port1 image # 也可使用-P选项启动 docker run -P image # 声明暴露多个端口示例 EXPOSE port1 port2 port3 # 相应的运行容器使用的命令 docker run -p port1 -p port2 -p port3 image # 也可指定需要映射到宿主机器上的端口号 docker run -p host_port1:port1 -p host_port2:port2 -p host_port3:port3 image FROM 指定基础镜像指定基础镜像，FROM指令有点像Java里面的extend关键字。需要注意的是，FROM指令必须指定且需要写在其他指令之前。FROM指令后的所有指令都依赖于该指令所指定的镜像。 支持三种格式： FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; FROM &lt;image&gt;@&lt;digest&gt; LABEL 为镜像添加元数据为镜像添加元数据。 格式为： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... 示例： LABEL &quot;com.example.vendor&quot;=&quot;ACME Incorporated&quot; LABEL com.example.label-with-value=&quot;foo&quot; LABEL version=&quot;1.0&quot; LABEL description=&quot;This text illustrates \\that label-values can span multiple lines.&quot; MAINTAINER 指定维护者的信息（已过时）MAINTAINER指令用于指定维护者的信息，用于为Dockerfile署名。 格式为： MAINTAINER &lt;name&gt; 示例： MAINTAINER 周立&lt;eacdy0000@126.com&gt; 注：该指令已过时，建议使用如下形式： LABEL maintainer=&quot;SvenDowideit@home.org.au&quot; RUN 执行命令该指令支持两种格式： RUN &lt;command&gt; RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] RUN &lt;command&gt; 在shell终端中运行，在Linux中默认是/bin/sh -c ，在Windows中是 cmd /s /c，使用这种格式，就像直接在命令行中输入命令一样。RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 使用exec执行，这种方式类似于函数调用。指定其他终端可以通过该方式操作，例如：RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] ，该方式必须使用双引号[“]而不能使用单引号[‘]，因为该方式会被转换成一个JSON 数组。 USER 设置用户该指令用于设置启动镜像时的用户或者UID，写在该指令后的RUN、CMD以及ENTRYPOINT指令都将使用该用户执行命令。 格式为： USER 用户名 示例： USER daemon VOLUME 指定挂载点该指令使容器中的一个目录具有持久化存储的功能，该目录可被容器本身使用，也可共享给其他容器。当容器中的应用有持久化数据的需求时可以在Dockerfile中使用该指令。格式为： VOLUME [&quot;/data&quot;] 示例： VOLUME /data 使用示例： FROM nginxVOLUME /tmp 当该Dockerfile被构建成镜像后，/tmp目录中的数据即使容器关闭也依然存在。如果另一个容器也有持久化的需求，并且想使用以上容器/tmp目录中的内容，则可使用如下命令启动容器： docker run -volume-from 容器ID 镜像名称 # 容器ID是di一个容器的ID，镜像是第二个容器所使用的镜像。 WORKDIR 指定工作目录格式为： WORKDIR /path/to/workdir 切换目录指令，类似于cd命令，写在该指令后的RUN，CMD以及ENTRYPOINT指令都将该目录作为当前目录，并执行相应的命令。 其他Dockerfile还有一些其他的指令，例如STOPSINGAL、HEALTHCHECK、SHELL等。由于并不是很常用，本书不作赘述。有兴趣的读者可前往https://docs.docker.com/engine/reference/builder/ 扩展阅读。 CMD/ENTRYPOINT/RUN区别 参考：https://segmentfault.com/q/1010000000417103 实战相关链接Docker官方网站 Docker GitHub Docker 入门到实践","link":"/2021/09/10/docker/"},{"title":"centOS7.2搭建nginx环境以及负载均衡","text":"之所以要整理出这篇文章，是因为1是搭建环境的过程中会遇到大大小小各种问题，2是网上目前也没有关于centos7.2搭建nginx环境的问题整理，因此在这里记录。 前置工作就不赘述了，首先ssh root@115.29.102.81 (换成你们自己的公网IP)登陆进入到自己的服务器命令行，之后开始基本的安装： 1.添加资源 添加CentOS 7 Nginx yum资源库,打开终端,使用以下命令(没有换行): sudo rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 2.安装Nginx 在你的CentOS 7 服务器中使用yum命令从Nginx源服务器中获取来安装Nginx： 这里有一个需要注意的地方，尽量不要用网上的下载源码包然后再传到服务器上的方式进行安装，因为nginx已经不算是简单的Linux了，做了很多扩展，这个时候如果你用源码包安装会出现各种各样的问题，尽量用已经封装好的rpm\\yum进行安装 sudo yum install -y nginx Nginx将完成安装在你的CentOS 7 服务器中。 3.启动Nginx 刚安装的Nginx不会自行启动。运行Nginx: sudo systemctl start nginx.service 如果一切进展顺利的话，现在你可以通过你的域名或IP来访问你的Web页面来预览一下Nginx的默认页面 当然，这里一般很可能会无法访问的。 我们先不急于解决我们的问题，先看看nginx的基本配置： Nginx配置信息 网站文件存放默认目录 /usr/share/nginx/html 网站默认站点配置 /etc/nginx/conf.d/default.conf 自定义Nginx站点配置文件存放目录,自己在这里也可以定义别的名字的.conf，这个的作用以后再说。 /etc/nginx/conf.d/ Nginx全局配置 /etc/nginx/nginx.conf 在这里你可以改变设置用户运行Nginx守护程序进程一样,和工作进程的数量得到了Nginx正在运行,等等。 Linux查看公网IP 您可以运行以下命令来显示你的服务器的公共IP地址:(这个其实没用，不是公网IP) ip addr show eth0 | grep inet | awk '{ print $2; }' | sed 's/\\/.*$//' 好了，这个时候我们再来看看可能遇到的问题：无法在公网访问。 这个时候首先看看配置文件default.conf对不对，一个正确的例子：(域名要先进行解析到响应的IP) server { listen 80; server_name nginx.310058.cn; #charset koi8-r; #access_log /var/log/nginx/log/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } 确定文件没问题了，看看这个时候是不是开启了nginx进程： ps -ef | grep nginx 应该会输出一个或者多个进程，如果没有的话就开启或者重启试试看。 这个时候接下来再试试在服务器上： ping 115.29.102.81 telnet 115.29.102.81 80 wget nginx.310058.cn 如果有的命令没有就直接yum安装下: yum -y install telnet 如果都可以的话，之后在本机尝试以上三行。如果没有命令也要安装下： brew install wget 发现很可能本机telnet不通，而服务器telnet通。这个时候就是防火墙的问题。 ####centos7.2防火墙 由于centos 7版本以后默认使用firewalld后，网上关于iptables的设置方法已经不管用了，所以根本就别想用配置iptables做啥，根本没用。 查看下防火墙状态： [root@iZ28dcsp7egZ conf.d]# systemctl status firewalld ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2016-08-03 12:06:44 CST; 2h 49min ago Main PID: 424 (firewalld) CGroup: /system.slice/firewalld.service └─424 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid Aug 03 12:06:41 iZ28dcsp7egZ systemd[1]: Starting firewalld - dynamic firewall daemon... Aug 03 12:06:44 iZ28dcsp7egZ systemd[1]: Started firewalld - dynamic firewall daemon. 增加80端口的权限： firewall-cmd --zone=public --add-port=80/tcp --permanent 别忘了更新防火墙的配置： firewall-cmd --reload 这个时候再restart nginx.service 一下就会发现应该好了。 nginx 停止： service nginx restart 也可以重启nginx kill -QUIT 进程号 #从容停止 kill -TERM 进程号 #或者 kill -INT 进程号 #快速停止 p-kill -9 nginx 强制停止 nginx -t #验证配置文件 前提是进入相应的配置的目录（自己实际测试的时候发现没有进入相应的配置目录也是可以的） nginx -s reload #重启 kill -HUP 进程号 #重启的另外一种方式 官方文档地址：https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/Security_Guide/sec-Using_Firewalls.html#sec-Introduction_to_firewalld 附1:一个简单的负载均衡的实现:weight默认是1，自己也可以更改。 upstream mypro { ip_hash; server 111.13.100.92 weight=2; server 183.232.41.1; server 42.156.140.7; } server { listen 8090; location / { proxy_pass http://mypro; } } 附2:防火墙基本学习： 1、firewalld简介 firewalld是centos7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念 firewalld有图形界面和工具界面，由于我在服务器上使用，图形界面请参照官方文档，本文以字符界面做介绍 firewalld的字符界面管理工具是 firewall-cmd firewalld默认配置文件有两个：/usr/lib/firewalld/ （系统配置，尽量不要修改）和 /etc/firewalld/ （用户配置地址） zone概念： 硬件防火墙默认一般有三个区，firewalld引入这一概念系统默认存在以下区域（根据文档自己理解，如果有误请指正）： drop：默认丢弃所有包 block：拒绝所有外部连接，允许内部发起的连接 public：指定外部连接可以进入 external：这个不太明白，功能上和上面相同，允许指定的外部连接 dmz：和硬件防火墙一样，受限制的公共连接可以进入 work：工作区，概念和workgoup一样，也是指定的外部连接允许 home：类似家庭组 internal：信任所有连接 对防火墙不算太熟悉，还没想明白public、external、dmz、work、home从功能上都需要自定义允许连接，具体使用上的区别还需高人指点 2、安装firewalld root执行 # yum install firewalld firewall-config 3、运行、停止、禁用firewalld 启动：# systemctl start firewalld 查看状态：# systemctl status firewalld 或者 firewall-cmd --state 停止：# systemctl disable firewalld 禁用：# systemctl stop firewalld 4、配置firewalld 查看版本：$ firewall-cmd --version 查看帮助：$ firewall-cmd --help 查看设置： 显示状态：$ firewall-cmd --state 查看区域信息: $ firewall-cmd --get-active-zones 查看指定接口所属区域：$ firewall-cmd --get-zone-of-interface=eth0 拒绝所有包：# firewall-cmd --panic-on 取消拒绝状态：# firewall-cmd --panic-off 查看是否拒绝：$ firewall-cmd --query-panic 更新防火墙规则：# firewall-cmd --reload # firewall-cmd --complete-reload 两者的区别就是第一个无需断开连接，就是firewalld特性之一动态添加规则，第二个需要断开连接，类似重启服务 将接口添加到区域，默认接口都在public # firewall-cmd --zone=public --add-interface=eth0 永久生效再加上 --permanent 然后reload防火墙 设置默认接口区域 # firewall-cmd --set-default-zone=public 立即生效无需重启 打开端口（貌似这个才最常用） 查看所有打开的端口： # firewall-cmd --zone=dmz --list-ports 加入一个端口到区域： # firewall-cmd --zone=dmz --add-port=8080/tcp 若要永久生效方法同上 打开一个服务，类似于将端口可视化，服务需要在配置文件中添加，/etc/firewalld 目录下有services文件夹，这个不详细说了，详情参考文档 # firewall-cmd --zone=work --add-service=smtp 移除服务 # firewall-cmd --zone=work --remove-service=smtp 还有端口转发功能、自定义复杂规则功能、lockdown，由于还没用到，以后再学习","link":"/2016/08/03/centOS7-2%E6%90%AD%E5%BB%BAnginx%E7%8E%AF%E5%A2%83%E4%BB%A5%E5%8F%8A%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"title":"国产linux操作系统deepin","text":"背景音乐 Linux说起Linux，你一定会联想到一只傻傻的企鹅坐在空气上。 就在快要过去的2020年，linux29岁了。对29了。很明显，我这次文章的目的不是为了解密这只企鹅为什么可以坐在空气上。现在，进入正题。 linux,又叫GNU/linux,是一种免费使用和自由传播的类UNIX操作系统，其内核由林纳斯·本纳第克特·托瓦兹于1991年10月5日首次发布，它主要受到Minix和Unix思想的启发，是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的Unix工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。Linux有上百种不同的发行版，如基于社区开发的debian、archlinux，和基于商业开发的Red Hat Enterprise Linux、SUSE、oracle linux等。 系统简史Linux操作系统的诞生、发展和成长过程始终依赖着五个重要支柱：Unix操作系统、MINIX操作系统、GNU计划、POSIX标准和Internet网络。20世纪80年代，计算机硬件的性能不断提高，PC的市场不断扩大，当时可供计算机选用的操作系统主要有Unix、DOS和MacOS这几种。Unix价格昂贵，不能运行于PC；DOS显得简陋，且源代码被软件厂商严格保密；MacOS是一种专门用于苹果计算机的操作系统。此时，计算机科学领域迫切需要一个更加完善、强大、廉价和完全开放的操作系统。由于供教学使用的典型操作系统很少，因此当时在荷兰当教授的美国人AndrewS.Tanenbaum编写了一个操作系统，名为MINIX，为了向学生讲述操作系统内部工作原理。MINIX虽然很好，但只是一个用于教学目的的简单操作系统，而不是一个强有力的实用操作系统，然而最大的好处就是公开源代码。全世界学计算机的学生都通过钻研MINIX源代码来了解电脑里运行的MINIX操作系统，芬兰赫尔辛基大学大学二年级的学生Linus Torvalds就是其中一个，在吸收了MINIX精华的基础上，Linus于1991年写出了属于自己的Linux操作系统，版本为Linux0.01，是Linux时代开始的标志。他利用Unix的核心，去除繁杂的核心程序，改写成适用于一般计算机的x86系统，并放在网络上供大家下载，1994年推出完整的核心Version1.0，至此，Linux逐渐成为功能完善、稳定的操作系统，并被广泛使用。 服务器Linux服务器是设计出来进行业务处理应用的，在网络和计算机系统当中有广泛的应用，可以提供数据库管理和网络服务等内容，是一种性能非常高的和开源的服务器，在我国的计算机系统的客户端当中，有很多采用的就是Linux系统，其使用的范围非常广泛，用户体验反应较好。但是对于一些希望计算机应用性能比较高的单位而言，windows系统需要经常进行资源整合和碎片化管理，系统在配置的时候经常需要重新启动，这就无法避免产生停机的问题。同时，由于Linux系统的处理能力非常强悍，具备不可比拟的稳定性特征，因而Linux系统就不用经常进行重启，Linux系统的变化可以在配置的过程中实现，所以Linux服务器出现故障的概率比较小，所以很多企业组织在计算机配置的过程中经常使用Linux系统，从而降低服务器发生崩溃的可能性，很多企业在配置Linux系统的时候，都是通过减少服务器的故障发生率，实现企业业务的高效运转。 系统内核的路由转发Linux操作系统嵌入了TCP/IP协议栈，协议软件具有路由转发功能。路由转发依赖作为路由器的主机中安装多块网卡，当某一块网卡接收到数据包后，系统内核会根据数据包的目的IP地址，查询路由表，然后根据查询结果将数据包发送到另外一块网卡，最后通过此网卡把数据包发送出去。此主机的处理过程就是路由器完成的核心功能。通过修改Linux系统内核参数ip_forward的方式实现路由功能，系统使用sysctl命令配置与显示在/proc/sys目录中的内核参数。首先在命令行输入：cat/proc/sys/net/ipv4/ip_forwad，检查Linux内核是不是开启IP转发功能。如果结果为1，表明路由转发功能已经开启；如果结果为0，表明没有开启。出于安全考虑，Linux内核默认是禁止数据包路由转发的。在linux系统中，有临时和永久两种方法启用转发功能。临时启用：此种方法只对当前会话起作用，系统重启后不再启用。临时开启的命令格式：sysctl–wnet.ipv4.ip_forward=1。永久启用：此种永久性的启用IP转发功能，通过更改配置文件/etc/sysctl.conf中的语句行“net.ipv4.ip_forward=0”，修改为“net.ipv4.ip_forward=1”，保存配置文件后执行命令sysctl–p/etc/sysctl.conf，配置便立即启用。 安全隐患及加固措施用户账户以及登录安全删除多余用户和用户组。Linux是多用户操作系统，存在很多种不一样的角色系统账号，当安装完成操作系统之后，系统会默认为未添加许用户组及用户，若是部分用户或是用户组不需要，应当立即删除它们，否则黑客很有可能利用这些账号，对服务器实施攻击。具体保留哪些账号，可以依据服务器的用途来决定。关闭不需要的系统服务。操作系统安装完成之后，其会在安装的过程当中，会自主的启动各种类型的服务程序内容，对于长时间运行的服务器而言，其运行的服务程序越多，则系统的安全性就越低。所以，用户或是用户组就需要将一些应用不到的服务程序进行关闭，这对提升系统的安全性能，有着极大的帮助。密码安全策略。在Linux之下，远程的登录系统具备两种认证的形式：即密钥与密码认证。其中，密钥认证的形式，主要是将公钥储存在远程的服务器之上，私钥存储在本地。当进行系统登陆的时候，再通过本地的私钥，以及远程的服务器公钥，进行配对认证的操作，若是认证的匹配度一致，则用户便能够畅通无阻的登录系统。此类认证的方式，并不会受到暴力破解的威胁。与此同时，只需要确保本地私钥的安全，使其不会被黑客所盗取即可，攻击者便不能够通过此类认证方式登陆到系统中。所以，推荐使用密钥方式进行系统登陆。有效应用su、sudo命令。su命令的作用的是对用户进行切换。当管理员登录到系统之后，使用su命令切换到超级用户角色来执行一些需要超级权限的命令。但是由于超级用户的权限过大，同时，需要管理人员知道超级用户密码，因此su命令具有很严重的管理风险。sudo命令允许系统赋予普通用户一些超级权限，并且不需普通用户切换到超级用户。因此，在管理上应当细化权限分配机制，使用sudo命令为每一位管理员服务其特定的管理权限。 远程访问及登陆认证安全远程登录应用SSH登陆方式。telnet是一类存在安全隐患的登录认证服务，其在网络之上利用明文传输内容，黑客很容易通过截获telnet数据包，获得用户的登陆口令。并且telnet服务程序的安全验证方式存在较大的安全隐患，使其成为黑客攻击的目标。SSH服务则会将数据进行加密传输，能够防止DNS欺骗以及IP欺骗，并且传输的数据是经过压缩，在一定程度上保证了服务器远程连接的安全。文件系统的安全加固系统重要文件。在Linux系统中，如果黑客取得超级权限，那么他在操作系统里面就不会再有任何的限制地做任何事情。在这种情况下，一个加固的文件系统将会是保护系统安全的最后一道防线。管理员可通过chattr命令锁定系统一些重要文件或目录。文件权限检查与修改。如果操作系统当中的重要文件的权限设置不合理，则会对操作系统的安全性，产生最为直接的影响。所以，系统的运行维护人员需要及时的察觉到权限配置不合理的文件和目录，并及时修正，以防安全事件发生。安全设定/tmp、/var/tmp、/dev/shm。在该操作系统当中，其用于存放临时文件的目录，主要有两个，分别为/tmp与/var/tmp。它们有个共同特点，就是所有的用户可读可写和执行，这样就对系统产生了安全隐患。针对这两个目录进行设置，不允许这两个目录下执行应用程序。 系统软件安全绝大多数的服务器遭受攻击是因为系统软件或者应用程序有重大漏洞。黑客通过这些漏洞，可以轻松地侵入服务器。管理员应定期检查并修复漏洞。最常见的做法是升级软件，将软件保持在最新版本状态。这样就可以在一定程度上降低系统被入侵的可能性。 开发工具Linux已经成为工作、娱乐和个人生活等多个领域的支柱，人们已经越来越离不开它。在Linux的帮助下，技术的变革速度超出了人们的想象，Linux开发的速度也以指数规模增长。因此，越来越多的开发者也不断地加入开源和学习Linux开发地潮流当中。在这个过程之中，合适的工具是必不可少的，可喜的是，随着Linux的发展，大量适用于Linux的开发工具也不断成熟。 容器放眼现实，如今已经是容器的时代了。容器既极其容易部署，又可以方便地构建开发环境。如果针对的是特定的平台的开发，将开发流程所需要的各种工具都创建到容器映像中是一种很好的方法，只要使用这一个容器映像，就能够快速启动大量运行所需服务的实例。 版本控制工具如果正在开发一个大型项目，又或者参与团队开发，版本控制工具是必不可少的，它可以用于记录代码变更、提交代码以及合并代码。如果没有这样的工具，项目几乎无法妥善管理 文本编辑工具如果没有文本编辑器，在Linux上开发将会变得异常艰难。当然，文本编辑器之间孰优孰劣，具体还是要取决于开发者的需求。 集成开发环境有时候会需要比较两个文件的内容来找到它们之间的不同之处，它们可能是同一文件的两个不同副本（例如有一个经过编译，而另一个没有）。这种情况下，肯定不想要凭借肉眼来找出差异，而是想要使用像Med这样的工具。 Linux有多少？ 这还不算多的，说实在一点，Mac只是Linux的一个亚种…. 那么，这么多的操作系统，我偏偏选了deepin来讲，是为什么？说实在一点因为这操作系统是一个超新星，它的外貌很是出众，看看官方的视频就知道了。 Deepindeepin（原名：Linux Deepin；中文通称：深度操作系统）是由武汉深之度科技有限公司在Debian基础上开发的Linux操作系统，其前身是Hiweed Linux操作系统，于2004年2月28日开始对外发行，可以安装在个人计算机和服务器中 deepin操作系统内部集成了deepin Desktop Environment（中文通称：深度桌面环境），并支持deepin store、deepin Music、deepin Movie等第一方应用软件。 2019年，华为开始销售预装有deepin操作系统的笔记本电脑。 2020年，深之度正式发布了deepin v20版本，底层仓库升级到Debian 10.5，系统安装则采用了Kernel 5.4和Kernel 5.7双内核机制，同时用户操作界面也得到了大幅度的调整 介绍深度操作系统是基于Linux内核，以桌面应用为主的开源GNU/Linux操作系统，支持笔记本、台式机和一体机。深度操作系统（deepin）包含深度桌面环境（DDE）和近30款深度原创应用，及数款来自开源社区的应用软件，支撑广大用户日常的学习和工作。另外，通过深度商店还能够获得近千款应用软件的支持，满足您对操作系统的扩展需求。深度操作系统由专业的操作系统研发团队和深度技术社区共同打造，其名称来自深度技术社区名称“deepin”一词，意思是对人生和未来深刻的追求和探索。深度操作系统（deepin）是中国第一个具备国际影响力的Linux发行版本，截止至2019年7月25日，深度操作系统支持33种语言，用户遍布除了南极洲的其它六大洲。深度桌面环境（deepinDDE）和大量的应用软件被移植到了包括Fedora、Ubuntu、Arch等十余个国际Linux发行版和社区，在开源操作系统统计网站DistroWatch上，deepin长期位于世界前十。 Deepin 12.12 正式版本将搭载一个全新的桌面环境。该桌面环境由Deepin 团队开发，以轻型、美观、稳定等作为设计目标。新桌面环境使用 Compiz 作为默认的窗口管理器。系统设置模块全部进行代码重写，不再使用“GNOME 控制中心”(gnome control center)，系统设置中心也会采用 Deepin UI 库作为界面库。深度音乐播放器、影音播放器最初的版本也是基于此界面库进行外观设计。最新版本的深度截图工具也采用了 Deepin UI 库。新的桌面环境不仅对Deepin社区，也会对其他操作系统社区带来令人刺激的变革。国际社区也将看到一个概念独特、回归用户操作的桌面环境，一切都会变得熟悉。深度桌面环境应用程序一览无余应用程序概览视图，可通过点击屏幕左下角的“应用程序启动器（Launcher）”按钮，或 Alt+F2 组合键打开。它可以让您快速查找并启动应用程序。新底部 Dock，快速打开常用程序新Dock主要由传统的Dock+托盘（系统级别+程序级别）两部分组成。点击Dock面板即可弹出“系统级托盘显示”和“Dock显示”功能选项，可以让用户自定义系统级托盘的显示和Dock的显示方式。传统的底部 Dock，快速打开常用程序（就是屏幕底部的水平条）。它包括了应用程序启动器（Launcher）、显示桌面按钮，常用应用程序快捷方式和系统托盘等部分。支持应用程序快捷方式的添加与删除，并显示已打开应用程序的窗口列表。简洁的消息通知它会及时提示您来自聊天工具或其他应用程序、系统发出的通知，通知显示区域为屏幕右下角。消息托盘功能会在之后版本中继续完善。深度系统设置深度系统设置（Deepin System Settings），采用 Deepin UI 图形库，对各个设置模块进行了全新设计，主要包括显示、声音、个性化、电源、账户、网络等系统设置模块，可以方便地对系统各模块进行个性化设置。下面重点介绍几个方面:支持自动调节屏幕亮度。如果您的电脑配有采光设备，该功能可根据外界光亮程度自动调整屏幕亮度，以节省电源。个性化主题和壁纸设置。a: 系统默认提供四组精彩壁纸，可根据您的喜好进行切换。 b: 支持壁纸随机播放，可设置图片切换的间隔时间。 c: 集成爱壁纸HD在线壁纸模块。支持农历日期显示。在日期时间模块，增加了对中国农历日期的支持，并支持显示国际性节日与中国传统节日。更加方便的网络设置。各个网络设置类型，如有线、拨号、移动等网络分类一目了然，设置界面极其简洁，可以帮助您快速设置网络。快速设置用户头像：支持深度截图工具与摄像头拍摄。可以使用深度截图工具截取屏幕并进行简单的编辑后设置为用户头像，也可以通过摄像头拍摄后直接设置为头像。 很官方的发言.... 深度原生应用：深度文件管理器、深度系统监视器、深度字体安装器、深度备份还原工具、深度取色器、深度商店、深度录屏、深度录音、深度截图、深度终端、深度看图、深度影院、深度音乐、深度云打印、深度云扫描、深度日历、深度远程协助、深度启动盘制作工具、深度安装器…… 如何安装deepin? 还是看官方的视频吧…… 文章到此结束，谢谢你看到了这里...送个大风车给你吧！不要谢我。 我是","link":"/2020/12/13/deepin/"},{"title":"YouMeek开展捐赠陪聊服务","text":"@YouMeek开展捐赠陪聊服务（希望对 IntelliJ IDEA 新人有所帮助） 活动想法来源： 这个点子来源于上次无止境（QQ：994***265）捐赠的时候与之沟通的时候，在此万分感谢他的拜访让我产生此灵感，也再次感谢他的热心捐赠（鞠躬）！ 活动目的： 别人对我好，我得回报别人，也想间接促进让我自己变得更好、了解更多人、传播更多我自己喜欢并且在做的内容，也带来一点额外靠知识得到的收入，仅此而已。 服务内容： 目前我收集的素材中就属 IntelliJ IDEA 相关的最多，也貌似别人给我捐赠的也都是因为 IntelliJ IDEA 吧，所以目前只针对这个进行。 沟通 IntelliJ IDEA 通用内容有： 针对你当前正在使用的 Eclipse 开发项目转换成 IntelliJ IDEA 项目，帮你把当前的项目开发环境搭建起来，不管你用的是系统是 Mac/Windows/Linux 我目前的硬件设备都有了。 但是因为 JAVA 相关的框架一大堆，我并不是所有内容都会，所以如果我没用过的，或是不熟的，我需要花点时间自己先学习下。我只会 Web 开发，移动端的知识我帮不上你什么。 针对你的开发情况，告诉你 IntelliJ IDEA 开发过程中必学哪些内容和注意点。 针对你目前的个人情况，学习进度，聊聊我所知道的知识。 其他内容暂时都不沟通： 很多内容，比如 Java、运维，单独一个就是一个大的知识系统，我还很难去还原别人的问题环境，并去思考，如果要去做，肯定也要花很多时间，那捐赠的那点钱真的不值得我花大量时间这样去做，并且这个没有固定性，我没办法积累起来作为后面跟别人沟通的材料。 等以后我在其他方向上我觉得有所系统地了解和整理，我愿意也跟别人分享我所知道的。 捐赠费用： 99元起。 参加活动方式： 只能通过加我微信发红包的方式来，不然我没办法联系到你。我的微信号看本篇文章最底下。 提供服务方式： 我领取红包之后，我会主动和你沟通，了解下你目前工作上是做啥，我能帮你啥。如果我什么都帮不上，那这个红包再回发给你，单纯支持的捐赠我不建议发这么大的面额，因为我帮不上你啥。 了解到你的基本情况后，我针对你的内容开始做功课，跟你约定下一次沟通的时间。 我做好了功课，通过微信语音、电脑远程的方式，聊聊我知道的一些内容。 我额外还可以做的： 提供一个 IDEA 交流群，在平时空闲时间里，回答我会的内容。 提供 Shadowsocks 账号，供群里大家使用 Google 搜索。 因为最近有很多支持我的朋友，用我博客上的京东购物链接进去，所以我这两个月平均就京东的推广就有一百多，我想拿出来购买 VPS，给博客做活动，让更多的人用上 Google，我对 Google 是真爱。 我的微信号： 我的公众号：","link":"/2021/09/10/donate/"},{"title":"dva源码解读","text":"声明本文章用于个人学习研究，并不代表 dva 团队的任何观点。 原文以及包含一定注释的代码见这里，若有问题也可以在这里进行讨论 起步为什么是dva?笔者对 dva 的源代码进行解读，主要考虑到 dva 并不是一个和我们熟知的主流技术无关的从0到1的框架，相反，它是对主流技术进行整合，提炼，从而形成一种最佳实践，分析 dva，意味着我们可以对自己掌握的很多相关技术进行回顾，另外，dva 的代码量并不多，也不至于晦涩难懂，可以给我们平时的业务开发以启发。 本文章作为 dva 的源码解读文章，并不面向新手用户，读者应当有一定的 react 使用经验和 ECMAscript 2015+ 的使用经验，并且应当了解 redux 和 redux-saga，以及对 dva 的使用有所了解(可以从这里了解为什么需要使用 dva) 重点推荐: 通过这里的内容了解使用dva的最小知识集 通过这里学习 redux-saga 其他推荐： dva的概念 dva的全部API React+Redux 最佳实践 React在蚂蚁金服的实践 dva 2.0的改进 ReSelect介绍 浅析Redux 的 store enhancer 几个 dva 版本之间的关系: dva@2.0：基于 react 和 react-router@4 dva-react-router-3@1.0：基于 react 和 react-router@3 dva-no-router@1.0：无路由版本，适用于多页面场景，可以和 next.js 组合使用 dva-core@1.0：仅封装了 redux 和 redux-saga 我们本次主要分析目标为 dva@2.0 和 dva-core@1.0 我们为什么需要 redux-saga目前，在大多数项目开发中，我们现在依然采用的是redux-thunk + async/await (或 Promise)。 实际上这个十几行的插件已经完全可以解决大多是场景下的问题了，如果你在目前的工作中正在使用这一套方案并且能够完全将当下的需求应付自如并且没有什么凌乱的地方，其实也是没有必要换成redux-saga的。 接下来我们讲 redux-saga，先看名字：saga，这个术语常用于CQRS架构，代表查询与责任分离。 相比于 redux-thunk，前者通常是把数据查询等请求放在 actions 中(不纯净的 actions)，并且这些 actions 可以继续回调调用其他 actions(纯净的 actions)，从而完成数据的更新；而 redux-saga，则保持了 actions 的纯粹性，单独抽出一层专门来处理数据请求等操作(saga函数)。 这样做还有另外一些好处： 由于我们已经将数据处理数据请求等异步操作抽离出来了，并且通过 generator 来处理，我们便可以方便地进行多种异步管理：比如同时按顺序执行多个任务、在多个异步任务中启动race等。 这样做可以延长任务的生命周期，我们的一次调用可以不再是一个”调完即走”的过程，还可以是一个LLT（Long Lived Transaction)的事物处理过程，比如我们可以将用户的登入、登出的管理放在一个saga函数中处理。 当然，redux-saga还有比如拥有有诸多常用并且声明式易测的 Effects、可以无阻塞的fork等一些更复杂的异步操作和管理方法，如果应用中有较多复杂的异步操作流程，使用redux-saga无疑会让条理更加清楚。 当然，本文的目的不是介绍或者安利redux-saga，只是因为redux-saga是 dva 的一个基础，相关概念点到为止，如需了解更多请自行参考资料。 dva 源码解读我们的源码分析流程是这样的：通过一个使用 dva 开发的例子，随着其对 dva 函数的逐步调用，来分析内部 dva 相关函数的实现原理。 我们分析采用的例子是 dva 官方提供的一个增删改查的应用，可以在这里找到它的源代码。 我们先看该例子的入口文件： import dva from 'dva'; import createHistory from 'history/createBrowserHistory'; import createLoading from 'dva-loading'; import { message } from 'antd'; import './index.css'; const ERROR_MSG_DURATION = 3; // 3 秒 // 1. Initialize const app = dva({ history: createHistory(), onError(e) { message.error(e.message, ERROR_MSG_DURATION); }, }); // 2. Plugins app.use(createLoading()); // 3. Model // Moved to router.js // 这里的 Model 被转移到了动态加载的 router 里面，我们也可以如下写： // app.model(require('./models/users')); // 4. Router app.router(require('./router')); // 5. Start app.start('#root'); 我们发现dva从初始化配置到最后的start(现在的dva start函数在不传入container的情况下可以返回React Component，便于服务端渲染等，但这里我们还是按照例子的写法来)。 这里我们先有必要解释一下，dva 在当前依据能力和依赖版本的不同，有多个可引入的版本，我们的例子和所要分析的源代码都是基于 react-router V4 的 dva 版本。 在源代码中，相关目录主要为 dva 目录(packages/dva) 和 dva-core(packages/dva-core)目录，前者主要拥有history管理、router、动态加载等功能，而后者是不依赖这些内容的基础模块部分，为前者所引用 第一步第一步这里传入了两个内容：(dva构造函数总共可以传入那些 opts，会在下文中进行说明) const app = dva({ history: createHistory(), onError(e) { message.error(e.message, ERROR_MSG_DURATION); }, }); 这一步的相关核心代码如下: export default function (opts = {}) { const history = opts.history || createHashHistory(); // 默认为 HashHistory const createOpts = { initialReducer: { routing, // 来自 react-router-redux 的 routerReducer }, setupMiddlewares(middlewares) { return [ routerMiddleware(history), // 来自 react-router-redux 的 routerMiddleware ...middlewares, ]; }, setupApp(app) { app._history = patchHistory(history); }, }; const app = core.create(opts, createOpts); const oldAppStart = app.start; app.router = router; app.start = start; return app; // 一些用到的函数的定义... } 这里面大多数内容都比较简单，这里面提两个地方： patchHistory： function patchHistory(history) { const oldListen = history.listen; history.listen = (callback) =&gt; { callback(history.location); return oldListen.call(history, callback); }; return history; } 显然，这里的意思是让第一次被绑定 listener 的时候执行一遍 callback，可以用于初始化相关操作。 我们可以在router.js中添加如下代码来验证： history.listen((location, action)=&gt;{ console.log('history listen:', location, action) }) 在完成可选项的构造之后，调用了 dva-core 中暴露的 create 函数。 create 函数本身也并不复杂，核心代码如下： export function create(hooksAndOpts = {}, createOpts = {}) { const { initialReducer, setupApp = noop, } = createOpts; const plugin = new Plugin(); // 实例化钩子函数管理类 plugin.use(filterHooks(hooksAndOpts)); // 这个时候先对 obj 进行清理，清理出在我们定义的类型之外的 hooks，之后进行统一绑定 const app = { _models: [ prefixNamespace({ ...dvaModel }), // 前缀处理 ], _store: null, _plugin: plugin, use: plugin.use.bind(plugin), model, // 下文定义 start, // 下文定义 }; return app; //一些函数的定义 } 这里面我们可以看到，这里的 hooksAndOpts 实际上就是一开始我们构造 dva 的时候传入的 opts 对象经过处理之后的结果。 我们可以传入的可选项，实际上都在 Plugin.js 中写明了: const hooks = [ 'onError', 'onStateChange', 'onAction', 'onHmr', 'onReducer', 'onEffect', 'extraReducers', 'extraEnhancers', ]; 具体 hooks的作用可以在这里进行查阅。 Plugin 插件管理类(实际上我认为称其为钩子函数管理类比较合适)除了定义了上文的使用到的use方法(挂载插件)、还有apply方法(执行某一个钩子下挂载的所有回调)、get方法(获取某一个钩子下的所有回调，返回数组) 第二步这里的第二步比较简洁：我们知道实际上这里就是使用了plugin.use方法挂载了一个插件 app.use(createLoading()); // 需要注意，插件挂载需要在 app.start 之前 createLoading 这个插件实际上是官方提供的 Loading 插件，通过这个插件我们可以非常方便地进行 Loading 的管理，无需进行手动管理，我们可以先看一篇文章来简单了解一下。 这个插件看似神奇，实际上原理也比较简单，主要用了onEffect钩子函数(装饰器)： function onEffect(effect, { put }, model, actionType) { const { namespace } = model; if ( (only.length === 0 &amp;&amp; except.length === 0) || (only.length &gt; 0 &amp;&amp; only.indexOf(actionType) !== -1) || (except.length &gt; 0 &amp;&amp; except.indexOf(actionType) === -1) ) { return function*(...args) { yield put({ type: SHOW, payload: { namespace, actionType } }); yield effect(...args); yield put({ type: HIDE, payload: { namespace, actionType } }); }; } else { return effect; } } 结合基于的redux-saga，在目标异步调用开始的时候yield put({ type: SHOW, payload: { namespace, actionType } });，在异步调用结束的时候yield put({ type: HIDE, payload: { namespace, actionType } });，这样就可以管理异步调用开始和结束的Loading状态了。 第三步第三步这里其实省略了，因为使用了动态加载，将 Models 定义的内容和 React Component 进行了动态加载，实际上也可以按照注释的方法来写。 但是没有关系，我们还是可以分析 models 引入的文件中做了哪些事情(下面列出的代码在原基础上进行了一些简化): import queryString from 'query-string'; import * as usersService from '../services/users'; export default { namespace: 'users', state: { list: [], total: null, page: null, }, reducers: { save(state, { payload: { data: list, total, page } }) { return { ...state, list, total, page }; }, }, effects: { *fetch({ payload: { page = 1 } }, { call, put }) { const { data, headers } = yield call(usersService.fetch, { page }); yield put({ type: 'save', payload: { data, total: parseInt(headers['x-total-count'], 10), page: parseInt(page, 10), }, }); }, //... *reload(action, { put, select }) { const page = yield select(state =&gt; state.users.page); yield put({ type: 'fetch', payload: { page } }); }, }, subscriptions: { setup({ dispatch, history }) { return history.listen(({ pathname, search }) =&gt; { const query = queryString.parse(search); if (pathname === '/users') { dispatch({ type: 'fetch', payload: query }); } }); }, }, }; 这些内容，我们通过app.model(require('./models/users'));就可以引入。 实际上，model 函数本身还是比较简单的，但由于 dva 拥有 model 动态加载的能力，实际上调用 app.start 前和 app.start 后model函数是不一样的。 调用 start 函数前，我们直接挂载即可(因为start函数中会对所有model进行遍历性统一处理，所以无需过多处理)： function model(m) { if (process.env.NODE_ENV !== 'production') { checkModel(m, app._models); } app._models.push(prefixNamespace(m)); // 把 model 注册到 app 的 _models 里面，但是当 app start 之后，就不能仅仅用这种方法了，需要 injectModel } 调用了 start 函数之后，model函数被替换成如下: function injectModel(createReducer, onError, unlisteners, m) { model(m); const store = app._store; if (m.reducers) { store.asyncReducers[m.namespace] = getReducer(m.reducers, m.state); store.replaceReducer(createReducer(store.asyncReducers)); } if (m.effects) { store.runSaga(app._getSaga(m.effects, m, onError, plugin.get('onEffect'))); } if (m.subscriptions) { unlisteners[m.namespace] = runSubscription(m.subscriptions, m, app, onError); } } 我们首先分析第一个 if 中的内容：首先通过getReducer函数将转换好的 reducers 挂载(或替换)到 store.asyncReducers[m.namespace] 中，然后通过 redux 本身提供的能力 replaceReducer 完成 reducer 的替换。 这里我们需要注意 getReducer 函数，实际上，dva 里面 reducers 写法和我们之前直接使用 redux 的写法略有不同： 我们这里的 reducers，实际上要和 action 中的 actionType 同名的 reducer，所以这里我们没有必要去写 switch case 了，对于某一个 reducer 来说其行为应该是确定的，这给 reducers 的写法带来了一定的简化，当然，我们可以使用 extraReducers 定义我们之前习惯的那种比较复杂的 reducers。 接下来我们分析第二个 if 中的内容：第二个函数首先获取到了我们定义的 effects 并通过 _getSaga 进行处理，然后使用 runSaga(实际上就是createSagaMiddleware().run，来自于redux-saga) 进行执行。 实际上，这里的 _getSaga 函数比较复杂，我们接下来重点介绍这个函数。 _getSaga 函数由 getSaga.js 暴露，其定义如下： export default function getSaga(resolve, reject, effects, model, onError, onEffect) { return function *() { // 返回一个函数 for (const key in effects) { // 这个函数对 effects 里面的所有键 if (Object.prototype.hasOwnProperty.call(effects, key)) { // 先判断一下键是属于自己的 const watcher = getWatcher(resolve, reject, key, effects[key], model, onError, onEffect); // 然后调用getWatch获取watcher const task = yield sagaEffects.fork(watcher); // 利用 fork 开启一个 task yield sagaEffects.fork(function *() { // 这样写的目的是，如果我们移除了这个 model 要及时结束掉 yield sagaEffects.take(`${model.namespace}/@@CANCEL_EFFECTS`); yield sagaEffects.cancel(task); }); } } }; } getWatcher 的一些核心代码如下: function getWatcher(resolve, reject, key, _effect, model, onError, onEffect) { let effect = _effect; let type = 'takeEvery'; let ms; if (Array.isArray(_effect)) { effect = _effect[0]; const opts = _effect[1]; // 对 opts 进行一定的校验 //... } function *sagaWithCatch(...args) { // 都会调用这个过程 try { yield sagaEffects.put({ type: `${key}${NAMESPACE_SEP}@@start` }); const ret = yield effect(...args.concat(createEffects(model))); yield sagaEffects.put({ type: `${key}${NAMESPACE_SEP}@@end` }); resolve(key, ret); } catch (e) { onError(e); if (!e._dontReject) { reject(key, e); } } } const sagaWithOnEffect = applyOnEffect(onEffect, sagaWithCatch, model, key); // 挂载 onEffect 钩子 switch (type) { case 'watcher': return sagaWithCatch; case 'takeLatest': return function*() { yield takeLatest(key, sagaWithOnEffect); }; case 'throttle': // 起到节流的效果，在 ms 时间内仅仅会被触发一次 return function*() { yield throttle(ms, key, sagaWithOnEffect); }; default: return function*() { yield takeEvery(key, sagaWithOnEffect); }; } } 这个函数的工作，可以主要分为以下三个部分： 1.将 effect 包裹成 sagaWithCatch，除了便于错误处理和增加前后钩子，值得我们注意的是 resolve 和 reject， 这个 resolve 和 reject，实际上是来自createPromiseMiddleware.js 我们知道，我们在使用redux-saga的过程中，实际上是监听未来的action，并执行 effects，所以我们在一个 effects 函数中执行一些异步操作，然后 put(dispatch) 一个 action，还是会被监听这个 action 的其他 saga 监听到。 所以就有如下场景：我们 dispatch 一个 action，这个时候如果我们想获取到什么时候监听这个 action 的 saga 中的异步操作执行结束，是办不到的(因为不是所有的时候我们都把所有处理逻辑写在 saga 中)，所以我们的 dispatch 有的时候需要返回一个 Promise 从而我们可以进行异步结束后的回调(这个 Promise 在监听者 saga 异步执行完后被决议，见上文sagaWithCatch函数源代码)。 如果我讲的还是比较混乱，也可以参考这个issue 对于这个情况，我认为这是 dva 代码最精彩的地方之一，作者通过定义如下的middleware: const middleware = () =&gt; next =&gt; (action) =&gt; { const { type } = action; if (isEffect(type)) { return new Promise((resolve, reject) =&gt; { map[type] = { resolve: wrapped.bind(null, type, resolve), reject: wrapped.bind(null, type, reject), }; }); } else { return next(action); } }; function wrapped(type, fn, args) { if (map[type]) delete map[type]; fn(args); } function resolve(type, args) { if (map[type]) { map[type].resolve(args); } } function reject(type, args) { if (map[type]) { map[type].reject(args); } } 并且在上文的sagaWithCatch相关effect执行结束的时候调用 resolve，让 dispatch 返回了一个 Promise。 当然，上面这段代码还是有点问题的，这样会导致同名 reducer 和 effect 不会 fallthrough（即两者都执行），因为都已经返回了，action 便不会再进一步传递，关于这样设计的好坏，在这里有过一些讨论，笔者不进行展开表述。 2.在上面冗长的第一步之后，又通过applyOnEffect函数包裹了OnEffect的钩子函数，这相当于是一种compose，(上文的 dva-loading 中间件实际上就是在这里被处理的)其实现对于熟悉 redux 的同学来说应该不难理解： function applyOnEffect(fns, effect, model, key) { for (const fn of fns) { effect = fn(effect, sagaEffects, model, key); } return effect; } 3.最后，根据我们定义的type(默认是takeEvery，也就是都执行)，来选择不同的 saga，takeLatest 即为只是执行最近的一个，throttle则起到节流的效果，一定时间内仅仅允许被触发一次，这些都是 redux-saga 的内部实现，dva 也是基本直接引用，因此在这里不进行展开。 最后我们分析injectModel第三个if中的内容:处理subscriptions: if (m.subscriptions) { unlisteners[m.namespace] = runSubscription(m.subscriptions, m, app, onError); } subscriptions可以理解为和这个model有关的全局监听，但是相对独立。这一个步骤首先调用runSubscription来一个一个调用我们的subscriptions: export function run(subs, model, app, onError) { // 在index.js中被重命名为 runSubscription const funcs = []; const nonFuncs = []; for (const key in subs) { if (Object.prototype.hasOwnProperty.call(subs, key)) { const sub = subs[key]; const unlistener = sub({ dispatch: prefixedDispatch(app._store.dispatch, model), history: app._history, }, onError); if (isFunction(unlistener)) { funcs.push(unlistener); } else { nonFuncs.push(key); } } } return { funcs, nonFuncs }; } 正如我们所期待的，run函数就是一个一个执行subscriptions，但是这里有一点需要我们注意的，我们定义的subscriptions应该是需要返回一个unlistener来返回接触函数，这样当整个 model 被卸载的时候 dva 会自动调用这个接解除函数(也就是为什么这里的返回函数被命名为unlistener) 第四步源代码中的第四步，是对 router 的挂载： app.router(require('./router')); require('./router')返回的内容在源代码中经过一系列引用传递最后直接被构造成 React Component 并且最终调用 ReactDom.render 进行渲染，这里没有什么好说的，值得一提的就是 router 的动态加载。 动态加载在该样例中是这样使用的： import React from 'react'; import { Router, Switch, Route } from 'dva/router'; import dynamic from 'dva/dynamic'; function RouterConfig({ history, app }) { const IndexPage = dynamic({ app, component: () =&gt; import('./routes/IndexPage'), }); const Users = dynamic({ app, models: () =&gt; [ import('./models/users'), ], component: () =&gt; import('./routes/Users'), }); history.listen((location, action)=&gt;{ console.log('history listen:', location, action) }) return ( &lt;Router history={history}&gt; &lt;Switch&gt; &lt;Route exact path=&quot;/&quot; component={IndexPage} /&gt; &lt;Route exact path=&quot;/users&quot; component={Users} /&gt; &lt;/Switch&gt; &lt;/Router&gt; ); } 我们可以看出，主要就是利用dva/dynamic.js暴露的 dynamic 函数进行动态加载，接下来我们简单看一下 dynamic 函数做了什么: export default function dynamic(config) { const { app, models: resolveModels, component: resolveComponent } = config; return asyncComponent({ resolve: config.resolve || function () { const models = typeof resolveModels === 'function' ? resolveModels() : []; const component = resolveComponent(); return new Promise((resolve) =&gt; { Promise.all([...models, component]).then((ret) =&gt; { if (!models || !models.length) { return resolve(ret[0]); } else { const len = models.length; ret.slice(0, len).forEach((m) =&gt; { m = m.default || m; if (!Array.isArray(m)) { m = [m]; } m.map(_ =&gt; registerModel(app, _)); // 注册所有的 model }); resolve(ret[len]); } }); }); }, ...config, }); } 这里主要调用了 asyncComponent 函数，接下来我们再看一下这个函数： function asyncComponent(config) { const { resolve } = config; return class DynamicComponent extends Component { constructor(...args) { super(...args); this.LoadingComponent = config.LoadingComponent || defaultLoadingComponent; this.state = { AsyncComponent: null, }; this.load(); } componentDidMount() { this.mounted = true; } componentWillUnmount() { this.mounted = false; } load() { resolve().then((m) =&gt; { const AsyncComponent = m.default || m; if (this.mounted) { this.setState({ AsyncComponent }); } else { this.state.AsyncComponent = AsyncComponent; // eslint-disable-line } }); } render() { const { AsyncComponent } = this.state; const { LoadingComponent } = this; if (AsyncComponent) return &lt;AsyncComponent {...this.props} /&gt;; return &lt;LoadingComponent {...this.props} /&gt;; } }; } 这个函数逻辑比较简洁，我们分析一下动态加载流程； 在 constructor 里面调用 this.load(); ( LoadingComponent 为占位 component) 在 this.load(); 函数里面调用 dynamic 函数返回的 resolve 方法 resolve 方法实际上是一个 Promise，把相关 models 和 component 加载完之后 resolve (区分这两个 resolve) 加载完成之后返回 AsyncComponent (即加载的 Component) 动态加载主流程结束，至于动态加载的代码分割工作，可以使用 webpack3 的 import() 动态加载能力(例子中也是这样使用的)。 第五步第五步骤就是 start 了： app.start('#root'); 这个时候如果我们在 start 函数中传入 DomElement 或者 DomQueryString，就会直接启动应用了，如果我们这个时候不传入任何内容，实际上返回的是一个&lt;Provider /&gt; (React Component)，便于服务端渲染。 相关判断逻辑如下： if (container) { render(container, store, app, app._router); app._plugin.apply('onHmr')(render.bind(null, container, store, app)); } else { return getProvider(store, this, this._router); } 至此，主要流程结束，以上几个步骤也包括了 dva 源码做的主要工作。 当然 dva 源码中还有一些比如前缀处理等工作，但是相比于以上内容非常简单，所以在这里不进行分析了。 dva-core 文件目录dva-core中的源码文件目录以及其功能: checkModel 对我们定义的 Model 进行检查是否符合要求 constants 非常简单的常量文件，目前只定义了一个常量：NAMESPACE_SEP(/) cratePromiseMiddleware 笔者自己定义的 redux 插件 createStore 封装了 redux 原生的 createStore getReducer 这里面的函数其实主要就是调用了 handleActions 文件导出的函数 getSaga 将用户输入的 effects 部分的键值对函数进行管理 handleActions 是将 dva 风格的 reducer 和 state 转化成 redux 本来接受的那种方式 index 主入口文件 Plugin 插件类：可以管理不同钩子事件的回调函数，拥有增加、获取、执行钩子函数的功能 perfixedDispatch 该文件提供了对 Dispatch 增加前缀的工具性函数 prefixedDispatch prefixNamespace 该文件提供了对 reducer 和 effects 增加前缀的工具性函数 prefixNamespace prefixType 判断是 reducer 还是 effects subscriptions 该文件提供了运行 subscriptions 和调用用户返回的 unlisten 函数以及删除缓存的功能 utils 提供一些非常基础的工具函数 优势总结 动态 model，已经封装好了整套调用，动态添加/删除 model 变得非常简单 默认封装好了管理 effects 的方式，有限可选可配置，降低学习成本的同时代码更利于维护 易于上手，集成redux、redux-saga、react-router等常用功能 劣势总结 版本区隔不明显，dva 有 1.x 和 2.x 两种版本，之间API有些差异，但是官网提供的一些样例等中没有说明基于的版本，并且有的还是基于旧版本的，会给新手带来很多疑惑。 内容繁杂，但是却没有一个整合性质的官方网站，大都是通过 list 的形式列下来写在README的。 目前比如动态加载等还存在着一些问题，和直接采用react配套工具写的效果有所区别。 很多 issues 不知道为什么就被关闭了，作者在最后也并未给出合理的解释。 dva2 之后有点将 effects 和 actions 混淆，这一点我也并不是非常认同，当然原作者可能有自己的考虑，这里不过多评议。 总之，作为一个个人主力的项目(主要开发者贡献了99%以上的代码)，可以看出作者的功底深厚，经验丰富，但是由于这样一个体系化的东西牵扯内容较多，并且非常受制于react、redux、react-router、redux-saga等的版本影响，不建议具备一定规模的非阿里系团队在生产环境中使用，但是如果是快速成型的中小型项目或者个人应用，使用起来还是有很大帮助的。 TODOS笔者也在准备做一个和 dva 处于同一性质，但是设计、实现和使用有所区别的框架，希望能够尽快落成。","link":"/2018/04/11/dva%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"},{"title":"机械键盘ikbc","text":"ikbc-f-rgb @YouMeek主推的机械键盘ikbc f 时光机系列（欢迎给广告费） 声明 本文没有收任何人、企业的广告费，纯属个人主观意识。如果不是就各种诅咒我。 写这种文章最让人掉泪的就是：明明没钱收，却要被认为是软文，真是会伤心一万年。当然了，如果 ikbc 愿意给我广告费我表示非常地欢迎！ 讨论需求 当我们讨论某个物品的时候，最应该先说说要使用的那个人，所以先说说我和我对机械键盘目前的任何/要求吧。 我没钱专门玩外设过，所以只是普通用户群体。 我不懂改装键盘，所以我都是直接用原厂的，换个键帽不算。 对机械键盘的做工，要求其实不大，主要是要有：樱桃轴，心里觉得有 Cherry 原厂轴才有保障。 对背光没啥要求，能 RGB 混光是最好，不能也无所谓 键帽能用 PBT 材质最好，没有也无所谓了。 60%、87 键、104 键，一般会选择 87，除非在某个阶段会需要经常按数字会选择 104，60% 完全不考虑，我喜欢方向键和F区域，虽然 60% 的键盘自己可以用autohotkye、硬件编程写一些组合，但是不方便。只是 60% 的轻便无法代替。 不需要无冲功能 我用过的机械键盘： Cherry：G80-3494 青轴、MX-Board 3.0 G80-3850 茶轴 ikbc：f-108 青轴、f-87 红轴、c-104 茶轴 各轴体的使用感受 结论：要嘛就选段落感最强的青轴，要嘛就选择舒适度较高的红轴。 青轴，段落感最强，打字起来最啪啪响，很清脆，很有打字节奏，但是比较累，相对其他轴体用的力度相对会大点，久了我个人感觉会累。所以女性的话，我是建议可以用用青轴， 但是长久选择还是红轴。 红轴，就力度而言跟薄膜键盘差距不是很大，没有啪啪响，但是还是会有节奏感，只是没有青轴那么夸张。长久用起来既有小节奏感，又不会太累。 茶轴，有稍强的段落感，但是永久了也是累。 黑轴，忘记感触了，反正不喜欢那种 ikbc f 时光机系列介绍 推荐 ikbc f 系列主要是因为它的背光终于 get 到我的痛点了：我需要计时器 我平时用计时器要嘛就是手机端的闹铃，要嘛就是电脑端的应用，但是不管怎么用都感觉还是不够便捷、方便，而且这个频率还很高。 但是用了 ikbc 的 F 系列我终于可以稍微解脱了。它设置定时器就需要下面几个步骤： 当开始计时以后，键盘上的背光会一个一个消失，当设置的时间过去了，整个键盘一闪一闪地提醒你时间到了。这对于使用番茄工作的人是不是很福音。 而最最最重要的是，相对 cherry、filco、hhkb 它算是便宜很多了，手感又没有太大明显差别。当然了，做工是相对他们差了点，但是绝对够用。 目前的 f 系列中有：87、108、RGB、黑、白，各自组合的版本，你可以在文章下面看到官网的地址、以及京东自营的官网，点击进去自己好好欣赏。 RGB 的效果是最绚丽，但是也相对贵了 50% 左右，看你有没有这种需求了。 买回来记得看说明书，常用的背光调整操作说明书上都有介绍，自己试一下就会懂了。 时光机效果演示 上面图片为设置时间后的倒数效果，可设置的时间最长是 129 分钟（隐约是这个数）。 上面图片为时间倒数结束后闪烁的效果 京东自营购买链接 ikbc f-87 黑色 RGB ikbc f-87 白色 RGB ikbc f-108 黑色 RGB ikbc f-108 白色 RGB ikbc f-87 黑色 ikbc f-87 白色 ikbc f-108 黑色 ikbc f-108 白色 结束语 主图来源官网：http://www.ikbc.com.cn/f87_rgb_black.html Gif 图我没有自己拍摄录制，我找了评测文章中，因为效果是一样的，我就没必要再拍了，更多图片：http://news.mydrivers.com/1/505/505862_all.htm 如果你非要折腾一个非常特别机械键盘，那我推荐你在淘宝搜索：GH60，自己玩一下。 ikbc 真的很适合我这种有闹铃要求的普通人 YouMeek 公众号，鞠躬","link":"/2021/09/10/eventually-chooses-ikbc-f87/"},{"title":"F-link","text":"Apache Flink 是一个在无界和有界数据流上进行状态计算的框架和分布式处理引擎.Flink 已经可以在所有常见的集群环境中运行,并以 in-memory 的速度和任意的规模进行计算. 可以类比 spring batch 或者spark进行学习,基本流程就是source-&gt;computer/transformation-&gt;sink 本文章的大部分文字都来源于互联网,最底下会附上链接. QuickStart搭建执行环境这边通过 docker-compose 构建,当然也可以直接下载编译好的二进制版本了,download version: &quot;3&quot; services: jobmanager: image: flink expose: - &quot;6123&quot; ports: - &quot;8081:8081&quot; command: jobmanager environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager taskmanager: image: flink expose: - &quot;6121&quot; - &quot;6122&quot; depends_on: - jobmanager command: taskmanager links: - &quot;jobmanager:jobmanager&quot; environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager 创建应用这里根据创建一个WordCount应用 buildscript { repositories { jcenter() // this applies only to the Gradle 'Shadow' plugin } dependencies { classpath 'com.github.jengelman.gradle.plugins:shadow:2.0.4' } } plugins { id 'java' id 'application' // shadow plugin to produce fat JARs id 'com.github.johnrengelman.shadow' version '2.0.4' } configurations { flinkShadowJar // dependencies which go into the shadowJar // always exclude these (also from transitive dependencies) since they are provided by Flink flinkShadowJar.exclude group: 'org.apache.flink', module: 'force-shading' flinkShadowJar.exclude group: 'com.google.code.findbugs', module: 'jsr305' flinkShadowJar.exclude group: 'org.slf4j' flinkShadowJar.exclude group: 'org.apache.logging.log4j' } ext { javaVersion = '1.8' flinkVersion = '1.11.2' scalaBinaryVersion = '2.12' slf4jVersion = '1.7.15' log4jVersion = '2.12.1' } dependencies { compile &quot;org.apache.flink:flink-streaming-java_${scalaBinaryVersion}:${flinkVersion}&quot; compile &quot;org.apache.flink:flink-clients_${scalaBinaryVersion}:${flinkVersion}&quot; compile &quot;org.apache.flink:flink-connector-kafka_${scalaBinaryVersion}:${fflinkVersion}&quot; compile 'org.slf4j:slf4j-simple:1.7.21' } // make compileOnly dependencies available for tests: sourceSets { main.compileClasspath += configurations.flinkShadowJar main.runtimeClasspath += configurations.flinkShadowJar test.compileClasspath += configurations.flinkShadowJar test.runtimeClasspath += configurations.flinkShadowJar javadoc.classpath += configurations.flinkShadowJar } run.classpath = sourceSets.main.runtimeClasspath jar { manifest { attributes 'Built-By': System.getProperty('user.name'), 'Build-Jdk': System.getProperty('java.version') } } shadowJar { configurations = [project.configurations.flinkShadowJar] } public class WordCount { public static void main(String[] args) throws Exception { // 获取本地执行环境 final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // 设置并行数量 env.setParallelism(1); // 获取数据流 DataStream&lt;String&gt; stream = env.socketTextStream(&quot;localhost&quot;, 9999); // 转换算子处理数据流并输出结果 stream.flatMap(new Tokenizer()).keyBy(r -&gt; r.f0).sum(1).print(); // 执行 env.execute(&quot;Flink Streaming Java API Skeleton&quot;); } public static class Tokenizer implements FlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt; { @Override public void flatMap(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out) throws Exception { String[] stringList = value.split(&quot;\\\\s&quot;); for (String s : stringList) { // 使用out.collect方法向下游发送数据 out.collect(new Tuple2(s, 1)); } } } } 如果是在IDEA本地运行的话,记得引入依赖flink-clients nc -lk 9999 如果，已经搭建好了 Flink WebUI 运行环境,上传提交编译好的jar包 JobGraph 即可,或者通过命令行运行 flink run -c todo.lib.flink.WordCount WordCount.jar DataStream APIDataSource内置数据源Elements从数组或者集合，一般本地调试使用 String[] elementInput = new String[]{&quot;hello Flink&quot;, &quot;Second Line&quot;}; DataStream&lt;String&gt; stream = env.fromElements(elementInput); File可以使用 readTextFile 方法直接读取文本文件, 这种方式可以用来监控一下 log 日志文件, 也可以使用 readFile 方法通过指定 InputFormat 来读取特定数据类型的文件, InputFormat可以是内置类,如 CsvInputFormat 或者用户自定义 InputFormat 接口类. 在 readFile() 方法中有一项参数为 WatchType, 共有两种模式 (PROCESS_CONTINUOUSLY / PROCESS_ONCE). 在 PROCESS_CONTINUOUSLY 模式下, 检测到文件变动就会将文件全部内容加载在 flink, 在 PROCESS_ONCE 模式下, 只会将文件变动的那部分加载到 flink. // 添加文件源 // 直接读取文本文件 DataStream&lt;String&gt; stream = env.readTextFile(logPath); // 读取csv CsvInputFormat csvInput = new RowCsvInputFormat( new Path(csvPath), // 文件路径 new TypeInformation[]{Types.STRING, Types.STRING, Types.STRING},// 字段类型 &quot;\\n&quot;, // 行分隔符 &quot;,&quot;); // 字段分隔符 csvInput.setSkipFirstLineAsHeader(true); // 指定 CsvInputFormat, 监控csv文件(两种模式), 时间间隔是10ms DataStream&lt;Row&gt; stream = env.readFile(csvInput, csvPath, FileProcessingMode.PROCESS_CONTINUOUSLY, 10); Socket// 添加Socket作为数据输入源 // 4个参数 -&gt; (hostname:Ip地址, port:端口, delimiter:分隔符, maxRetry:最大重试次数) DataStream&lt;String&gt; stream = env.socketTextStream(&quot;localhost&quot;, 9999, &quot;\\n&quot;, 4); 外部数据源外部数据源是重头戏, 一般来说项目中均是使用外部数据源作为数据的源头. 第三方数据源flink 通过实现 SourceFunction 定义了非常丰富的第三方数据连接器.对于第三方数据源, flink的支持分为三种,有只读型(Twitter Streaming API / Netty ), 只写型( Cassandra / Elasticsearch / hadoop FileSystem), 支持读写(Kafka / Amazon Kinesis / RabbitMQ) Apache Kafka (Source / Sink) Apache Cassandra (Sink) Amazon Kinesis Streams (Source / Sink) Elasticsearch (Sink) Hadoop FileSystem (Sink) RabbitMQ (Source / Sink) Apache NiFI (Source / Sink) Twitter Streaming API (Source) Apache Bahir 中的连接器: Apache ActiveMQ (Source / Sink) Apache Flume (Sink) Redis (Sink) Akka (Sink) Netty (Source) 以Kafka 为例 做演示 我这边是远程服务器上docker-compose启动kafka,主要注意下面的EN_IP表示外网的IP地址 # 一个 kafka节点 就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个 topic KAFKA_BROKER_ID: 0 # 配置zookeeper管理kafka的路径 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 # 把kafka的地址端口注册给zookeeper，若远程访问要改成外网IP,千万注意是外网IP KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${EN_IP}:9092 # 配置kafka的监听端口 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 Properties properties = new Properties(); properties.setProperty(&quot;bootstrap.servers&quot;, &quot;EN_IP:9092&quot;); properties.setProperty(&quot;group.id&quot;, &quot;test&quot;); DataStream&lt;String&gt; dataStream = env .addSource(new FlinkKafkaConsumer&lt;&gt;(&quot;topic&quot;, new SimpleStringSchema(), properties)); dataStream.print(); docker exec -it kafka_container_id bash cd /opt/kafka/bin // 生产数据 ./kafka-console-producer.sh --broker-list EN_IP:9092 --topic flink-test // 消费数据 ./kafka-console-consumer.sh --bootstrap-server EN_IP:9092 --topic flink-test --from-beginning 自定义数据源用户也可以自己定义连接器, 通过实现 SourceFunction 定义单个线程的接入的数据连接器, 也可以通过实现ParallelSourceFunction 接口或者继承 RichParallelSourceFunction 类定义并发数据源接入器. class SourceFromMySQL extends RichSourceFunction&lt;User&gt; { PreparedStatement ps; private Connection connection; @Override public void run(SourceContext&lt;User&gt; ctx) throws Exception { ResultSet resultSet = ps.executeQuery(); while (resultSet.next()) { User user = new User( resultSet.getInt(&quot;id&quot;), resultSet.getString(&quot;name&quot;).trim()); ctx.collect(user); } } ........ Transformation基本转换算子基本转换算子会针对流中的每一个单独的事件做处理,也就是说每一个输入数据会产生一个输出数据.单值转换,数据的分割,数据的过滤,都是基本转换操作的典型例子.这个有个概念就行,可以跳过. filterDataStream&lt;SensorReading&gt; filteredReadings = readings.filter(r -&gt; r.temperature &gt;= 25); mapDataStream&lt;String&gt; sensorIds = filteredReadings.map(r -&gt; r.id); flatMapDataStream&lt;String&gt; splitIds = sensorIds .flatMap((FlatMapFunction&lt;String, String&gt;) (id, out) -&gt; { for (String s: id.split(&quot;_&quot;)) { out.collect(s);}}) // provide result type because Java cannot infer return type of lambda function // 提供结果的类型，因为Java无法推断匿名函数的返回值类型 .returns(Types.STRING); richFunction在函数处理数据之前,需要做一些初始化的工作;或者需要在处理数据时可以获得函数执行上下文的一些信息;以及在处理完数据时做一些清理工作 public static class MyFlatMap extends RichFlatMapFunction&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt; { private int subTaskIndex = 0; @Override public void open(Configuration configuration) { int subTaskIndex = getRuntimeContext.getIndexOfThisSubtask; // 做一些初始化工作 // 例如建立一个和HDFS的连接 } @Override public void flatMap(Integer in, Collector&lt;Tuple2&lt;Integer, Integer&gt;&gt; out) { if (in % 2 == subTaskIndex) { out.collect((subTaskIndex, in)); } } @Override public void close() { // 清理工作，断开和HDFS的连接。 } } 键控流转换算子很多流处理程序的一个基本要求就是要能对数据进行分组,分组后的数据共享某一个相同的属性.DataStream API提供了一个叫做KeyedStream的抽象,此抽象会从逻辑上对DataStream进行分区,分区后的数据拥有同样的Key值,分区后的流互不相关. keyByKeyedStream&lt;SensorReading, String&gt; keyed = readings.keyBy(r -&gt; r.id); fold通过将最后一个文件夹流与当前记录组合来推出 KeyedStream.它会发回数据流. KeyedStream.fold(&quot;1&quot;, new FoldFunction&lt;Integer, String&gt;() { @Override public String fold(String accumulator, Integer value) throws Exception { return accumulator + &quot;=&quot; + value; } }) aggregate滚动聚合算子由KeyedStream调用,并生成一个聚合以后的DataStream. 滚动聚合算子只能用在滚动窗口,不能用在滑动窗口. 滚动聚合操作会对每一个key都保存一个状态。因为状态从来不会被清空，所以我们在使用滚动聚合算子时只能使用在含有有限个key的流上面。 常见的滚动聚合算子: sum,min,max,minBy,maxBy DataStream&lt;Tuple3&lt;Integer, Integer, Integer&gt;&gt; resultStream = inputStream .keyBy(0) // key on first field of the tuple .sum(1); // sum the second field of the tuple in place window允许按时间或其他条件对现有 KeyedStream 进行分组.以下是以 10 秒的时间窗口聚合: inputStream.keyBy(0).window(Time.seconds(10)); inputStream.keyBy(0).windowAll(Time.seconds(10)); window join我们可以通过一些 key 将同一个 window 的两个数据流 join 起来. 以下示例是在 5 秒的窗口中连接两个流,其中第一个流的第一个属性的连接条件等于另一个流的第二个属性 inputStream.join(inputStream1) .where(0).equalTo(1) .window(Time.seconds(5)) .apply (new JoinFunction () {...}); split此功能根据条件将流拆分为两个或多个流.当您获得混合流并且您可能希望单独处理每个数据流时,可以使用此方法. SplitStream&lt;Integer&gt; split = inputStream.split(new OutputSelector&lt;Integer&gt;() { @Override public Iterable&lt;String&gt; select(Integer value) { List&lt;String&gt; output = new ArrayList&lt;String&gt;(); if (value % 2 == 0) { output.add(&quot;even&quot;); } else { output.add(&quot;odd&quot;); } return output; } }); select此功能允许您从拆分流中选择特定流 SplitStream&lt;Integer&gt; split; DataStream&lt;Integer&gt; even = split.select(&quot;even&quot;); DataStream&lt;Integer&gt; odd = split.select(&quot;odd&quot;); DataStream&lt;Integer&gt; all = split.select(&quot;even&quot;,&quot;odd&quot;); projectProject 函数允许您从事件流中选择属性子集,并仅将所选元素发送到下一个处理流. DataStream&lt;Tuple4&lt;Integer, Double, String, String&gt;&gt; in = // [...] DataStream&lt;Tuple2&lt;String, String&gt;&gt; out = in.project(3,2); reducereduce函数可以通过实现接口ReduceFunction来创建一个类.ReduceFunction接口定义了reduce()方法,此方法接收两个输入事件,输入一个相同类型的事件. reduce作为滚动聚合的泛化实现,同样也要针对每一个key保存状态.因为状态从来不会清空,所以我们需要将reduce算子应用在一个有限key的流上. DataStream&lt;SensorReading&gt; maxTempPerSensor = keyed .reduce((r1, r2) -&gt; { if (r1.temperature &gt; r2.temperature) { return r1; } else { return r2; } }); 多流转换算子许多应用需要摄入多个流并将流合并处理,还可能需要将一条流分割成多条流然后针对每一条流应用不同的业务逻辑. union合流的方式为FIFO方式,合并流类型要一致. DataStream&lt;SensorReading&gt; parisStream = ... DataStream&lt;SensorReading&gt; tokyoStream = ... DataStream&lt;SensorReading&gt; rioStream = ... DataStream&lt;SensorReading&gt; allCities = parisStream .union(tokyoStream, rioStream) connect,comap,coflatmap两个流的数据类型可以不同,会对两个流中的数据应用不同的处理方法. DataStream&lt;Tuple2&lt;Integer, Long&gt;&gt; one = ... DataStream&lt;Tuple2&lt;Integer, String&gt;&gt; two = ... // keyBy two connected streams ConnectedStreams&lt;Tuple2&lt;Int, Long&gt;, Tuple2&lt;Integer, String&gt;&gt; keyedConnect1 = one .connect(two) .keyBy(0, 0); // key both input streams on first attribute // alternative: connect two keyed streams ConnectedStreams&lt;Tuple2&lt;Integer, Long&gt;, Tuple2&lt;Integer, String&gt;&gt; keyedConnect2 = one .keyBy(0) .connect(two.keyBy(0)); 分布式转换算子定义了事件如何分配到不同的任务中去 当我们使用DataStream API来编写程序时,系统将自动的选择数据分区策略,然后根据操作符的语义和设置的并行度将数据路由到正确的地方去.有些时候,我们需要在应用程序的层面控制分区策略,或者自定义分区策略 random随机数据交换由DataStream.shuffle()方法实现。shuffle方法将数据随机的分配到下游算子的并行任务中去 round-robinrebalance()方法使用Round-Robin负载均衡算法将输入流平均分配到随后的并行运行的任务中去 rescalerescale()方法使用的也是round-robin算法,但只会将数据发送到接下来的并行运行的任务中的一部分任务中.本质上,当发送者任务数量和接收者任务数量不一样时,rescale分区策略提供了一种轻量级的负载均衡策略.如果接收者任务的数量是发送者任务的数量的倍数时,rescale操作将会效率更高. rebalance()和rescale()的根本区别在于任务之间连接的机制不同.rebalance()将会针对所有发送者任务和所有接收者任务之间建立通信通道,而rescale()仅仅针对每一个任务和下游算子的一部分子并行任务之间建立通信通道 broadcastbroadcast()方法将输入流的所有数据复制并发送到下游算子的所有并行任务中去. globalglobal()方法将所有的输入流数据都发送到下游算子的第一个并行任务中去.这个操作需要很谨慎,因为将所有数据发送到同一个task,将会对应用程序造成很大的压力. custom当Flink提供的分区策略都不适用时,我们可以使用partitionCustom()方法来自定义分区策略.这个方法接收一个Partitioner对象,这个对象需要实现分区逻辑以及定义针对流的哪一个字段或者key来进行分区. SinkFlink没有类似于spark中foreach方法,让用户进行迭代的操作.所有对外的输出操作都要利用Sink完成.最后通过类似如下方式完成整个任务最终输出操作. stream.addSink(new MySink(xxxx)); 官方提供了一部分的框架的sink.除此以外,需要用户自定义实现sink. 第三方sinkkafka&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; DataStream&lt;String&gt; union = high .union(low) .map(r -&gt; r.temperature.toString); union.addSink( new FlinkKafkaProducer011&lt;String&gt;( &quot;localhost:9092&quot;, &quot;test&quot;, new SimpleStringSchema() ) ); redis&lt;dependency&gt; &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-redis_2.11&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; public class RedisSink_ { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(1); DataStream&lt;User&gt; stream = env.addSource(new UserSource()); FlinkJedisPoolConfig conf = new FlinkJedisPoolConfig.Builder().setHost(&quot;localhost&quot;).build(); stream.addSink(new RedisSink&lt;SensorReading&gt;(conf, new MyRedisSink())); env.execute(); } public static class MyRedisSink implements RedisMapper&lt;User&gt; { @Override public String getKeyFromData(User user) { return user.getId().toString(); } @Override public String getValueFromData(User User) { return user.getName(); } @Override public RedisCommandDescription getCommandDescription() { return new RedisCommandDescription(RedisCommand.HSET, &quot;flink-test&quot;); } } } docker exec -it redis_container_id redis-cli auth 123456 keys keys flink-test hvals flink-test elasticsearch&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-elasticsearch6_2.11&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 可选依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.9.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;7.9.1&lt;/version&gt; &lt;/dependency&gt; public class EsSink_ { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(1); DataStreamSource&lt;User&gt; stream = env.addSource(new UserSource()); ArrayList&lt;HttpHost&gt; httpHosts = new ArrayList&lt;&gt;(); httpHosts.add(new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;)); ElasticsearchSink.Builder&lt;User&gt; sensorReadingBuilder = new ElasticsearchSink.Builder&lt;&gt;( httpHosts, (ElasticsearchSinkFunction&lt;User&gt;) (user, runtimeContext, requestIndexer) -&gt; { HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(&quot;data&quot;, user.toString()); IndexRequest indexRequest = Requests .indexRequest() .index(&quot;flink-test&quot;) // 索引是flink-test，相当于数据库 .type(&quot;user&quot;) // es6需要加这一句 .source(map); requestIndexer.add(indexRequest); } ); sensorReadingBuilder.setBulkFlushMaxActions(1); stream.addSink(sensorReadingBuilder.build()); env.execute(); } } 自定义sink继承 RichSinkFunction 抽象类,重写 invoke 方法 public static class MyJDBCSink extends RichSinkFunction&lt;User&gt; { private Connection conn; private PreparedStatement insertStmt; private PreparedStatement updateStmt; @Override public void invoke(User value, Context context) throws Exception { updateStmt.setString(1, value.getName()); updateStmt.setInt(2, value.getId()); updateStmt.execute(); if (updateStmt.getUpdateCount() == 0) { insertStmt.setInt(1, value.getId()); insertStmt.setString(2, value.getName()); insertStmt.execute(); } } .... Window时间 time事件时间 Event Time,即事件实际发生的时间,可以处理乱序事件,一般都用这个;摄入时间 Ingestion Time,事件进入流处理框架的时间;处理时间 Processing Time,事件被处理的时间,执行操作算子的本地时间,与机器无关.统计某些延时非常高的日志. final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); //设置时间属性为 EventTime env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime); DataStream&lt;MyEvent&gt; stream = env.addSource(new FlinkKafkaConsumer09&lt;MyEvent&gt;(topic, schema, props)); stream .keyBy( (event) -&gt; event.getUser() ) .timeWindow(Time.hours(1)) .reduce( (a, b) -&gt; a.add(b) ) .addSink(...); // 这个方法中的 while 循环部分会从 eventTimeTimersQueue 中依次取出触发时间小于参数 time 的所有定时器，调用 triggerTarget.onEventTime() 方法进行触发。这就是 EventTime 从注册到触发的流程。 InternalTimeServiceImpl.advanceWatermark。 public void advanceWatermark(long time) throws Exception { currentWatermark = time; InternalTimer&lt;K, N&gt; timer; while ((timer = eventTimeTimersQueue.peek()) != null &amp;&amp; timer.getTimestamp() &lt;= time) { eventTimeTimersQueue.poll(); keyContext.setCurrentKey(timer.getKey()); triggerTarget.onEventTime(timer); } } 水位线 watermark概念水印的出现是为了解决实时计算中的数据乱序问题，它的本质是 DataStream 中一个带有时间戳的元素。 如果 Flink 系统中出现了一个 WaterMark T,那么就意味着 EventTime &lt; T 的数据都已经到达,窗口的结束时间和 T 相同的那个窗口被触发进行计算了. 也就是说:水印是 Flink 判断迟到数据的标准,同时也是窗口触发的标记. 在程序并行度大于 1 的情况下,会有多个流产生水印和窗口,这时候 Flink 会选取时间戳最小的水印. 使用水印a. 在 Source Function 中 直接指定 Timestamps 和 Watermark 用户需要复写 SourceFunction 接口中 run( ) 方法实现数据逻辑, 同时调用 SourceContext 的 collectWithTimestamp( ) 方法生成 event time 时间戳, 调用 emitWatermark( ) 方法生成 watermark. DataStream&lt;String&gt; text = env.addSource(new SourceFunction&lt;String&gt;() { @Override public void run(SourceContext&lt;String&gt; ctx) throws Exception { for (String s : elementInput) { // 切割每一条数据 String[] inp = s.split(&quot;,&quot;); Long timestamp = new Long(inp[1]); // 生成 event time 时间戳 ctx.collectWithTimestamp(s, timestamp); // 调用 emitWatermark() 方法生成 watermark, 最大延迟设定为 2 ctx.emitWatermark(new Watermark(timestamp - 2)); } // 设定默认 watermark ctx.emitWatermark(new Watermark(Long.MAX_VALUE)); } @Override public void cancel() { } }); b. 通过 Flink 自带的 Timestamp Assigner 指定 Timestamp 和 生成 watermark b.1 使用 Ascending Timestamp Assigner 指定 Timestamps 和 Watermark DataStream&lt;Tuple2&lt;String, Long&gt;&gt; dataStream = env.fromCollection(collectionInput); dataStream.assignTimestampsAndWatermarks( (WatermarkStrategy&lt;Tuple2&lt;String, Long&gt;&gt;) context -&gt; new WatermarkGenerator&lt;Tuple2&lt;String,Long&gt;&gt;(){ private long maxTimestamp; private long delay = 3000; @Override public void onEvent( Tuple2&lt;String,Long&gt; event, long eventTimestamp, WatermarkOutput output){ maxTimestamp = Math.max(maxTimestamp, event.f1); } @Override public void onPeriodicEmit(WatermarkOutput output){ output.emitWatermark(new Watermark(maxTimestamp - delay)); } }); b.2 内置水印生成策略 b.2.1 固定延迟生成水印 通过静态方法forBoundedOutOfOrderness提供,入参接收一个Duration类型的时间间隔，也就是我们可以接受的最大的延迟时间.使用这种延迟策略的时候需要我们对数据的延迟时间有一个大概的预估判断。 WatermarkStrategy.forBoundedOutOfOrderness(Duration maxOutOfOrderness) 我们实现一个延迟3秒的固定延迟水印，可以这样做： DataStream dataStream = ...... ; dataStream.assignTimestampsAndWatermarks(WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(3))); 他的底层使用的WatermarkGenerator接口的一个实现类BoundedOutOfOrdernessWatermarks。我们看下源码中的这两个方法，是不是和我们上面自己写的很像. @Override public void onEvent(T event, long eventTimestamp, WatermarkOutput output) { maxTimestamp = Math.max(maxTimestamp, eventTimestamp); } @Override public void onPeriodicEmit(WatermarkOutput output) { output.emitWatermark(new Watermark(maxTimestamp - outOfOrdernessMillis - 1)); } b.2.2 单调递增生成水印 通过静态方法forMonotonousTimestamps来提供. WatermarkStrategy.forMonotonousTimestamps() 这个也就是相当于上述的延迟策略去掉了延迟时间，以event中的时间戳充当了水印。 在程序中可以这样使用： DataStream dataStream = ...... ; dataStream.assignTimestampsAndWatermarks(WatermarkStrategy.forMonotonousTimestamps()); 它的底层实现是AscendingTimestampsWatermarks，其实它就是BoundedOutOfOrdernessWatermarks类的一个子类，没有了延迟时间，我们来看看具体源码的实现. @Public public class AscendingTimestampsWatermarks&lt;T&gt; extends BoundedOutOfOrdernessWatermarks&lt;T&gt; { /** * Creates a new watermark generator with for ascending timestamps. */ public AscendingTimestampsWatermarks() { super(Duration.ofMillis(0)); } } event时间的获取上述我们讲了flink自带的两种水印生成策略，但是对于我们使用eventtime语义的时候，我们想从我们的自己的数据中抽取eventtime，这个就需要TimestampAssigner了. @Public @FunctionalInterface public interface TimestampAssigner&lt;T&gt; { ............ long extractTimestamp(T element, long recordTimestamp); } 使用的时候我们主要就是从我们自己的元素element中提取我们想要的eventtime。 使用flink自带的水印策略和eventtime抽取类，可以这样用： DataStream dataStream = ...... ; dataStream.assignTimestampsAndWatermarks( WatermarkStrategy .&lt;Tuple2&lt;String,Long&gt;&gt;forBoundedOutOfOrderness(Duration.ofSeconds(5)) .withTimestampAssigner((event, timestamp)-&gt;event.f1)); 处理空闲数据源在某些情况下，由于数据产生的比较少，导致一段时间内没有数据产生，进而就没有水印的生成，导致下游依赖水印的一些操作就会出现问题，比如某一个算子的上游有多个算子，这种情况下，水印是取其上游两个算子的较小值，如果上游某一个算子因为缺少数据迟迟没有生成水印，就会出现eventtime倾斜问题，导致下游没法触发计算。 所以filnk通过WatermarkStrategy.withIdleness()方法允许用户在配置的时间内（即超时时间内）没有记录到达时将一个流标记为空闲。这样就意味着下游的数据不需要等待水印的到来。 当下次有水印生成并发射到下游的时候，这个数据流重新变成活跃状态。 通过下面的代码来实现对于空闲数据流的处理 WatermarkStrategy .&lt;Tuple2&lt;Long, String&gt;&gt;forBoundedOutOfOrderness(Duration.ofSeconds(20)) .withIdleness(Duration.ofMinutes(1)); 窗口简介 window窗口是流式计算中非常重要的一个概念, 很多常见的功能都是通过各种窗口实现的, 比如每5分钟统计一下刚去1小时的热度. Flink DataStream API 将窗口独立成 Operator. 每个窗口算子包含了以下几个部分: Windows Assigner 指定窗口的类型, 定义如何将数据流分配到一个或者多个窗口 Windows Trigger 指定窗口触发的时机, 定义窗口满足什么样的条件触发计算 Evictor 用户数据剔除 Lateness 标记是否处理迟到的数据, 当迟到数据到达窗口中是否触发计算 Output Tag 标记输出标签, 然后再通过 getSideOutput 将窗口中的数据根据标签输出 Windows Function 定义窗口上的数据处理的逻辑, 例如对数据进行sum Window Assigner首先最需要了解的就是 windows Assigner了, 我们想要一个什么样的窗口划分, 主要就是通过他来实现的. 根据 flink 上游的数据集是否为 KeyedStream 类型 来做分别的处理. 如果使用了keyBy( ) 则对应使用window( ) 来处理, 否则可以使用 windowAll( )来使用 Flink 可以支持两种类型的窗口, 分别是基于时间的窗口和基于数量的窗口.基于时间的意思就是按照时间去划分窗口,同理,基于数量的也是根据窗口中的数量来做切分的. 对应的分别就是 timeWindow() 和 countWindow() 来使用, 下面的示例主要使用 timeWindow() 来演示. 对于不同的 Window Assigner, 还可以把窗口划分为4大类, 分别是 滚动窗口(Tumbling Windows) / 滑动窗口(Sliding Window) / 会话窗口(Session Window) 和 全局窗口(Global Window). 滚动窗口 Tumbling WindowsDataStream API 提供基于 EventTime 和 ProcessingTime 的两种类型的 Tumbling window.对应的 Assigner 分别是 TumblingEventTimeWindow 和 ProcessingEventTimeWindow . 举例如下,完整代码见Github. // 使用ProcessTime的滚动时间窗口, 长度为10s stream.keyBy(x -&gt; x.f1) .window(TumblingProcessingTimeWindows.of(Time.seconds(10))).process(...) // 使用ProcessTime的滚动时间窗口, 长度为10s stream.keyBy(x -&gt;x.f1).window(TumblingEventTimeWindows.of(Time.seconds(10))).process(...) 使用 window(TumblingProcessingTimeWindows.of(Time.seconds(10))) 的方法有点啰嗦, Flink 还提供了timeWindow( ) 的 API 来简化这一行代码. // 直接使用 timeWindow API 便可实现滚动窗口的操作, 参数依旧是窗口的长度 // 窗口类型的时间由 time characteristic 确定, 如果指定为 event time,那么窗口也会自动用这个时间 input.keyBy(x -&gt; x.f1).timeWindow(Time.seconds(10)); 滑动窗口 Sliding Window滑动窗口顾名思义就是一个在不断往后滑动的窗口, 比如说 每5分钟 统计一个 最近一小时的时间, 那么就需要用滑动窗口来做处理. 滑动窗口主要是依靠 window size 和 slide time 来确定. 与滚动窗口类似的, flink 也提供了对应不同时间的 Assigner API(SlidingEventTimeWindow / SlidingEventTimeWindow), 语法基本类似, 只是由原本的一个参数(窗口长度) 变为了两个参数(窗口长度和滑动时间), 同样的, 为了简化代码, 依然可以使用timeWindow() 来简化. // 两个参数分别是 窗口长度 和 滑动时间, 窗口时间类型依旧通过time characteristic 确定 input.keyBy(x -&gt; x.f1).timeWindow(Time.seconds(10), Time.seconds(1)) 会话窗口 Session Window会话窗口主要是将某段时间内活跃度较高的数据聚合成一个窗口计算. 触发条件是 Session Gap. 在规定的时间内没有数据接入则认为这个窗口结束,然后触发窗口计算. Session Gap 除了固定间隔的方式, 也可以动态抽取. // 创建 Session Window, 间隔为 3s DataStream&lt;Tuple3&lt;String, Long, Integer&gt;&gt; aggregated = source .keyBy(0) .window(EventTimeSessionWindows.withGap(Time.seconds(3L))) .sum(2); 全局窗口 Global Window全局窗口将所有key的数据分配到单个窗口中计算结果. // 创建 GlobalWindow input.keyBy(1) .window(GlobalWindows.create()) .sum(1); Window FunctionWindow Assigner 的作用是划分窗口的, 而 Window Function 就是对窗口内的数据做处理的一个过程 ReduceFunction (增量)对输入的两个相同类型的元素按照指定的计算方式进行聚合, 通过实现 ReduceFunction 接口就可以在reduce( ) 函数内部进行聚合操作了. input.keyBy(x -&gt; x.f1).timeWindow(Time.seconds(10), Time.seconds(1)) .reduce((t1,t2) -&gt; new Tuple2&lt;&gt;(t1.f0 + t2.f0, t1.f1)); AggregateFunction (增量)AggregateFunction 相对于ReduceFunction更加灵活,但是实现起来也更复杂, AggregateFunction有 4 个需要复写的方法, 其中createAccumulator( ) 定义累加器, add( ) 定义数据的添加逻辑, getResult( ) 定义了根据 accumulator 计算结果的逻辑, merge()方法定义合并 accumulator 的逻辑. input.keyBy(x -&gt; x.f1) .timeWindow(Time.seconds(10), Time.seconds(1)) // 自定义一个AggregateFunciton, 将相同标号 f1 的数据的 f0字符串字段合并在一起 // (&quot;hello&quot;, 1L) + (&quot;world&quot;, 1L) = (&quot;hello world&quot;, 1L) .aggregate(new MyAggregateFunction()); 通过自定义的 MyAggregateFunction() 来实现 AggregateFunction 接口 public static class MyAggregateFunction implements AggregateFunction&lt;Tuple2&lt;String, Long&gt;, String, String&gt;{ @Override public String createAccumulator() { // 初始化累加器 return &quot;&quot;; } @Override public String add(Tuple2&lt;String, Long&gt; t, String s) { // 输入数据与累加器的合并 return s + &quot; &quot; +t.f0; } @Override public String getResult(String s) { // 得到累加器的结果 return s.trim(); } @Override public String merge(String s, String acc1) { // 合并累加器 return s + &quot; &quot; + acc1; } } FoldFunction (增量)FoldFunction定义了如何将窗口中的输入元素与外部的元素合并的逻辑 input.keyBy(x -&gt; x.f1) .timeWindow(Time.seconds(10), Time.seconds(1)).fold(&quot;flink&quot;, (acc, t) -&gt;t.f0 + acc); FoldFunction在新版本已经被标记@Deprecated了, 建议使用AggregateFunction代替 ProcessWindowFunction (全量)ProcessWindowFunction 相较于其他的 Window Function, 可以实现一些更复杂的计算, 比如基于整个窗口做某些指标计算 或者需要操作窗口中的状态数据和窗口元数据. Flink 提供了 ProcessWindowFunction 这个抽象类, 继承此类就可以实现ProcessWindowFunction, 其中, 必须要实现 process( ) 方法, 这是处理窗口数据的主要方法.还在一下跟窗口数据相关的方法可以有选择的实现. public static class MyProcessWindowFunction extends ProcessWindowFunction&lt;Tuple3&lt;String, Long, Long&gt;, String, Long, TimeWindow&gt; { @Override public void process(Long s, Context context, Iterable&lt;Tuple3&lt;String, Long, Long&gt;&gt; elements, Collector&lt;String&gt; out) throws Exception { // 统计每个窗口内的所有数据的 f0字段加起来共有多少个单词 // 也就做单个窗口的 wordcount Long count = 0L; for (Tuple3&lt;String, Long, Long&gt; element : elements) { count += element.f0.split(&quot; &quot;).length; } out.collect(&quot;window: &quot; + context.window() + &quot; word count: &quot; + count); } } Window JoinFlink 中支持窗口上的多流合并, 需要保证的是输入的 stream 要构建在相同的 Window 上, 并使用相同类型的 Key 作为关联条件. inputStream1.join(inputStream2) // 指定inputStream1的关联key .where(0) // 指定inputStream2的关联key .equalTo(1) // 指定 window Assigner .window(TumblingEventTimeWindows.of(Time.seconds(10))) // 指定窗口计算函数 .apply(&lt;JoinFunction&gt;) 处理迟到的元素迟到的元素是指当这个元素来到时,这个元素所对应的窗口已经计算完毕了(也就是说水位线已经没过窗口结束时间了).这说明迟到这个特性只针对事件时间. DataStream API提供了三种策略来处理迟到元素 直接抛弃抛弃迟到的元素是event time window operator的默认行为.也就是说一个迟到的元素不会创建一个新的窗口. process function可以通过比较迟到元素的时间戳和当前水位线的大小来很轻易的过滤掉迟到元素. 重定向迟到的元素也可以使用侧输出(side output)特性被重定向到另外的一条流中去.迟到元素所组成的侧输出流可以继续处理或者sink到持久化设施中去. 更新窗口计算结果由于存在迟到的元素,所以已经计算出的窗口结果是不准确和不完全的.我们可以使用迟到元素更新已经计算完的窗口结果. window operator API提供了方法来明确声明我们要等待迟到元素.当使用event-time window,我们可以指定一个时间段叫做allowed lateness.window operator如果设置了allowed lateness,这个window operator在水位线没过窗口结束时间时也将不会删除窗口和窗口中的状态.窗口会在一段时间内(allowed lateness设置的)保留所有的元素. 当迟到元素在allowed lateness时间内到达时,这个迟到元素会被实时处理并发送到触发器(trigger).当水位线没过了窗口结束时间+allowed lateness时间时,窗口会被删除,并且所有后来的迟到的元素都会被丢弃. State官方文档有详细描述,这里不多赘述. https://ci.apache.org/projects/flink/flink-docs-release-1.11/zh/dev/stream/state/state.html TableFlink本身是批流统一的处理框架,所以Table API和SQL,就是批流统一的上层处理API.目前还在完善中,所以后面待完善. compileOnly &quot;org.apache.flink:flink-table-api-java-bridge_${scalaBinaryVersion}:${flinkVersion}&quot; // 本地运行，线上lib已经包含，不需要引入 compileOnly &quot;org.apache.flink:flink-table-planner-blink_${scalaBinaryVersion}:${flinkVersion}&quot; // 自定义函数，线上lib已经包含，不需要引入 compileOnly &quot;org.apache.flink:flink-table-common:${flinkVersion}&quot; 未完待续….. 相关链接apache flink github flink github flink-learning github flink-simple-tutorial 尚硅谷","link":"/2021/09/10/flink/"},{"title":"git","text":"[Git][https://en.wikipedia.org/wiki/Git] 是一个分布式的管理系统，作者 Linus Torvalds 2005 创建它，主要是维护linux内核，现在很多人用它作为大型项目的版本控制软件，来管理源代码，或是一些纯文本的笔记或者文档。本篇文字，很多的文本描述，或者图片资源来自互联网，我只是互联网的搬运工，本文仅作为个人学习的一个记录跟总结。我将在最下方列出部分链接，感兴趣的朋友可以去看看。 基本介绍特点Git 有如下几个特点： 1.直接记录快照，而非差异比较 2.近乎所有操作都是本地执行，所以速度很快 3.时刻保持数据的完整性，在保存到 Git 之前，所有数据都要进行内容的校验和（checksum）计算，并将此结果作为数据的唯一标识和索引。换句话说，不可能在你修改了文件或目录之后，Git 一无所知。这项特性作为 Git 的设计哲学，建在整体架构的最底层。所以如果文件在传输时变得不完整，或者磁盘损坏导致文件数据缺失，Git 都能立即察觉。 Git 使用 SHA-1 算法计算数据的校验和，通过对文件的内容或目录的结构计算出一个 SHA-1 哈希值，作为指纹字符串。该字串由 40 个十六进制字符（0-9 及 a-f）组成，看起来就像是： 24b9da6552252987aa493b52f8696cd6d3b00373 Git 的工作完全依赖于这类指纹字串，所以你会经常看到这样的哈希值。实际上，所有保存在 Git 数据库中的东西都是用此哈希值来作索引的，而不是靠文件名。 4.多数操作仅添加数据，不用担心数据丢失 5.文件的三种状态，对于任何一个文件，在 Git 内都只有三种状态：已提交（committed），已修改（modified）和已暂存（staged）。已提交表示该文件已经被安全地保存在本地数据库中了；已修改表示修改了某个文件，但还没有提交保存；已暂存表示把已修改的文件放在下次提交时要保存的清单中。 由此我们看到 Git 管理项目时，文件流转的三个工作区域：Git 的工作目录，暂存区域，以及本地仓库。 每个项目都有一个 Git 目录（如果 git clone 出来的话，就是其中 .git 的目录；如果 git clone --bare 的话，新建的目录本身就是 Git 目录。），它是 Git 用来保存元数据和对象数据库的地方。该目录非常重要，每次克隆镜像仓库的时候，实际拷贝的就是这个目录里面的数据。 从项目中取出某个版本的所有文件和目录，用以开始后续工作的叫做工作目录。这些文件实际上都是从 Git 目录中的压缩对象数据库中提取出来的，接下来就可以在工作目录中对这些文件进行编辑。 所谓的暂存区域只不过是个简单的文件，一般都放在 Git 目录中。有时候人们会把这个文件叫做索引文件，不过标准说法还是叫暂存区域。 工作流程基本的 Git 工作流程如下： 在工作目录中修改某些文件。 对修改后的文件进行快照，然后保存到暂存区域。 提交更新，将保存在暂存区域的文件快照永久转储到 Git 目录中。 所以，我们可以从文件所处的位置来判断状态：如果是 Git 目录中保存着的特定版本文件，就属于已提交状态；如果作了修改并已放入暂存区域，就属于已暂存状态；如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 技术说明文件内容并没有真正存储在索引(.git/index)或者提交对象中，而是以blob的形式分别存储在数据库中(.git/objects)，并用SHA-1值来校验。 索引文件用识别码列出相关的blob文件以及别的数据。对于提交来说，以树(tree)的形式存储，同样用对于的哈希值识别。树对应着工作目录中的文件夹，树中包含的 树或者blob对象对应着相应的子目录和文件。每次提交都存储下它的上一级树的识别码。 如果用detached HEAD提交，那么最后一次提交会被the reflog for HEAD引用。但是过一段时间就失效，最终被回收，与git commit --amend或者git rebase很像。 基本命令Git 命令是一些命令行工具的集合，它可以用来跟踪，记录文件的变动。比如你可以进行保存，比对，分析，合并等等，这个过程被称之为版本控制。 git configgit的基本配置，配置文件在用户目录下的**.gitconfig** user 设置当前系统的git用户的名称跟邮件 alias 设置一些别名，简化命令，提高效率，当然本文档为了介绍git的命令的使用，在下文的shell中都没有使用别名。 http 跟 https 设置shadowsocks的http代理，避免有的仓库被GWF墙，拉取不了。 git config --global user.name &quot;jianchengwang&quot; git config --global user.email &quot;jiancheng_wang@yahoo.com&quot; git config --global https.proxy socks5://127.0.0.1:1080 git config --global https.proxy socks5://127.0.0.1:1080 git config --global --unset http.proxy git config --global --unset https.proxy vim ~/.gitconfig ## [user] name = jianchengwang email = jiancheng_wang@yahoo.com [alias] co = checkout br = branch ci = commit st = status unstage = reset HEAD -- dog = log --all --decorate --oneline --graph [http] proxy = socks5://127.0.0.1:1080 [https] proxt = socks5://127.0.0.1:1080 git initInitialized empty Git repository， 在目录下为出现一个**.git**目录文件夹，是为你的项目存储所有历史和元信息的目录 - 包括所有的对象(commits,trees,blobs,tags)，这些对象指向不同的分支。 mkdir git-tutorial cd git-tutorial git init git status可以看到当前目录的git状态，比如所处分支，提交记录，未追踪的文件等，还有一个很好的命令提示作用，提示你可以使用哪些命令进行操作。 git status ## n branch master No commits yet Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) README.md nothing added to commit but untracked files present (use &quot;git add&quot; to track) git add未追踪的文件，我们通过这个命令告诉git将这个文件进行版本控制，添加到暂存区 staged，暂存区的记录在**.git/index** git add README.md git status ## On branch master No commits yet Changes to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: README.md git rm --cached README.md git add -A git mv移动或者重命名文件，目录，或符号链接，类比linux mv git mv a.txt dir 如果是window，mac系统对大小写不敏感，一般git config ignorecase true，这时候也可以用git mv修正文件大小写问题， git mv -f a.js A.js git commit通过以下命令将暂存区的内容提交到本地仓库，会生成一个版本快照。 git commit -m &quot;add README.md&quot; ## [master (root-commit) 65f838e] add README.md 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 README.md git remote如果我们需要跟别人进行协作开发，就要把本地的代码推送到远程的服务器的仓库上，比如这里我在github上创建一个远程仓库，然后将本地仓库添加一个远程仓库地址，名字命名为origin 一般，这个名字是约定俗称的，不建议去修改，但是假如你有多个远程仓库，可以自定义命名。 ## 添加远程仓库 git remote add origin https://github.com/jianchengwang/git-tutorial.git ## 查看远程仓库 git remote -v origin https://github.com/jianchengwang/git-tutorial.git (fetch) origin https://github.com/jianchengwang/git-tutorial.git (push) git remote -help git push我们可以将本地仓库当前分支的代码推送到远程仓库的分支上，**-u** 表示set upstream for git pull/status 即设置当前远程分支为默认上游仓库，下次直接使用git push即可 # 格式 git push &lt;远程仓库名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; # 省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支(通常两者同名)，如果该远程分支不存在，则会被新建 git push -u origin master git push origin master:master # 省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 git push origin :master git push origin --delete master # 如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 git push origin # 如果当前分支只有一个追踪分支，那么主机名都可以省略。 git push # 推送本地所有分支到远程仓库 git push --all origin # 如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用–force选项。使用–force选项，结果导致在远程主机产生一个”非直进式”的合并(non-fast-forward merge)。除非你很确定要这样做，否则应该尽量避免使用–force选项。 git push --force origin # git push不会推送标签(tag)，除非使用–tags选项。 git push origin --tags git clone克隆远程仓库到本地文件夹git-demo，然后进行一些简单的修改，然后推送到远程仓库，现在我们有两个本地仓库了，其中git-demo的代码已经发生改变，并且推送到远程仓库，远程仓库的代码也发生改变，但是之前的本地的git-tutorial代码还是旧的，这时候我们切换到之前的git-tutorial文件目录，拉取远程仓库的代码。 git clone https://github.com/jianchengwang/git-tutorial.git git-demo cd git-demo echo &quot;hello git&quot; &gt; README.md git add README.md git commit -m 'modify README.md' git push git fetch | pull取回远程主机某个分支的更新，再与本地的指定分支合并 git pull &lt;远程仓库&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; git pull origin master:master # 如果远程分支与当前分支进行合并，则冒号后面的本地分支可以省略 git pull origin master # 等同于 git fetch origin git merge origin/master # 如果当前分支与远程分支存在追踪关系 git branch --set-upstream master origin/master git pull origin # 如果当前分支只有一个追踪分支 git pull git branch在实现一些新功能或者修复 BUG 的时候，我们希望所有的修改环境都是独立的，Git 给我们提供了分支，它可以保证稳定版本的代码不会被破坏、不同的功能可以由不同开发者同时开发、开发者可以专注于自己的分支，不用担心被其他人破坏了环境。 HEAD -&gt; 当前分支的最后一次更新，通常默认是指向master的最后一次提交。我们可以移动这个指针或者叫坐标，就可以变更使用的分支。 提交时使用(tilde)和^(caret)就可以指定某个提交的相对位置。最常用的就是相对于HEAD的位置。HEAD后面加上(tilde）可以指定HEAD之前的提交记录。合并分支会有多个根节点，您可以用^(caret) 来指定使用哪个为根节点。 STASH -&gt; 还未提交的修改内容以及新添加的文件，留在索引区域或工作树的情况下切换到其他的分支时，修改内容会从原来的分支移动到目标分支。 但是如果在checkout的目标分支中相同的文件也有修改，checkout会失败的。这时要么先提交修改内容，要么用stash暂时保存修改内容后再checkout。 stash是临时保存文件修改内容的区域。stash可以暂时保存工作树和索引里还没提交的修改内容，您可以事后再取出暂存的修改，应用到原先的分支或其他的分支上。 我们在所在分支创建一个分支的时候，新建的分支会拥有当前分支的一份拷贝。 # 创建分支 git branch feature1 # 切换分支 git checkout feature1 # 创建并切换 git checkout -b feature2 # checkout 后面跟文件名，会使用 HEAD 中的最新内容替换掉你的工作目录中的文件。已添加到暂存区的改动以及新文件都不会受到影响。 git checkout -- &lt;filename&gt; # 查看当前分支，q键退出 git branch # 查看远程分支 git branch -r # 删除分支，如果当前分支处于feature2则不允许删除 git branch -d feature2 # 如果我们分支有进行版本的改变，跟master分支不一致，那么我么将分支的内容merge到master分支上，或是直接使用-D 进行强制删除 git branch -D feature2 # 推送分支到远程仓库并创建一个跟本地分支同名的分支 git push origin feature1 # 推送分支到远程仓库并创建一个名为f1的分支 git push origin feature1:f1 # 删除远程仓库的分支 git push origin :feature1 git tag为软件发布创建标签是推荐的。这个概念早已存在，在 SVN 中也有。你可以执行如下命令创建一个叫做 1.0.0 的标签 git tag 1.0.0 1b2e1d63ff git log通过日志，我们可以很方便的查看并且追溯各个版本快照，并且stackoverflow有人展示了很多漂亮的日志格式，我们可以借鉴下 https://stackoverflow.com/questions/1057564/pretty-git-branch-graphs git log # 只看某人的提交日志 git log --author=bob # 一行显示 git log --online # 显示前10条 git log --oneline -10 # 显示某一次日志详情 git show a2f5b8c # 因为命令很长，所以我们可以在.gitconfig里设置别名 git log --all --decorate --oneline --graph git dog git merge | rebase在做一些新特性或者修复 bug 的时候，我们通常会建立一个新的分支，而完成后我们需要做一个合并分支的操作。 合并分支默认使用fast-forward(–ff)模式，这种模式不会产生一个新的commit提交，如果你要使用**–no-ff**，如果是与他人协作开发，建议采用这种模式，因为它会原有的开发分支整个提交链的完整性。 使用rebase 会重写项目历史，能让我们的项目提交日志保持一条竖线，但是这破坏协作的工作流，所以有一条黄金法则，绝对不要在公共分支上使用rebase merge 是合并操作，它会将两个分支的操作合并在一起，它关注点在真实的提交历史记录上 rebase 没有合并操作，它只是将当前分支的修改复制到目标分支的最后一次提交上面，它的关注点在开发的过程上面 如果两个分支同时对一个文件进行修改，并且commit，那么合并的时候会产生conflict ，我们要解决冲突后才能进行合并操作。解决冲突一般会使用一些可视化的工具进行解决，命令行的话即使是使用vimdiff感觉也比较麻烦。 # merge git checkout master git merge feature1 git merge feature1 --no-ff # 将分支issue1的所有提交合并成一个提交并导入到master分支 git merge --squash issue1 # rebase git rebase feature1 # conflict git cherry-pickgit cherry-pick 可以选择某一个分支中的一个或几个commit(s)来进行操作。例如，假设我们有个稳定版本的分支，叫v2.0，另外还有个开发版本的分支v3.0，我们不能直接把两个分支合并，这样会导致稳定版本混乱，但是又想增加一个v3.0中的功能到v2.0中，这里就可以使用cherry-pick了,其实也就是对已经存在的commit 进行再次提交. 命令集合: git cherry-pick :单独合并一个提交 git cherry-pick -x ：同上，不同点：保留原提交者信息。 Git从1.7.2版本开始支持批量cherry-pick，就是一次可以cherry-pick一个区间的commit。 git cherry-pick .. git cherry-pick ^.. 前者表示把到之间(左开右闭，不包含start-commit-id)的提交cherry-pick到当前分支； 后者有”^”标志的表示把到之间(闭区间，包含start-commit-id)的提交cherry-pick到当前分支。 其中，到只需要commit-id的前6位即可，并且在时间上必须早于 注：以上合并，需要手动push代码。 # 从其他分支复制指定的提交，然后导入到现在的分支 git cherry-pick 99daed2 git cherry-pick &lt;commit id&gt; git cherry-pick --continue git cherry-pick --quit git cherry-pick --abo git reset | revert时光不能倒流，但是 Git 可以做时光机让你的提交记录回到过去。git revert 撤销某次操作，此次操作之前和之后的 commit 和 history 都会保留，并且把这次撤销作为一次最新的提交。git revert是提交一个新的版本，将需要revert的版本的内容再反向修改回去，版本会递增，不影响之前提交的内容。相比 git reset，它不会改变现在的提交历史。因此，git revert 可以用在公共分支上，git reset 应该用在私有分支上。 在reset可以遗弃不再使用的提交。执行遗弃时，需要根据影响的范围而指定不同的模式，可以指定是否复原索引或工作树的内容。 除了默认的mixed模式，还有soft和hard模式。欲了解受各模式影响的部分，请参照下面的表格。 模式名称 HEAD的位置 索引 工作树 soft 修改 不修改 不修改 mixed 修改 修改 不修改 hard 修改 修改 修改 主要使用的场合： 复原修改过的索引的状态(mixed) 彻底取消最近的提交(hard) 只取消提交(soft) # 回退到之前一次提交 git reset master^ # 回退到之前5次提交 git reset master~5 # 回到之前某次提交 git reset --hard HEAD~ gti reset --hard 99daed2 # 在reset之前的提交可以参照ORIG_HEAD。Reset错误的时候，在ORIG_HEAD上reset 就可以还原到reset前的状态。 git reset --hard ORIG_HEAD # 会产生一次新的commit提交 git revert --hard HEAD~ git stashgit stash 可用来暂存当前正在进行的工作， 比如想pull 最新代码， 又不想加新commit， 或者另外一种情况，为了fix 一个紧急的bug, 先stash, 使返回到自己上一个commit, 改完bug之后再stash pop, 继续原来的工作。 git statsh do some work git statsh pop git stash # save uncommitted changes # pull, edit, etc. git stash list # list stashed changes in this git git show stash@{0} # see the last stash git stash pop # apply last stash and remove it from the list git stash --help # for more info .gitignore记录为.gitignore的文件是Git的非管理对象，但是需要提交.gitignore本身。 可以到 Gitignore网站上找忽略模板。 fock | pull request我们经常fock其他上游仓库，来pull request做贡献等，首先是保证本地仓库跟上游仓库的同步。关于pr相关操作，可以看相关链接的工作流，这里不多做介绍。 ## 添加上游仓库 git remote add upstream https://github.com/jianchengwang/git-tutorial.git ## 查看远程仓库列表 git remote -v ## 拉取上游仓库dev分支，如果没有分支名，默认拉取master分支的代码 git fetch upstrem dev ## 合并分支 git checkout git rebase upstream/dev ## 提交到我们自己的远程仓库 git push SSH 免密登录我们会发现每次进行git push的时候都要输入密码，这样比较麻烦，所以我们可以通过ssh进行免密登录。 这里只列出了linux的简单命令，其他系统或是更详细的帮助信息请自行查看github的 相关帮助文档 ## 创建 ssh key ssh-keygen -t rsa -b 4096 -C &quot;jianchengwang@yahoo.com&quot; ## 添加 ssh key -&gt; ssh-agent eval &quot;$(ssh-agent -s)&quot; ssh-add ~/.ssh/id_rsa ## add ssh public key to your github account cat ~/.ssh/id_rsa.pub Hubhub is an extension to command-line git that helps you do everyday GitHub tasks without ever leaving the terminal 我一般比较常用hub create命令，你也可以设置别名 git -&gt; hub # indicate that you prefer HTTPS to SSH git clone URLs git config --global hub.protocol https # create a repo to host a new project on GitHub git init git add . git commit -m &quot;And so, it begins.&quot; hub create → (creates a new GitHub repository with the name of the current directory) git push -u origin HEAD # clone your own project hub clone dotfiles → git clone git://github.com/YOUR_USER/dotfiles.git # clone another project hub clone github/hub → git clone git://github.com/github/hub.git # fast-forward all local branches to match the latest state on the remote cd myproject hub sync # share log output via Gist hub gist create --copy build.log → (the URL of the new private gist copied to clipboard) 相关链接官方文档 互联网人都该懂点git 猴子都能懂的git入门 廖雪峰git教程 git工作流 Git Community Book 中文版","link":"/2021/09/10/git/"},{"title":"Gradle","text":"软件行业的蓬勃发展，新旧交替，版本构建工具从 ant -&gt; maven -&gt; gradle 进行演变，个人不喜欢 maven 的 xml 的配置文件，基于 Groovy 语言作为构建脚本语言，相对于 JAVA 开发人员来说比较容易上手，动态语言也比 xml 配置文件更灵活，构建速度也更加的快速，所以入了 gradle 的坑。当然，目前，很多公司还是使用 maven 作为构建工具，所以建议maven 还是要懂点的。 本文仅供自己学习 gradle 的记录笔记，如果你想深入的学习，请戳 官方文档 个人觉得，官方文档是最好的学习文档，我简单过了一遍，感觉官方文档的例子都很精炼，总结得很到位，底下很多代码实例也是来自官方文档。 基本概念每一次 Gradle 构建都是由一个或者多个 projects 组成， 比如一个 root projects 依赖多个 sub projects (module) 项目，每个 projects 又由编译，打包，生成javadoc，发布等多个 tasks 组成。tasks 之间也可以相互依赖，形成一个依赖关系图以确保他们的执行顺序。 项目 Projects一个项目代表一个正在构建的组件，比如一个jar文件，当构建启动的时候，Gradle 会基于 build.gradle 实例化一个 org.gradle.api.Project 类，并且能够通过 project 变量使其隐式可用。 属性: group name version 方法: apply denpendencies repositories task 其他配置方式: ext gradle.properties 任务 Tasks任务对应 org.gradle.api.Task ，主要包括任务动作和任务依赖。任务工作定义了一个最小的工作单元，可以定义依赖其他任务，动作序列和动作执行条件等。 方法: dependsOn doFirst do Last(&lt;&lt;) 构建生命周期 Build LifecycleA Gradle build has three distinct phases. Initialization Gradle supports single and multi-project builds. During the initialization phase, Gradle determines which projects are going to take part in the build, and creates a Project instance for each of these projects. Configuration During this phase the project objects are configured. The build scripts of all projects which are part of the build are executed. Execution Gradle determines the subset of the tasks, created and configured during the configuration phase, to be executed. The subset is determined by the task name arguments passed to the gradle command and the current directory. Gradle then executes each of the selected tasks. 配置文件 Settings file简要概述，就是如果你是多项目，那么你要在 root project 里创建 settings.gradle 里去定义跟 sub project的关系，这个文件会在所有 project build.gradle 执行前执行。 每个 project 都有一个构建脚本 build.gradle 来完成每个 project 的构建。 在构建的时候，你如果需要对 gradle 运行一些通用的构建配置，你可以定义在 gradle.properties 里，比如全局的 group 跟 name 等。 另外，gradle 是插件配置，你可以通过 apply 引入各种现成的或者自定义的插件构建脚本。 关于 gradle 项目的几种构建脚本或者配置文件描述如下 settings.gradleThis is executed during the initialization phase. The main role of settings.gradle is to define all included submodules and to mark the directory root of a tree of modules, so you can only have one settings.gradle file in a multi-module project. rootProject.name = 'project-x' include 'sub-a', 'sub-b' The settings file is also written in groovy, and submodule lookup can be adapted alot. build.gradleThis is executed during the configuration phase. There is one such file per module, it contains the build logic for this module. In the build.gradle file of the main module, you can use allprojects {} or subprojects {}to define settings for all other modules. In the build.gradle file of the submodules, you can use compile project(':sub-a') to make one submodule depend on the other. gradle.propertiesThis is optional, it’s main purpose is to provide startup options to use for running gradle itself, e.g. org.gradle.jvmargs=-Dfile.encoding=UTF-8 ... org.gradle.configureondemand=true gradle/utils.gradle(Any name of folder or file is possible.) You can define additional custom gradle files to reuse definitions, and include them in other gradle files via apply from: &quot;$rootDir/gradle/utils.gradle&quot; Groovy 基础Groovy是一门jvm语言，它最终是要编译成class文件然后在jvm上执行，所以Java语言的特性Groovy都支持，我们完全可以混写Java和Groovy。 既然如此，那Groovy的优势是什么呢？简单来说，Groovy提供了更加灵活简单的语法，大量的语法糖以及闭包特性可以让你用更少的代码来实现和Java同样的功能。比如解析xml文件，Groovy就非常方便，只需要几行代码就能搞定，而如果用Java则需要几十行代码。 基本语法深入学习或者有问题请戳 Groovy Api文档 // 完全兼容 java 的语法 // 分号可选 // 类，方法默认都是 public // 编译器给属性自动添加 getter/setter 方法 // 属性可以直接通过 . 号获取 // == 调用 equals 方法，判断对象是否同一个使用.is() Object a = new Object() Object b = a.clone() assert a == b assert !a.is(b) // 弱类型语言，可以直接用 def 定义 def version = 1 // assert 语句 version = null assert version == 2 // 括号可选 println version // 方法返回值可省略 def hello() { 1; } // 字符串 // .1 单引号仅仅表示字符 def s1 = 'hello world' // .2 双引号可以引用变量 def world = 'world' def s2 = &quot;hello ${world}&quot; // .3 三个引号可以换行 def s3 = ''' hello world ''' // 循环 for (i in 1..5){ println(&quot;hello world&quot;) } 4.times { println it } // 集合api // .1 list -&gt; ArrayList def buildTools = ['ant', 'maven'] buildTools &lt;&lt; 'gradle' assert buildTools.getClass() == ArrayList assert buildTools.size // .2 map -&gt; LinkedHashMap def map = 'a':'b' def buildYears = ['ant': 2000, 'maven': 2004] buildYears.gradle = 2009 println buildYears.ant println buildYears['ant'] println buildYears.getClass() // 闭包 -&gt; 类似于c语言的函数指针，可以作为方法的参数和返回值，也可以作为一个变量而存在。 def c1 = { v -&gt; println v } def c2 = { println 'world' } def method1(Closure closure) {方法: apply denpendencies repositories task closure('hello') } def method2(Closure closure) { closure() } c1.call('hello') c1('hello') c2.call() method1(c1) method2(c2) // io def file = new File(&quot;a.txt&quot;) println &quot;read file using two parameters&quot; file.eachLine { line, lineNo -&gt; println &quot;${lineNo} ${line}&quot; } println &quot;read file using one parameters&quot; file.eachLine { line -&gt; println &quot;${line}&quot; } file.eachLine(&quot;utf-8&quot;) { println it } // wich 操作符 Book bk = new Book() bk.id = 1 bk.name = &quot;android art&quot; bk.press = &quot;china press&quot; Book bk = new Book() bk.with { id = 1 name = &quot;android art&quot; press = &quot;china press&quot; } // 判断是否为真 if (name) {} // 三元表达式 def result = name ?: &quot;Unknown&quot; // 非空判断 println order?.customer?.address // switch def x = 1.23 def result = &quot;&quot; switch (x) { case &quot;foo&quot;: result = &quot;found foo&quot; // lets fall through case &quot;bar&quot;: result += &quot;bar&quot; case [4, 5, 6, 'inList']: result = &quot;list&quot; break case 12..30: result = &quot;range&quot; break case Integer: result = &quot;integer&quot; break case Number: result = &quot;number&quot; break case { it &gt; 3 }: result = &quot;number &gt; 3&quot; break default: result = &quot;default&quot; } assert result == &quot;number&quot; 构建脚本解析详细介绍或者想深入了解请戳 官方api // PluginAware.apply(java.util.Map) apply plugin:'java' version = '0.1' // void repositories​(Closure configureClosure) // Configures the repositories for this project. repositories { mavenCentral() } // void dependencies​(Closure configureClosure) // Configures the dependencies for this project. dependencies { // https://mvnrepository.com/artifact/com.google.guava/guava compile group: 'com.google.guava', name: 'guava', version: '27.1-jre' } Todo使用插件Gradle的设计理念是，所有有用的特性都由Gradle插件提供，一个Gradle插件能够： 在项目中添加新任务 为新加入的任务提供默认配置，这个默认配置会在项目中注入新的约定（如源文件位置）。 加入新的属性，可以覆盖插件的默认配置属性。 为项目加入新的依赖。 Gradle 用户手册提供了 一系列标准的gradle插件 The Java Plugin比如 The Java Plugin， 提供了 java 相关的目录结构，属性配置，构建任务等等 如果我们使用标准的gradle插件， 注意这个不能在配置在 multi-project configurations(subprojects, allprojects) plugins: { id: 'java' } 当然我们也可以使用 apply 方法，就比较灵活了 apply plugin: 'java' 我们还可以定义 jvm 的编译级别 sourceCompatibility: 1.8 targetCompatibility: 1.8 Project Layout当我们使用 java 这个插件的时候，它默认的项目结构是 src/main/java Production Java source. src/main/resources Production resources, such as XML and properties files. src/test/java Test Java source. src/test/resources Test resources. src/*sourceSet*/java Java source for the source set named sourceSet. src/*sourceSet*/resources Resources for the source set named sourceSet. 当然我们也可以更改它 sourceSets { main { java { srcDirs = ['src/java'] } resources { srcDirs = ['src/resources'] } } } Dependency management compile(Deprecated) Compile time dependencies. Superseded by implementation. implementation extends compile Implementation only dependencies. compileOnly Compile time only dependencies, not used at runtime. compileClasspath extends compile, compileOnly, implementation Compile classpath, used when compiling source. Used by task compileJava. annotationProcessor Annotation processors used during compilation. runtime(Deprecated) extends compile Runtime dependencies. Superseded by runtimeOnly. runtimeOnly Runtime only dependencies. runtimeClasspath extends runtimeOnly, runtime, implementation Runtime classpath contains elements of the implementation, as well as runtime only elements. testCompile(Deprecated) extends compile Additional dependencies for compiling tests. Superseded by testImplementation. testImplementation extends testCompile, implementation Implementation only dependencies for tests. testCompileOnly Additional dependencies only for compiling tests, not used at runtime. testCompileClasspath extends testCompile, testCompileOnly, testImplementation Test compile classpath, used when compiling test sources. Used by task compileTestJava. testRuntime(Deprecated) extends runtime, testCompile Additional dependencies for running tests only. Used by task test. Superseded by testRuntimeOnly. testRuntimeOnly extends runtimeOnly Runtime only dependencies for running tests. Used by task test. testRuntimeClasspath extends testRuntimeOnly, testRuntime, testImplementation Runtime classpath for running tests. archives Artifacts (e.g. jars) produced by this project. Used by tasks uploadArchives. default extends runtime The default configuration used by a project dependency on this project. Contains the artifacts and dependencies required by this project at runtime. jar插件也会提供很多构建任务，比如 compileJava ， processResources，classes，jar，clean，test 等等，这里只简要地提一下 jar 构建的 Manifest Each jar or war object has a manifest property with a separate instance of Manifest. When the archive is generated, a corresponding MANIFEST.MF file is written into the archive. jar { from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } } manifest { attributes 'Main-Class': 'cn.jianchengwang.todo.gradle.HelloWorld' } } The War PluginThe War plugin extends the Java plugin to add support for assembling web application WAR files. It disables the default JAR archive generation of the Java plugin and adds a default WAR archive task. 这里只显示一些简单的配置脚本 apply plugin: 'war' configurations { moreLibs } repositories { flatDir { dirs &quot;lib&quot; } jcenter() } dependencies { implementation module(&quot;:compile:1.0&quot;) { dependency &quot;:compile-transitive-1.0@jar&quot; dependency &quot;:providedCompile-transitive:1.0@jar&quot; } providedCompile &quot;javax.servlet:servlet-api:2.5&quot; providedCompile module(&quot;:providedCompile:1.0&quot;) { dependency &quot;:providedCompile-transitive:1.0@jar&quot; } runtimeOnly &quot;:runtime:1.0&quot; providedRuntime &quot;:providedRuntime:1.0@jar&quot; testImplementation &quot;junit:junit:4.12&quot; moreLibs &quot;:otherLib:1.0&quot; } war { from 'src/rootContent' // adds a file-set to the root of the archive webInf { from 'src/additionalWebInf' } // adds a file-set to the WEB-INF dir. classpath fileTree('additionalLibs') // adds a file-set to the WEB-INF/lib dir. classpath configurations.moreLibs // adds a configuration to the WEB-INF/lib dir. webXml = file('src/someWeb.xml') // copies a file to WEB-INF/web.xml } 其他还有很多官方标准插件这里就不都叙述了，还有怎么编写 gradle 插件，官方文档里有详细的介绍，有兴趣可以去了解下。 自定义任务 task hello { doLast -&gt; { println 'hello world' } } task count { &lt;&lt; { 4.times { print &quot;$it &quot; } } } // Task dependencies task intro { dependsOn hello doLast { println &quot;I'm Gradle&quot; } } // Dynamic tasks 4.times { counter -&gt; task &quot;task$counter&quot; { doLast { println &quot;I'm task number $counter&quot; } } } // Manipulating existing tasks hello.doFirst { println 'Hello Venus' } hello.configure { doLast { println 'Hello Mars' } } hello.configure { doLast { println 'Hello Jupiter' } } // Extra task properties task myTask { ext.myProperty = &quot;myValue&quot; } task printTaskProperties { doLast { println myTask.myProperty } } // Default tasks // Gradle allows you to define one or more default tasks that are executed if no other tasks are specified. defaultTasks 'clean', 'run' task clean { doLast { println 'Default Cleaning!' } } task run { doLast { println 'Default Running!' } } task other { doLast { println &quot;I'm not a default task!&quot; } } // working with files // .1 Copy task copyReport(type: Copy) { from file(&quot;$buildDir/reports/my-report.pdf&quot;) into file(&quot;$buildDir/toArchive&quot;) } task copyReportsForArchiving(type: Copy) { from &quot;$buildDir/reports/my-report.pdf&quot;, &quot;src/docs/manual.pdf&quot; into &quot;$buildDir/toArchive&quot; } task copyPdfReportsForArchiving(type: Copy) { from &quot;$buildDir/reports&quot; include &quot;*.pdf&quot; into &quot;$buildDir/toArchive&quot; } // .2 Archive or UnPack task packageDistribution(type: Zip) { archiveFileName = &quot;my-distribution.zip&quot; destinationDirectory = file(&quot;$buildDir/dist&quot;) from &quot;$buildDir/toArchive&quot; } task unpackFiles(type: Copy) { from zipTree(&quot;src/resources/thirdPartyResources.zip&quot;) into &quot;$buildDir/resources&quot; } // .3 Creating &quot;uber&quot; or &quot;fat&quot; JARs plugins { id 'java' } version = '1.0.0' repositories { mavenCentral() } dependencies { implementation 'commons-io:commons-io:2.6' } task uberJar(type: Jar) { archiveClassifier = 'uber' from sourceSets.main.output dependsOn configurations.runtimeClasspath from { configurations.runtimeClasspath.findAll { it.name.endsWith('jar') }.collect { zipTree(it) } } } 管理依赖依赖类型// module dependencies dependencies { runtime group: 'org.springframework', name: 'spring-core', version: '2.5' implementation 'org.springframework:spring-web:5.+' implementation('org.ow2.asm:asm:6.0') { because 'we require a JDK 9 compatible bytecode generator' } } // file dependencies dependencies { runtime files('libs/a.jar', 'libs/b.jar') runtime fileTree('libs') { include '*.jar' } } // project dependencies dependencies { implementation project(':shared') } 仓库类型// flat dir repositories { flatDir { dirs 'lib' } flatDir { dirs 'lib1', 'lib2' } } // maven repo repositories { mavenCentral() jcenter() google() mavenLocal() maven { url &quot;http://repo.mycompany.com/maven2&quot; } maven { url &quot;http://repo.mycompany.com/snapshots&quot; mavenContent { snapshotsOnly() } } maven { url &quot;sftp://repo.mycompany.com:22/maven2&quot; credentials { username &quot;user&quot; password &quot;password&quot; } } } 版本冲突如果存在依赖的版本冲突，那么 gradle 默认会选择最高版本的的依赖以解决依赖冲突，当然我们也可以手动解决，比如排除依赖，或者手动设置一个版本。当然，一般使用 gradle 默认的处理就可以了。 // Excluding transitive dependency for a particular dependency declaration dependencies { implementation('log4j:log4j:1.2.15') { exclude group: 'javax.jms', module: 'jms' exclude group: 'com.sun.jdmk', module: 'jmxtools' exclude group: 'com.sun.jmx', module: 'jmxri' } } // Excluding transitive dependency for a particular configuration configurations { implementation { exclude group: 'javax.jms', module: 'jms' exclude group: 'com.sun.jdmk', module: 'jmxtools' exclude group: 'com.sun.jmx', module: 'jmxri' } } dependencies { implementation 'log4j:log4j:1.2.15' } // Enforcing a dependency version dependencies { implementation 'org.apache.httpcomponents:httpclient:4.5.4' implementation('commons-codec:commons-codec:1.9') { force = true } } 多项目构建多项目构建就是在 root project配置一个 settings.gradle 引入需要的子项目即可， 比如我这边 root project 为 todo-gradle，有三个 sub project ， 则 settings.gradle 配置如下 rootProject.name = 'todo-gradle' include 'web' include 'model' include 'dao' 如果，sub project 很多配置项一样，那我们可以在 root project 的 build.gradle 构建脚本里进行通用的配置，使其对子项目生效， allprojects { apply plugin: 'java' sourceCompatibility = 1.8 } subprojects { repositories { mavenCentral() } dependencies { testCompile group: 'junit', name: 'junit', version: '4.12' } } 如果自定义的配置的任务或者选项，则在每个 project 的 build.gradle 构建脚本里配置即可，比如我 web sub project 还引入了 The War Plugin，那么我在 web sub project 的build.gradle 构建脚本可以配置如下 apply plugin: 'war' 最后就是项目依赖配置了，比如我 dao sub project 依赖 model sub project dependencies { implementation project(':model') } 因为依赖是可以传递的，所以假如我 web sub project 依赖 dao sub project 跟 model sub project，而 dao sub project 又依赖 model sub project，实际上我只要在 web sub project 构建脚本里面依赖 dao sub project 即可 dependencies { implementation project(':dao') } 如果存在依赖关系，显而易见，那么被依赖的项目或者任务都会先执行。 测试一般只要类继承 junit.framework.TestCase 或者 groovy.util.GroovyTestCase 或是假如使用 springboot 框架，带有 @RunWith 注解的类 最常见的就是任何至少一个包含 @Test 注解的类 当然，不同测试框架使用大同小异，你可以具体使用的时候查阅下资料即可， 下面官方的代码实例就显示了 test task 的相关配置。 Executes JUnit (3.8.x, 4.x or 5.x) or TestNG tests. Test are always run in (one or more) separate JVMs. The sample below shows various configuration options. apply plugin: 'java' // adds 'test' task test { // enable TestNG support (default is JUnit) useTestNG() // enable JUnit Platform (a.k.a. JUnit 5) support useJUnitPlatform() // set a system property for the test JVM(s) systemProperty 'some.prop', 'value' // explicitly include or exclude tests include 'org/foo/**' exclude 'org/boo/**' // show standard out and standard error of the test JVM(s) on the console testLogging.showStandardStreams = true // set heap size for the test JVM(s) minHeapSize = &quot;128m&quot; maxHeapSize = &quot;512m&quot; // set JVM arguments for the test JVM(s) jvmArgs '-XX:MaxPermSize=256m' // listen to events in the test execution lifecycle beforeTest { descriptor -&gt; logger.lifecycle(&quot;Running test: &quot; + descriptor) } // Fail the 'test' task on the first test failure failFast = true // listen to standard out and standard error of the test JVM(s) onOutput { descriptor, event -&gt; logger.lifecycle(&quot;Test: &quot; + descriptor + &quot; produced standard out/err: &quot; + event.message ) } } 一般测试的最终结果，会显示在 project 的 build/reports 目录里面 发布假如我们开发完一个功能模块，打包成一个 jar 包，需要提供给他人依赖引用，那么我们就可以发布出去了，一般 gradle 没有自己的仓库，如果是java 项目的话一般都是发布到 maven 仓库，因为 lvh 现在用的人比较少了，这里就简单的介绍一下怎么发布到 maven 仓库 Maven Publish Plugingapply plugin: 'maven-publish' publishing { publications { maven(MavenPublication) { groupId = 'org.gradle.sample' artifactId = 'project1-sample' version = '1.1' from components.java } } repositories { maven { name = 'myRepo' def releasesRepoUrl = &quot;$buildDir/repos/releases&quot; def snapshotsRepoUrl = &quot;$buildDir/repos/snapshots&quot; url = version.endsWith('SNAPSHOT') ? snapshotsRepoUrl : releasesRepoUrl } } } 相关链接官方用户手册 慕课网新一代构建工具gradle TODO 代码","link":"/2021/09/10/gradle/"},{"title":"gulp压缩","text":"下载插件&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;下载gulp-cli： npm install gulp-cli -g --save &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;接着，确认一下版本： $ gulp -v CLI version: 2.3.0 Local version: 4.0.2 算了，你什么也没看见 压缩 html&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;任选其一： npm install gulp-htmlmin --save npm install gulp-htmlclean --save &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;gulp-htmlmin的配置： .pipe(htmlmin({ removeComments: true, // 清除 HTML 註釋 collapseWhitespace: true, // 壓縮 HTML collapseBooleanAttributes: true, // 省略布爾屬性的值 &lt;input checked=&quot;true&quot;/&gt; ==&gt; &lt;input /&gt; removeEmptyAttributes: true, // 刪除所有空格作屬性值 &lt;input id=&quot;&quot; /&gt; ==&gt; &lt;input /&gt; removeScriptTypeAttributes: true, // 刪除 &lt;script&gt; 的 type=&quot;text/javascript&quot; removeStyleLinkTypeAttributes: true, // 刪除 &lt;style&gt; 和 &lt;link&gt; 的 type=&quot;text/css&quot; minifyJS: true, // 壓縮頁面 JS minifyCSS: true, // 壓縮頁面 CSS minifyURLs: true })) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;gulp-htmlclean的配置： .pipe(htmlclean({ protect: /&lt;\\!--%fooTemplate\\b.*?%--&gt;/g, edit: function(html) { return html.replace(/\\begg(s?)\\b/ig, 'omelet$1'); } })) 压缩 css&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;任选其一： npm install gulp-clean-css --save &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;gulp-clean-css的配置： gulp.task('minify-css', () =&gt; { return gulp.src('./public/**/*.css') .pipe(cleanCSS()) .pipe(gulp.dest('./public')) }) 压缩 js&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;任选其一： 重要：gulp-babel、gulp-uglify搭配食用! npm install gulp-tester --save npm install gulp-babel --save &amp;&amp; npm install gulp-uglify --save &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;gulp-tester的配置： 不好意思，terser配置没写，，哈哈哈哈。 .pipe(terser()) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;gulp-babel+gulp-uglify的配置： .pipe(babel({presets: ['@babel/preset-env']})) .pipe(uglify().on('error', function (e) {console.log(e)})) 压缩 imagenpm install gulp-imagemin --save &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;gulp-imagemin的配置： .pipe(imagemin({ optimizationLevel: 5, // 類型：Number 預設：3 取值範圍：0-7（優化等級） progressive: true, 7// 類型：Boolean 預設：false 無失真壓縮jpg圖片 interlaced: false, // 類型：Boolean 預設：false 隔行掃描gif進行渲染 multipass: false // 類型：Boolean 預設：false 多次優化svg直到完全優化 })) gulpflie&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;在你的博客根目录创建一个gulpfile.js的文件，格式如下：&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;并且根据你自己的插件安装情况，来进行配置：Gulpfile.js: /* Gulp 压缩 */ // gulp-cli const gulp = require('gulp') /* html */ /* 如果是使用 htmlclean，请注释掉下面一行 */ const htmlmin = require('gulp-html-minifier-terser') /* 同理 */ //const htmlclean = require('gulp-htmlclean') /* css */ const cleanCSS = require('gulp-clean-css') /* js */ /* gulp-tester (如果使用 gulp-terser,把下面的//去掉) */ //const terser = require('gulp-terser'); /* babel (如果使用babel,把下面兩行註釋去掉) */ /* 重要：gulp-uglify + gulp-babel */ const uglify = require('gulp-uglify') const babel = require('gulp-babel') /* image */ const imagemin = require('gulp-imagemin') /* 压缩 */ // --------------- // 壓縮 html gulp.task('minify-html', () =&gt; { return gulp.src('./public/**/*.html', './public/**/**/*.html', './public/*.html') // 如果使用的是 htmlclean，则保留如下。 /*.pipe(htmlclean({ protect: /&lt;\\!--%fooTemplate\\b.*?%--&gt;/g, edit: function(html) { return html.replace(/\\begg(s?)\\b/ig, 'omelet$1'); } }))*/ // 如果使用的是 htmlmin，则保留如下。 .pipe(htmlmin({ removeComments: true, // 清除 HTML 註釋 collapseWhitespace: true, // 壓縮 HTML collapseBooleanAttributes: true, // 省略布爾屬性的值 &lt;input checked=&quot;true&quot;/&gt; ==&gt; &lt;input /&gt; removeEmptyAttributes: true, // 刪除所有空格作屬性值 &lt;input id=&quot;&quot; /&gt; ==&gt; &lt;input /&gt; removeScriptTypeAttributes: true, // 刪除 &lt;script&gt; 的 type=&quot;text/javascript&quot; removeStyleLinkTypeAttributes: true, // 刪除 &lt;style&gt; 和 &lt;link&gt; 的 type=&quot;text/css&quot; minifyJS: true, // 壓縮頁面 JS minifyCSS: true, // 壓縮頁面 CSS minifyURLs: true })) .pipe(gulp.dest('./public')) }) /* 压缩 css */ gulp.task('minify-css', () =&gt; { return gulp.src('./public/**/*.css', './public/mysource/**/*.css') .pipe(cleanCSS()) .pipe(gulp.dest('./public')) }) /* 压缩 js */ // minify js - gulp-tester (如果使用 gulp-terser,把注释//去掉) /* 重要：gulp-uglify + gulp-babel */ //gulp.task('compress', () =&gt; // gulp.src(['./public/**/*.js', '!./public/**/*.min.js']) // .pipe(terser()) // .pipe(gulp.dest('./public')) //) // minify js - babel（ 如果不是使用babel,把下面註釋掉） gulp.task('compress', () =&gt; gulp.src(['./public/**/*.js', '!./public/**/*.min.js', './public/mysource/**/*.js', './public/*.js']) .pipe(babel({ presets: ['@babel/preset-env'] })) .pipe(uglify().on('error', function (e) { console.log(e) })) .pipe(gulp.dest('./public')) ) /* 压缩 image */ // 壓縮 public/uploads 目錄內圖片 gulp.task('minify-images', async () =&gt; { gulp.src('./public/img/**/*.*', './public/mysource/image/*.*') .pipe(imagemin({ optimizationLevel: 5, // 類型：Number 預設：3 取值範圍：0-7（優化等級） progressive: true, 7// 類型：Boolean 預設：false 無失真壓縮jpg圖片 interlaced: false, // 類型：Boolean 預設：false 隔行掃描gif進行渲染 multipass: false // 類型：Boolean 預設：false 多次優化svg直到完全優化 })) .pipe(gulp.dest('./public/img')) }) // 執行 gulp 命令時執行的任務 gulp.task('default', gulp.parallel( 'compress', 'minify-css', 'minify-html', 'minify-images' )) 部署&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;既然配置都设置好了！接下来就是真材实料的压缩了！&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;在hexo g之后，hexo d之前，加一句命令行gulp即可。 hexo cl &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d","link":"/2021/03/23/gulpyasuo/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","link":"/2022/07/09/hello-world/"},{"title":"化学笔记①","text":"四个实验实验一加热蒸馏水，在瓶口放一块玻璃片。 实验二第二个，是把块状的这个胆矾也叫蓝矾，放到这个研玻中，用研杵进行研磨。 Note 序号 变化前物质 变化时发生的现象 变化后形成的物质 有无新物质产生？ 实验一 液态的水 水中游无色的气泡冒出，玻璃片上出现小液滴 液态的水 无 实验二 蓝色的块状胆矾 由块状变成粉末状 蓝色的粉末胆矾 无 实验三 蓝色的胆矾溶液 有蓝色沉淀物生成 蓝色的氢氧化铜沉淀 有 实验四 石灰水，稀盐酸，澄清石灰水 固体减少，有气泡冒出，石灰石变浑浊 二氧化碳气体等 有 物理变化和化学变化$\\begin{cases}物理变化&amp; \\text{没有生成其他物质的变化（没有新的物质生成）}\\\\化学变化&amp; \\text{生成其他物质的变化（有新的物质生成）}\\end{cases}$ 物理变化常表现为形状，或者是状态上的改变，比如说水由液体变成固体，再由固体变成液体，再由液体变成气体的这一过程是物理变化，而不是化学变化，期间水的物态发生改变，但是其本质还是水，所以没有产生新的物质，不是化学变化。 化学变化 化学变化常表现为颜色的改变，释放出气体，生成沉淀等等。比如说实验四中生成的二氧化碳气体，实验三中生成的蓝色沉淀都是化学变化。 化学变化除了物质本身变化，也伴随着能量的变化，比如说，吸热，发光，发热。 化学变化的过程中会同时发生物理变化。 物理性质和化学性质$\\begin{cases}物理性质&amp; \\text{物质不需要发生化学变化就表现出来的性质}\\\\化学性质&amp; \\text{物质在化学变化之表现出来的性质}\\end{cases}$","link":"/2021/08/27/huaxue-1/"},{"title":"图床的千层套路","text":"本文转载于CYF ，已获得其本人同意 &ensp;&ensp; 原文👉 图床的千层套路 博客最近在细心打磨终于上95分了，其中我认为图片功劳不可没。 2020年8月9日Jsdelivr发布了一次使用政策：Create Acceptable Use Policy，其中第4条Prohibited Use引起了众多议论： 4. Prohibited Use The following behavior is prohibited: 1. Hosting or accessing content that: - contains malware or harmful code in any form, - violates proprietary rights of others, - is sexually explicit, - is potentially illegal in the EU or the USA. 2. Abusing the service and its resources, or using jsDelivr as a general-purpose file or media hosting service. This includes, for example: - running an image hosting website and using jsDelivr as a storage for all uploaded images, - hosting videos, file backups, or other files in large quantities. We recognize that there are legitimate projects that consist of a large number of files, and these are not considered abuse. For example: icons packs, apps, or games with a large number of assets. 其中running an image hosting website and using jsDelivr as a storage for all uploaded images 这一句相当的有歧义，要多少的图片才能算是图站？博客里面图片放里面算吗？上传的图片怎样才不行？ 反观网上流传的白嫖Github做图床，基本点进去都是https://cdn.jsdelivr.net/gh/ 这样子的图床，这种行为，我不敢妄加评论。但是，jsdelivr诞生的意义似乎并不是为了图床而生的，这种行为也很难判断成滥用。 使用政策发布之后，一时间，QQ群、v2ex、知乎上立刻就炸了锅。很多人猜测jsdelivr是不是滥用过度而禁止将其作为图床？免费图床的白嫖日子要结束了吗？更多的人，是在哭诉和询问那里还有像jsd一样优秀的图床可以白嫖，微博炸了，那里还有免费图床啊？ 实际上，我一般采用的是BackBlaze+CloudFlare 但是自从八月底移动开始改道，从原先优秀的CMI绕路LAX后，国内CloudFlare访问质量再次暴跌，这不得不使我将博客迁至Vercel。好在八月份我有幸申请到了doegdoge图床使用权限，获得了国内较高速的图床. 但是，对于哪些没有没有图床的人来说，免费图床真的这么难以获得吗？ 不好意思，免费图床非常多，只是你不会用而已，这篇文章，就是拯救面前陷入图床危机的你【当然是面向小白，大佬也可以在底下给我提意见鸭】。 公益图床sm.mshttps://sm.ms 推荐程度：★ 首先推荐的是这个图床，loli.net域名经典重现。三年前此图床域名还有备案采用的是国内CDN，可惜后来因为滥用吊销备案号而被迫迁移国外，用的是CloudFlare。实际使用效果面向国内确实不太好，建议备用。 你不需要注册，拖拽直接上传，只要不违反大陆和香港法律，他就能永久保留你的图片 可搭配PicGo Imgurhttps://imgur.com 推荐程度：★★ 国外一家牛逼的图片托管服务商，你可以选择注册或不注册，同样的，拖拽上传，永久保留，其SLA有着相当高的保证。 然而很可惜的是，这种网站很早就在国内被DNS域名污染，也就意味着访客无法正常加载你的图片。这也就是被打为两颗星的原因。 当然，你也可以通过#图像缓存服务 从而实现国内访问。 可搭配PicGo【需注册】 去不图床https://7bu.top/ 推荐程度：★★★★ 由杜老师提供的个人公益图床，存储于阿里和腾讯的COS，官方保证SLA&gt;=99%，是一个不错的选择，当然，7bu毕竟是个人维护的图床，能不能永久撑下去还是个问题，我也没有做过深度评测，无法表明其可用性。 可搭配PicGo。 接口地址：https://7bu.top/api/upload post参数：image 回调json：data.url 更准确的API文档 而且，就在我上传测试图片的时候，明明已经表明图片已经上传，打开却发现COS提示404，这一点我不得陷入思考，个人维持的公益项目真的能保证SLA吗？ 昨天上传的时候撞上服务器维修了，很抱歉做出了不够恰当的评价.7bu采用的是全国腾讯云CDN加速，国内访问速度十分优良。然而请注意，7bu刚开始建立的目的并不是面向全球【仅面对中国大陆游客】，这导致其大陆以外基本解析至国内西藏腾讯，访问效果并不好。并且，这是通过腾讯云的鉴黄，可能会存在误杀行为。具体使用请个人斟酌【不过作为开发环境还是可行的】。 白嫖的阿里图床推荐程度：★★★★ 我个人搭建的API：https://picbed.cyfan.top 不保证上传SLA 由于小鸡联通国内网络不太好，很有可能无法正常上传，原项目已经开源 ，你完全可以通过在国内的机子或者是本地搭建以获得更佳体验。 如果上传成功了，图片将会托管于阿里云的CDN，无论是速度还是延迟都相当的优秀。 官方大厂，下载SLA有保障。 可搭配PicGo。 接口地址：https://picbed.cyfan.top/update.php post参数：file 回调json：data.url DogeDoge图床推荐程度：★★★★★ 其实很早就看到V2EX的那篇征文了： 可是当时我不够优秀啊虽然现在同样不优秀，博客也没满一年啊，于是白嫖的心态搁浅了。 后来突然看到Jalen的博客也用了DogeDoge图床，这才突然意识到原来我已经满一年了。于是抱着试试看的心态向doge官方邮箱发送了邮件，结果真过了。。。 dogedoge拥有着国内相当不错的CDN，国内访问飞快，但是国外的访问质量的确不如人意。【反正此博客面向中国大陆】 而且，DogeDoge拥有着很良心的处理参数： w：宽 h：高 mode：模式 - crop 裁剪、clip 缩略 fmt：格式 - jpg、png、webp（原图为 gif，且没有 frame 参数时，不做任何裁切、缩略处理） frame：1 - EOF帧，默认为 1 （对动画有效） q：压缩质量 - 1 - 100（默认 90 ） rect：指定位置裁剪 - top,left,w,h（若与 w / h 参数同时存在，则 会在 rect 裁剪过后，继续按照 w / h 的要求缩略） pos：（配合 w / h ）裁剪位置 - top-left、top、top-right、left、center、right、bottom-left、bottom、bottom-right，默认为center pos 还有一个特殊的值 auto，该值目前为 alpha 状态，可以根据图片重点来进行 pos 的位置取舍。 当然，DogeDoge也可以搭配PicGo使用。 接口地址：https://www.dogedoge.com/tools/upload/{Your_Token} post参数：file 回调json：data.o_url 当然，现在的Doge图床还是处于免费的试用期【Creater】，不过好在试用期过后价格也比较合理，一般的tester也足够使用，目前看来SLA还是不错的。 当然，申请不到dogedoge图床也没关系，看下去你就会发现，白嫖的路千千万万，何必执着于一条。 BackBlaze推荐程度：★★★ 具体可以看看这篇文章 千奇百怪的Github+JSDelivr正如我所说的，这种组合已经被广大博主所采纳，并且网上教程已经泛滥了，在这里不再阐述。 npm+JSDelivr&amp;&amp;Zhimg&amp;&amp;bdstatic&amp;&amp;自定义镜像推荐程度：★★★★★ 为什么很多文章都没有提到用npm做图床？我想其中很大的原因是，白嫖jsd做图床的，很多都是小白【或者不愿花时间在于此的大佬】，同样的，这些文章面向的都是这些人，毕竟，以拖拽方式上传的Github和命令行方式上传，我想，大都数人会选择前者吧。 可是，你们没有想到的是，github文件镜像【github.com.cnpmjs.org是站点镜像】只有jsd一个，npm镜像可远远不止这一个啊！ 让我们看看分别镜像在jsd、zhimg、bdstatic的文件怎么样： 【unpkg镜像用的是CloudFlare，国内加速效果不好，暂时不写】 jsd就不必多说了，国内拥有强劲的网宿节点支撑【虽然以前出现过网宿下游投毒】，速度丝滑无比，国外也有强劲的CloudFlare上岗，可谓国内外两不误。而且，jsd对于npm的package单文件没有大小限制，也就是说泡个视频也不是问题。 zhimg是知乎的unpkg镜像，也是一个不错的选择【阿里CDN】，知乎官方也未对此做出限制，日常使用是可以的。 bdstatic是百度的内用npm镜像，速度也很好【百度CDN】，但是请注意，bdstatic作为内用cdn，其拉取频率较慢，经常出现无法及时更新。 啊哈？不会上传？去npm官网注册个账号去,然后先： npm login 接着： npm init npm publish 请注意，如果你之前用过淘宝镜像，那么请先手动切回源： npm config set registry https://registry.npmjs.org 每一次发布图片后，你可以将原来的图片删除，更改package.json 版本号【向上增加】,然后npm publish即可 这个似乎可以搭配picgo，不过好像没这个插件，写起来也麻烦。。。 unpkg的国内镜像其实远远不止这些，包括七牛、饿了么、腾讯都有，不过这个就要自己找了。 一些推荐的npm【or unpkg镜像】： 【jsd出品，网宿国内节点】https://cdn.jsdelivr.net/npm/ 【知乎出品，阿里国内节点】https://unpkg.zhimg.com/ 【百度出品，网宿国内节点】https://code.bdstatic.com/npm/ 【饿了么出品，网宿国内节点】https://shadow.elemecdn.com/npm/ 或者说，你还可以自建unpkg镜像。 啊，你说你没有服务器反向代理unpkg？ 其实，七牛的对象存储，腾讯的COS和阿里的OSS都是支持镜像回源的鸭！ 七牛http流量每月免费10GB，腾讯的国内免费60GB6个月，作为自用完全足够了！ ipfs我曾经写过关于ipfs的讲解 ,作为一个去中心化的存储系统拿来做公开图床其实挺不错的。 我个人搭建的ipfs镜像【托管于CloudFlareWorkers】：https://ipfs.cyfan.top 我个人搭建的ipfs上传API：https://ipfsupload.cyfan.top 接口地址：https://ipfsupload.cyfan.top/api/v0/add?pin=true post参数：file 回调json：Hash 此处Hash获得的是文件的Qmhash，你还要依托ipfs镜像，如https://ipfs.cyfan.top/ipfs/{QmHash} 顺便收录一些ipfs网关【可访问】： 【北京 阿里云】https://hashnews.k1ic.com/ 【香港 阿里云】https://ipfs.jbb.one/ 【美国 DigitalOcean】https://ipfs.telos.miami/ 【Amazon】https://ipfs.oceanprotocol.com/ 你可以在https://ipfs.github.io/public-gateway-checker/找到更多 图片缓存服务正如##Imgur所说的，imgur在国内已经无法访问了，但是，图片缓存服务可以啊！ 收集了一些图片缓存服务： 【国内网宿节点，只能加载特定图床图片如imgur】https://search.pstatic.net/common/?src= 【Akamai节点，没有使用限制】https://imageproxy.pimg.tw/resize?url= 【CloudFlare节点】https://images.weserv.nl/?url= 【CloudFlare节点】https://pic1.xuehuaimg.com/proxy/ PicGo的搭配使用PicGo默认已经集成了部分图床，其拖拽上传、自动复制剪贴板实在赢得了无数人的心。但是，对于一些冷门的图床支持似乎就不太好，这时候你需要用自定义web图床实现这一切： 我在上方介绍的图床如果支持web端上传，基本上就会写一个post请求，你可以依葫芦画瓢填写进去 这样子你就可以实现较为丝滑的上传图片了： 【为了压缩方便删除了部分帧】","link":"/2020/09/17/images/"},{"title":"关于javaScript变量 作用域链 this指针的详解","text":"Undefined代码： var a = 1; function hehe() { window.alert(a); var a = 2; window.alert(a); } hehe(); 第一个alert： 图片失效！！！ 第二个alert： 图片失效！！！ 原理我描述如下： 按照javascript作用域链的原理，当一个变量在当前作用域下找不到该变量的定义，会沿着作用域链往上找直到在全局作用域里查找。 按上面的代码所示，虽然函数内部重新定义了变量的值，但在定义之前使用了该变量；按照作用域链的原理会在全局作用域里找到变量定义，而实际情况却是变量未定义，这到底是怎么回事呢？ 下面开始本文的主要内容，我会从基础知识一步步讲起。 Javascript的变量变量的两种类型：基本类型和引用类型。基本类型是指：Undefined、Null、Boolean、Number和String，引用类型是指多个基本类型构成的对象。 下面我们来看看下面的代码： var str = &quot;sharpxiajun&quot;; str.attr01 = &quot;hello world&quot;; console.log(str);// 运行结果：sharpxiajun console.log(str.attr01);// 运行结果：undefined 运行之，发现基本类型无法添加属性，当然方法也同样不可以，例如下面的代码： str.ftn = function(){ console.log(&quot;str ftn&quot;); } str.ftn(); 运行之，结果如下图所示： 当我们使用引用类型时候，结果就和上面完全不同了，大家请看下面的代码： var obj1 = new Object(); obj1.name = &quot;obj1 name&quot;; console.log(obj1.name);// 运行结果：obj1 name Javascript里的基本类型是存放在栈区（内存里的栈内存），存储结构如下图所示： javascript里引用类型的存储需要内存的栈区和堆区（内存里的堆内存）共同完成，如下图所示： 场景一：如下代码所示： var qqq; console.log(qqq);// 运行结果：undefined 上面的代码就是命名了变量但未初始化，此时在内存里只有栈区的变量标示符而没有变量值，更没有堆区存储的对象。 场景二：如下代码所示： var qqq; console.log(qqq);// 运行结果：undefined console.log(xxx); 提示变量未定义！在任何语言里变量未定义就使用都是违法的，但是我们javascript变量未定义也可以使用，怎么我的例子里却不能使用了？ 那么我们看看下面的代码： xxx = &quot;outer xxx&quot;; console.log(xxx);// 运行结果：outer xxx function testFtn(){ sss = &quot;inner sss&quot;; console.log(sss);// 运行结果：outer sss } testFtn(); console.log(sss);//运行结果：outer sss console.log(window.sss);//运行结果：outer sss 我们看看window对象的结构，如下图所示： 由这两个场景我们可以知道： ***javascript**变量如果没有被var定义也没有赋值操作才会**报出“xxx is not defined”，后续的代码将不能正常运行；而只有赋值操作的变量，不管在哪个作用域里赋值，都是全局变量即window对象*。 下面我修改一下代码，如下所示： //var a = 1; function hehe() { console.log(a); var a = 2; console.log(a); } hehe(); 结果如下图所示： 我再改下代码： //var a = 1; function hehe() { console.log(a); // var a = 2; console.log(a); } hehe(); 运行之，结果如下所示： 对比二者代码，我们发现问题的关键是var a=2所引起的！ javascript变量是松散类型即定义时不需要指定变量类型，当变量值确定后才有类型，但没有使用var的变量必须有赋值。 **javascript代码运行前还有一个*预加载*，构造运行环境例如全局环境、函数运行环境和作用域链。环境和作用域的构造就是指定好变量属于哪个作用域，变量的定义是在预加载时完成而非在运行时。*预加载时会扫描所有代码但不运行，当扫描到被赋值操作的变量没有var定义，那么该变量就会被赋予全局变量即window对象。* 重新分析引子里的代码：在函数的局部作用域内变量a被重新定义了，在预加载时a的作用域也就不再属于全局变量而是函数作用域；赋值操作是在运行期执行的，第一次使用a变量时，a变量在局部作用域内还没被赋值，只有栈区的标示符，结果就undefined了。 *javascript两个特别的类型：undefined和null。变量的值为undefined，说明只有栈区的标示符；如果对变量进行赋值基本类型，那么栈区就有值了；如果***赋值引用类型******那么堆区会有一个对象，而栈区的值则是堆区对象的地址。变量的值是null，说明这个变量是个空对象，栈区的标示符和值都有值，堆区也有个空对象，这么说来null其实比undefined更耗内存了！ 那么我们看看下面的代码： var ooo = null; console.log(ooo);// 运行结果：null console.log(ooo == undefined);// 运行结果：tru console.log(ooo == null);// 运行结果：true console.log(ooo === undefined);// 运行结果：false console.log(ooo === null);// 运行结果：true 运行之，null可以和undefined相等；但使用更加精确的三等号“===”，发现还是有点不同，其实javascript里null是undefined的父类，要让一个变量是null必须使用等号“=”进行赋值！ javascript开发规范要求变量定义时马上赋值，好处就是程序很难因为变量未定义报错从而终止程序的运行，而且变量定义最好放在变量作用域的最前端。 下面我们再看一段代码： var str; if (undefined != str &amp;&amp; null != str &amp;&amp; &quot;&quot; != str){ console.log(&quot;true&quot;); }else{ console.log(&quot;false&quot;); } if (undefined != str &amp;&amp; &quot;&quot; != str){ console.log(&quot;true&quot;); }else{ console.log(&quot;false&quot;); } if (null != str &amp;&amp; &quot;&quot; != str){ console.log(&quot;true&quot;); }else{ console.log(&quot;false&quot;); } if (!!str){ console.log(&quot;true&quot;); }else{ console.log(&quot;false&quot;); } str = &quot;&quot;; if (!!str){ console.log(&quot;true&quot;); }else{ console.log(&quot;false&quot;){ } 运行之，结果都是打印出false。 使用双等号“==”时，undefined和null是一回事，所以第一个if语句的写法完全多余，而第二种和第三种写法是等价，究其本质前三种写法本质都是一致的；第四种写法更加完美，javascript里如果if语句的条件是undefined和null，if判断是false，所以判断代码是否为未定义和null时最好使用！运算符。 代码四里字符串被赋值空字符串时，if的判断也是false。javascript里有五种基本类型，undefined、null、boolean、Number和string，现在我们发现除了Number都可以使用！来判断if的ture和false，那么基本类型Number呢？ var num = 0; if (!!num){ console.log(&quot;true&quot;); }else{ console.log(&quot;false&quot;); } 运行之，结果是false；如果我们把num改为负数或正数，那么运行之的结果就是true了。 所以变量初始化值如果基本类型是string就赋值空字符串，如果是number就赋值0，***if语句就可以判断变量是否初始化过***！ 但是当变量是对象时候，结果却不一样了，如下代码： var obj = {}; if (!!obj){ console.log(&quot;true&quot;)； }else{ console.log(&quot;false&quot;); } 运行之，代码是true。 所以引用类型变量赋值null，if语句就可以判断变量是否初始化过！ 场景三：复制变量的值和函数传递参数 首先看看这个场景的代码： var s1 = &quot;sharpxiajun&quot;; var s2 = s1; console.log(s1); 运行结果：sharpxiajun console.log(s2); 运行结果：sharpxiajun s2 = &quot;xtq&quot;; console.log(s1); 运行结果：sharpxiajun console.log(s2); 运行结果：xtq 上面是基本类型变量的复制，我们再看看下面的代码： var obj1 = new Object(); obj1.name = &quot;obj1 name&quot;; console.log(obj1.name);// 运行结果：obj1 name var obj2 = obj1; console.log(obj2.name);// 运行结果：obj1 name obj1.name = &quot;sharpxiajun&quot;; console.log(obj2.name);// 运行结果：sharpxiajun 当复制的是对象，obj1和obj2两个对象被关联起来了，obj1的属性改变时，obj2的属性也改变。 我们看看下面的代码： function testFtn(sNm,pObj){ console.log(sNm);// 运行结果：new Name console.log(pObj.oName);// 运行结果：new obj sNm = &quot;change name&quot;; pObj.oName = &quot;change obj&quot;; } var sNm = &quot;new Name&quot;; var pObj = {oName:&quot;new obj&quot;}; testFtn(sNm,pObj); console.log(sNm);// 运行结果：new Name console.log(pObj.oName);// 运行结果：change obj 这个结果和变量复制的结果是一致的。 函数传参的本质就是外部的变量复制到函数参数的变量里，是按值传递的。 如下两张图所示： 在javascript里变量的存储有三个位置： 位置一：栈区变量标示符； 位置二：栈区变量值（栈区对象地址）； 位置三：堆区对象。 **javascript的变量复制（函数传参也是）本质是传栈区变量值。基本类型的值在**栈区变量值里，复制时**两个变量是独立的；复制引用类型时，*栈区变量值*是堆区对象的地址，因此其中一个改变，另一个也改变。 原理讲完了，下面我列举一个拔高的例子，代码如下： var ftn1 = function(){ console.log(&quot;test:ftn1&quot;); }; var ftn2 = function(){ console.log(&quot;test:ftn2&quot;); }; function ftn(f){ f(); f = ftn2; } ftn(ftn1);// 运行结果：test:ftn1 console.log(&quot;====================华丽的分割线======================&quot;); ftn1();// 运行结果：test:ftn1 这个代码以前是这么分析的：f是函数的参数，属于函数的局部作用域，更改f的值，是没法改变ftn1的值，因为到了外部作用域f就失效了。但是这种解释很难说明我上文里给出的函数传参的实例。其实这个问题应该这么分析：在javascript里函数也是对象，局部作用域里f = ftn2操作是将f在栈区变量地址改为ftn2的地址，对ftn1和ftn2没有影响。 ***记住：javascript变量复制和函数传参是在传递栈区变量值，*当栈区变量值为undefined、null、“”（空字符串）、0、false时，if判断是为false，我们可以通过！运算符计算。 当我们的代码如下： var obj = {}; if (!!obj){ console.log(&quot;true&quot;); }else{ console.log(&quot;false&quot;); } 结果则是true，其中var obj = {}相当于var obj = new Object()。虽然对象里没什么内容，但是在堆区里对象的内存已经分配，栈区变量值已经是内存地址了，所以if判断是true。 3) 作用域链相关的问题了解作用域链前先了解作用域： 作用域在许多程序设计语言中非常重要。 通常来说，一段程序代码中所用到的名字并不总是有效/可用的，而限定这个名字的可用性的代码范围就是这个名字的作用域。 作用域的使用提高了程序逻辑的局部性，增强程序的可靠性，减少名字冲突。 在java里通过{}来设置作用域，在{}里面的变量会得到保护，这种保护就是不让{}里的变量被外部变量混淆。那么{}的方式适合于javascript吗？ 我们看看下面的例子： var s1 = &quot;sharpxiajun&quot;; function ftn(){ var s2 = &quot;xtq&quot;; console.log(this);// 运行结果： windows console.log(&quot;s1:&quot; + this.s1 + &quot;;s2:&quot; + this.s2);//运行结果：s1:sharpxiajun;s2:undefined console.log(&quot;s1:&quot; + this.s1 + &quot;;s2:&quot; + s2);// 运行结果：s1:sharpxiajun;s2:xtq } ftn(); javascript最大的作用域是window，加载时自动构造。上面代码里的大括号是函数定义，函数作用域内定义的s2变量不能被window对象访问的。可以说s2变量是被{}保护起来了，它的生命周期和这个函数的生命周期有关。 但是在javascript语言里还有非函数的{}，我们再看看下面的例子： if (true){ var a = &quot;aaaa&quot;; } console.log(a);// 运行结果：aaaa 我们发现javascript里{}有时是起不到定义作用域的功能。这也说明javascript里的作用域定义是和其他语言例如java不同的。 javascript作用域execution context，翻译成执行上下文或执行环境。我们来想想javascript里哪些情况是执行的： 情况一：页面加载时script标签下的代码会顺序执行，而这些能被执行的代码都是属于window的变量或函数； 情况二：函数的名字后面加上小括号()，例如ftn()，执行的是函数。 如此说来，javascript里的执行环境有两类一类是全局执行环境，即window代表的全局环境；一类是函数代表的函数执行环境，这也就是局部作用域。 执行环境有个对象叫做variable object，翻译为变量对象或上下文变量，存储其执行环境里所有的变量和函数，全局执行环境的上下文变量就是window。 javascript执行环境栈execution context stack：每个要被执行的函数会先把函数的执行环境压入到执行环境栈里，执行完后被弹出，控制权交给全局环境；如果函数后面还有代码，代码接着执行；如果函数里嵌套了函数，那么嵌套函数执行完毕后，执行环境栈的控制权就交由了外部函数，然后依次类推，最后就是全局执行环境了。 函数的执行环境被压入到执行环境栈里后，函数执行的第一步不是函数里的第一行代码而是在上下文变量里构造一个作用域链scope chain，保证执行环境里有权访问的变量和函数是有序的。 我们看看下面的代码： var b1 = &quot;b1&quot;; function ftn1(){ var b2 = &quot;b2&quot;; var b1 = &quot;bbb&quot;; function ftn2(){ var b3 = &quot;b3&quot;; b2 = b1; b1 = b3; console.log(&quot;b1:&quot; + b1 + &quot;;b2:&quot; + b2 + &quot;;b3:&quot; + b3);// 运行结果：b1:b3;b2:bbb;b3:b3 } ftn2(); } ftn1(); console.log(b1);// 运行结果：b1 ftn2函数可以访问变量b1，b2，这个体现了有权访问；当ftn1作用域里改变了b1的值并且把b1变量重新定义为ftn1的局部变量，那么ftn2访问到的b1就是ftn1的，ftn2访问到b1后就不会在全局作用域里查找b1了，这个体现了有序性。 **总结：**作用域指的是执行环境execution context，通过上下文变量variable object体现。**当函数的执行环境压入到了执行环境栈**execution context stack**时上下文变量会构造一个对象作用域链scope chain保证执行环境里有权访问的变量和函数是有序的。作用域链只能向上访问**变量**，直到window，*不允许*向下访问。 4) this、new、apply和call详解*this***对象****：上下文变量构建作用域链时还会构造一个this对象，*是当前执行环境外部上下文变量的一份拷贝，*不包含作用域链变量。 例如代码： var b1 = &quot;b1&quot;; function ftn1(){ console.log(this);// 运行结果： window var b2 = &quot;b2&quot;; var b1 = &quot;bbb&quot;; function ftn2(){ console.log(this);// 运行结果： window var b3 = &quot;b3&quot;; b2 = b1; b1 = b3; console.log(&quot;b1:&quot; + b1 + &quot;;b2:&quot; + b2 + &quot;;b3:&quot; + b3);// 运行结果：b1:b3;b2:bbb;b3:b3 } ftn2(); } ftn1(); 函数ftn1和ftn2里的this指针都是指向window，这是为什么了？因为通过function xxx(){}形式定义函数，这个函数不管在哪定义都属于window。 但是我们知道很多this指针都不是指向window，例如下面的代码： var obj = { name:&quot;sharpxiajun&quot;, ftn:function(){ console.log(this);// 运行结果: Object { name=&quot;sharpxiajun&quot;, ftn=function()} console.log(this.name);//运行结果: sharpxiajun } } obj.ftn();// ： 这里this指针指向了Object，我前文不是说javascript里作用域只有两种：一个是全局的一个是函数，为什么这里Object也是可以制造出作用域？ 那我们看看下面的代码： var obj1 = new Object(); obj1.name = &quot;xtq&quot;; obj1.ftn = function(){ console.log(this);// 运行结果: Object { name=&quot;xtq&quot;, ftn=function()} console.log(this.name);//运行结果: xtq } obj1.ftn(); 这两种写法是等价的，第一种叫做字面量定义，而第二种是标准写法。Object对象的本质也是个function，调用对象里的函数时，函数的外部执行环境就是obj1本身，this指针也是指向了obj1。 下面我们看看在java语言里是如何使用this指针的，代码如下： public class Person { private String name; private String sex; private int age; private String job; public Person(String name, String sex, int age, String job) { super(); this.name = name; this.sex = sex; this.age = age; this.job = job; } private void showPerson(){ System.out.println(&quot;姓名：&quot; + this.name); System.out.println(&quot;性别：&quot; + this.sex); System.out.println(&quot;年龄：&quot; + this.age); System.out.println(&quot;工作：&quot; + this.job); } public void printInfo(){ this.showPerson(); } public static void main(String[] args) { Person person = new Person(&quot;马云&quot;, &quot;男&quot;, 46, &quot;董事长&quot;); person.printInfo(); } } //姓名：马云 //性别：男 //年龄：46 //工作：董事长 上面的代码执行后没有任何问题，下面我修改下这个代码，加一个静态的方法，静态方法里使用this指针调用类里的属性，如下图所示： 我们发现IDE会报出语法错误“Cannot use this in a static context”，this指针在java语言里是不能在静态方法里使用的。 在面向对象编程里有两个重要的概念：一个是类，一个是实例化的对象。类是一个抽象的概念，类就像一个模具，而实例化对象就是通过这个模具制造出来的产品。 有上面代码我们可以看到，this指针在java语言里只能在实例化对象里使用，this指针等于这个被实例化好的对象，而this后面加上点操作符后面的东西就是this所拥有的东西，例如：姓名，工作，手，脚等等。 javascript的this指针也只能在实例化对象里使用，但是javascript的this指针却比java难以理解的多，原因得有三： 原因一：javascript是一个函数编程语言，也是面向对象的语言；javascript的函数是高阶函数，可以作为对象传递，还可以作为构造函数，创建实例化对象，结果导致方法执行时候this指针的指向会不断发生变化。 原因二：由上面java的例子我们看到，this指针只有在使用new操作符后才会生效；但是javascript里的this在没有进行new操作也会生效，这时候this往往会指向全局对象window。 原因三：javascript里call和apply操作符可以改变this指针。 我们先看看下面的代码： &lt;script type=&quot;text/javascript&quot;&gt; this.a = &quot;aaa&quot;; console.log(a);//aaa console.log(this.a);//aaa console.log(window.a);//aaa console.log(this);// window console.log(window);// window console.log(this == window);// true console.log(this === window);// true &lt;/script&gt; script标签里直接使用this指针就指向window，window在页面加载时由javascript引擎完成。程序员无法通过编程语言来控制这个实例化过程，所以开发时就没有构建这个this指针的感觉，常常会忽视它。 还和function的使用有关，我们看看下面的代码： &lt;script type=&quot;text/javascript&quot;&gt; function ftn01(){ console.log(&quot;I am ftn01!&quot;); } var ftn02 = function(){ console.log(&quot;I am ftn02!&quot;); } &lt;/script&gt; 上面是两种定义函数的方式，第一种称作声明函数，第二种称作函数表达式，这两种方式的区别常常会让我们混淆this指针的使用。 我们再看看下面的代码： &lt;script type=&quot;text/javascript&quot;&gt; console.log(ftn01);//ftn01() 注意：在firebug下这个打印结果是可以点击，点击后会显示函数的定义 console.log(ftn02);// undefined function ftn01(){ console.log(&quot;I am ftn01!&quot;); } var ftn02 = function(){ console.log(&quot;I am ftn02!&quot;); } &lt;/script&gt; 这又是一段没有按顺序执行的代码，ftn02打印结果是undefined，有栈区变量标识符，没有栈区变量值，堆区没有对象，这是javascript引擎在预处理时扫描变量定义所致。ftn01打印出完整的函数定义，这只能说明一个问题： ***声明函数会在预处理时把函数定义和赋值操作都完成，且声明函数都是window对象的属性*。 关于函数表达式的写法还有秘密可以探寻，我们看下面的代码： &lt;script type=&quot;text/javascript&quot;&gt; function ftn03(){ var ftn04 = function(){ console.log(this);// window }; ftn04(); } ftn03(); &lt;/script&gt; ftn04虽然在ftn03作用域下，但是它里面的this指针指向window。说明函数表达式在函数内部写时，this指针指向window。 原因是javascript里任何匿名函数都是属于window，在全局作用域构造时完成定义和赋值。匿名函数是没有名字的变量，定义时会返回内存地址；如果有个变量接收了这个地址，那么匿名函数就能使用了；匿名函数是在全局执行环境构造时定义和赋值，所以匿名函数内的this指向window对象。 这下子坏了，this都指向window，那我们到底怎么才能改变它了？ 在本文开头我说出了this的秘密，this都是指向实例化对象，前面讲到那么多情况this都指向window，就是因为这些时候只做了一次实例化操作，实例化window对象，所以this都是指向window。我们要把this从window变成别的对象，就得要让function被实例化，那如何让javascript的function实例化呢？ 答案就是使用new操作符。我们看看下面的代码： &lt;script type=&quot;text/javascript&quot;&gt; var obj = { name:&quot;sharpxiajun&quot;, job:&quot;Software&quot;, show:function(){ console.log(&quot;Name:&quot; + this.name + &quot;;Job:&quot; + this.job); console.log(this);// Object { name=&quot;sharpxiajun&quot;, job=&quot;Software&quot;, show=function()} } }; var otherObj = new Object(); otherObj.name = &quot;xtq&quot;; otherObj.job = &quot;good&quot;; otherObj.show = function(){ console.log(&quot;Name:&quot; + this.name + &quot;;Job:&quot; + this.job); console.log(this);// Object { name=&quot;xtq&quot;, job=&quot;good&quot;, show=function()} }; obj.show();//Name:sharpxiajun;Job:Software otherObj.show();//Name:xtq;Job:good &lt;/script&gt; 这是我上篇讲到的关于this指向Object的实例。Javascript里通过字面量方式定义对象的方式是new Object的简写，二者是等价的，本质也是new操作符。 下面我使用javascript来重写本篇开头用java定义的类，代码如下： &lt;script type=&quot;text/javascript&quot;&gt; function Person(name,sex,age,job){ this.name = name; this.sex = sex; this.age = age; this.job = job; this.showPerson = function(){ console.log(&quot;姓名:&quot; + this.name); console.log(&quot;性别:&quot; + this.sex); console.log(&quot;年龄:&quot; + this.age); console.log(&quot;工作:&quot; + this.job); console.log(this);// Person { name=&quot;马云&quot;, sex=&quot;男&quot;, age=46, 更多...} } } var person = new Person(&quot;马云&quot;, &quot;男&quot;, 46, &quot;董事长&quot;); person.showPerson(); &lt;/script&gt; function Person相当于在定义一个类，javascript的function既是函数又是对象；javascript的构造函数可以理解为类和构造函数合二为一，当然javascript语言规范里是没有类的概念。 new操作符会让构造函数产生如下变化： 1. 创建一个新对象； 2. 将构造函数的作用域赋给新对象（因此this就指向了这个新对象）； 3. 执行构造函数中的代码（为这个新对象添加属性）； 4. 返回新对象 第四点要着重讲下，记住构造函数被new操作，要让new正常作用最好不要在构造函数里写return，没有return的构造函数都是按上面四点执行，有了return情况就复杂了，这个知识我会在讲prototype时候讲到。 Javascript改变this指针还有call和apply，它们的作用相同，只是参数不同。call和apply的第一个参数一样，apply第二个参数是数组，call从第二个参数开始后面有许多参数。 我们看看下面的码： &lt;script type=&quot;text/javascript&quot;&gt; var name = &quot;sharpxiajun&quot;; function ftn(name){ console.log(name); console.log(this.name); console.log(this); } ftn(&quot;101&quot;); var obj = { name:&quot;xtq&quot; }; ftn.call(obj,&quot;102&quot;); /* * 结果如下所示： *101 T002.html (第 73 行) sharpxiajun T002.html (第 74 行) Window T002.html T002.html (第 75 行) T002.html (第 73 行) xtq T002.html (第 74 行) Object { name=&quot;xtq&quot;} * */ &lt;/script&gt; 其实理清上面情况也是有迹可循的，就以定义对象里的方法有传入函数参数为例： 情形一：传入的参数是函数的别名，那么函数的this就是指向window； 情形二：传入的参数是被new过的构造函数，那么this就是指向实例化的对象本身； 情形三：如果想把被传入的函数对象里this的指针指向外部字面量定义的对象，那么我们就是用apply和call 我们可以通过代码看出我的结论，代码如下： &lt;script type=&quot;text/javascript&quot;&gt; var name = &quot;I am window&quot;; var obj = { name:&quot;sharpxiajun&quot;, job:&quot;Software&quot;, ftn01:function(obj){ obj.show(); }, ftn02:function(ftn){ ftn(); }, ftn03:function(ftn){ ftn.call(this) } }; function Person(name){ this.name = name; this.show = function(){ console.log(&quot;姓名:&quot; + this.name); console.log(this); } } var p = new Person(&quot;Person&quot;); obj.ftn01(p); obj.ftn02(function(){ console.log(this.name); console.log(this); }); obj.ftn03(function(){ console.log(this.name); console.log(this); }); &lt;/script&gt;","link":"/2021/02/14/jsbl/"},{"title":"JsDelivr图床","text":"介绍先说一下： JsDelivr是GitHub的CDN 直接访问即可。 使用GitHub新建一个库，放图片。 （细说略。。） PicGo下载不说了。 默认的不好用。 用插件githubPlus 配置 项目 描述 repo 你的库名：用户名/库名 branch 直接填：master token Github申请token(后面讲) path 库内路径(选)：img/ customUrl 使用JsDerlivr：https://cdn.jsdelivr.net/gh/用户名/库名 origin 选github GitHub TokenGitHub申请Token 注意： Token妥善保管，且只显示一次。 上传 如果出错，改个名字，重试。 视频版","link":"/2020/08/12/jsdelvr/"},{"title":"2016微信朋友圈音乐收集","text":"@微信朋友圈音乐收集2016-10合集+生活（音乐+文字） 10 月份，目前的我只记得我回了一趟家，把 iPhone 的 16G 硬盘换成了 64G，买了 MacBook Pro，貌似没有再发生什么事了，一切平静。 移动端阅读的趋势我无法阻挡，可是我还是不愿意接受，我很喜欢电脑端的阅读和整理，但是不管怎样我还是开了公众号提供一个文章推送的入口，方便别人知道我更新了东西。 RSS 的人会越来越少了，看来 Google 是对的，即使 GR 还在，也改变不了太多 下载地址：http://pan.baidu.com/s/1o8LJhwe 公众号提供自动回复功能，如果你想试听和下载对应月份的音乐请关注后根据提示进行操作！","link":"/2016/11/27/judasn-mymusic-2016-10/"},{"title":"2016微信朋友圈音乐收集","text":"@微信朋友圈音乐收集2016-11合集+生活（音乐+文字） 11 月最让自己感到意外的就是整理自己的生活购物指南、MacOS 系列，这个完全不在计划中，只是突然冒出来的。 11 月也让我了解当有消费纠纷的时候要走哪些流程。广州这边的工商局看来还是有点用的，解决速度还是很快的，只奢望政府部门能日益高效。 广州的天气时不时地升温到 20 度左右，看上去还没打算入冬的样子，只是不管天气如何，我是很想赖床了，醒来的第一个念头：变身植物人！ 这个月的歌曲我减少了几首歌没下载。有几首有版权的歌曲网易不给下载，我也懒得再去境外的站点下了，每个月就属这个境外下载就是烦人，即使开了 SS 一样很慢很慢，没办法这样折腾。 对于下载境外的音乐，我在导航：http://i.YouMeek.com，有提供几个下载地址，有兴趣的可以自己去那几个网站下载，或是 Google 下：歌手+歌名+mp3 download，这样的字眼。 下载地址：http://pan.baidu.com/s/1o8LJhwe 公众号提供自动回复功能，如果你想试听和下载对应月份的音乐请关注后根据提示进行操作！","link":"/2016/11/27/judasn-mymusic-2016-11/"},{"title":"MacPro 苹果最贵的产品之一","text":"首先，我们看看它的售价好吧。来到Apple官网，找到MAC Pro，这里全选最贵的！ヾ(≧▽≦*)o 然后我数了数 41768RMB，这是它的顶尖配置价钱。我看了看基础的，170000RMB，没错170000RMB，四舍五入一下200000RMB 以上是它的价格，穷人家的孩子只配捡垃圾，根本没法比的好吧。 说说外观 银白色的机身，侧面有个大大的Logo 内部 以实力刷新一切。 这，是一台方方面面均登峰造极的 Mac。它拥有极致的性能、强大的扩展能力，以及卓越的配置潜能，让广大专业用户能突破极限，挑战不可能。 借用官网这句话，阐述我此时的心情。就拿最顶尖的配置来说话吧。取下MacPro的外壳，用的是最新的2.5GHz 8核Intel-Xeon W 处理器，睿频加速最高可以达到4.4GHz搭配1.5个T的内存，两个 Radeon Pro Vega II Duo 图形处理器，各配备 2x32GB HBM2 显存，8TB 固态硬盘的固态硬盘看看这，一般人根本买不起啊！所以我就发现了，做关于MacPro,视频，文章的人十分的少，不是吗？说句废话这堆价值40w的废铁2019年的Apple发布会上就出了！ 2019年6月4日，在2019年WWDC全球开发者大会上，苹果发布号称史上最强的新版Mac Pro电脑。起售价5999美元，2019年秋上市。 好了回到正题，我刚刚提到了英特尔的睿频加速，那就一起说了吧。 英特尔睿频加速技术可以理解为自动超频。当开启睿频加速之后，CPU会根据当前的任务量自动调整CPU主频，从而重任务时发挥最大的性能，轻任务时发挥最大节能优势。 说的技术一点就是：当启动一个运行程序后，处理器会自动加速到合适的频率，而原来的运行速度会提升 10%~20% 以保证程序流畅运行；应对复杂应用时，处理器可自动提高运行主频以提速，轻松进行对性能要求更高的多任务处理；当进行工作任务切换时，如果只有内存和硬盘在进行主要的工作，处理器会立刻处于节电状态。这样既保证了能源的有效利用，又使程序速度大幅提升。通过智能化地加快处理器速度，从而根据应用需求最大限度地提升性能，为高负载任务提升运行主频高达20%以获得最佳性能即最大限度地有效提升性能以符合高工作负载的应用需求：通过给人工智能、物理模拟和渲染需求分配多条线程处理，可以给用户带来更流畅、更逼真的游戏体验。同时，英特尔智能高速缓存技术提供性能更高、更高效的高速缓存子系统，从而进一步优化了多线程应用上的性能。听不懂？ 通俗点就是：当操作系统遇到计算密集型任务（例如处理复杂的游戏物理引擎或实时预览多媒体编辑内容）时，它需要CPU提供更强的性能。这时CPU会确定其当前工作功率、电流和温度是否已达到最高极限。如仍有多余空间，则CPU会逐渐提高活动内核的频率，以进一步提高当前任务的处理速度。 企业级解释就是：英特尔智能加速技术是一个英特尔新一代的能效管理方案，与以前一味的降低主频以达到控制能耗的想法不同，Turbo Boost的主旨在于——在不超过总TDP的前提下，尽量挖掘CPU的性能潜力。在英特尔Nehalem、Lynnfield架构的处理器中，每个处理核心都带有自己的PLL同步逻辑单元，每个核心的时钟频率都是独立的，而且每个处理核心都是有自己单独的核心电压，这样的好处是在深度睡眠的时候，个别的处理核心几乎可以完全被关闭。而在之前的多核心处理器中，所有的处理核心都具备相同的核心电压，也就是说着活跃的处理核心与不活跃的处理核心都要消耗相同的功耗。英特尔Nehalem架构处理器中的PCU(Power Control Unit)单元可以监控操作系统的性能，并且向其发出命令请求。因此它可以非常智能的决定系统的运行状态，是在高性能模式，还是在节电模式。即是说当应用负载提高时，系统可以在TDP的允许范围内对核心主频进行超频： 如果4个CPU内核中有一个或两个核心检测到负荷不高，那么其功耗将会被切断，也就是将相关核心的工作电压设置为0，而节省下来的电力就会被处理器中的CPU用来提升高负荷内核的电压，从而提升核心频率最终提升性能。当然不仅限于这一种状态，也可以是关闭一个核心或者是关闭三个核心。 好了，我不多BB Mac Pro的话，emm，最高达 28 核的威力，纵情挥洒创造力。 Mac Pro 专为对中央处理器性能有着极高要求的专业用户而设计。无论是后期制作渲染，演奏数百种虚拟乐器，还是模拟多部设备来运行一款 iOS app，它都游刃有余。系统的核心是一款 Intel Xeon 处理器，最高可达 28 核，而这也是 Mac 历来之最。此外，它还配备大型二级缓存和共享三级缓存，并拥有 64 条 PCI Express 通道，提供了极高的处理器数据传输带宽，这点真的令我折服。全功率，全天候。 要让处理器不遗余力地发挥性能，需要充沛的电力。在这里，就意味着超过 300 瓦的功率。得益于大型散热器，系统能够保持低温，放开手脚全力运行。热导管将热量从芯片上导出，并通过铝质鳍片疏散。与此同时，三个轴流风扇也会持续疏导着整个系统中的空气。重新认识一下内存。 多核心工作站处理器需要极大的内存支持。Mac Pro 配有六通道的高速 ECC 内存和 12 个实体 DIMM 插槽，内存最高可扩充至 1.5TB，因此专业用户能迅速流畅地进行各种工作，如处理大型项目、分析庞大数据集或运行多个专业应用程序等。一般的塔式主机将内存条塞在很难够到的位置，而 Mac Pro 采用了双面主板，将接触和操作变得非常容易。 最高达 2933MHz DDR4 ECC 内存最高达 140GB/s 内存带宽六通道内存系统 八个 PCI Express 扩展插槽，任你怎样配置。 Mac Pro 的设计满足了需要为系统配置更高带宽性能的专业用户，它配有四个双槽位宽度插槽、三个标准宽度插槽，以及一个预配了 Apple I/O 卡的半长插槽，插槽数量是上一代 Mac 塔式主机的两倍。现在，你就能在一个单一工作站中，实现以往所不能企及的定制和扩展。 图像处理的话。。官网的描述：极致性能，尽在设计之中。 对很多专业人士来说，高性能的图形处理架构对他们的工作至关重要，特别是制作动画三维影片素材、合成 8K 场景、构建栩栩如生的游戏环境之类的任务。要为他们提供极尽强大的性能，将图形处理能力提升至新的境界，进行突破就势在必行。于是，Mac Pro 扩展模块，也就是 MPX 模块应运而生。 BB不下去了 找个官网文字凑凑字数 上述所示 Mac Pro 的分期付款金额仅为使用特定期数免息分期付款估算得出的示例 (仅显示整数数额，未显示小数点以后的金额)，实际支付金额以银行账单为准。最高可享 24 期免息分期，到 Apple Store 零售店和在线商店购买时可享受的免息分期期数和最低限额可能有所不同，银行和花呗提供的免息分期期数和最低限额可能有所不同。银行或花呗可能要求你的可用信用额度大于所购买产品的总金额，才能使用分期付款服务。有关信用卡或花呗分期服务的申请及使用问题，请与银行或花呗联系，Apple 对此不做任何承诺和保证。订单可能需要满足特定金额要求，如需了解更多免息分期付款信息，请点击此处。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统，已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 Logic Pro X 10.4.7 进行，采用一个包含 253 个音轨的项目，每个音轨均应用一个 Amp Designer 插件实例。播放时逐个加载音轨，直至中央处理器超载为止。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统，已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 MATLAB 与 Simulink R2019b Update 1 和 Parallel Computing Toolbox 进行，采用车辆动力学模型。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用预发行版 Adobe Photoshop 2020 21.0.04 进行，采用晶格化、点状化、径向模糊、蒙尘与划痕以及中间值滤镜。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 Autodesk Maya 2019.2 进行，采用一个 399.6MB 的场景。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 Mathematica v12 进行，采用内置基准 WolframMark。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。构建时间测试使用 Xcode 11.1 (11A1027)、ninja (v.1.7.2 标签)、swift (swift-5.0.1-RELEASE 标签)、swift-clang (swift-5.0.1-RELEASE 标签)、swift-llvm (swift-5.0.1-RELEASE 标签)、swift-cmark (swift-5.0.1-RELEASE 标签)、swift-compiler-rt (swift-5.0.1-RELEASE 标签) 和 CMake 3.9.4 进行。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 并配置 Afterburner 加速卡的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5 处理器、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 Final Cut Pro 10.4.7 进行，采用一个时长 60 秒的项目，项目包含分辨率为 8192x4320、帧率为 29.97 fps 的 8K Apple ProRes RAW 媒体，转码为 Apple ProRes 422。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II Duo 图形处理器 (均配备 64GB HBM2) 的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5 处理器、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 Cinema 4D R21 ProRender 进行，采用一个 22.2MB 的场景。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II Duo 图形处理器 (均配备 64GB HBM2) 的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5 处理器、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 DaVinci Resolve Studio 16 进行，采用 8 种常用特效以及一个分辨率为 3840x2160、帧率为 24 fps 的 10 秒超高清项目。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。Cinema 4D R21 实时三维性能测试采用一个 1.98GB 的场景。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 并配置 Afterburner 加速卡的 Mac Pro 系统；已上市的配备 2.3GHz 18 核 Intel Xeon W 处理器、256GB RAM、Radeon Pro Vega 64X 图形处理器 (配备 16GB HBM2) 的 27 英寸 iMac Pro 系统，以及已上市的配备 2.7GHz 12 核 Intel Xeon E5 处理器、64GB RAM、双 AMD FirePro D700 图形处理器 (均配备 6GB VRAM) 的 Mac Pro 系统进行了此项测试。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 Final Cut Pro 10.4.7 进行，采用一个时长为 90 秒的复杂项目，项目包含各种媒体，分辨率最高达 8K。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 和 iMac Pro 的性能。Apple 于 2019 年 11 月使用试生产的配备 2.5GHz 28 核 Intel Xeon W 处理器、384GB RAM、双 AMD Radeon Pro Vega II 图形处理器 (均配备 Infinity Fabric Link 和 32GB HBM2) 的 Mac Pro 系统进行了此项测试，系统配备 Afterburner 加速卡和 4TB 固态硬盘。测试的 Mac Pro 系统连接一台 5K 显示器。测试使用 Final Cut Pro 10.4.7 进行，采用一个时长为 50 秒的画中画项目，项目包含 6 条分辨率为 8192x4320，帧率为 29.97 fps 的 Apple ProRes RAW 视频流；一个时长为 50 秒的画中画项目，项目包含 23 条分辨率为 4096x2160，帧率为 29.97 fps 的 Apple ProRes RAW 视频流；一个时长为 5 分钟的画中画项目，项目包含 16 条分辨率为 4096x2160，帧率为 30 fps 的 Apple ProRes 422 视频流。性能测试在特定电脑系统上进行，能够大致反映 Mac Pro 的性能。 总结总结一下吧，这台电脑售价17w，这个价格的话，还算是贵了，单说内存条200RMB/g，一块就22g，不是么？这个定价确实不。。MACPRO的话，剪辑还可以，100多线一起跑，很爽。PR不建议，PR不会用A卡，其他的还可以比如说达芬奇都还是可以的。 就这样水一篇文章我是问心无愧的.","link":"/2021/04/11/macpro/"},{"title":"intro to serverless functions","text":"最近喵了下 Introduction to Serverless Functions 视频感觉还不错。下面主要根据视频作者Jason Lengstorf 的ppt 简单做下笔记，最底下会列出相关链接。 示例代码 示例网站 前言serverless 一般分为bass(Backend as a Service)和fass(Function as a Service)两种，今天我们主要学习一下fass，国内云厂商一般称为云函数。简单来说，就是依赖云厂商的平台建设，使我们只关注业务代码，不需要考虑服务器相关内容，也更容易的进行资源的弹性扩容，基于事件驱动，避免闲时资源浪费。 当然有利也有弊，fass基于Data-shipping架构，即：将数据传输到代码所在处执行，而不是将代码传输到数据所在处执行，因为数据一般都比代码的传输量要大得多。而目前主流的 Faas 平台都是『将数据传输到代码所在处执行』这种架构，所以这是 Faas 的最大缺陷，同时也不好维护状态，事务啥的。 所以，一般就作为一些公共基础建设，比如图片预处理，API网关数据拉取，这种无状态的独立功能函数。 准备工作今天我们主要使用node.js构建我们的函数应用，所以你要先安装下node.js v12 or higher， 需要云服务商Netlify跟Hasura提供服务，所以需要你有这两个网站的账号，都提供免费额度使用，所以无需担心费用问题。 还需要，omdbapi，提供模拟数据，所以创建一个API KEY即可， 另外有的网站可能需要科学上网，这个需要你自己解决了。 搭建本地环境# install the Netlify CLI for local development npm install -g netlify-cli@latest # clone the starting point for development git clone --branch start https://github.com/jlengstorf/frontendmasters-serverless.git # recommended use vscode code frontendmasters-serverless # create functions dir cd frontendmasters-serverless mkdir functions # cofnig functions location vim netlify.toml [build] command = &quot;npm run build&quot; publish = &quot;_site&quot; functions = &quot;functions&quot; 最终目录结构如下： .eleventy.js .env # 环境变量 .gitignore _site data # 静态数据 functions # 函数目录 netlify.toml # 配置文件 node_modules package.json package-lock.json README.md src # 网站代码 这个看你使用哪个云厂商提供服务了，目录跟配置项可能不一样，本示例使用的是Netlify Functions， 我们现在就来使用serverless functions 搭建一个简单的我看过的电影展示列表，网站静态页面跟样式已经有了，你可以启动服务看下效果 ntl dev Boopcd functions vim boop.js exports.handler = (event, context, callback) =&gt; { // &quot;event&quot; has information about the path, body, headers, etc. of the request console.log('event', event) // &quot;context&quot; has information about the lambda environment and user details console.log('context', context) // The &quot;callback&quot; ends the execution of the function and returns a response back to the caller return callback(null, { statusCode: 200, body: JSON.stringify({ data: 'Boop!' }) }) } 可以看到，serverless functions 函数结构很简单，就是声明一个方法，预处理，然后执行回调函数。 当然你直接使用return exports.handler = async () =&gt; { return { statusCode: 200, body: 'Boop!' } } 然后，我们访问http://localhost:8888/.netlify/functions/boop，即可看到返回的数据了 获取本地数据现在我们要从本地，data/movies.json 获取数据，然后渲染在页面上，functions 目录下创建movies.js // get movies from local json const movies = require('../data/movies.json') exports.handler = async () =&gt; { return { statusCode: 200, body: JSON.stringify(moviesWithRatings), } } 然后src/index.html 请求数据，渲染页面即可 &lt;script&gt; async function initialize() { const movies = await fetch('/.netlify/functions/movies').then((response) =&gt; response.json(), ); const container = document.querySelector('.movies'); const template = document.querySelector('#movie-template'); movies.forEach((movie) =&gt; { const element = template.content.cloneNode(true); const img = element.querySelector('img'); img.src = movie.poster; img.alt = movie.title; element.querySelector('h2').innerText = movie.title; element.querySelector('.tagline').innerText = movie.tagline; container.appendChild(element); }); } &lt;/script&gt; 获取请求参数用过event参数获取，functions 目录下创建movie-by-id.js const movies = require('../data/movies.json') exports.handler = async({ queryStringParameters }) =&gt; { const { id } = queryStringParameters; const moive = movies.find(m =&gt; m.id === id); if(!moive) { return { statusCode: 404, body: 'Not Found' } } return { statusCode: 200, body: JSON.stringify(moive) } } 然后访问http://localhost:8888/.netlify/functions/movie-by-id?id=tt2975590 当然event还包含很多其他信息，有兴趣的话可以喵下官方文档，或者，把event返回出来看看。 拉取OMDBAPI数据获取第三方接口，一般需要API-KEY提供凭证，一般配置在环境变量里面， vim .env OMDB_API_KEY= 这边使用node-fetch请求第三方接口 npm install node-fetch 我们这里，通过OMDBAPI获取影片的评分信息，调整functions/movies.js代码示例如下： const { URL } = require('url') const fetch = require('node-fetch') // get movies from local json const movies = require('../data/movies.json') exports.handler = async () =&gt; { const movieScoreApi = new URL(&quot;https://www.omdbapi.com/&quot;); // add the secret API key to the query string movieScoreApi.searchParams.set('apiKey', process.env.OMDB_API_KEY) const promises = movies.map(movie =&gt; { movieScoreApi.searchParams.set('i', movie.id); return fetch(movieScoreApi) .then(response =&gt; response.json()) .then(data =&gt; { const scores = data.Ratings; return { ...movie, scores } }) }) // awaiting all Promises lets the requests happen in parallel // see: https://lwj.dev/blog/keep-async-await-from-blocking-execution/ const moviesWithRatings = await Promise.all(promises); return { statusCode: 200, body: JSON.stringify(moviesWithRatings), } } src/index.html 代码页面也做相应调整，这里就不多赘述。 Hasura Graphqlmovies.json的数据到达一定量的话，一般会存到数据库便于管理，这边使用Hasura Graphql，创建一张表movies表存储，并将movies.json数据填充几条到movies表中。 所以这边也要配置下Hasura Graphql 请求的环境变量： vim .env HASURA_API_URL= HASURA_ADMIN_SECRET= 关于Hasura Graphql的使用，语法等可以参考官方文档hasura graphql， HASURA_ADMIN_SECRET 其实就是NEW ENV VARS即可， 首先我们写一个工具方法，用来调用Hasura Graphql接口，functions/util/hasura.js const fetch = require('node-fetch') async function query({ query, variables = {} }) { const result = await fetch(process.env.HASURA_API_URL, { method: 'POST', headers: { 'Content-Type': 'application/json', 'X-Hasura-Admin-Secret': process.env.HASURA_ADMIN_SECRET, }, body: JSON.stringify({ query, variables }), }) .then(response =&gt; response.json()) .catch(function(e) { console.log(e); }); // TODO send back helpful information if there are errors console.info(result) return result.data; } exports.query = query; 然后再调整一下，functions/movies.js const { query } = require('./util/hasura'); exports.handler = async () =&gt; { // get movies from db const { movies } = await query({ query: ` query { movies { id title tagline poster } } `, }); ...other code return { statusCode: 200, body: JSON.stringify(moviesWithRatings), } } 然后再写个添加方法functions/add-movie.js const { query } = require('./util/hasura') exports.handler = async function(event) { const { id, title, tagline, poster } = JSON.parse(event.body); const result = await query({ query: ` mutation CreateMovie($id: String!, $poster: String!, $tagline: String!, $title: String!) { insert_movies_one(object: {id: $id, poster: $poster, tagline: $tagline, title: $title}) { id poster tagline title } } `, variables: { id, title, tagline, poster }, }); return { statusCode: 200, body: JSON.stringify(result), }; } 调整下添加页面，src/admin.html &lt;script&gt; async function handleSubmit(event) { event.preventDefault(); const data = new FormData(event.target); const result = await fetch('/.netlify/functions/add-movie', { method: 'POST', body: JSON.stringify({ id: data.get('id'), title: data.get('title'), tagline: data.get('tagline'), poster: data.get('poster'), }), }).then((response) =&gt; { document.querySelector( '.message', ).innerText = `Response: ${response.status} — ${response.statusText}`; }); } document.querySelector('#add-movie').addEventListener('submit', handleSubmit); &lt;/script&gt; Netlify Identify网站一般要进行身份验证，然后不同身份认证有不同的操作权限。比如我的影片列表，我可以进行添加编辑操作，其他人只能进行浏览。所以，一般要引入身份认证，如果从头自己搞登录逻辑，可能比较繁琐，一般也是独立出一个认证的微服务。 这边简单的使用Netlify Identify来进行网站的身份认证，如果你使用其他云厂商，这部分可以略过 此时需要我们先部署一个网站，你可以直接使用netlify-cli ntl init 我这边不知道是因为网络原因还是啥的，netlify-cli认证不了，所以我直接登录app.netlify操作了，部署后，可以直接在线访问， app.netlify 对应站点管理，对我们刚部署的站点启用Identify， Netlify Identify 已经集成了UI界面，所以我们要引入 netlify-identity-widget &lt;!-- include the widget --&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://identity.netlify.com/v1/netlify-identity-widget.js&quot;&gt;&lt;/script &gt; 这里，我只在src/admin.html src/login.html引入了， 这边我想要实现的效果是，用户登录才能访问src/admin页面进行添加电影的操作， 首先，我们在src/login.html 添加如下代码： &lt;div data-netlify-identity-button&gt;&lt;/div&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;https://identity.netlify.com/v1/netlify-identity-widget.js&quot; &gt;&lt;/script&gt; &lt;script&gt; function handleLogin(user) { if (!user || !user.token) { return; } // if we get here, we have an active user; redirect to the admin page! window.location.pathname = '/admin/'; } window.netlifyIdentity.on('init', handleLogin); window.netlifyIdentity.on('login', handleLogin); &lt;/script&gt; 调整src/admin.html 代码， &lt;script type=&quot;text/javascript&quot; src=&quot;https://identity.netlify.com/v1/netlify-identity-widget.js&quot; &gt;&lt;/script&gt; &lt;script&gt; function handleIdentityEvent(user) { if (user &amp;&amp; user.token) { return; } window.location.pathname = '/login/'; } netlifyIdentity.on('init', handleIdentityEvent); netlifyIdentity.on('logout', handleIdentityEvent); document.querySelector('.logout').addEventListener('click', (event) =&gt; { event.preventDefault(); netlifyIdentity.logout(); }); .... 腾讯云函数这里简单举个小例子，比如做一个返回json数据的接口，触发管理为API网关触发器，可以看到语言规范基本一致。 'use strict'; exports.main_handler = (event, context, callback) =&gt; { console.log(&quot;Hello World&quot;) console.log(event) console.log(event[&quot;non-exist&quot;]) console.log(context) callback(null, require('data/fooddata.js')) }; 跟据自己的需要选择合适的云平台，当然也有很多完善云平台使用的serverless框架， 本篇仅作为一个简单的入门demo，回调方法也不仅仅是返回JSON，也有很多OUTPUT形式，各个云平台也会跟据自己现有的服务，提供各种集成机制，感兴趣的自己自行扩展阅读。 相关链接github:serverless github:awesome-serverless Introduction to Serverless Functions gihub:frontendmasters-serverless netlify hasura","link":"/2021/09/10/of/"},{"title":"qlc解决了什么问题","text":"目前遇到的问题作为一名前端工程师，陆陆续续负责了不少项目，这些项目中，有一些是正在迭代的，其他同事同时在负责的项目，但是也有不少项目，要么就是老旧项目维护的同事已经离职或转岗了的，要么就是新项目从 0 开始的，再加上前端代码积累速度和迭代速度都比较快，其中暴露了不少问题。 我身边的大多数程序员都有一个特点，就是喜欢把具体的东西抽象化，我们通常会抽象出公共的函数或方法、公共的类或HOC，放在一起，集中在项目的某一个文件夹下，叫做 js 文件夹或 lib 文件夹（以下我们用 js 文件夹代表公共函数文件夹 ）。 这样做的确带来了很多便利，但同时也有一些隐患： js 文件夹下代码越来越多，而且大多数鹅厂小伙伴的作风是 0 文档 0 注释，这给新接手项目的同学熟悉项目带来了极大的麻烦。 不同项目都有自己的 js 文件夹，在开发一个新项目时，我们通常的做法是： 直接将原有项目的 js 文件夹拷贝到新项目中，这样在新项目中，我们也可以直接使用这些公共函数了。 将原有项目的部分 js 文件拷贝到新项目中，并且随着新项目的开发，增量拷贝。 以上两种做法，本质区别不大，前者会直接给新项目增加很多无用代码（原有项目中所谓的公共函数在新项目中并不一定会用到），而对这两种方式，如果我们要修复一个 bug，修改或升级公共代码中的一个文件，那么我们就要一个一个的，将修复好的文件拷贝到不同的项目中，如果项目多了并且已经交由不同的人维护了，这简直是一个灾难。 由于公共 js 文件夹下内容比较多，并且有的开发同学习惯以 ‘urlUtils.js’、’strUtils.js’ 这种方式来整合一些小的函数集，这样会造成函数重复的隐患（毕竟我们一个文件一行行的去分析目前的公共库已经有了哪些能力是不现实的），我观察过之前自己接手的一个不算复杂的项目（潘多拉），其仅仅是从 url 解析 query 这种功能函数，就有多达 3个(甚至更多)，分布在 js 文件夹以及 node_modules 里面，这显然是不同的维护人员由于信息不对称重复引入的。 对于怎么样才能算作“公共”函数，目前是缺乏一个 review 过程的，任何项目开发人员，几乎都可以无限制地在公共 js 文件夹下增加内容，并在之后被携带着拷贝到其他项目中，这其中有些函数，也许并不适合在这里。 问题归纳与解决实际上，总结下来，我们需要解决三个痛点： 以低成本的方式增加高可读性的文档，方便新接手项目的同学熟悉。 解决跨项目之间的公共函数复用和更新维护困难的问题。 增加必要的 review 环节，对公共函数库的必要性和代码正确性进行 review。 就第一个问题而言，其实现在的前端文档工具链已经极大降低了写文档的成本了，利用 jsdoc 或 esdoc 等文档生成工具，我们基本上已经不需要手动写文档，而是在写代码的同时写注释，就可以自动生成文档，并且配合相关的编辑器插件，一部分注释都可以自动生成。 但是目前我经历的大多数项目还是没有文档，这里可能是由于以下四个原因： 部分同学并不知道有 esdoc、jsdoc 这种比较好用的文档生成工具。 开发组中没有人去推动，文档不属于 KPI 和考核的内容，加之时间紧迭代快，缺乏前人栽树的动力。 虽然现在的文档生成工具比较简单了，但一般还是需要一定的配置，也有一点上手成本。 生成的文档不能十分满足需求，例如 esdoc 默认只能生成 html 格式的文档，在编辑器里面没法直接看。 针对第一个问题，qlc 做出了一些努力： 0 配置，全自动化生成文档，甚至集成到了其他开发流程中，命令行也不用敲。 基于 esdoc 以及开源插件二次开发，可以选择性生成 html 和 markdown 格式的文档，注重文档体验。 基于 esdoc 注释写作成本更低，更能节省时间。 跟 jsdoc 相比，esdoc 使用方式比较简单，不需要严格使用标签，而且能够支持搜索，并且官方资料更为齐全。 至此，使用 qlc 生成文档，已经非常简单了。 第二、第三个问题实际上是公共函数库的维护问题，qlc 也设计了对应的流程，着力解决该问题： 首先有一个远程公共库（基于 git）。 对于某一个项目而言，可以从远程库中下拉所需要的公共函数/类，并自动生成文档。 如果我们对某一个项目增加了一个公共函数并且认为可以为更多的项目所用，命令行上传到远程库自动触发 MR，维护人员 review 通过后即可供其他项目使用。 修复或更新某一个公共函数之后，我们只需同步到远程库，其他项目维护人员在命令行工具的辅助下同步即可。 更多到此，你是否认为 qlc 给你带来了一定的价值呢，可以到 qlc 的官方仓库查看更多的文档细节","link":"/2019/02/16/qlc%E8%A7%A3%E5%86%B3%E4%BA%86%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98/"},{"title":"每天一个小技巧","text":"关闭右键用visual studio打开&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;在桌面新建一个.txt文件，将以下内容复制粘贴进去，保存。将文件后缀名改为.reg格式，文件名称随便取。之后，双击运行。然后点击右键查看效果。 Windows Registry Editor Version 5.00 [-HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\AnyCode] [-HKEY_CLASSES_ROOT\\Directory\\shell\\AnyCode]","link":"/2020/12/26/skills/"},{"title":"使用 ssh Key","text":"什么是ssh&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;SSH为Secure Shell的缩写，由IETF的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;SSH 是较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;SSH在正确使用时可弥补网络中的漏洞。SSH客户端适用于多种平台。几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。 来自：百度百科 安装&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;首先，你需要安装git for windows。然后，不出意外的话，随意的地方，点击鼠标右键，都会有git bash here，点击，输入以下代码，确认Git安装完成， git --version git version 2.28.0.windows.1 第二行就是版本了，出现了，就说明成功了。如果没有，建议手动添加git环境变量，或者重启电脑。 配置运行bash、cmd等等，都可以，只要你能运行下列代码： cat ~/.ssh/id_rsa.pub &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;在任意文件夹运行此行代码，查看本地生成的密钥。如果有报错或者提示啥的，或者没有以ssh-rsa开头和youremail@example.com结尾的话，就说明没有生成过。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;那么，接下来，部署sshkey，并关联到Github。 git config --global user.name &quot;用户名&quot; git config --global user.email &quot;邮箱地址&quot; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;其中， “用户名”、“邮箱地址”，分别为Github的用户名、邮箱地址。 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;然后，开始生成密钥， ssh-keygen -t rsa -C &quot;上面的邮箱&quot; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;之后，无需多做什么，连按三次回车，即可。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;接下来，再次检查密钥， cat ~/.ssh/id_rsa.pub &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;如果显示的是，ssh-rsa开头的，yourmail@xx.com结尾的一大串英文。那么，恭喜你。密钥部署成功。 连接至githubssh -T git@github.com Hi ciraos! You've successfully authenticated, but GitHub does not provide shell access. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;运行第一行代码，如果出现第二行，就说明连接至GitHub成功，。这下，就可以随意下载、clone和上传了。","link":"/2021/02/04/ssh-key/"},{"title":"java知识点汇总","text":"第一个java程序public class test { public static void main(String[] args) { System.out.println(&quot;hello java&quot;); } } 注释 public class test { /* 这是一行注释 */ public static void main(String[] args) { /* * 这也是注释 */ System.out.println(&quot;666&quot;); // 这也可以是注释 } } 获取用户输入import java.util.Scanner; public class scanner { public static void main(String[] args) { System.out.println(&quot;enter two numbers:&quot;); Scanner in = new Scanner(System.in); int num = in.nextInt(); int doub = in.nextInt(); int resu = num * doub; System.out.println(&quot;result is &quot; + num + &quot;x&quot; + doub + &quot;=&quot; + resu); in.close(); } } 数据类型整数类型 数 据 类 型 内存空间（8位等于1字节） 取 值 范 围 byte 8位 -128 ~ 127 short 16位 -32768 ~ 32767 int 32位 -2147483648 ~ 2147483647 long 64位 -9223372036854775802 ~ 9223372036854775807 浮点类型 数 据 类 型 内存空间（8位等于1字节） 取 值 范 围 float 32位 1.4E-45 ~ 3.4028235E38 double 64位 4.9E-324 ~ 1.7976931348623157E308 隐式类型转换 操作数1 操作数2 转换后的 byte short char int int byte short char int long long byte short char int long float float byte short char int long float double double","link":"/2021/04/02/studyJava01/"},{"title":"turtle","text":"写在前面其实我也不知道为什么我会写这个，本文涉及信号与传递，Python 正题近期看到一个3年前的视频，1000个圆一笔画出一个Miku在观看完源码了以后，我发现这是这调用的是基本的goto,用了傅里叶级函数（傅里叶级变化），那个视频中给出了分析，只要圆足够多，就可以画出任意的封闭曲线 $f(x)=\\frac{a_{0}}{2}+\\sum\\limits_{n=1}^{\\infty}\\left(a_{n}\\cos{nx}+b_{n}\\sin{nx}\\right)$任意满足狄利克雷条件的函数，其本身的傅里叶级数都是收敛的。也就是说，函数可以表示成无限个正弦函数和余弦函数和的形式。假如说我我能把我们需要绘制的二维图像表现在复平面上，把它的轨迹表现成有关时间t的复函数，那么，横坐标的移动和纵坐标的移动都可以看作是关于时间t的函数。$f(x)=\\frac{a_{0}}{2}+\\sum\\limits_{n=1}^{\\infty}\\left(a_{n}\\cos{nx}+b_{n}\\sin{nx}\\right)$ $g(x)=\\frac{c_{0}}{2}+\\sum\\limits_{n=1}^{\\infty}\\left(c_{n}\\cos{nx}+d_{n}\\sin{nx}\\right)$ 以上的两个函数都是实函数,都可以展开成傅里叶级数 展开的公式太难写了，所以就截图了。然后，我们对二维图像的轨迹稍加处理,发现这也是个傅里叶级展开式，只不过前面的系数变成了复数。这样子的解释不是证明，但是在傅里叶级变换的复数表示里，正弦函数都是可以通过余弦函数增加一个初始相位来表示，实函数的傅立叶变换才是傅立叶变换的特殊形式，这里不解释。 $c_n=\\int_{0}^{1}{e^{-2i\\pi nt}f(t)dt}$我们求得这些级数了以后，只需要把系数代回这个公式得到一个坐标这时，就可以用turtle的goto函数移动到指定的坐标，达到绘制图形的目的 值得思考的同时函数的傅立叶变换相同，我们计算的级数越多，结果我们越接近我们原本绘制的轨迹，不联系的函数也可以进行傅里叶变换，配合turtle的penup和pendown函数，我们就可以得到断断续续线，绘制过程中的精度也不是越大越好，最佳精度和我们上面分析的级数有关系。 操作在Adobe illustrator里面设计好自己的图案 图案要一笔带过，中间的线条可以重叠，可以急转弯，但是一定是一笔 然后保存为SVG。 在SVG文件中 把路径复制， &lt;path class=&quot;st0&quot; d='............' /&gt; 把省略号中的复制,就是那一大串数字和字母的组合。保存到ra开头的txt文件中，源码在下面源码接下来的，自己琢磨吧… 彩蛋# 画个绿色的长虫 import turtle as t def drawSnake(radius, angle, length): t.seth(-40) for i in range(length): t.circle(radius, angle) t.circle(-radius, angle) t.circle(radius, angle/2) t.fd(40) t.circle(16, 180) t.fd(40*2/3) t.setup(650, 350, 200, 200) t.penup() t.fd(-250) t.pendown() t.pensize(25) t.pencolor('green') drawSnake(40, 80, 4) t.down()","link":"/2021/01/29/turtle/"},{"title":"Vue.JS基础的详讲( 安装 )","text":"Vue.JS Vue是个啥？ Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。 说简单点就是Vue是一套用于构建用户界面(模板引擎)的渐进式）框架 渐进式 Vue2.0 中，“渐进式框架”和“自底向上增量开发的设计”这两个概念是什么？我理解的“渐进式框架”也非常简单，就是用你想用或者能用的功能特性，你不想用的部分功能可以先不用。VUE不强求你一次性接受并使用它的全部功能特性。场景一：公司刚开始一个项目，技术人员对Vue的掌握也不足够。那么我们就不能使用VUE了么？当然不是，如果你只是使用VUE做些基础操作，如：页面渲染、表单处理提交功能，那还是非常简单的，成熟技术人员上手也就一两天。完全可以用它去代替jquery。并不需要你去引入其他复杂特性功能。场景二：我们项目用了VUE，使用的效果也挺好。那么我们想逐渐实现代码组件化，实现代码的复用，或者是基于组件原型的跨项目的代码复用。那么我们就可以引入VUE的components组件特性了。场景三：我们的项目规模逐渐的变大了，我们可能会逐渐用到前端路由、状态集中管理、并最终实现一个高度工程化的前端项目。这些功能特性我们可以逐步引入，当然不用也可以。所以VUE的适用面很广，你可以用它代替老项目中的JQuery。也可以在新项目启动初期，有限的使用VUE的功能特性，从而降低上手的成本。MVVM响应式编程模型，避免直接操作DOM , 降低DOM操作的复杂性。 MVVM：页面输入改变数据，数据改变影响页面数据展示与渲染 M（model）：普通的javascript数据对象 V（view）：前端展示页面 VM（ViewModel）：用于双向绑定数据与页面，对于我们的课程来说，就是vue的实例 VUE核心功能 声明式渲染：页面渲染、表单处理提交、帮我们管理DOM(虚拟DOM)节点 组件：组件化开发：增强代码的复用能力，复杂系统代码维护更简单 前端路由：更流畅的的用户体验、灵活的在页面切换已渲染组件的显示，不需与后端做多余的交互状态集中管理：MVVM响应式模型基础上实现多组件之间的状态数据同步与管理前端工程化：结合webpack等前端打包工具，管理多种静态资源，代码，测试，发布等，整合前端大型项目。 引入(安装)兼容性Vue 不支持 IE8 及以下版本，因为 Vue 使用了 IE8 无法模拟的 ECMAScript 5 特性。但它支持所有兼容 ECMAScript 5 的浏览器。 语义化版本控制Vue 在其所有项目中公布的功能和行为都遵循语义化版本控制。对于未公布的或内部暴露的行为，其变更会描述在发布说明中。 官网日志最新稳定版本：2.6.12每个版本的更新日志见 GitHub。 Script引入首先，我们还是用JS引入 Vue &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; 欲知后事如何，且听下回分解","link":"/2021/04/26/vue-1/"},{"title":"Vue.JS基础的详讲( 组件 )","text":"组件 Vue的组件是Vue.JS里最难掌握的，当然也是最有趣，精彩的。 基本分类为 根组件 可复用的功能组件 根组件的创建通过 vue 提供的构造函数可以实例化出来一个跟组件实例对象 let app = new Vue(创建组件所需要的一些配置选项); // [根组件] [vue组件，配置（声明式）构建方式React组件，命令式] // 对于React // render函数:确定组件的视图 class MyComponent extends React.Component{ } ReactDOM.render( &lt;MyComponent&gt;, document.querySelector('#app') ); // 对于Vue let app = new Vue({ el:'#app',//挂载点 template:` &lt;div&gt;这是vue&lt;/div&gt; ` //最后组件产生的视图覆盖掉挂载点 }) 如果不写el挂载点，只有模板。使用app对象.$mount('#app'); // 手动挂载 可复用的功能组件通过 Vue 提供的静态方法 component 窗口可复用的功能组件 let component1 = Vue.component(创建组件所需要的一些配置选项) 注意事项:[React中区分原生元素和自定义组件，原生：div(小写)，自定义组件Div(首字母必须大写)Vue中，必须小写。Vue：注册时：驼峰MyComponent。使用：my-component。Vue在遇到的时候也会自动解析成驼峰式的MyComponent去在注册的组件中寻找。] &lt;body&gt; &lt;div id=&quot;app&quot;&gt; &lt;h1&gt;这是vue&lt;/h1&gt; &lt;hr /&gt; &lt;my-component&gt;&lt;/my-component&gt; &lt;my-component&gt;&lt;/my-component&gt; &lt;!--注意转换规则:驼峰变串--&gt; &lt;/div&gt; &lt;script src=&quot;js/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; Vue.component('MyComponent', {//注意转换规则:驼峰变串 template: ` &lt;div&gt;MyComponent&lt;/div&gt; ` }); let app = new Vue({ el: '#app' }); &lt;/script&gt; &lt;/body&gt; 组件配置选项：https://cn.vuejs.org/v2/api/ 组件内容渲染渲染一个组件的内容可以通过两种方式来进行 template 选项 render 选项（函数） templatetype : string 组件的模板结构（HTML），模板内容会被 vue 进行渲染，生成最终的 HTML 内容，并替换占位（挂载）元素 eltype : string | Element 提供一个在页面上已存在的 DOM 元素作为 Vue 实例的挂载目标。可以是 CSS 选择器，也可以是一个 HTMLElement 实例， 该选择只对 new 创建的实例有效如果提供 el ，但是没有提供 template ，则 el 的内容讲作为 template rendertype : (createElement: () =&gt; VNode) =&gt; VNode 发挥 JavaScript 最大的编程能力，直接创建 VNode （虚拟dom对象），优先级高于 el 和 template https://cn.vuejs.org/v2/guide/render-function.html /** * vue: template -&gt; vNode -&gt; HTML * react: JSX -&gt; VDOM -&gt; HTML */ let app = new Vue({ el: '#app', // 挂载点不能是html、body元素 template: `&lt;div&gt;开课吧&lt;/div&gt;`, render(createElement) { // render优先级高于其他视图处理 // return `&lt;div&gt;开课吧&lt;/div&gt;`; let vNode = createElement( 'div', '开课吧123' ); // console.log(vNode); /** * vNode 类似原生中的 元素对象 */ // let div = document.createElement('div'); // let text = document.createTextNode('开课吧'); // div.appendChild(text); // console.dir(div); return vNode; } }); 使用 $mount 方法延迟 Vue 实例的挂载当 Vue 实例没有 el 选项的时候，它会处于一种 未挂载 的状态，我们可以通过组件 Vue 实例对象的 $mount 方法来手动挂载，通过该方式，我们也可以达到延迟 Vue 实例的挂载的目的 渲染的3个注意事项 /** * // 挂载点不能是html、body元素 */ let app = new Vue({ el: 'body', template: `&lt;div&gt;开课吧&lt;/div&gt;` }); /** * 每一个组件有且只能有一个顶级元素 */ let app = new Vue({ el: '#app', template: `&lt;div&gt;开课吧&lt;/div&gt;&lt;div&gt;开课吧&lt;/div&gt;` }); /** * 如果一个组件没有template也没有render，那么el（挂载点）的outerHTML就作为模板 */ let app = new Vue({ el: '#app' }); 组件中的数据（状态）data组件内部使用的数据，data 是一个对象，data 中的值可以中模板中直接访问 Vue 实例组件（根组件）的 data 是一个对象可复用功能组件的 data 必须是一个函数，且该函数必须返回一个对象（因为复用性，避免多个组件实例引用同一个对象。换句话说，组件中使用的数据必须是一个对象，但是可复用组件的这个数据对象必须通过函数返回 data 的访问data 数据可以直接通过组件实例对象访问，也可以通过实例对象下的 $data 属性进行访问 组件实例对象下有很多的以 $ 开头的属性，这些都是实例对象内置的一些属性和方法，vue 为了区分数据与内置属性方法，内置的属性和方法默认都是以 $ 开始的，所以我们中数据中应该避免使用 $ 开头的数据 模板语法vue 使用了基于 html 的模板语法，使用声明式的方式把实例中的数据（data）与 DOM 进行绑定，data 中的数据在模板中可以直接使用","link":"/2021/04/27/vue-2/"},{"title":"web跨端融合方案浅析","text":"本文会对目前流行的基于 JavaScript 的 web 跨端融合方案进行总结和分析，目标人群为 web 方向的从业者但是对跨端融合方案了解不多的人。 web 跨端融合简介在 2015 年 React Native 发布之前，web 在移动端 APP 上主要通过 WebView 进行承载，其有许多优点，可以快速迭代发布，不特别受 APP 版本的影响，因此，一些快速发展的业务（包括前期的手机QQ、手机淘宝）大量采用了 WebView 内嵌 H5 页面的形式来推动业务。 但是这种方式缺点也比较明显，主要体现在以下两点： 加载时间较长，包括 WebView 初始化的时间、网络请求的时间。 HTML 页面在性能上天然不如 Native 页面，无论怎么进行性能优化。 在 2015 年，Facebook 推出了 React Native，从而打开了 web 跨端融合的大门，后续在此架构基础上又出现了阿里巴巴的 Weex（2016）、腾讯的小程序（小程序实际上更偏 web 一点，和其他几类稍有不同，本文不作介绍）、 Hippy（2018）、Taro（Taro 其实更偏向解释翻译，和其他几类定位不同）等跨端融合解决方案，并且渐渐被用到越来越多的项目中，目前，跨端融合开发已经是一种比较主流的 web 开发模式，在阿里系应用、腾讯的微信、QQ浏览器、手机QQ均已经进行了大规模应用。 基本架构虽然 web 跨端融合方案众多，除了上述提到的三种，还有各个公司的更多方案，但是一般来说跨端融合的技术架构都比较相近，我们可以通过下面这一个图来简单概括： 接下来，我们逐个进行简析： 业务代码：即我们写的 React Native 代码、Weex 代码，一般来说，我们的业务代码需要经过框架工具或者打包工具（例如 webpack 配合 loader）进行打包，从而兼容一些 ES Next 的写法以及一些框架本身不支持的 Web 写法。 Javascript FrameWork：这部分主要是针对 Weex、Hippy 来讲的，Weex 声称支持 Vue、Rax 语法，而 Hippy 声称支持 React、Vue 写法，实际上，对于这些库而言，并不是直接将 React、Vue 引入到项目中，而是会对其源代码进行修改（Vue 有针对 Weex 平台的版本），而 Hippy 也是对 React 源代码进行了修改，例如，你写的一个createElement的操作，在 Web 平台中实际调用的是 document.createElement(tagName) 这个接口；而在 Weex 平台中实际执行的是 new renderer.Element(tagName)（renderer 由 Javascript Runtime 提供，并且最终和 Native 通信渲染上屏）。 Javascript Runtime：Runtime 的部分，主要是对外暴露了一些统一的接口，比如说节点的增删改查、网络请求的接口等，而这些借口，实际上是其“代理”的客户端的能力，通过客户端 JSAPI 的方式进行调用。另外，把 Runtime 和 FrameWork 进行抽离，也可以便于一个跨端方案适配多个框架，只需要将不同的 FrameWork 和浏览器交互的部分代码转换成 Runtime 提供的标准接口，就可以实现对不同框架的支持。 Core：这部分主要是对 Javascript 的解释执行，在 iOS 上一般是 JSCore（系统自带，给客户端提供了执行 JavaScript 程序的能力），而安卓上则可以采用 V8、X5 等。 最下层则是分 Android 和 iOS 端去进行渲染。 发展现状实际上，React Native 最初提出这种解决方案的时候，市面上并没有同类的产品，但是由于 React Native 的一些问题和其他原因，各个大公司基本都在实现自己的跨端融合方案，这里 React Native 的问题主要体现在： 最主要的是协议风险。 React Native 打包出来的 JSBundle 较大，并且默认没有灵活的分包机制，需要自行解决相关问题。 在部分组件比如 List 组件中，性能较差（据非官方说法，性能并不是 React Native 团队首要考察因素，但是国内团队一般都比较重视性能）。 部分事件发送频繁导致性能损失、例如列表滚动事件、手势事件等。 双端 API 大量没有对齐（这也和其 slogan 是‘learn once, write everywhere’ 而不是 ‘write once, run everywhere’ 相对应）。 而对于国内的 Weex 和 Hippy 框架，其都做了大量的性能优化解决了上述问题，并且规避了协议风险（Weex 采用了 Apache 2.0 协议，而 Hippy 即将开源）。 另外值得一提的是，Weex 和 Hippy 都可以在 web 端进行运行，一般可以作为降级方案使用，从而真正做到了“一份代码”，三端运行。 性能优化实际上，采用目前的跨端融合方案的体验已经比采用 WebView 的方案强太多了，但是性能优化是没有止境的，随着页面复杂度的提高以及用户体验的要求，实际上目前这类跨端融合方案采用了以下几个方向的性能和用户体验优化： 减少网络请求在我们上述提供的架构图中，一般而言对于一个这类页面，业务代码是通过网络请求加载的，这个时候在加载上主要省去的是 WebView 的初始化时间，这其实是不够的，所以我们也可以采用将业务代码提前下发并存在用户本地，打开的时候只需要从本地拉取并执行代码，这样可以减少相关的网络请求阻塞，优化加载时间。 另外，减少网络请求还体现在对资源的缓存上，对一个页面中所采用的图片等资源文件进行 LRU 策略的缓存，从而防止重复的请求（在传统的 WebView 的方案上，也可以采用对 WebView 增加 Hook 的方式实现）。 当然，以上两点在 WebView 的方案上也可以采用。 降低通信成本我们从上文的架构图中可以看出，这里的层级实际上比较多，如果不同层级的通信数据较多，并且有比较频繁甚至重复的编解码操作，肯定会有很大的开销，从而影响性能，所以，在不同层级之间做好数据的传递，并且防止重复的编解码操作是比较重要的。 这里可以优化的细节其实比较多，我们举一个 Hippy 的例子： 在 Hippy 架构中，jsRuntime 会生成一个 jsObject 对象树（即需要渲染的 DOM 信息），其在经过 JSBridge 时需要通过JSON.stringify 进行序列化，而在 Java（andriod) 接收端，则需要先将其变成一个 JsonObject，最终转化成 HippyMap，这里实际上是有重复的编解码操作的，我们看看 Hippy 的优化策略： 图片来自 IMWeb 2018 通过 hippybuffer 的方式减少通信的数据量，并且防止重复的编解码操作，可以有效提高性能。 减少通信次数为了减少在通信方面的消耗，我们除了降低通信的成本，还可以做的就是减少通信次数，当然，前提是不影响用户体验。 这方面可以减少的通信消耗，其中一个方面是频繁的事件通信，我们知道，事件的触发是在 native 端的，但是事件处理的逻辑代码实际上是在 js 层来完成的，在这方面的通信，React Native 就因为频繁的通信从而影响了性能。 我们可以优化的地方在于，首先减少没有绑定回调函数的事件通信，一般而言这部分通信是不必要的，其次是多次通信可以进行合并，比如说 list 滚动回调函数、以及动画通信，我们可以通过配置驱动代替数据驱动的方式（即一次向客户端传递整个配置，后续相同事件可以直接在客户端进行处理），来减少通信次数。 这方面 Hippy 和 Weex 都有大量细碎的实践，在此便不具体介绍了。 降低首屏时间在原来的 WebView 页面中，我们为了增强用户体验，防止用户进来之后看到白屏，可以采用服务端渲染的方式，将渲染好的页面返回给客户端，同时优化了首屏请求，也防止了客户端设备较差造成JS执行时间较长的情况。 在跨端融合方案中我们仍然有类似的解决方案，在不考虑离线包的情况下（即只考虑业务代码从远程加载的情况），我们也可以由服务端渲染好再返回，Weex 便采用了类似的方案，不过其做的更加彻底，在服务端将代码结果编译成 AST 树并转化成字节码（OPcode），在客户端解析后直接生成虚拟 DOM： 图片来自 IMWeb 2018 客户端级别的其他优化客户端的优化有一部分是本来客户端开发就会面临的内容，也有一部分是和混合方案有关的优化，比如 Flex Render 的优化，不过这方面的内容一般而言和前端关系不是非常密切，笔者作为初级前端工程师，对这方面的内容还并不熟悉。 框架选型本文的最后一部分，介绍框架选型。 对于各类跨端融合的方案，其相对于 WebView 都有非常大的性能提升，因此在前期，无论选择什么框架都能够看到成效，这里也并不进行特定的框架选型推荐，但是一般认为，如果是从 Vue 的项目切换，Weex 会更合适一点，而如果从 React 项目切换，在确保没有证书风险的情况下可以采用 React Native，否则可以尝试原生支持 React 的 Hippy。 以上。","link":"/2018/12/04/web%E8%B7%A8%E7%AB%AF%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88%E6%B5%85%E6%9E%90/"},{"title":"web应用开发与部署","text":"本文基于笔者在腾讯的项目经验，从真实场景出发分析一个中型 Web 应用从立项到上线稳定运行的平稳解决方案，力求既不太空泛以至于看完了仍然找不到落地的点，也尽量不会特别纠结于个别细节导致没有相关使用经历的同学无法感同身受，而是从宏观到方法论，分析整个流程中我们需要用到的工具、方法与规范，给大家提供一个参考。 本文适合具有一定经验的初中级前端开发者，如果有相关问题，也欢迎与我交流。 目录 项目构建的搭建，关键词：webpack、react/vue cli，steamer，组件库 代码的规范约束，关键词：typescript、eslint、prettier 测试与测试部署，关键词：测试部署方案、docker 日志查看与脚本错误的监控，关键词：sentry、vconsole、mlogger 版本发布更新，关键词：发布系统、灰度发布 访问量实时监控 起步：项目构建的搭建使用 webpack 搭建脚手架目前在一般的项目中，我们都会使用 webpack 作为搭建开发环境的基础，而 react 和 vue 也各自提供了 cli 工具用于开发一个中小型项目，react 提供了 eject 功能让我们可以更加自由的配置 webpack，而 vue 脚手架虽然没有提供类似命令，但是借助 webpack 工具链我们几乎也可以自由定制每一个角落。 不过，这里我的建议是，如果是个人项目或小型项目，我们可以基于 react 或 vue 的脚手架进行更改使用，对于一个具备一定规模的项目团队，建议还是自己维护一套单独的 webpack 构建环境，原因如下： 由于我们一般需要在项目中接入各类司内工具、支持高级API和语法、同时支持 react/vue、构建目录定制化等各类工作，实际上 80% 以上的工作我们都需要在模版之上自行添加，这个时候我们再用脚手架带来的收益已经非常小了，反而还会受制于项目的初始目录结构。 我们在自定义脚手架的 webpack 构建的时候，也需要梳理出一定的目录规范与约束，这样也有利于提高后期脚手架的可维护性和扩展性，一般来说，我们也要对脚手架中的公共部分和项目私有部分进行分离，对于一个具体项目而言，可以不用改动 webpack 的项目公共部分，这样也有利于减少不同项目之间的切换成本，对于我们目前的项目，一般会有如下两个目录： - project - project.js - config - feature - plugins - rules - script.js - webpack.base.js 对于一个项目，只需更改 project 下的配置。 这里我也推荐一个前同事做的steamer研发体系，在从中也可以找到很多相关参考，最简单的方式，就是直接在steamer-simple 的基础上进行扩展。 定制生成目录生成目录的格式，这里需要单独讲一下。 一般来说，我们生成目录的格式都是要跟发布系统进行结合的，不过也有的时候，我们做项目的时候还没有明确要接入发布系统，或者尚不知道发布系统的格式要求，但是一般情况下我们应当遵循下面的约定： js/css/img 等资源文件和 html 文件分离，前者发布到 CDN，后者发布到 http 服务器。 html 中引入的文件地址，应当是在构建过程中更新的 CDN 地址，而不是相对路径地址。 如果有离线包（offline 能力需要对应的客户端 webview 支持）等，需要单独一个目录。 对于我们目前的项目而言，一般情况下会有三个生成目录： - cdn - offline # 需要客户端支持该能力 - webserver 如果一开始我们把所有内容生成到一个目录中了，这给我们后期的改动和维护，都带来很大的隐患。 组件库组件库这一部分，适合项目开始变得复杂的情况下进行启动，而不建议一开始进行过渡设计，建设组件库能够通过组件复用降低我们的开发成本，同时，组件库也需要专人维护，保持更新。 开发：代码的规范约束对于 js 文件的代码格式，诸如要不要分号、两个还是四个字符缩进等，一只争议不断，本文也不对此进行讨论，但是对于一个团队的项目集合（而不是单个项目）而言，代码风格的统一，是一个非常有必要而且必须要做的事情。 typescript关于 typescript 的相关文章实在太多了，这里也不对此进行详细的说明，其对代码的可读性、规范约束、降低报错风险等都有很好的改进，对于越复杂的项目其效果越明显。 另外， typescript 入门教程的作者也在我们团队中，这里我想说，如果现在还没有开始使用 typescript，请开始学习并使用 typescript 吧。 eslint 与 prettier除了 typescript 以外，在代码格式方面还建议使用 eslint 和 prettier 来进行代码格式的约束，这里虽然 eslint 和 prettier 两者在某些情景下会有些重叠，但是两者的侧重点不同，eslint 侧重于代码质量的检查并且给出提示，在某种层面上，可以看作是 typescript 的补充，而 prettier 在格式化代码方面更具有优势，并且 prettier 在设计之初就考虑了和 eslint 的集成，所以你可以完全放心的在项目中使用两者，而不用担心出现无法解决的冲突。 另外，eslint 社区中已经形成了很多种最佳实践，而我们团队也设计出了自己的一套 eslint 规则，可以按需取用 p.s. 目前 tslint 后续计划不在维护，转向 eslint 增强，因此我们在项目中可以不再使用 tslint。 以上这几种代码风格方面的约束，适合项目之初即开始约束，这样在中后期会有巨大的时间成本的节省和效率的提升。 协作：使用 git使用 git 进行协作这里其实包括两个点，使用 git 管理项目与自建 gitlab，后者是一个比较基础性的工作，并且实际上难度并不大，我认为每一个公司都可以使用自建的 gitlab 进行版本管理，这个实际上难度并不大，并且可以有效的保护公司的代码财产，如果你所在的公司还没有，那么这也是你的机会。 在具体的使用 git 中，对于git的分支/TAG管理、PR规范、提交文件约束等都应当有一套合理的流程，这里我对几点比较重要的进行说明： 锁定主干与分支开发，我们在日常开发中禁止直接提交主干，而是只能在分支中进行开发，并且通过 MR 的方式提交到主干。 git hooks 检查：我们应该通过 git hooks 进行必要的检查，比如自动化测试、eslint 检查、以及一些项目中必要的检查。 MR 检查与 Code Review，这里建议在 Merge Request 的时候做两件事情，一件是 Code Review，不过这个在某些特殊情况下不具备条件，尤其是团队人力紧张的时候，另外一个则是 MR 的 HOOK 触发检查，这个一般需要借助一些持续集成工具来完成，可以说是我们代码在合并主干之前的最后一个关卡。 测试：测试与测试部署测试是代码开发中重要的一个环节，但实际上对于前端开发来说，前端开发工程师一般较少书写测试用例，也并没有专业的测试开发工程师来辅助工作，不过，一般会有配备系统测试工程师在黑盒的情况下进行冒烟测试和功能测试以及整体链路的验收，俗称“点点点”。而这个时候，前端开发要做的就是把程序代码部署到测试服务器上，同时提供一个尽可能真实的场景供测试进行测试。 在笔者经历的项目中，虽然也使用了单元测试、端对端测试，不过这一部分体系并不十分完备，并且可能也不是大多数前端开发者感兴趣的内容，所以这里主要总结如何进行高效的测试部署与发布对接。 一般来说，我们一般会有一台到多台 Linux 测试机，供测试环境部署使用，对于前端项目而言，一般不需要特殊环境，可以进行 webpack 构建以及有 nginx 进行转发即可。 而测试环境的部署，如果是让我们手动登录去部署，显然是不合理的，如果我们纯粹使用 CI 来完成这件事，则对 CI 工具的能力和项目人员素质有一定要求，并且不具备可视化管理能力，容易出错，这里我建议可以维护一个可视化系统来进行测试环境的部署和管理，其整个环节应该是这样的： 本地代码 -&gt; gitlab -&gt; 测试系统部署 -&gt; 对接发布系统 这里的测试系统，实际上是从 gitlab 拉取代码，并且本地执行 build 命令（一般是 npm run build）并把构建结果存储在 nginx 可代理的目录即可，出于系统完备性考虑，一般我们会有多台测试机，这里我建议一般拿其中的一台作为构建机，其他的测试机仅提供 nginx 代理能力即可，我们在一台构建机中进行构建，并且将构建结果通过系统命令发送到其他的测试机。 一台构建机可以服务于所有的项目，这里还可能涉及到 webpack、nodejs 版本的维护，我们需要约束各个测试项目构建处在一个相对独立的环境中，我们也可以使用过 Docker 来进行构建，保证隔离。 构建完成后，一般我们借助 Fiddler、Charles、Whistle 等任意一款代理工具，即可以进行测试。 监控：日志查看与脚本错误的监控对于前端项目而言，即使我们已经使用了 typescript、eslint 并且也有了一些测试脚本和系统测试工程师进行的功能测试，我们还是免不了会出现 js 脚本错误，特别是 js 代码的运行环境和设备的多样化，很多错误我们并没有发现，但是产品、运营同学却出现了，或者到了线上在用户设备上出现了。 所以，有两个事情我们必须要做： 日志查看功能（手机端）：现在我们写的大多数 TO C 页面都是在手机端进行，查看 console 非常不方便，我们需要一个线上实时查看 console 的工具。 我们需要脚本错误日志统计系统来进行错误统计管理与具体错误查看。 对于第一个功能，进行细分，我们需要做这样几件事情： 嵌入一个 console 和 网络请求查看器，并且只在特殊情况下才能触发（比如连续点击标题十次、或者使用特定交互手势） 在触发查看器的时候，可以将日志完整地进行上传并分析。 同时可以对该用户进行染色，会自动上传并记录该用户一定时间内后续刷新后操作的全部日志。 不过这里并没有完全实现以上三点的开源库推荐，可以在 vconsole 或者 mlogger 的基础上进行适当扩展，完成相关功能。 对于第二个功能，我们需要一个完整的统计分析与管理的错误系统，这个如果自行开发的话，难度会比较大，这里强烈推荐 sentry，可以非常方便的使用 Docker 部署到服务器端，并且拥有非常强大的日志错误分析与处理能力，通过结合 JavaScript 的 sourcemap ，可以给我们的错误定位带来极大的方便。 总之，日志查看与脚本错误监控，是比较重要但是同时容易被忽视的地方，很多时候，我们的系统在线上使用了几个月了，真正有问题反馈了，我们才会考虑加上这些功能，但这个时候通常已经造成了损失。 发布：版本发布更新发布系统，一般作为前端最后环节的系统，通常会和测试部署系统打通（或合二为一），一般的发布系统的必要功能如下： 对于前端的发布，每次只发布有改变的文件，无变动的文件则无需发布。 每次发布先发布 js/css/img 等资源文件，生效之后再发布 html 文件。 发布系统保留线上旧版代码，出问题后可以快速一键回滚。 至于一些其他的日志、报表等辅助性功能，则根据需要满足，这里不再赘述。 灰度发布灰度发布是大型项目在发布时的常见方法，指在发布版本时，初始情况下，只允许小比例（比如1-5%比例的用户使用），若出现问题时，可以快速回滚使用老版本，适用于主链路和访问量较大的页面。 对于前端的灰度，实际上有以下几种方案： 在代码层面进行灰度，即通过 if/else 进行判断，这样无需发布系统关注，也可以自由配置规则、比例与白名单/黑名单。 在入口层面进行灰度，比如 App 内嵌的 H5 则在客户端的对应入口进行回复，这样通常也无需发布系统关注。 通过发布系统，按照比例灰度，比如我们有 10 台 webserver，如果我们先发布 1 台，这样我们的灰度比例为 10%。 访问量实时监控最后一点，我们还需要一个访问量实时监控系统，我们上述有了错误查看与脚本监控系统，但是对于我们的各个页面的访问量、点击率等指标，通常是产品/运营同学比较关心的，同时访问量的波动情况也是项目健康度的一个表征（访问量突然大幅上涨或下跌，一般都有其特定原因），所以我们需要访问量实时监控系统。 而实际上访问量监控系统也有两种不同形态： 对于每一个上报 key，只进行数量上的统计 对于每一个上报 key，可以携带一些信息，对携带信息进行统计分析。 通常情况下，前者的功能是实时或者低延时的，而后者由于需要一部分统计分析，通常可以接受非实时情况（一般每天出前一天的报表）。 这部分内容，需要较强的后端接口稳定性，通常前端需要和对应岗位的同学共建。 总结总结下来，我们一个稳定的前端项目，至少涉及到以下环节： 完善的项目脚手架与代码约束规范 内部 gitlab 可视化管理的测试部署系统 实时日志查看工具 脚本错误统计管理系统 发布管理系统 访问量实时监控系统 如果你所在的团队哪个环节还没有或者不完善，那么这也是你的机会。","link":"/2019/06/16/web%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B8%8E%E9%83%A8%E7%BD%B2%E2%80%94%E2%80%94%E4%BD%A0%E5%BF%85%E9%A1%BB%E6%8E%8C%E6%8F%A1%E7%9A%84%E5%86%85%E5%AE%B9/"},{"title":"关于windows11的0x800f0950语言包安装失败","text":"最近windows11的风头很热，作为爱折腾的人，当然要去搞一搞啦。搞好了以后我发现中文语言的拓展包是无法安装的，于是我找到了3个办法，当然如果想100%成功的话我建议直接跳到第三个，如果你不嫌累，指望1和2可以成功的话，那么你可以试试，万一就成功了呢。[狗头] 安装windows11 最近Windows11的ISO镜像文件泄露了出来，本着爱折腾的性子，还是选择在不会大翻车的情况下第一时间上车了。之前微软就已经曝出自己不会在出新的系统。但是当时说出这句话的微软员工已经被辞退了。那么最近泄露出来的win11究竟是官方为了蹭一波操作系统的热度而故意为之的呢。这里解释下为什么这么说，可能最近鸿蒙的势头正盛，所以微软在这时候故意泄露win11的ISO其目的究竟是为了win11正式发布会预热还是震慑PC操作系统的使用者们的呢。言归正传。 ISO: 版本名称：Windows 11 消费者版 (含家庭版/专业版/专业工作站/家庭单语言版) 文件名称：21996.1.210529-1541.co_release_CLIENT_CONSUMER_x64FRE_en-us.iso 系统语言：美国-英语 (en-us) 安装后可安装简体中文 文件大小：4.76GB 发布时间：2021-06-15 / 泄露时间非编译时间非微软发布时间 SHA-1值：3B6DA9194BA303AC7DBBF2E521716C809500919C 从天翼云网盘下载：https://cloud.189.cn/web/share?code=InQ3637BvEbu 从MEGA网盘下载：https://mega.nz/file/wXxi0aYK#URAP1qSJ-HM2A5qNQTZeyqVTEMopn-3qQycX136HW94 转至泰戈尔 补充链接:迅雷磁力链: magnet:?xt=urn:btih:DD5BCB82E3637B62C11333DEC9BD32A25D6FE7FD&amp;dn=22000.51.210617-2050.CO_RELEASE_SVC_PROD2_CLIENTMULTICOMBINED_UUP_X64FRE_ZH-CN.ISO&amp;xl=5727295488 PS:安装时可能会要什么tpm2.0，绕过教程 话又说回来了可能安装完windows11后，全部显示为英文，先安装中文的语言包。操作如下:微标 → Setting → Time and languages → languages → Add a Language → 输入chinese，选择中华人民共和国安装完了以后，windows11的界面已经变成中文，这还不算完，重复以上步骤，看到有中文和English，对比右侧图标你会发现中文的只有个显示字，点一下，选择选项，安装其他的拓展包。 然后你会发现安装不了，显示一串代码为0x800f0950 办法办法一 更改注册表，键盘上的微标 + R，输入regedit，打开注册表，定位到HLEY_LOCAL_MACHINE/SOFTWARE/Policies/Microsoft/Windows Defender 注意了，这里的定位只是到Windows Defender不要再往下！！！ 右键，选择新建，新建名为DisableAntiSpyware的项，把属性0更改为1，在右侧显示0x0000001，保存完后重启既可以关闭Windows自带的防火墙功能，或者你可以手动关闭，但是windows11似乎无法关闭防火墙，因为有个Windows Defender，还是把教程写出来。 办法二(手动关闭windows11的防火墙) 键盘上的微标 + Q打开windows自带的搜索功能，输入控制面板，点击打开。 在右上角选择Windows Defender和防火墙，就是那个有个地球和墙的图标，选择左手蓝色链接的第二项，把两个都改成关闭。 重启 去到时间和语言选项，安装中文语言拓展包。 如果还是失败请看以下教程。 最终教程 下载并解压所要用到的压缩包，推荐解压软件:BandZip/winRaR字体：https://www.jianguoyun.com/p/DV2oPU0QgsXTCRi-2P8D 密码：30113Dism++: https://www.jianguoyun.com/p/DZb2BF8QgsXTCRjR2P8D 密码：30113安装完中文包后食用。 打开Dism++64/86，选择右边栏常用工具栏的工具箱，在里面选择文件浏览器，选择解压好的windows字体包，不要改文件夹名！ 复制到C盘或者其他什么盘（你安装windows11的盘）显示文件名重复请直接替换。 重启看效果，先试试Windows自带输入法，可以用就差不多了。 如果要转载，请注明地址。原作者: 301.QQ: 325454747","link":"/2021/07/10/windows11/"},{"title":"Vue.JS基础的详讲( MVVN )","text":"一 vue.js的M-V-VM思想MVVM 是Model-View-ViewModel 的缩写，它是一种基于前端开发的架构模式。 1. Model指代的就是vue对象的data属性里面的数据。这里的数据要显示到页面中。 2. View指代的就是vue中数据要显示的HTML页面，在vue中，也称之为“视图模板” 。 3. ViewModel指代的是vue.js中我们编写代码时的vm对象了，它是vue.js的核心， &gt; 负责连接 View 和 Model，保证视图和数据的一致性，所以前面代码中，data里面的数据被显示中p标签中就是vm对象自动完成的。 二.大致的用法&lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;js/vue.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; window.onload = function(){ // 创建vm对象 var vm = new Vue({ el: &quot;#app&quot;, data: { name:&quot;大标题&quot;, age:16, }, }) } &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;app&quot;&gt; &lt;!-- 在双标签中显示数据要通过{{ }}来完成 --&gt; &lt;h1&gt;{{name}}&lt;/h1&gt; &lt;p&gt;{{age}}&lt;/p&gt; &lt;!-- 在表单输入框中显示数据要使用v-model来完成 --&gt; &lt;input type=&quot;text&quot; v-model=&quot;name&quot;&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 如果要输出data里面的数据作为普通标签的内容，需要使用{{ }} 使用v-model把data里面的数据显示到表单元素以后，一旦用户修改表单元素的值 则data里面对应数据的值也会随之发生改变，甚至，页面中凡是使用了这个数据都会发生变化。 双花括号仅用输出文本内容,如果要输出html代码,则不能使用这个.要使用v-html来输出. v-html必须在html标签里面作为属性写出来. &lt;span v-html=&quot;img&quot;&gt;&lt;/span&gt; &lt;script&gt; let vm = new Vue({ el:&quot;.app&quot;, data:{ img:'&lt;img src=&quot;images/shendan.png&quot;&gt;', } }) &lt;/script&gt; 在输出内容到普通标签的使用{{ }}还支持js代码。 &lt;h1&gt;{{str1.split(\"\").reverse().join(\"\")}}&lt;/h1&gt; 支持js的运算符 &lt;h1&gt;{{num1+3}}&lt;/h1&gt; 三元运算符,类似于python里面的三元表达式 三元运算符的语法: 判断条件 ? 条件为true : 条件为false的结果 &lt;h1&gt;num1和num2之间进行比较,最大值:{{ num2>num1?num2:num1 }}&lt;/h1&gt; python 三元表达式[三目运算符]的语法: a if 条件 else b 图片标签 &lt;span v-html=&quot;img&quot;&gt;&lt;/span&gt; &lt;img :src=&quot;img2&quot; alt=&quot;&quot; width=&quot;200px&quot;&gt; &lt;!-- 冒号：表示 设置属性 --&gt; data:{ // data 相当于 model img:'&lt;img src=&quot;img/1.png&quot; width=&quot;100px&quot;&gt;' ,// 数据为标签时，在页面展示时需要放在一个标签中显示设置v-html 属性 img2:'img/1.png' , //用设置属性的方法 :src='img2' } &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;app&quot;&gt; &lt;span v-html=&quot;img&quot;&gt;&lt;/span&gt; &lt;img :src=&quot;img2&quot; alt=&quot;&quot; width=&quot;200px&quot;&gt; &lt;!-- 冒号：表示 设置属性 --&gt; &lt;img v-bind:src=&quot;img2&quot; width=&quot;50&quot;&gt; &lt;!--1.0版本用 v-bind： 设置属性--&gt; &lt;/div&gt; &lt;script&gt; // 页面加载完执行 window.onload=function (ev) { let vm = new Vue({ // 至少两个数据el 和data el:'#app', //通过css 选择器 确定vue要控制的范围 data:{ // data 相当于 model img:'&lt;img src=&quot;img/1.png&quot; width=&quot;100px&quot;&gt;' ,// 数据为标签时，在页面展示时需要放在一个标签中显示设置v-html 属性 img2:'img/1.png' , //用设置属性的方法 :src='img2' } }) } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 常用指令1.指令 (Directives) 是带有“v-”前缀的特殊属性。每一个指令在vue中都有固定的作用。在vue中，提供了很多指令，常用的有：v-if、v-model、v-for等等。 指令会在vm对象的data属性的数据发生变化时，会同时改变元素中的其控制的内容或属性。 vue1.x写法 ——&gt; vue2.x的写法 v-html ——&gt; {{ }} v-bind:属性名 —-&gt; :属性 表示： 设置属性 v-on:事件名 —-&gt; @事件名 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;app&quot;&gt; &lt;span v-html=&quot;img&quot;&gt;&lt;/span&gt; &lt;p v-html=&quot;{{title}}&quot;&gt;&lt;/p&gt; &lt;img v-bind:src=&quot;img2&quot; width=&quot;50&quot;&gt; &lt;!--1.0版本用 v-bind： 设置属性--&gt; &lt;button v-on:click=&quot;func&quot;&gt;点击&lt;/button&gt; &lt;!-- 点击事件 --&gt; &lt;button @click=&quot;(num&lt;10)?(num):(num-10)&quot;&gt;点击{{num}}&lt;/button&gt; &lt;!-- 点击事件 使用了三元运算符 --&gt; &lt;/div&gt; &lt;script&gt; // 页面加载完执行 window.onload=function (ev) { let vm = new Vue({ // 至少两个数据el 和data el:'#app', //通过css 选择器 确定vue要控制的范围 data:{ // data 相当于 model img:'&lt;img src=&quot;img/1.png&quot; width=&quot;100px&quot;&gt;' ,// 数据为标签时，在页面展示时需要放在一个标签中显示设置v-html 属性 title:&quot;hello world&quot;, num:10 }, methods:{ func:function () { alert(&quot;你点我干嘛！&quot;); } } }) } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 2. 操作属性格式： &lt;标签名 :标签属性=”data属性”&gt;&lt;/标签名&gt; &lt;p :title=&quot;str1&quot;&gt;{{ str1 }}&lt;/p&gt; &lt;!-- 也可以使用v-html显示双标签的内容，{{ }} 是简写 --&gt; &lt;a :href=&quot;url2&quot;&gt;淘宝&lt;/a&gt; &lt;a v-bind:href=&quot;url1&quot;&gt;百度&lt;/a&gt; &lt;!-- v-bind是vue1.x版本的写法 --&gt; 3.事件绑定有两种写法，@事件名 和 v-on:事件名 &lt;button v-on:click=&quot;num++&quot;&gt;按钮&lt;/button&gt; &lt;!-- v-on 是vue1.x版本的写法 --&gt; &lt;button @click=&quot;num+=5&quot;&gt;按钮2&lt;/button&gt; 使用@事件名来进行事件的绑定语法： 绑定的事件的事件名，全部都是js的事件名： @submit —&gt; onsubmit @focus —&gt; onfocus 案例1 ： - 知识点： 1. v-model input 框 2. @click 点击事件 3. 三元运算符 核心代码: &lt;button @click=&quot;num+=1&quot;&gt;添加商品&lt;/button&gt; &lt;input type=&quot;text&quot; v-model=&quot;num&quot;&gt; &lt;button @click=&quot;(num&lt;=1)?(num=1):(num-=1)&quot;&gt;减少商品&lt;/button&gt; &lt;!--三元运算 --&gt; &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; // 页面加载完执行 window.onload=function (ev) { let vm = new Vue({ // 至少两个数据el 和data el:'#app', //通过css 选择器 确定vue要控制的范围 data:{ // data 相当于 model num:10 } }) } &lt;/script&gt; &lt;div id=&quot;app&quot;&gt; &lt;button @click=&quot;num+=1&quot;&gt;添加商品&lt;/button&gt; &lt;input type=&quot;text&quot; v-model=&quot;num&quot;&gt; &lt;button @click=&quot;(num&lt;=1)?(num=1):(num-=1)&quot;&gt;减少商品&lt;/button&gt; &lt;!--三元运算 --&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 4 操作样式 控制标签class类名 格式：&lt;h1 :class=&quot;值&quot;&gt;元素&lt;/h1&gt; 值可以是对象、对象名、数组添加class类名，值是一个对象 &lt;style&gt; .box1{color: red;border: 1px solid #000;} .box2{background-color: orange;font-size: 32px;} &lt;/style&gt; &lt;!---直接给标签设置class属性时，用的是 单花括号 --&gt; &lt;p :class=&quot;{box1:mycls1}&quot;&gt;段落一&lt;/p&gt; &lt;p @click=&quot;mycls3=!mycls3&quot; :class=&quot;{box2:mycls3,box1:mycls2,}&quot;&gt;段落一&lt;/p&gt; data:{ // data 相当于 model mycls1:false, // class属性设置是 bool mycls2:true, mycls3:true } { class类1:布尔值变量1, class类2:布尔值变量2, } 批量给元素增加多个class样式类 &lt;style&gt; .box4{ background-color: red; } .box5{ color: green; } &lt;/style&gt; &lt;!-- 批量给元素增加多个class样式类 --&gt; &lt;style&gt; .box6{background-color: red;} .box7{color: green;} .box8{border: 1px solid yellow;} &lt;/style&gt; &lt;div id=&quot;app3&quot;&gt; &lt;p :class=&quot;[mycls1,mycls2]&quot;&gt;第3段落&lt;/p&gt; &lt;/div&gt; &lt;script&gt; let vm3=new Vue({ el:&quot;#app3&quot;, data:{ mycls1:{ box6:false, box7:true }, mycls2:{ box8:true } } }) &lt;/script&gt; 控制标签style样式格式1：值是json对象，对象写在元素的:style属性中 &lt;div :style=&quot;{color: activeColor, fontSize: fontSize + 'px' }&quot;&gt;&lt;/div&gt; data: { activeColor: 'red', fontSize: 30 } 格式2：值是对象变量名，对象在data中进行声明 &lt;div v-bind:style=&quot;styleObject&quot;&gt;&lt;/div&gt; data: { styleObject: { color: 'red', fontSize: '13px' } } 格式3：值是数组 &lt;div v-bind:style=&quot;[style1, style2]&quot;&gt;&lt;/div&gt; data: { style1:{ color:&quot;red&quot; }, style2:{ background:&quot;yellow&quot;, fontSize: &quot;21px&quot; } } &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;style&gt; .box1{color: red;border: 1px solid #000;} .box2{background-color: orange;font-size: 32px;} &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;!--方式一--&gt; &lt;div id=&quot;box1&quot;&gt; &lt;p :style=&quot;{color:mycolor,backgroundColor:mybg}&quot;&gt;第一段内容&lt;/p&gt; &lt;/div&gt; &lt;br&gt; &lt;script&gt; var vm1= new Vue({ el:&quot;#box1&quot;, data:{ mycolor:'red', mybg:'pink' } }) &lt;/script&gt; &lt;!--方式二--&gt; &lt;div id=&quot;box2&quot;&gt; &lt;p :style=&quot;mystyle&quot;&gt;第一段内容&lt;/p&gt; &lt;/div&gt; &lt;br&gt; &lt;script&gt; var vm2= new Vue({ el:&quot;#box2&quot;, data:{ mystyle:{ color:&quot;red&quot;, backgroundColor:&quot;pink&quot; } } }) &lt;/script&gt; &lt;!--方式三：--&gt; &lt;div id=&quot;box3&quot;&gt; &lt;div :style=&quot;[mystyle,mystyle2]&quot;&gt;第一段内容&lt;/div&gt; &lt;/div&gt; &lt;br&gt; &lt;script&gt; var vm3= new Vue({ el:&quot;#box3&quot;, data:{ mystyle:{ color:&quot;red&quot;, backgroundColor:&quot;pink&quot; }, mystyle2:{ height:&quot;400px&quot;, width:&quot;400px&quot; } } }) &lt;/script&gt; 例子3. 条件渲染指令vue中提供了两个指令可以用于判断是否要显示元素，分别是v-if和v-show。 v-if &lt;!-- vue对象最终会把条件的结果变成布尔值 --&gt; &lt;h1 v-if=&quot;ok&quot;&gt;Yes&lt;/h1&gt; data:{ ok:false // true则是显示，false是该标签不会出现，不只是隐藏 } 2 v-else v-else指令来表示 v-if 的“else 块”，v-else 元素必须紧跟在带 v-if 或者 v-else-if 的元素的后面，否则它将不会被识别。 &lt;h1 v-if=&quot;ok&quot;&gt;Yes&lt;/h1&gt; &lt;h1 v-else&gt;No&lt;/h1&gt; data:{ ok:false // true则是显示，false是隐藏 } 3 v-else-if &lt;h1 v-if=&quot;num==1&quot;&gt;num的值为1&lt;/h1&gt; &lt;h1 v-else-if=&quot;num==2&quot;&gt;num的值为2&lt;/h1&gt; &lt;h1 v-else&gt;num的值是{{num}}&lt;/h1&gt; data:{ num:2 } 4 v-show 用法和v-if大致一样，区别在于2点： 1. v-show后面不能v-else 2. v-show隐藏元素时，使用的是display:none来隐藏的， 而v-if是直接从HTML文档中移除元素[ DOM操作中的remove ] &lt;h1 v-show=&quot;ok&quot;&gt;Hello!&lt;/h1&gt; data数据：data:{ok:false // true则是显示，false是隐藏案例： &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;box&quot;&gt; &lt;p v-if=&quot;is_login&quot;&gt;欢迎再次登录我们网站&lt;/p&gt; &lt;p v-else&gt;&lt;a href=&quot;&quot;&gt;注册&lt;/a&gt;&lt;a href=&quot;&quot;&gt;登录&lt;/a&gt;&lt;/p&gt; &lt;p v-if=&quot;num%3==0&quot;&gt;这个数能被3整除&lt;/p&gt; &lt;p v-else-if=&quot;num%5==0&quot;&gt;这个数能被5整除&lt;/p&gt; &lt;p v-else-if=&quot;num==1&quot;&gt;这个数为{{num}}&lt;/p&gt; &lt;p v-else&gt;你好&lt;/p&gt; &lt;!--v-show 符合条件就展示 ，不符合条件就隐藏 --&gt; &lt;p v-show=&quot;num==3&quot;&gt;这个数为3&lt;/p&gt; &lt;p v-show=&quot;num&quot;&gt;这个数为3&lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;script&gt; var vm =new Vue({ el:'#box', data:{ // is_login:true, is_login:false, num:3 } }) &lt;/script&gt; &lt;/html&gt; v-if v-else v-show5 列表渲染指令在vue中，可以通过v-for指令可以将一组数据渲染到页面中，数据可以是数组或者对象。 数据是数组： &lt;ul&gt; &lt;!--i是列表的每一个元素--&gt; &lt;li v-for=&quot;i in list&quot;&gt;{{i}}&lt;/li&gt; &lt;/ul&gt; 数据是对象： &lt;ul&gt; &lt;!--i是每一个value值,j是每一个键名--&gt; &lt;li v-for=&quot;(i, j) in obj1&quot;&gt;{{j}}:{{i}}&lt;/li&gt; &lt;/ul&gt; 实用案例 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; // 页面加载完执行 window.onload=function (ev) { let vm = new Vue({ // 至少两个数据el 和data el:'#app', //通过css 选择器 确定vue要控制的范围 data:{ // data 相当于 model num:10 } }) } &lt;/script&gt; &lt;div id=&quot;app&quot;&gt; &lt;button @click=&quot;num+=1&quot;&gt;添加商品&lt;/button&gt; &lt;input type=&quot;text&quot; v-model=&quot;num&quot;&gt; &lt;button @click=&quot;(num&lt;=1)?(num=1):(num-=1)&quot;&gt;减少商品&lt;/button&gt; &lt;!--三元运算 --&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 商品增减 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;style&gt; span{ height: 100px; width: 100px; background: grey; display: inline-block; line-height: 100px; text-align: center; } .new div{ width: 320px; height: 300px; background: red; display: none; } .new .active{ display: block; } .current{ background: red; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;box&quot;&gt; &lt;div class='item'&gt; &lt;span :class=&quot;num==1?'current':''&quot; @click=&quot;num=1&quot;&gt;国内新闻&lt;/span&gt; &lt;span :class=&quot;num==2?'current':''&quot; @click=&quot;num=2&quot;&gt;国外新闻&lt;/span&gt; &lt;span :class=&quot;num==3?'current':''&quot; @click=&quot;num=3&quot;&gt;银河新闻&lt;/span&gt; &lt;/div&gt; &lt;div class=&quot;new&quot; &gt; &lt;div :class=&quot;num==1?'active':''&quot;&gt;国内新闻&lt;/div&gt; &lt;div :class=&quot;num==2?'active':''&quot;&gt;国外新闻&lt;/div&gt; &lt;div :class=&quot;num==3?'active':''&quot;&gt;银河新闻&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;script&gt; var vm =new Vue({ el:'#box', data:{ num:1 } }) &lt;/script&gt; &lt;/html&gt; 内容切换 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;../vue.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;bootstrap/css/bootstrap.css&quot;&gt; &lt;/head&gt; &lt;style&gt; .active { color: red } #good_add, #good_edit { width: 300px; height: 300px; border: 1px solid grey; background: grey; text-align: center; /*display: none;*/ } .proform{ display: block; } .hide_cls{ display: none; } #good_edit div ,#good_add div{ margin-top: 20px; } &lt;/style&gt; &lt;body&gt; &lt;div id=&quot;box&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col col-md-3&quot;&gt; &lt;div id=&quot;good_add&quot; :class=&quot;{'proform':add_cls1,'hide_cls':add_cls2}&quot;&gt; &lt;h3&gt;添加商品&lt;/h3&gt; &lt;div&gt;商品标题&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;input type=&quot;text&quot; v-model=&quot;add_name&quot;&gt;&lt;/div&gt; &lt;div&gt;商品数量&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;input type=&quot;text&quot; v-model=&quot;add_num&quot;&gt;&lt;/div&gt; &lt;div&gt;商品价格&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;input type=&quot;text&quot; v-model=&quot;add_price&quot;&gt;&lt;/div&gt; &lt;div&gt;&lt;button class=&quot;btn btn-default&quot; @click=&quot;add_keep&quot; style=&quot;margin-right: 20px&quot;&gt;保存&lt;/button &gt;&lt;button class=&quot;btn btn-default &quot; @click=&quot;add_cancel&quot; style=&quot;margin-left: 20px&quot;&gt;取消&lt;/button&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;col col-md-6 &quot;&gt; &lt;button class=&quot;btn btn-info&quot; @click=&quot;add&quot;&gt;添加&lt;/button&gt; &lt;table class=&quot;table table-bordered&quot;&gt; &lt;tr&gt; &lt;th&gt;编号&lt;/th&gt; &lt;th&gt;书名&lt;/th&gt; &lt;th&gt;价格&lt;/th&gt; &lt;th&gt;数量&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;tbody&gt; &lt;tr v-for=&quot;good,key in goods&quot;&gt; &lt;td&gt;{{key+1}}&lt;/td&gt; &lt;td&gt;{{good.name}}&lt;/td&gt; &lt;td v-if=&quot;good.price&gt;100&quot; :class=&quot;{active:mycls}&quot;&gt;{{good.price}}&lt;/td&gt; &lt;td v-if=&quot;good.price&lt;=100&quot;&gt;{{good.price}}&lt;/td&gt; &lt;td&gt;{{good.num}}&lt;/td&gt; &lt;td&gt; &lt;button class=&quot;btn btn-info&quot; @click=&quot;edit(key)&quot;&gt;编辑&lt;/button&gt; &lt;button class=&quot;btn btn-danger&quot; @click=&quot;goods.splice(key,1)&quot;&gt;删除&lt;/button&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;col col-md-3 pull-right&quot;&gt; &lt;div id=&quot;good_edit&quot; :class=&quot;{'proform':edit_cls1,'hide_cls':edit_cls2}&quot; &gt; &lt;!--&lt;div&gt;编号&lt;input type=&quot;text&quot; v-model=&quot;k&quot;&gt;&lt;/div&gt;--&gt; &lt;h3&gt;编辑商品&lt;/h3&gt; &lt;div&gt;商品标题&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;input type=&quot;text&quot; v-model=&quot;name&quot;&gt;&lt;/div&gt; &lt;div&gt;商品数量&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;input type=&quot;text&quot; v-model=&quot;num&quot;&gt;&lt;/div&gt; &lt;div&gt;商品价格&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;input type=&quot;text&quot; v-model=&quot;price&quot;&gt;&lt;/div&gt; &lt;div&gt;&lt;button class=&quot;btn btn-default&quot; @click=&quot;edit_keep&quot; style=&quot;margin-right: 20px&quot;&gt;保存&lt;/button &gt;&lt;button class=&quot;btn btn-default&quot; @click=&quot;edit_cancel&quot; style=&quot;margin-left: 20px&quot;&gt;取消&lt;/button&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; let l = new Vue({ el: &quot;#box&quot;, data: { goods: [ {'name': &quot;python1&quot;, 'price': 150,&quot;num&quot;:1000}, {'name': &quot;python2&quot;, 'price': 100,&quot;num&quot;:2000}, {'name': &quot;python3&quot;, 'price': 70,&quot;num&quot;:3000}, {'name': &quot;python4&quot;, 'price': 60,&quot;num&quot;:4000}, {'name': &quot;python5&quot;, 'price': 110,&quot;num&quot;:5000} ], //编辑所用的值 k:&quot;&quot;,// 记录该书的索引值，方便编辑后保存用 name:&quot;&quot;, //点击编辑时，把该书的开始name显示 ，之后修改后同步改变，下面的价格和数量也是一样 price:&quot;&quot;, num:&quot;&quot;, edit_init_dic:&quot;&quot;,// 点击编辑时，记录最初 的书籍信息 // edit_init_k:&quot;&quot;,//点击编辑时，记录该书最初索引值 可以不用 edit_cls1: false, edit_cls2: true, //添加用的参数 add_name:&quot;&quot;, add_price:&quot;&quot;, add_num:&quot;&quot;, add_cls1:false, add_cls2:true, mycls:true }, methods:{ edit:function (key) { //显示编辑框 this.edit_cls1=true; this.edit_cls2=false; //数据处理 this.k=key; this.name=this.goods[key].name; this.price=this.goods[key].price; this.num=this.goods[key].num; this.edit_init_dic={&quot;name&quot;:this.goods[key].name,&quot;price&quot;:this.goods[key].price,&quot;num&quot;:this.goods[key].num}; this.edit_init_k=key }, edit_keep:function () { this.goods.splice(this.k,1,{&quot;name&quot;:this.name,&quot;price&quot;:this.price,'num':this.num}) this.edit_cls1=false; this.edit_cls2=true; }, edit_cancel:function () { this.goods.splice(this.k,1,this.edit_init_dic); this.edit_cls1=false; this.edit_cls2=true; }, add:function () { //点击添加按钮弹出 添加框 //:class=&quot;{'proform':add_cls1,'hide_cls':add_cls2} this.add_cls1=true; this.add_cls2=false; //将上次的数据清空显示 this.add_name=&quot;&quot;; this.add_price=&quot;&quot;; this.add_num=&quot;&quot;; }, add_keep:function () { //保存数据 this.goods.splice(this.goods.length,1,{'name':this.add_name,'price':this.add_price,'num':this.add_num}); //隐藏 添加框 this.add_cls1=false; this.add_cls2=true; }, add_cancel:function () { //把数据清空 this.add_name=&quot;&quot;; this.add_price=&quot;&quot;; this.add_num=&quot;&quot;; //隐藏 添加框 this.add_cls1=false; this.add_cls2=true; } } }) &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 表格的增删改查 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;../vue.js&quot;&gt;&lt;/script&gt; &lt;style&gt; table,tr,th,td{ border: 1px solid; border-collapse: collapse; text-align: center; } table{ width: 600px; margin-left: 100px; } th{ padding-top: 10px; } .box{ width: 300px; height: 200px; border: 1px solid; border-radius: 5px; position: fixed; margin: auto; right: 0; left: 0; top: 0; bottom: 0; } .box div{ text-align: center; margin: 15px; } .box button{ margin: 20px; } table button{ margin-left: 10px; } &lt;/style&gt; &lt;/head&gt; &lt;div id=&quot;app&quot;&gt; &lt;body&gt; &lt;div&gt;&lt;button @click=&quot;is_show=true&quot;&gt;添加商品&lt;/button&gt;&lt;/div&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;商品编号&lt;/th&gt; &lt;th&gt;商品名称&lt;/th&gt; &lt;th&gt;商品价格&lt;/th&gt; &lt;th&gt;商品数量&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;tbody&gt; &lt;tr v-for=&quot;good,key in goods&quot;&gt; &lt;td&gt;{{key+1}}&lt;/td&gt; &lt;td&gt;{{good.name}}&lt;/td&gt; &lt;td&gt;{{good.price}}&lt;/td&gt; &lt;td&gt;{{good.num}}&lt;/td&gt; &lt;td&gt;&lt;button @click=&quot;edit(key)&quot;&gt;编辑&lt;/button&gt;&lt;button @click=&quot;del(key)&quot;&gt;删除&lt;/button&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;div class=&quot;box&quot; v-show=&quot;is_show&quot;&gt; &lt;div&gt;商品名称：&lt;input type=&quot;text&quot; v-model=&quot;name&quot;&gt;&lt;/div&gt; &lt;div&gt;商品价格：&lt;input type=&quot;text&quot; v-model=&quot;price&quot;&gt;&lt;/div&gt; &lt;div&gt;商品数量：&lt;input type=&quot;text&quot; v-model=&quot;num&quot;&gt;&lt;/div&gt; &lt;div&gt;&lt;button @click=&quot;keep&quot; &gt;保存&lt;/button&gt;&lt;button @click=&quot;cancel&quot;&gt;取消&lt;/button&gt;&lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/div&gt; &lt;script&gt; var vm = new Vue({ el:&quot;#app&quot;, data:{ edit_key:'', name:'', price:'', num:'', is_show:false, goods: [ {'name': &quot;python1&quot;, 'price': 150,&quot;num&quot;:1000}, {'name': &quot;python2&quot;, 'price': 100,&quot;num&quot;:2000}, {'name': &quot;python3&quot;, 'price': 70,&quot;num&quot;:3000}, {'name': &quot;python4&quot;, 'price': 60,&quot;num&quot;:4000}, {'name': &quot;python5&quot;, 'price': 110,&quot;num&quot;:5000}] }, methods:{ //删除 del:function (key) { this.goods.splice(key,1); }, // 保存 keep:function () { // box 隐藏 this.is_show=false; // 数据追加到后面 if (this.edit_key){ //编辑时保存 this.goods[this.edit_key].name=this.name; this.goods[this.edit_key].price=this.price; this.goods[this.edit_key].num=this.num; }else { this.goods.push({&quot;name&quot;:this.name,&quot;price&quot;:this.price,&quot;num&quot;:this.num}); } //清空 数据 this.name=&quot;&quot;; this.price=&quot;&quot;; this.num=&quot;&quot;; this.edit_key=''; }, cancel:function () { //添加时取消 this.is_show=false; //清空 数据 this.name=&quot;&quot;; this.price=&quot;&quot;; this.num=&quot;&quot;; this.edit_key=''; }, //编辑 edit:function (key) { //显示box this.edit_key=key; this.is_show=true; //将数据显示 this.name=this.goods[key].name; this.price=this.goods[key].price; this.num=this.goods[key].num; } } }) &lt;/script&gt; &lt;/html&gt;","link":"/2021/04/27/vue-3/"},{"title":"Windows terminal 的安装和美化","text":"前言这段时间呢，我一直是用cmder或者windows ISE的，但是这两货的优点很多，缺点也不少，比如说：启动慢（ISE一个启动都要2s，我打命令都打完了他还没启动完），颜值低（ISE不支持更改外观，cmder可以更改的地方很少。）于是，我到一些群里面去问：“有没有大佬，求一个windows下的Shell客户端”，回答的答案很多：“cmder,Xshell,WSL(Windows子Linux),Windows terminal”，当我看到windows terminal的时候，我脑中浮现出一个奇怪的问题：“可以魔改吗？”，于是我发出了这个问题，得到的结果是：“可以”，我那颗折腾的心变得Exciting了起来! 下载怎么下载呢？你可以在这个链接下载,或者直接到Windows Store里面搜索”windows terminal”下载 阐述Windows 终端是一个面向命令行工具和 shell（如命令提示符、PowerShell 和适用于 Linux 的 Windows 子系统 (WSL)）用户的新式终端应用程序。 它的主要功能包括多个选项卡、窗格、Unicode 和 UTF-8 字符支持、GPU 加速文本呈现引擎，你还可用它来创建你自己的主题并自定义文本、颜色、背景和快捷方式。 支持多种命令行应用程序的多个配置文件任何具有命令行接口的应用程序都可以在 Windows 终端中运行。 这包括从 PowerShell 和命令提示符到 Azure Cloud Shell 和任何 WSL 分发（如 Ubuntu 或 Oh-My-Zsh）的所有应用程序。 自定义方案和配置可以将 Windows 终端配置为具有多种配色方案和设置。 若要了解如何创建自己的配色方案，请访问配色方案页面。 还可以在自定义终端库中查找自定义终端配置。 自定义操作可在 Windows 终端中使用多种自定义命令，获得更加自然的体验。 如果不喜欢特定的键盘快捷方式，可以将其更改为你喜欢的方式。例如，若要复制命令行中的文本，默认的快捷方式为 ctrl+shift+c。 你可以将其更改为 ctrl+1 或你喜欢的其他方式。 要打开新的选项卡，默认快捷方式是 ctrl+t，但你可能想要将其更改为 ctrl+2。 用于在打开的选项卡之间进行切换的默认快捷方式是 ctrl+tab，可以将这个快捷方式更改为 ctrl+- 并改为用于创建新选项卡。可在操作页面上了解如何自定义快捷方式。 Unicode 和 UTF-8 字符支持Windows 终端可以显示 Unicode 和 UTF-8 字符，如各种语言的表情符号和字符。 GPU 加速文本呈现Windows 终端使用 GPU 来呈现其文本，从而提供比默认 Windows 命令行体验更好的性能。 背景图像支持可以在 Windows 终端窗口中显示背景图像和 gif。 有关如何向配置文件添加背景图像的信息，请参阅配置文件设置页。 命令行参数可以使用命令行参数将 Windows 终端设置为在特定配置中启动。 可以指定要在新选项卡中打开哪个配置文件、应选择哪个文件夹目录，指定使用拆分窗口窗格打开终端，并指定选择应专注于哪个选项卡。例如，若要使用三个窗格从 PowerShell 打开 Windows 终端（左窗格运行命令提示符配置文件，右窗格拆分为两个，一个用于 PowerShell，另一个用于运行 WSL 的默认配置文件），请输入： wt -p &quot;Command Prompt&quot; `; split-pane -p &quot;Windows PowerShell&quot; `; split-pane -H wsl.exe 更新微软宣布从 2020 年 7 月开始，Windows Terminal 每月都会获得一次更新。这是一个开源项目，微软欢迎全球开发者社区参与。如要参与，请访问：GitHub | Windows Terminal此外，微软宣布正式启动预览项目 Windows Terminal Preview，开发者还可以从微软官方文档页面获取相关支持：Windows Terminal | Microsoft Docs 美化powershell美化在美化windows terminal之前，我们先来美化powershell这个傻大蓝。 在命令行依次输入 # 安装 PSReadline 包，让命令行更好用 Install-Module -Nane PSReadLine -AllowPrerelease -Force # 安装 posh-git 包,优化Git(bash) Install-Module posh-git -Scope CurrentUser # 划重点！安装 oh-my-posh 包，美化傻大蓝(poweshell) Install-Module oh-my-posh -Scope CurrentUser # 允许脚本本地运行 &amp; 安装 Scope 包管理器 set-executionpolicy remotesigned -scope currentuser iex (new-object net.webclient).downloadstring('https://get.scoop.sh') 没网络的时候~ ⚡ ChenShang ~ ❯❯❯ if (!(Test-Path -Path $PROFILE )) { New-Item -Type File -Path $PROFILE -Force } # 检验是否有 $PROFILE，没有就创建一个 ⚡ ChenShang ~ ❯❯❯ notepad $PROFILE # 记事本打开 $PROFILE ⚡ ChenShang ~ ❯❯❯ code $PROFILE # 记事本打开 $PROFILE ⚡ ChenShang ~ ❯❯❯ code $PROFILE # 记事本打开 $PROFILE ⚡ ChenShang ~ ❯❯❯ code $PROFILE # 记事本打开 $PROFILE ⚡ ChenShang ~ ❯❯❯ # 安装 PSReadline 包，让命令行更好用 ⚡ ChenShang ~ ❯❯❯ Install-Module -Nane PSReadLine -AllowPrerelease -Force Install-Module : 找不到与参数名称“Nane”匹配的参数。 所在位置 行:1 字符: 16 + Install-Module -Nane PSReadLine -AllowPrerelease -Force + ~~~~~ + CategoryInfo : InvalidArgument: (:) [Install-Module]，ParameterBindingException + FullyQualifiedErrorId : NamedParameterNotFound,Install-Module ⨯ ⚡ ChenShang ~ ❯❯❯ # 安装 posh-git 包,优化Git(bash) ⚡ ChenShang ~ ❯❯❯ Install-Module posh-git -Scope CurrentUser 警告: Unable to resolve package source 'https://www.powershellgallery.com/api/v2'. PackageManagement\\Install-Package : 找不到与指定的搜索条件和程序包名称“posh-git”匹配的项目。请尝试使用 Get-PSRepository 查看所有可用的注册程序包源。 所在位置 C:\\Program Files\\WindowsPowerShell\\Modules\\PowerShellGet\\1.0.0.1\\PSModule.psm1:1809 字符: 21 + ... $null = PackageManagement\\Install-Package @PSBoundParameters + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ObjectNotFound: (Microsoft.Power....InstallPackage:InstallPackage) [Install-Package], Exception + FullyQualifiedErrorId : NoMatchFoundForCriteria,Microsoft.PowerShell.PackageManagement.Cmdlets.InstallPackage ⨯ ⚡ ChenShang ~ ❯❯❯ # 划重点！安装 oh-my-posh 包，美化傻大蓝(poweshell) ⚡ ChenShang ~ ❯❯❯ Install-Module oh-my-posh -Scope CurrentUser 警告: Unable to resolve package source 'https://www.powershellgallery.com/api/v2'. PackageManagement\\Install-Package : 找不到与指定的搜索条件和程序包名称“oh-my-posh”匹配的项目。请尝试使用 Get-PSRepository 查看所有可用的注册程序包源。 所在位置 C:\\Program Files\\WindowsPowerShell\\Modules\\PowerShellGet\\1.0.0.1\\PSModule.psm1:1809 字符: 21 + ... $null = PackageManagement\\Install-Package @PSBoundParameters + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ObjectNotFound: (Microsoft.Power....InstallPackage:InstallPackage) [Install-Package], Exception + FullyQualifiedErrorId : NoMatchFoundForCriteria,Microsoft.PowerShell.PackageManagement.Cmdlets.InstallPackage ⨯ ⚡ ChenShang ~ ❯❯❯ # 允许脚本本地运行 &amp; 安装 Scope 包管理器 ⚡ ChenShang ~ ❯❯❯ set-executionpolicy remotesigned -scope currentuser ⚡ ChenShang ~ ❯❯❯ iex (new-object net.webclient).downloadstring('https://get.scoop.sh')^C ⚡ ChenShang ~ ❯❯❯ 安装完oh-my-posh后if (!(Test-Path -Path $PROFILE )) { New-Item -Type File -Path $PROFILE -Force } # 检验是否有 $PROFILE，没有就创建一个 notepad $PROFILE # 记事本打开 $PROFILE 在记事本里面输入以下： Import-Module posh-git # 导入posh-git的模块 Import-Module oh-my-posh # 导入oh-my-posh的模块 Set-Theme Sorin # 将样式设定为Sorin 美化Windows terminal所要用到的代码如下 &quot;backgroundImage&quot;: &quot;https://upimage.alexhchu.com/2021/01/01/378b347c10053.jpg&quot;, // bg url &quot;backgroundImageOpacity&quot;: 0.5, &quot;closeOnExit&quot;: true, &quot;color&quot;: &quot;#FFFFFF&quot;, &quot;cursorShape&quot;: &quot;bar&quot;, &quot;icon&quot;: &quot;E://shell//PS.png&quot;, &quot;padding&quot;: &quot;0, 0, 0, 0&quot;, &quot;snapOnInput&quot;: true, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot;: &quot;Windows-10-Shell&quot;, &quot;useAcrylic&quot;: true, 加在什么地方？加在这里 &quot;profiles&quot;: { &quot;defaults&quot;: { &quot;fontFace&quot; : &quot;JetBrains Mono&quot;, &quot;cursorColor&quot;: &quot;#9e9e9e&quot;, &quot;fontSize&quot; : 13 // 字体大小, // Put settings here that you want to apply to all profiles. }, 加在这里的话只需要写一次代码，然后所有的全部都一个样（除了标题） 或者放这： &quot;list&quot;: [ { // Make changes here to the powershell.exe profile. // powershell &quot;guid&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, &quot;name&quot;: &quot;Windows PowerShell&quot;, &quot;commandline&quot;: &quot;powershell.exe&quot;, &quot;backgroundImage&quot;: &quot;https://upimage.alexhchu.com/2021/01/01/378b347c10053.jpg&quot;, // bg url &quot;backgroundImageOpacity&quot;: 0.5, &quot;closeOnExit&quot;: true, &quot;color&quot;: &quot;#FFFFFF&quot;, &quot;cursorShape&quot;: &quot;bar&quot;, &quot;icon&quot;: &quot;E://shell//PS.png&quot;, &quot;padding&quot;: &quot;0, 0, 0, 0&quot;, &quot;snapOnInput&quot;: true, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot;: &quot;Windows-10-Shell&quot;, &quot;useAcrylic&quot;: true, &quot;hidden&quot;: false }, 但是放在这里的话就要每一个list都写一次刚才的代码了。很麻烦….但是很有效 我的个人主题配置文件// This file was initially generated by Windows Terminal 1.4.3243.0 // It should still be usable in newer versions, but newer versions might have additional // settings, help text, or changes that you will not see unless you clear this file // and let us generate a new one for you. // To view the default settings, hold &quot;alt&quot; while clicking on the &quot;Settings&quot; button. // For documentation on these settings, see: https://aka.ms/terminal-documentation { &quot;$schema&quot;: &quot;https://aka.ms/terminal-profiles-schema&quot;, &quot;defaultProfile&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, // You can add more global application settings here. // To learn more about global settings, visit https://aka.ms/terminal-global-settings // If enabled, selections are automatically copied to your clipboard. &quot;copyOnSelect&quot;: false, // If enabled, formatted data is also copied to your clipboard &quot;copyFormatting&quot;: false, // A profile specifies a command to execute paired with information about how it should look and feel. // Each one of them will appear in the 'New Tab' dropdown, // and can be invoked from the commandline with `wt.exe -p xxx` // To learn more about profiles, visit https://aka.ms/terminal-profile-settings &quot;profiles&quot;: { &quot;defaults&quot;: { &quot;fontFace&quot; : &quot;JetBrains Mono&quot;, &quot;cursorColor&quot;: &quot;#9e9e9e&quot;, &quot;fontSize&quot; : 13 // 字体大小, // Put settings here that you want to apply to all profiles. }, &quot;list&quot;: [ { // Make changes here to the powershell.exe profile. // powershell &quot;guid&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, &quot;name&quot;: &quot;Windows PowerShell&quot;, &quot;commandline&quot;: &quot;powershell.exe&quot;, &quot;backgroundImage&quot;: &quot;https://upimage.alexhchu.com/2021/01/01/378b347c10053.jpg&quot;, // bg url &quot;backgroundImageOpacity&quot;: 0.5, &quot;closeOnExit&quot;: true, &quot;color&quot;: &quot;#FFFFFF&quot;, &quot;cursorShape&quot;: &quot;bar&quot;, &quot;icon&quot;: &quot;E://shell//PS.png&quot;, &quot;padding&quot;: &quot;0, 0, 0, 0&quot;, &quot;snapOnInput&quot;: true, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot;: &quot;Windows-10-Shell&quot;, &quot;useAcrylic&quot;: true, &quot;hidden&quot;: false }, { // Make changes here to the powershell.exe profile. // powershell &quot;guid&quot;: &quot;{1c4de342-38b7-51cf-b940-2309a097f584}&quot;, &quot;name&quot;: &quot;Git-Bash&quot;, &quot;commandline&quot;: &quot;E:\\\\Git\\\\bin\\\\bash.exe&quot;, &quot;backgroundImage&quot;: &quot;https://www.cxyxiaowu.com/wp-content/uploads/2020/06/1591422723-a39d058bfb6e1cf.png&quot;, // bg url &quot;backgroundImageOpacity&quot;: 0.9, &quot;closeOnExit&quot;: true, &quot;color&quot;: &quot;#FFFFFF&quot;, &quot;cursorShape&quot;: &quot;bar&quot;, &quot;icon&quot;: &quot;E://shell//git.png&quot;, &quot;padding&quot;: &quot;10, 10, 10, 10&quot;, &quot;snapOnInput&quot;: true, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot;: &quot;Git-Bash&quot;, &quot;useAcrylic&quot;: true, &quot;hidden&quot;: false }, { // Make changes here to the cmd.exe profile. // cmd &quot;guid&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa6101}&quot;, &quot;name&quot;: &quot;Command Prompt&quot;, &quot;acrylicOpacity&quot; : 0.75, &quot;backgroundImage&quot; : &quot;https://upimage.alexhchu.com/2021/01/01/f9ced42a624e7.jpg&quot;, // 图片地址 &quot;backgroundImageOpacity&quot; : 0.9, &quot;closeOnExit&quot; : true, &quot;cursorColor&quot; : &quot;#FFFFFF&quot;, &quot;cursorShape&quot; : &quot;bar&quot;, &quot;icon&quot; : &quot;E://shell//cmd.png&quot;, &quot;padding&quot; : &quot;0, 0, 0, 0&quot;, &quot;snapOnInput&quot; : true, &quot;startingDirectory&quot; : &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot; : &quot;default&quot;, &quot;useAcrylic&quot; : true, //毛玻璃 关掉 &quot;hidden&quot;: false }, { // -user cloud &quot;guid&quot;: &quot;{b453ae62-4e3d-5e58-b989-0a998ec441b8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Azure Cloud Shell&quot;, &quot;source&quot;: &quot;Windows.Terminal.Azure&quot; } ] }, // Add custom color schemes to this array. // To learn more about color schemes, visit https://aka.ms/terminal-color-schemes &quot;schemes&quot;: [], // Add custom actions and keybindings to this array. // To unbind a key combination from your defaults.json, set the command to &quot;unbound&quot;. // To learn more about actions and keybindings, visit https://aka.ms/terminal-keybindings &quot;actions&quot;: [ // Copy and paste are bound to Ctrl+Shift+C and Ctrl+Shift+V in your defaults.json. // These two lines additionally bind them to Ctrl+C and Ctrl+V. // To learn more about selection, visit https://aka.ms/terminal-selection { &quot;command&quot;: {&quot;action&quot;: &quot;copy&quot;, &quot;singleLine&quot;: false }, &quot;keys&quot;: &quot;ctrl+c&quot; }, { &quot;command&quot;: &quot;paste&quot;, &quot;keys&quot;: &quot;ctrl+v&quot; }, // Press Ctrl+Shift+F to open the search box { &quot;command&quot;: &quot;find&quot;, &quot;keys&quot;: &quot;ctrl+shift+f&quot; }, // Press Alt+Shift+D to open a new pane. // - &quot;split&quot;: &quot;auto&quot; makes this pane open in the direction that provides the most surface area. // - &quot;splitMode&quot;: &quot;duplicate&quot; makes the new pane use the focused pane's profile. // To learn more about panes, visit https://aka.ms/terminal-panes { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;auto&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; }, &quot;keys&quot;: &quot;alt+shift+d&quot; } ] } 建议在我的基础上加以修正，不要直接拿我的。 后记那个什么，这篇文章写的不怎么好，我没有什么文笔，写技术博客的时候很难下手，写这篇文章的原因是因为有人接的我的Windows terminal好…看…（怎么这么生疏）来简单讲讲流程和原理： 先下载，那怎么下载呢？ 安装需要的模块 # 安装 PSReadline 包，让命令行更好用 Install-Module -Nane PSReadLine -AllowPrerelease -Force # 安装 posh-git 包,优化Git(bash) Install-Module posh-git -Scope CurrentUser # 划重点！安装 oh-my-posh 包，美化傻大蓝(poweshell) Install-Module oh-my-posh -Scope CurrentUser # 允许脚本本地运行 &amp; 安装 Scope 包管理器 set-executionpolicy remotesigned -scope currentuser iex (new-object net.webclient).downloadstring('https://get.scoop.sh') 建议在有网络的环境下下载 配置ho-my-posh到Poweshell检验PS(powershell)的配置文件有没有呆在它应该呆在的地方，如果没有，那就给它造个兄弟，在他的兄弟的身体里面写下如下 Import-Module posh-git # 导入posh-git的模块 Import-Module oh-my-posh # 导入oh-my-posh的模块 Set-Theme Sorin # 将样式设定为Sorin 配Json，在标签旁边的“+”的设置，或者直接Ctrl+,我的setting.json: // This file was initially generated by Windows Terminal 1.4.3243.0 // It should still be usable in newer versions, but newer versions might have additional // settings, help text, or changes that you will not see unless you clear this file // and let us generate a new one for you. // To view the default settings, hold &quot;alt&quot; while clicking on the &quot;Settings&quot; button. // For documentation on these settings, see: https://aka.ms/terminal-documentation { &quot;$schema&quot;: &quot;https://aka.ms/terminal-profiles-schema&quot;, &quot;defaultProfile&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, // You can add more global application settings here. // To learn more about global settings, visit https://aka.ms/terminal-global-settings // If enabled, selections are automatically copied to your clipboard. &quot;copyOnSelect&quot;: false, // If enabled, formatted data is also copied to your clipboard &quot;copyFormatting&quot;: false, // A profile specifies a command to execute paired with information about how it should look and feel. // Each one of them will appear in the 'New Tab' dropdown, // and can be invoked from the commandline with `wt.exe -p xxx` // To learn more about profiles, visit https://aka.ms/terminal-profile-settings &quot;profiles&quot;: { &quot;defaults&quot;: { &quot;fontFace&quot; : &quot;JetBrains Mono&quot;, &quot;cursorColor&quot;: &quot;#9e9e9e&quot;, &quot;fontSize&quot; : 13 // 字体大小, // Put settings here that you want to apply to all profiles. }, &quot;list&quot;: [ { // Make changes here to the powershell.exe profile. // powershell &quot;guid&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, &quot;name&quot;: &quot;Windows PowerShell&quot;, &quot;commandline&quot;: &quot;powershell.exe&quot;, &quot;backgroundImage&quot;: &quot;https://upimage.alexhchu.com/2021/01/01/378b347c10053.jpg&quot;, // bg url &quot;backgroundImageOpacity&quot;: 0.5, &quot;closeOnExit&quot;: true, &quot;color&quot;: &quot;#FFFFFF&quot;, &quot;cursorShape&quot;: &quot;bar&quot;, &quot;icon&quot;: &quot;E://shell//PS.png&quot;, &quot;padding&quot;: &quot;0, 0, 0, 0&quot;, &quot;snapOnInput&quot;: true, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot;: &quot;Windows-10-Shell&quot;, &quot;useAcrylic&quot;: true, &quot;hidden&quot;: false }, { // Make changes here to the powershell.exe profile. // powershell &quot;guid&quot;: &quot;{1c4de342-38b7-51cf-b940-2309a097f584}&quot;, &quot;name&quot;: &quot;Git-Bash&quot;, &quot;commandline&quot;: &quot;E:\\\\Git\\\\bin\\\\bash.exe&quot;, &quot;backgroundImage&quot;: &quot;https://www.cxyxiaowu.com/wp-content/uploads/2020/06/1591422723-a39d058bfb6e1cf.png&quot;, // bg url &quot;backgroundImageOpacity&quot;: 0.9, &quot;closeOnExit&quot;: true, &quot;color&quot;: &quot;#FFFFFF&quot;, &quot;cursorShape&quot;: &quot;bar&quot;, &quot;icon&quot;: &quot;E://shell//git.png&quot;, &quot;padding&quot;: &quot;10, 10, 10, 10&quot;, &quot;snapOnInput&quot;: true, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot;: &quot;Git-Bash&quot;, &quot;useAcrylic&quot;: true, &quot;hidden&quot;: false }, { // Make changes here to the cmd.exe profile. // cmd &quot;guid&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa6101}&quot;, &quot;name&quot;: &quot;Command Prompt&quot;, &quot;acrylicOpacity&quot; : 0.75, &quot;backgroundImage&quot; : &quot;https://upimage.alexhchu.com/2021/01/01/f9ced42a624e7.jpg&quot;, // 图片地址 &quot;backgroundImageOpacity&quot; : 0.9, &quot;closeOnExit&quot; : true, &quot;cursorColor&quot; : &quot;#FFFFFF&quot;, &quot;cursorShape&quot; : &quot;bar&quot;, &quot;icon&quot; : &quot;E://shell//cmd.png&quot;, &quot;padding&quot; : &quot;0, 0, 0, 0&quot;, &quot;snapOnInput&quot; : true, &quot;startingDirectory&quot; : &quot;%USERPROFILE%&quot;, &quot;tabTitle&quot; : &quot;default&quot;, &quot;useAcrylic&quot; : true, //毛玻璃 关掉 &quot;hidden&quot;: false }, { // -user cloud &quot;guid&quot;: &quot;{b453ae62-4e3d-5e58-b989-0a998ec441b8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Azure Cloud Shell&quot;, &quot;source&quot;: &quot;Windows.Terminal.Azure&quot; } ] }, // Add custom color schemes to this array. // To learn more about color schemes, visit https://aka.ms/terminal-color-schemes &quot;schemes&quot;: [], // Add custom actions and keybindings to this array. // To unbind a key combination from your defaults.json, set the command to &quot;unbound&quot;. // To learn more about actions and keybindings, visit https://aka.ms/terminal-keybindings &quot;actions&quot;: [ // Copy and paste are bound to Ctrl+Shift+C and Ctrl+Shift+V in your defaults.json. // These two lines additionally bind them to Ctrl+C and Ctrl+V. // To learn more about selection, visit https://aka.ms/terminal-selection { &quot;command&quot;: {&quot;action&quot;: &quot;copy&quot;, &quot;singleLine&quot;: false }, &quot;keys&quot;: &quot;ctrl+c&quot; }, { &quot;command&quot;: &quot;paste&quot;, &quot;keys&quot;: &quot;ctrl+v&quot; }, // Press Ctrl+Shift+F to open the search box { &quot;command&quot;: &quot;find&quot;, &quot;keys&quot;: &quot;ctrl+shift+f&quot; }, // Press Alt+Shift+D to open a new pane. // - &quot;split&quot;: &quot;auto&quot; makes this pane open in the direction that provides the most surface area. // - &quot;splitMode&quot;: &quot;duplicate&quot; makes the new pane use the focused pane's profile. // To learn more about panes, visit https://aka.ms/terminal-panes { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;auto&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; }, &quot;keys&quot;: &quot;alt+shift+d&quot; } ] } 本人用的是Sorin的主题，不知道各位喜欢什么，在百度上面都有的。 也可以用 Set-Theme Theme-Name # 预览主题 后记-2平台这个Windows Terminal是不跨平台的，只在Windows下才有。如果是MAC的，我推荐一个命令行，你或许认得它，它的名字是——Item2。 WSLWSL是指Windows Linux。Windows下的Linux子系统，Windows terminal也是可以兼容的。至于怎么配置，我下一篇再写… 完成时间 2021/1/2/0：04：44","link":"/2021/01/01/wintm/"},{"title":"2016年末，2017年元旦电影名单","text":"@2016年末，2017年元旦电影名单（提供百度云链接） 如上图，先点题：一共 17 部。有的是重温，有的是首次看，本文不剧透。 以上电影下载地址：百度云提取密码：crvg 电影对应的豆瓣链接： 血色将至 There Will Be Blood 黑客帝国 The Matrix 黑客帝国2：重装上阵 The Matrix Reloaded 黑客帝国3：矩阵革命 The Matrix Revolutions 穆赫兰道 Mulholland Dr. 老无所依 No Country for Old Men 暖暖内含光 Eternal Sunshine of the Spotless Mind 窃听风暴 The Lives of Others 人类之子 Children of Men 十二宫 Zodiac 饥饿游戏3：嘲笑鸟(下) The Hunger Games: Mockingjay 对她说 Talk to Her 爱 Amour 上帝之城 City of God 花样年华 一一 刺客聂隐娘 我已经很长一段时间没系统地看电影了，平时晚上回来也就可以休息几个小时就得准备睡觉了，看一部电影至少也得 2 个小时，不可能有太多晚上可以这样安好的。所以趁着这个元旦不想出去就在家看看电影吧。 昨晚补看了《饥饿游戏3-嘲笑鸟下》，终于了解了这个尾巴。还记得第一次看《饥饿游戏》时被那惊艳的服装设计给惊呆了，或是华丽或是简洁的设计真的很符合电影所要表达的世界观。特别是那华丽到铺张浪费的衣服上，确实能好体现都城的贵族气。 对于《饥饿游戏3-嘲笑鸟下》我觉得最好的一点表现就是：政治的表演。在这最后一集用简单粗暴的方式告诉我们政治其实就是这样一个东西，我不知道你懂了没。 对于《黑客帝国》三部曲留给大家最深印象的应该是：架构、视觉特效（慢镜头）、武术指导、长句。里面的富含神学、哲学等内容，适合多看几遍。一两句话去说这部片子都是比较苍白的。此外对于 cyberpunk 这类故事我一直是很热衷的，不管是动画或是电影电视剧。 对于《血色将至》因为是很早以前就看了，今天还没重温，故事细节忘记了太多，但是我依稀记得第一次看完这个片子的时候，我自我感觉对人性的理解有了新的进步。这部片子虽然比较压抑缓慢，很适合在心情平静的情况下看。 电影、书、动画等都是一种表现手法，作者只是借着各种媒介来表达自己的内心想法，所以希望你不管年龄在哪里，都可以静下来好好欣赏一个好的作品，不管它是以怎样的方式来体现的。 最后：本篇的文字也有一个内心想法想要告诉大家，那、就、是：YouMeek 公众号开通了赞赏功能，要不要和我一起测试下微信这功能有没有 Bug 呢(≧▽≦)* 血色将至, 黑客帝国, 黑客帝国2, 黑客帝国3, 穆赫兰道, 老无所依, 暖暖内含光, 窃听风暴, 人类之子, 十二宫, 饥饿游戏3, 对她说, 爱, 上帝之城, 花样年华, 一一, 刺客聂隐娘","link":"/2016/11/27/year-end-movie-list/"},{"title":"一篇关于react历史的流水账","text":"react 目前已经更新到 V16.3，其一路走来，日臻完善，笔者接触 react 两年有余，在这里做一个阶段性的整理，也对 react 的发展和我对 react 的学习做一个整体记录。 笔者是在 16 年初开始关注 react，而实际上那个时候 react 已经发布快三年了， 16 年初的我写页面还是主要使用 backbone.js、Jquery，并且认为，相比于纯粹使用 Jquery 的“刀耕火种”的时代，使用 backbone.js 已经足够方便并且不需要替代品了。 这篇文章会从 react 开源之初进行讲起，直到 2018 年六月。 为什么是 react我们知道，react 并不是一个 MVC 框架，也并没有使用传统的前端模版，而是采用了纯 JS 编写（实际上用到了 JSX ），使用了虚拟 DOM，使用 diff 来保证 DOM 的更新效率，并且可以结合 facebook 的 Flux 架构，解决传统 MVC 模式的一些痛点。 在 react 开源之初，相关生态体系并不完善，甚至官方还在用Backbone.Router加 react 来开发单页面应用。 但是那个时候的 react，和现在的 react，解决的核心问题都没有变化，那就是复杂的UI渲染问题（ complex UI rendering ），所有的它的组件化，虚拟 DOM 和 diff 算法，甚至目前提出的 Fiber、async rendering等等，都是围绕这个中心。 FLUX在 2014 年五月左右，也就是距离 react 开源接近一年时间，react 公开了 FLUX 架构。当然，我们现在在学习的过程中，甚至都很难听到 FLUX 这个词汇了，更多的则是 redux 甚至 dva 等更上层的框架，但是目前绝大多数 react 相关的数据管理框架都受到了 FLUX 很大启发。 FLUX 和双向数据绑定的关系，我认为这里有必要援引当初官方写的一点解释（更详细的一些信息，可以看这篇文章）： To summarize, Flux works well for us because the single directional data flow makes it easy to understand and modify an application as it becomes more complicated. We found that two-way data bindings lead to cascading updates, where changing one data model led to another data model updating, making it very difficult to predict what would change as the result of a single user interaction. 总而言之，Flux对我们来说效果很好，因为单向数据流可以让应用程序变得更加复杂，从而轻松理解和修改应用程序。我们发现双向数据绑定导致级联更新，其中更改一个数据模型导致另一个数据模型更新，使得很难预测单个用户交互的结果会发生什么变化。 从此之后，下面这张图便多次出现在官方博客和各个网站中，相信我们也肯定见过下图： react-router2014年8月，react-router 的雏形发布，在其发布之前，不少示例应用还在使用 backbone.js 的 router，而 react-router 的发布，标志着 react 生态的进一步成熟。 react ES6 Class实际上，在 2015.01.27 之前，我们都是在使用 React.createClass来书写组件。 而在 2015.01.27 这一天，也就是第一届 reactjs conf 的前一天，react 官方发布了 React V0.13.0 beta 版本。这一个版本的最大更新就是支持 ES6 的 Class 写法来书写组件，同时也公布了比如 propTypes 类型检查、defaultProps、AutoBind、ref 等一系列相关工作在 ES6 Class 模式下的写法。 这次发布是 react 开源至此最为重大的一次更新，也因此直接将 react 的写法进行了革新，在我看来，这标志着 react 从刀耕火种的原始时代进入了石器时代。 实际上，直到一个半月后的 03.10 ，V0.13 的正式版本才发布。 而在之后的 V15.5 版本（2017年4月发布），react 才将React.createClass的使用设置为 Deprecation，并且宣布会在将来移除该 API，与此同时，react 团队仍然提供了一个单独的库create-react-class 来支持原来的 React.createClass 功能。 Relay &amp; GraphQL在 2015 年的 2月，Facebook 公布了 GraphQL，GraphQL 是一种新的数据查询解决方案，事实证明，它是非常优秀的一个解决方案，到现在已经基本在行业内人尽皆知。 而 Relay 则是链接 react 和 GraphQL 的一个解决方案，有点类似 redux（但是 stat 数只有 redux 的四分之一左右），但是对 GraphQL 更为友好，并且在缓存机制的设计（按照 Graph 来 cache）、声明式的数据获取等方面，有一些自己的独到之处。 当然，我们使用 redux 配合相关插件，也可以不使用 Relay。 React Native在第一届 React.js Conf 中，react 团队首次公开了 React Native，并且在3月份真正开源了 React Native（实际上这个时候安卓版本还并不可用），之后在2015年上半年，相关团队陆陆续续披露了关于 React Native 发展情况的更多信息。 并且也是在这个时候（2015年3月），react 团队开始使用 learn once, write anywhere 这个如今我们耳熟能详的口号。 react &amp; react-dom &amp; babel在2015年七月，官方发布了React v0.14 Beta 1，这也是一个变动比较大的版本，在这个版本中，主要有如下比较大的变化: 官方宣布废弃 react-tools 和 JSTransform，这是和 JSX 解析相关的库，而从此 react 开始使用 babel，我认为这对 react 以及其使用者来说无疑是一个利好。 分离 react 和 react-dom，由于 React Native 已经迭代了一段时间，这个分离同时也意味着 react 之后的发展方向，react 本身将会关注抽象层和组件本身，而 react-dom 可以将其在浏览器中落地，React Native 可以将其在客户端中落地，之后也许还会有 react-xxx … 将 react 和 react-dom 分离之后，react 团队又对 react-dom 在 dom 方面做了较为大量的更新。 Discontinuing IE 8 Support在 react V15 的版本中，放弃了对 IE 8 的支持。 Fiberreact 团队使用 Fiber 架构完成了 react V16 的开发，得益于 Fiber 架构，react 的性能又得到了显著提升（尤其是在某些要求交互连续的场景下），并且包大小缩小了 32%。 到目前来说，关于 Fiber 架构的中英文资料都已经相当丰富，笔者在这里就不进行过多的赘述了。 接下来的展望react 团队目前的主要工作集中在 async rendering 方面，这方面的改进可以极大提升用户交互体验（特别是在弱网络环境下），会在 2018 年发布。 如果你对这方面的内容很感兴趣，不妨看看 react 之前的演讲视频 附录1 一些你可能不知道的变化 react并非直接将 JSX 渲染成 DOM，而是对某些事件和属性做了封装（优化）。 react 对表单类型的 DOM 进行了优化，比如封装了较为通用的 onChange 回调函数，这其中需要处理不少问题，react 在 V0.4 即拥有了这一特性，可以参考这里 事实上，react 在V0.8之前，一直在以“react-tools”这个名字发布，而 npm 上面叫做 react 的实际上是另外一个包，而到 V0.8 的时候，react 团队和原来的 “react” 包开发者协商，之后 react 便接管了原来的这个包，也因此，react并没有 V0.6 和 V0.7，而是从 V0.5 直接到了 V0.8 react 从 V0.14 之后，就直接跳跃到了 V15，官方团队给出的理由是，react 很早就已经足够稳定并且可以使用在生产版本中，更改版本的表达方式更有助于表示 react 项目本身的稳定性。 附录2 一些比较优秀的博客 关于React Components, Elements, 和 Instances，如果你还有一些疑问，可以看一看React官方团队的文章：React Components, Elements, and Instances 如果你倾向于使用 mixins，不妨看看 react 关于取消 mixin的说法：Mixins Considered Harmful react props 相关的开发模式的建议，我认为目前在使用 react 的程序员都应该了解一下You Probably Don’t Need Derived State","link":"/2018/06/10/%E4%B8%80%E7%AF%87%E5%85%B3%E4%BA%8Ereact%E5%8E%86%E5%8F%B2%E7%9A%84%E6%B5%81%E6%B0%B4%E8%B4%A6/"},{"title":"二向箔","text":"建议放这首歌曲阅读 碎碎念为什么我会有写这个文章的念头？最近我看完了《三体》，你问我看懂没有，我不懂，但是里面基本的空间，物理学知识还可以看懂，就像是同一个分类里面的熵，你问我看懂没有了我也没看懂，呵~，这个《三体》的话，说简单点就是看视频吧。我把B站文曰大佬的 足足86分钟呢，嘿嘿嘿... 切入正题什么是降维打击？为什么我会把这个放在“二向箔”前面？因为我觉得这个是二向箔的命根子，现在切入书中….. 歌者 以下为《三体Ⅲ：死神永生》第五部片段 翻阅坐标数据是歌者的工作，判断坐标诚意是歌者的乐趣。 歌者知道自己做的不是什么大事....歌者翻阅坐标时正在英唱这一首古歌谣： 歌者的歌谣 我看到了我的爱恋 我飞到她的身边 我捧出给她的礼物 那是一小块凝固的时间 时间上有美丽的条纹 摸起来像浅海的泥一样柔软 她把时间涂满全身 然后拉起我飞向存在的边缘 这是灵态的飞行 我们眼中的星星像幽灵 星星眼中的我们也像幽灵 …… .... \"我需要一块二向箔，清理用。\" \"给\"长老给了歌者一块二向箔. 二向箔悬浮在歌者的眼前，是封装状态，晶莹剔透。虽然周是普通的东西，但歌者喜欢它。它并不喜欢安贵的东西，太爆裂，他就喜欢二向箔体现的这种最硬的柔软，能把死亡唱成一首歌的唯美。 .... 梗概歌者是该文明中唯一一位被作者赋予名字的外星文明个体，因此也成为了该文明的代名词。实际上这并不是这一文明的真正名称，关于它们的绝大多数资料都是模糊和未知的。 虽然证据有限，但是一种主流猜测认为歌者所在的文明是一个古老的硅基或碳基文明。而随着文明的进步，它们逐渐进化为依靠虚拟交互生存的虚拟信息化文明。但是歌者文明仍然保有一定比例的活性个体（如长老和歌者）来辅助运作一些虚拟生命无法完成的任务，其证据正是基于小说中两个个体之间的对话和对歌者自身的描述。 相对于太阳系中的人类，歌者文明的强大毫无争议。 但是歌者所在的文明自身也陷入到了生存危机，它们正与被称为“边缘世界”的敌人展开激烈的星际战争，而且随着战况的变迁，主动转为被动，战局越来越不利于歌者的“母世界”。于是“母世界”在意识到常规战争已经无力谋求最终胜利后，便开始着手准备“全面二维化”，也就是将自己能触及到的全部三维宇宙空间和自己一同送入二维宇宙从而一举消灭所有无法在二维宇宙生存的敌人。歌者的“母世界”是虚拟文明的现实决定了它们在经过改造后，有能力在进入二维宇宙后继续存活，而它们的敌人“边缘世界”就未必了。 歌者文明的描述可能暗指了文明发展的另一个方向——基于数据体的虚拟文明。但是即使文明实现数据化，对资源的争夺仍然是首要的——姑且不提文明发展和扩展必然涉及的物质利用，仅仅从安全上的考量上看，数据体文明就需要大量的实体武器以免数据载体遭到毁坏。况且即使自身放弃资源掠夺，仍然无法肯定其他文明的“判断”，而其他文明也无法保证这个强大的数据体不会在某一天突然对自己发起攻击。这就是另一个意义上的猜疑链，即使强大如母世界也无法摆脱。 好了，接下来让我们进入解刨，啊，错了，剖析歌者这个神奇的文明 歌者的古老童瑶 我看到了我的爱恋 我飞到她的身边 我捧出给她的礼物 那是一小块凝固的时间 时间上有美丽的条纹 摸起来像浅海的泥一样柔软 她把时间涂满全身 然后拉起我飞向存在的边缘 这是灵态的飞行 我们眼中的星星像幽灵 星星眼中的我们也像幽灵 …… 意义之塔这是歌者文明追求的一切，就像法律书写在石塔上那样，“意义之塔”上记录一个文明的追求和价值观。在歌者文明的塔上，最高的是生存。 我们已知的歌者文明的塔上的内容：生存，乐趣，在不断熵增的宇宙中保持和提高自己的低熵水平。其中乐趣是最不重要的。在开战之后，乐趣因为意义地位较低，很大程度上被遗忘了。 在意义之塔的更高处，在歌者文明看不到的高处，还有更高的意义。但这不是这个层次的文明所能考虑和理解的事情。 这个文明层次最大的矛盾和任务，是生存。为了生存，他们必须战争、隐藏和清理。 把海弄干的鱼咳咳，不说了，切回正题 记得在《三体》中魔戒说：“把海弄干的鱼先上了陆地，从一片黑暗森林奔向另一片黑暗森林。” 我草率得理解了一下，大致是这样子。 \"把海弄干的鱼先上了陆地\"的意思大概就是高纬度的生物先把自己改造成了低纬度的生物，海指的是高纬度，这里的鱼指的是维度打击者。但是却有一个问题，不同的维度对资源的使用是不同的，就比如说我们三维生物用木头造门，是为了把别人低挡在外面。但是在四维（只是举个例子），没有门这个概念，四维没有遮挡，直接穿透...所以就可以知道这么个道理：只有同维度的物种间才存在黑暗森林威慑。不同维度的物种间利用资源的方式是不同的，不存在威胁，不存在黑暗森林。高维物种降维打击后进去低维度空间，所以说\"从一片黑暗森林奔向另一片黑暗森林。\" 也就是说，发动降维打击者可能会先把自己改造成低纬度的生物，比如说魔戒；然后对自己之前或者更高的维度进行打击。它们就是把“海”弄干的“鱼” 二向箔三维空间由长度、面积、体积三个维度构成。而二向箔与三维宇宙接触的瞬间，会使其中一个维度由宏观蜷缩到微观，迫使三维宇宙及其中的所有物质向二维宇宙坍塌，并在二维空间中“融化”为只存在长度和面积而失去了体积概念的绝对平面。 歌者在2403年朝太阳系投掷了二向箔，同年太阳系和和绝大多数地球人被二维化而灭亡。但根据小说细节可知，毁灭太阳系的二向箔要先于歌者，表明地球坐标暴露后，太阳系实际上已经遭到大量外星文明的集火，灭亡只是时间问题。 二向箔所造成的空间二维化永远不会停止，并且维度坍塌速度会逐渐达到光速。但倘若能借助曲率引擎等手段以光速先行逃离，那么摆脱二维化的命运依然是可能的。然而由于所有的宇宙规律都已被不择手段的星际文明们武器化并频繁使用，因此宇宙本身正在逐渐解体。 超弦理论描述下的宇宙时空由十个空间维度和单个时间轴共同组成，而维度武器的存在，暗示了高维宇宙已经或正在走向毁灭，其中的幸存者通过改造自身逃入了维度更低的宇宙。如今部分强大的三维文明也开始主动转化为二维生命以求在二维宇宙这一平面世界中继续生存。 描述由于科技水平上的巨大差距，地球文明在毁灭前仅有的一些观察和研究直到最后也未能触及二向箔的本质，通常认为剧情中先行离开太阳系的银河系人类可能对二向箔一类的维度武器有更深刻的认知。二向箔的实质可能只是单纯的一小片二维空间，也可能是真空衰变的产物，亦或者是更加难以理解的存在。二向箔在封装状态下由特制力场束缚，可永久保存，呈现出晶莹剔透的透明纸片状，而待机状态下其封装力场逐渐消散时会发出柔和的白光，看起来就像是一张完全无害的二维薄膜，并以光速飞向目的地。当二向箔逼近目的地时，其速度会迅速降低至光速的千分之一，此时它会出现明显的引力波特征。根据地球人的检测，这种引力波极为强烈，通常只来自于大质量的天体，因此二向箔理论上应该有接近木卫二的质量。但是被力场束缚着的二向箔却只有一张卡纸这么大，暗示了其本身隐藏着难以想象的能量。而当二向箔抵达目标空间后，封装力场就会逐渐消散直至最终消失，最终此武器接触到三维空间并不可逆地发动，将三维空间中的一个维度由宏观蜷缩到微观，导致三维立体空间塌陷，变成二维平面空间并不断扩展。而二维化的进程如同一个巨大的气泡无休无止的膨胀。在这个“气泡”膨胀的同时，周遭的三维空间本身也会逐渐被拉入气泡之中，就如同一个正在急速向外扩张的瀑布口，周围的物体还没有跌入其中，就已经被湍急的水流拉了过去。而这个瀑布是360°全方位的，没有任何一个角度可以摆脱被吞没的厄运，想要逃出生天，就必须赶在被瀑布吞噬前达到逃逸速度，而这个速度正是光速。这就是为什么当第一批遇难者的飞船以反方向推动引擎至最大功率，直至达到光速的15%时，仍然震惊的发现自己依旧在缓缓的向二向箔产生的二维空间“跌落”，最后只得眼睁睁的看着自己卷入二维宇宙之中。被卷入其中的所有三维物质不可避免地变为二维，丧失大量物理特性并在失去厚度概念后崩解，留下没有光学特征（由于二维物体没有厚度，因此光线将直接穿透二维物体而不会产生任何反射，完成二维化的物体逐渐变的透明以至无法目睹到）但有质量的二维平面残骸。这些平面残骸绝不是简单的被压扁，而是在失去高度轴后逐渐“融化”为一张物体“平面设计图”。理论上被二维化的物体可以展现出这些物体本身的全部细节，并以一种没有任何重叠存在的平面展开状态呈现出来。 三维物体被迫融化为二维物体后，期间大量无法直接转移到二维宇宙的物理特征丢失，并还原成纯粹的能量释放出来，正因如此，太阳系被二维化时，庞大的能量源源不断的覆盖在二维平面之上，以至于人类仅用肉眼就可以观察到那些被二维化的平面残骸。无论是那些被绝望所吞没且扭曲的平面人体，还是苦苦挣扎却还是被二维宇宙所支配的平面太阳，都清晰的映照在逃亡者的眼里。但是当二维化最终完成，这些平面残骸残存的能量耗尽后便会彻底湮灭在黑暗之中，成为没有厚度，不存在光学特征的二维物体，无法直接被观察到。而另一方面，伴随着三维宇宙的解体，二维化的坍塌速度却在不断增加，直至达到真空中的光速。在《三体》中，真空中的光速被设为宇宙内的最大速度，且没有对虫洞以及空间跳跃技术的描写（维度武器的存在实际上暗示了高维宇宙的毁灭，而虫洞等超光速科技需要四维甚至更多维度才能实现，因此在宏观世界开发基于更高维度空间的科技已经是不可能的了），所以此武器对不掌握光速航行技术的常规文明是绝对致命的巨大威胁。 二向箔发动后无法停止，因此可能会导致使用者本身也会跌落到二维。使用该维度武器的文明被描述为掌握了把自身改造成二维生命而保持在二维空间继续生存的技术，因此不受宇宙二维化的威胁。此外由于二向箔的原理是使一个维度由宏观蜷缩到微观，原本的高维空间并不是消失了，而是进入了微观状态而已。所以理论上若是文明把自己改造成微观生命，就可以在处于微观状态下的高维宇宙中生存（就像《三体Ⅰ》中被读者称为魔眼文明的微观宇宙文明一样，对于它们来说，它们生活的质子就是一个九维的高维空间），也不必惧怕二维化。而维度武器实际上已经在整个宇宙被大量的星际文明频繁的使用，很可能正是因为这些先进的文明已经拥有了在低维宇宙或微观宇宙中生存的能力，因此便反过来导致了它们对这一类维度武器的滥用。即便对于打算毁灭太阳系的歌者而言，二向箔也仅仅是非常基础和经济的清理工具，在其之上必然存在着“更为暴烈”的武器。歌者本人甚至也只是这个文明群体中地位最卑微的一位“清洁工”。 外观长方形膜状物，长八点五厘米，宽五点二厘米，比一张信用卡略大一些，极薄，看不出任何厚度。封装状态下晶莹剔透、无色透明。待机模式下由于封装力场逐渐蒸发，会发出白光，使其表面呈纯白色，看上去就是一张纸条。 二向箔的原理其实从本质上说人类文明的劲敌-三体人的水滴（强相互作用力探测器）的科技还是经典物理学的利用，不过是将经典物理学运用到了极致。但是二向箔则是维度的变化，其利用宇宙规律作为武器，使对象从三维降到二维，导致大量的能量和物质信息丢失，最终泯灭于三维宇宙之中。 空间二维化，本质上说是将原本的三维空间中的单个维度卷曲压缩，进而实现对空间的逐步吞噬和拆解，原来的三维空间多数部分将不复存在，变成了二维的了。其实这是一个无限缩小和拆解的过程，一个点和一根线段比起来，长度为零。一根线段与一个平面比起来，面积为零。同样，一个二向箔与任何一个有限的三维体比起来，体积为零。 我们可以这样想象二向箔：在二向箔中，二维化的能量场极低。当我们像《三体》中想象的那样，用特制的力场将未被激活的二向箔包起来，它就不会危害我们的三维空间。 可是，当二向箔一旦与三维空间赤裸裸地接触，它就变得像沸水中的气泡那样，开始膨胀起来，但由于它是二维的，只会增大面积，像气泡一样不断扩张体积的是它产生的二维化进程。它触发我们三维空间的能量场向能量更低的地方跳。在这个场跳的同时，二向箔却越长越大。 也有部分读者认为二向箔的原理是真空衰变，也就是一块力场包裹的绝对真空 研发历史通过对基本粒子结构的拆分再重组，构造一个空间结构完全不同的区域。用力场隔离其和正常空间的接触。 维度武器的存在，可能暗示了现存的三维宇宙本身就是高维宇宙遗留下来的废墟，并且战争还在延续，仅存的三维空间仍然在进一步解体。从另一个角度也说明，二向箔和它所属的维度武器有着人类无法想象的悠久历史。 攻击范围和影响未知，影响范围会迅速扩大，但三维跌落的速度止步于光速。至于对遥远宇宙的影响未知，根据小说描述，如果时间足够长，可能使宇宙全部跌落到二维。但是根据书中人物的经历时间，二向箔并没有使宇宙全部跌落，因此二向箔影响范围应该是星系级别的，由于三维宇宙自身的膨胀（四维宇宙向三维宇宙的跌落），单个二向箔或许永远无法染指全宇宙。 单个维度武器的影响力注定有限，究其原因可能正是因为宇宙的膨胀，宇宙膨胀速度大于光速，因此被打击星系与距离其较远的星系相互离开的速度可能凌驾于光速之上，即大于三维空间跌落的速度。因此与打击星系之间距离为某段常数值的星系可能避免跌落至二维，又能使被打击星系中的文明能够到达此星系。 使周围的三维空间向二维跌落，并且二维范围迅速扩大。根据小说描述其逃逸速度为光速，除非被攻击文明拥有可以达到光速的飞船，否则任何物体均无法幸免。此方法比使用质量点杀伤范围更彻底。根据实际情况，被攻击文明如有达到光速的飞船，是能够逃脱的。 大刘在书中借关一帆之口说了：“三维向二维的跌落永远也不可能休止！” 副作用由于作用范围可能会扩大，最终使用者本身也可能跌落至二维，所以一般限制使用。但是向太阳系攻击的文明似乎开始改造自身以适应二维宇宙，以便消灭对手，同时避免自身灭亡。但这也可能导致最后整个宇宙全部跌落至二维的后果。 如何保存用特制的力场封装，以便与周围世界隔开，防止对己方产生危害。根据封装方式可知理论上二向箔可以隔离并防止扩散，但实际除了提到歌者文明进行了一些简单限制之外，未有文明防止二向箔扩散的描述。 情节在太阳系内行星带激活后约九天时间便将整个太阳系二维化。除了多年前已经逃离太阳系的“星舰地球”文明的人类和通过光速飞船逃脱的程心和艾AA逃脱了攻击以外，人类几乎全军覆没。另外，据长老和“歌者”（歌者文明的一名基层宇宙物质清理员，歌者文明即由其的名称命名，因为小说中并没有说明歌者所在的文明的名称）的对话可知二向箔已在其他很多战场被各种文明使用，已经造成三维宇宙的广泛崩解。 注：歌者的飞船是在银河系猎户座旋臂，掩体纪元67年（以地球为参照系）对太阳系发射的二向箔。而人类观测到的对太阳系发动黑暗森林打击的飞船是在掩体纪元66年（以地球为参照系），位于太阳系奥尔特星云外围，距离太阳一点三光年的位置发射的二向箔。太阳系收到二向箔是在掩体纪元67年。虽然二向箔是以光速飞行，但也不会使时间倒流。所以歌者向太阳系发出二向箔时，已经有另一个二向箔要到达太阳系了。人类观测到的那艘发射二向箔的飞船不是歌者的飞船，毁灭太阳系的二向箔也不是歌者发射的那个。 在黑暗森林里，不止一个猎人对地球开了枪。这也正好印证了长老对歌者所说的话：“你再快也有比你快的。”","link":"/2020/11/28/%E4%BA%8C%E5%90%91%E7%AE%94/"},{"title":"从Linux内核理解JAVA的NIO","text":"前言IO 可以简单分为磁盘 IO 和 网络 IO ,磁盘 IO 相对于网络 IO 速度会快一点，本文主要介绍 磁盘 IO ，网络 IO 下周写。 JAVA 对 NIO 抽象为 Channel , Channel 又可以分为 FileChannel （磁盘 io）和 SocketChannel （网络 io）。 如果你对 IO 的理解只是停留在 api 层面那是远远不够的，一定要了解 IO 在系统层面是怎么处理的。 本文内容： FileChannel 读写复制文件的用法。 ByteBuffer 的介绍 jvm 文件进程锁，FileLock HeapByteBuffer ，DirectByteBuffer 和 mmap 谁的速度更快 从 Linux 内核 中的 虚拟内存 、系统调用、文件描述符、Inode、Page Cache 、缺页异常讲述整个 IO 的过程 jvm 堆外的 DirectByteBuffer 的内存怎么回收 本文计算机系统相关的图全部来自 《深入理解计算机系统》 对 Linux 的了解都是来自书上和查阅资料，本文内容主要是我自己的理解和代码验证，有的描述不一定准确，重在理解过程即可。 NIONIO 是 从 Java 1.4 开始引入的，被称之为 Non Blocking IO，也有称之为 New IO。 NIO 抽象为 Channel 是面向缓冲区的（操作的是一块数据），非阻塞 IO。 Channel 只负责传输，数据由 Buffer 负责存储。 NIO 是 从 Java 1.4 开始引入的，被称之为 Non Blocking IO，也有称之为 New IO。 NIO 抽象为 Channel 是面向缓冲区的（操作的是一块数据），非阻塞 IO。 Channel 只负责传输，数据由 Buffer 负责存储。 BufferBuffer 中的 capacity、limit 和 position 属性是比较重要的，这些弄不明白，读写文件会遇到很多坑。 capacity 标识 Buffer 最大数据容量，相等于一个数组的长度。 limit 为一个指针，标识当前数组可操作的数据的最大索引。 position 表示为下一个读取数据时的索引 public void run1() { // `DirectByteBuffer` final ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024); // `HeapByteBuffer` final ByteBuffer allocate = ByteBuffer.allocate(1024); } HeapByteBuffer 会分配在 Jvm堆内，受 JVM 堆大小的限制，创建速度快，但是读写速度慢。实际底层是一个字节数组。 DirectByteBuffer 会分配 Jvm 堆外，不受 JVM 堆大小的限制，创建速度慢，读写快。DirectByteBuffer 内存在 Linux 中，属于进程的堆内。DirectByteBuffer 受 jvm 参数 MaxDirectMemorySize 的影响。 设置 jvm 堆 100m，运行程序报错 Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space。因为指定了 jvm 堆为 100m，然后一些 class 文件也会放在 堆中的，实际堆内存时不足 100m,当申请 100m 堆内存只能报错了。 public class BufferNio { // -Xmx100m public static void main(String[] args) throws InterruptedException { // HeapByteBuffer 是 jvm 堆内，因为堆不足分配 100m(java 中的一些 class 也会占用堆)，导致 oom System.out.println(&quot;申请 100 m `HeapByteBuffer`&quot;); Thread.sleep(5000); ByteBuffer.allocate(100 * 1024 * 1024); }; }; 设置 jvm 堆为 100m，MaxDirectMemorySize 为 1g，死循环创建 DirectByteBuffer，打印 10 次 申请 directbuffer 成功，报错 Exception in thread \"main\" java.lang.OutOfMemoryError: Direct buffer memory，后面再说这个堆外的 DirectByteBuffer 怎么进行回收。 public class BufferNio { // -Xmx100m -XX:MaxDirectMemorySize=1g public static void main(String[] args) throws InterruptedException { System.out.println(&quot;申请 100 m DirectByteBuffer&quot;); final ArrayList&lt;Object&gt; objects = new ArrayList&lt;&gt;(); while (true) { // DirectByteBuffer 不在 jvm 堆内，所以可以申请成功，但是不是无限制的，也有限制（MaxDirectMemorySize） final ByteBuffer byteBuffer = ByteBuffer.allocateDirect(100 * 1024 * 1024); objects.add(byteBuffer); System.out.println(&quot;申请 directbuffer 成功&quot;); System.out.println(ManagementFactory.getMemoryMXBean().getHeapMemoryUsage()); System.out.println(ManagementFactory.getMemoryMXBean().getNonHeapMemoryUsage()); }; }; }; FileChannel读文件@Test public void read() throws IOException { final Path path = Paths.get(FILE_NAME); // 创建一个 FileChannel,指定这个 channel 读写的权限 final FileChannel open = FileChannel.open(path, StandardOpenOption.READ); // 创建一个和这个文件大小一样的 buffer，小文件可以这样，大文件，循环读 final ByteBuffer allocate = ByteBuffer.allocate((int) open.size()); open.read(allocate); open.close(); // 切换为读模式，position=0 allocate.flip(); // 用 UTF-8 解码 final CharBuffer decode = StandardCharsets.UTF_8.decode(allocate); System.out.println(decode.toString()); } 写文件@Test public void write() throws IOException { // 通道具有写权限，create 标识文件不存在的时候创建 final FileChannel open = FileChannel.open(path, StandardOpenOption.WRITE, StandardOpenOption.CREATE); final ByteBuffer allocate = ByteBuffer.allocate(1024); allocate.put(&quot;ChenShang aaaaa-1111111&quot;.getBytes(StandardCharsets.UTF_8)); // 切换写模式，position=0 allocate.flip(); open.write(allocate); open.close(); } CV大法！@Test public void copy() throws IOException { final Path srcPath = Paths.get(FILE_NAME); final Path destPath = Paths.get(&quot;demo&quot; + FILE_NAME); final FileChannel srcChannel = FileChannel.open(srcPath, StandardOpenOption.READ); final FileChannel destChannel = FileChannel.open(destPath, StandardOpenOption.WRITE, StandardOpenOption.CREATE); // transferTo 实现类中，用的是一个 8M MappedByteBuffer 做数据的 copy ,但是这个方法只能 copy 文件最大字节数为 Integer.MAX srcChannel.transferTo(0, srcChannel.size(), destChannel); destChannel.close(); srcChannel.close(); } FileLockFileLcok 是 jvm 进程文件锁，在多个 jvm 进程间生效，进程享有文件的读写权限，有共享锁 和 独占锁。 同一个进程不能锁同一个文件的重复区域，不重复是可以锁的。 同一个进程中第一个线程锁文件的 （0，2），同时另一个线程锁（1，2），文件锁的区域有重复，程序会报错。 一个进程锁（0，2），另一个进程锁（1，2）这是可以的，因为 FileLock 是 JVM 进程锁。 运行下面程序两次，打印结果为 第一个程序顺利打印 获取到锁0-3,代码没有被阻塞 获取到锁4-7,代码没有被阻塞 第二个程序打印 获取到锁4-7,代码没有被阻塞 获取到锁0-3,代码没有被阻塞 第一个程序运行的时候，file_lock.txt 的 0-2 位置被锁住了，第一个程序持有锁 10 s,第二个程序运行的时候，会在这里阻塞等待 FileLock，直到第一个程序释放了锁。 public class FileLock { public static void main(String[] args) throws IOException, InterruptedException { final Path path = Paths.get(&quot;file_lock.txt&quot;); final FileChannel open = FileChannel.open(path, StandardOpenOption.WRITE, StandardOpenOption.READ); final CountDownLatch countDownLatch = new CountDownLatch(2); new Thread(() -&gt; { try (final java.nio.channels.FileLock lock = open.lock(0, 3, false)) { System.out.println(&quot;获取到锁0-3,代码没有被阻塞&quot;); Thread.sleep(10000); final ByteBuffer wrap = ByteBuffer.wrap(&quot;aaa&quot;.getBytes()); open.position(0); open.write(wrap); Thread.sleep(10000); } catch (IOException | InterruptedException e) { e.printStackTrace(); } finally { countDownLatch.countDown(); } }); .start(); Thread.sleep(1000); new Thread(() -&gt; { try (final java.nio.channels.FileLock lock = open.lock(4, 3, false)) { System.out.println(&quot;获取到锁4-7,代码没有被阻塞&quot;); final ByteBuffer wrap = ByteBuffer.wrap(&quot;bbb&quot;.getBytes()); open.position(4); open.write(wrap); } catch (IOException e) { e.printStackTrace(); } finally { countDownLatch.countDown(); }; }); .start(); countDownLatch.await(); open.close(); }; }; 当将上面的程序第二个线程改为 java.nio.channels.FileLock lock = open.lock(1, 3, false) ，因为同一个进程不允许锁文件的重复区域，程序会报错。 Exception in thread \"Thread-1\" java.nio.channels.OverlappingFileLockException HeapByteBuffer 和 DirectByteBuffer 谁的读写效率高？FileChannel 的实现类 FileChannelImpl，当读写 ByteBuffer 会判断是否是 DirectBuffer，不是的话，会创建一个 DirectBuffer，将原来的的 Buffer 数据 copy 到 DirectBuffer 中使用。所以读写效率上来说，DirectByteBuffer 读写更快。但是 DirectByteBuffer 创建相对来说耗时。 尽管 DirectByteBuffer 是堆外，但是当堆外内存占用达到 -XX:MaxDirectMemorySize 的时候，也会触发 FullGC ，如果堆外没有办法回收内存，就会抛出 OOM。 // 下面这个程序会一直执行下去，但是会触发 FullGC，来回收掉堆外的直接内存 public class BufferNio { // -Xmx100m -XX:MaxDirectMemorySize=1g public static void main(String[] args) throws InterruptedException { System.out.println(&quot;申请 100 m `HeapByteBuffer`&quot;); while (true) { // 当前对象没有被引用，GC root 也就到达不了 DirectByteBuffer ByteBuffer.allocateDirect(100 * 1024 * 1024); System.out.println(&quot;申请 directbuffer 成功&quot;); }; }; }; 死循环创建的 DirectByteBuffer 没有 GC ROOT 到达，对象会被回收掉，回收掉的时候，也只是回收掉堆内啊，堆外的回收怎么做到的呢？ 从 DirectByteBuffer 源码着手，可以看到它有一个成员变量 private final Cleaner cleaner;，当触发 FullGC 的时候，因为 cleaner 没有 gc root 可达，导致 cleaner 会被回收，回收的时候会触发 Cleaner.clean 在Reference.tryHandlePending 触发 方法的调用，thunk 就是 DirectByteBuffer.Deallocator 的示例，这个 run 方法中，调用了 Unsafe.freeMemory 来释放掉了堆外内存. public class Cleaner extends PhantomReference&lt;Object&gt; { private final Runnable thunk; public void clean() { if (remove(this)) { try { this.thunk.run(); } catch (final Throwable var2) { AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { if (System.err != null) { (new Error(&quot;Cleaner terminated abnormally&quot;, var2)).printStackTrace(); } System.exit(1); return null; } }); } } } } 内存映射 当应用程序读文件的时候，数据需要从先从磁盘读取到内核空间第一次读写，没有pagecache缓存数据，在从内核空间 copy 到用户空间，这样应用程序才能使用读到的数据。当一个文件的全部数据都在内核的 Page Cache 上时，就不用再从磁盘读了，直接从内核空间 copy 到用户空间去了。 应用程序对一个文件写数据时，先将要写的数据 copy 到内核 的 page cache，然后调用 fsync 将数据从内核落盘到文件上（只要调用返回成功，数据就不会丢失）。或者不调用 fsync 落盘，应用程序的数据只要写入到 内核的 pagecache 上，写入操作就算完成了，数据的落盘交由 内核 的 Io 调度程序在适当的时机来落盘（突然断电会丢数据，MySQL 这样的程序都是自己维护数据的落盘的）。 我们可以看到数据的读写总会经过从用户空间与内核空间的 copy ,如果能把这个 copy 去掉，效率就会高很多，这就是 mmap （内存映射）。将用户空间和内核空间的内存指向同一块物理内存。内存映射 英文为 Memory Mapping ,缩写 mmap。对应系统调用 mmap 这样在用户空间读写数据，实际操作的也是内核空间的，减少了数据的 copy 。 怎么实现的呢，简单来说就是 linux 中进程的地址是虚拟地址，cpu 会将虚拟地址映射到物理内存的物理地址上。mmap 实际是将用户进程的某块虚拟地址与内核空间的某块虚拟地址映射到同一块物理内存上，已达到减少数据的 copy 。 用户程序调用系统调用 mmap 之后的数据的读写都不需要调用系统调用 read 和 write 了。 虚拟内存与物理内存的映射计算机的主存可以看做是由 M 个连续字节组成的数组，每个字节都有一个唯一物理地址 (Physical Address)。 Cpu 使用的 虚拟寻址 （VA,Virtual Address） 来查找物理地址。 CPU 会将进程使用的 虚拟地址 通过 CPU 上的硬件 内存管理单元 (Memory Management Unit MMU) 的进行地址翻译找到物理主存中的物理地址，从而获取数据。 当进程加载之后，系统会为进程分配一个虚拟地址空间，当虚拟地址空间中的某个 虚拟地址 被使用的时候，就会将其先映射到主存上的 物理地址。 当多个进程需要共享数据的时候，只需要将其虚拟地址空间中的某些虚拟地址映射相同的物理地址即可。 通常我们操作数据的时候，不会一个字节一个字节的操作，这样效率太低，通常都是连续访问某些字节。所以在内存管理的时候，将内存空间分割为页来管理，物理内存中有物理页（Physical Page），虚拟内存中有 Virtual Page 来管理。通常页的大小为 4KB。 系统通过 MMU 和 页表（Page Table） 来管理 虚拟页 和 物理也 的对应关系，页表就是页表条目（Page Table Entry,PTE）的数组 PTE 的有效为1时，标识数据在内存中，标识为 0 时，标识在磁盘上。 当访问的虚拟地址对应的数据不再物理内存上时，会有两种情况处理： 1、在内存够用的时候，会直接将虚拟页对应在磁盘上的数据加载到物理内存上， 2、当内存不够用的时候，就会触发 swap,会根据 LRU 将最近使用频率比较低的虚拟页对应物理也淘汰掉，写入到磁盘中去，淘汰掉一部分物理内存中的数据，然后对对应的虚拟页设置为 0，然后将磁盘上的数据再加载到内存中去。 进程的虚拟内存Linux 会为每个进程分配一个单独的虚拟内存地址， 当我们的程序运行的时候，不是整个程序的代码文件一次性全部加载到内存中去，而是执行懒加载。 机械硬盘使用扇区来管理磁盘，磁盘控制器会通过块管理磁盘，系统通过 Page Cache 与磁盘控制器打交道。 一个块包含多个扇区，一个页也包含多个块。 磁盘上会有一个文件对应一个 Inode，Innode 记录文件的元数据及数据所在位置。 当系统启动的时候，这些 Inode 数据会被加载到主存中去。不过系统中的 Inode 还记录他们对应的物理内存中的位置（实际就是对应 Page Cache） ，有的 Inode 对应的数据没有加载到内存中，Inode 就不会记录其对应的内存地址。 程序执行之前会初始化其虚拟内存，虚拟内存会记录代码对应哪些 Innode。 当执行程序的时候，系统会初始化当前程序的虚拟内存，然后运行 main 函数，当发现执行代码时，有的代码没有加载到内存，就会触发缺页异常，将根据虚拟页找到对应的 Innoe ，然后将磁盘中需要的数据加载到内存中，然后将虚拟页标记为已加载到内存，下次访问直接从内存中访问。 Java 中的 mmap看源码我们发现 open.map 返回的也是 DirectByteBuffer，只是这个方法返回的 DirectByteBuffer 使用了不同的构造方法，它绑定了一个 fd 。当我们读写数据的时候是不会触发系统调用 read 和 write 的，也就是内存映射的好处。 public class MMapDemo { public static void main(String[] args) throws URISyntaxException, IOException,InterruptedException { final URL resource = MMapDemo.class.getClassLoader().getResource(&quot;demo.txt&quot;); final Path path = Paths.get(resource.toURI()); final FileChannel open = FileChannel.open(path, StandardOpenOption.READ); // 发起系统调用 mmap final MappedByteBuffer map = open.map(FileChannel.MapMode.READ_ONLY, 0, open.size()); // 读取数据时，不会再出发调用 read,直接从自己的虚拟内存中即可拿数据 final CharBuffer decode = StandardCharsets.UTF_8.decode(map); System.out.println(decode.toString()); open.close(); Thread.sleep(100000); } } 尽管下面这个也是 DirectByteBuffer ，但是它和 mmap 不同的是，他没有绑定 fd，读写数据的时候还是要经过从用户空间到内核空间的 copy ,也会发生系统调用，效率相对 mmap 低。 public class MMapDemo { public static void main(String[] args) throws URISyntaxException, IOException, InterruptedException { final URL resource = MMapDemo.class.getClassLoader().getResource(&quot;demo.txt&quot;); final Path path = Paths.get(resource.toURI()); final FileChannel open = FileChannel.open(path, StandardOpenOption.READ); // 这个 DirectByteBuffer 使用的构造不一样，它会走系统调用 read final ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024); final int read = open.read(byteBuffer); byteBuffer.flip(); System.out.println(StandardCharsets.UTF_8.decode(byteBuffer).toString()); Thread.sleep(100000); } } 追踪代码的系统调用，在 linux 下使用 strace #!/bin/bash rm -fr /nio/out.* cd /nio/target/classes strace -ff -o /nio/out java com.fly.blog.nio.MMapDemo 数据读写速度上 mmap 大于 ByteBuffer.allocateDirect 大于 ByteBuffer.allocate。","link":"/2021/09/10/%E4%BB%8ELinux%E5%86%85%E6%A0%B8%E7%90%86%E8%A7%A3JAVA%E7%9A%84NIO/"},{"title":"从源码分析sentry的错误信息收集","text":"raven.js 是 sentry 为 JavaScript 错误上报提供的 JS-SDK，本篇我们基于其源代码对其原理进行分析，本篇文章只分析前端部分，对应的文件目录是https://github.com/getsentry/sentry-javascript/tree/master/packages/raven-js。 首先抛出几个问题： raven.js 是如何收集浏览器错误信息的？ raven.js 上报的错误信息格式是什么样的？又是如何把这些信息传给后端？支不支持合并上报？ 面包屑（breadcrumbs）是什么？raven.js 如何来收集面包屑信息？ raven.js 如何和框架配合使用（比如 vue、react）？ 在回答以上这几个问题之前，我们首先来对 raven.js 做一个宏观的分析，主要涉及其文件目录、所引用的第三方框架等。 raven.js 的核心文件内容并不多，其中使用了三个第三方库，放在了 vendor 文件夹下： json-stringify-safe ：一个对 JSON.stringify 的封装，安全的 json 序列化操作函数，不会抛出循环引用的错误。 这里面有一个注意点要单独说一下，我们熟知的 JSON.stringify , 可以接受三个参数：第一个参数是我们要序列化的对象；第二个参数是对其中键值对的处理函数；第三个参数是控制缩进空格。reven.js 的 json-stringify-safe 就是充分利用了这三个参数。 md5：js 的 md5 函数。 TraceKit：TraceKit 是一个已经比较完善的错误收集、堆栈格式化的库，reven.js 的功能在很大程度上对它有所依赖。 除此之外，raven.js 支持插件，官方提供的一些知名库的 sentry 插件主要放在了 plugin 文件夹下面，raven.js 的一些核心文件，则放在了 src 文件夹下面。 raven.js 是如何收集错误信息的？我们知道，在前端收集错误，肯定离不开 window.onerror 这个函数，那么我们就从这个函数说起。 实际上，这部分工作是 raven.js 引用的第三方库 TraceKit 完成的： function installGlobalHandler() { if (_onErrorHandlerInstalled) { // 一个起到标志作用的全局变量 return; } _oldOnerrorHandler = _window.onerror; // _oldOnerrorHandler 是防止对用户其他地方定义的回调函数进行覆盖 // 该 _window 经过兼容，实际上就是 window _window.onerror = traceKitWindowOnError; _onErrorHandlerInstalled = true; } 相关错误回调函数交给 traceKitWindowOnError 处理，下面我们来看一下 traceKitWindowOnError 函数，为了避免太多冗余代码，我们仅分析一种主要情况： function traceKitWindowOnError(msg, url, lineNo, colNo, ex) { var exception = utils.isErrorEvent(ex) ? ex.error : ex; //... stack = TraceKit.computeStackTrace(exception); notifyHandlers(stack, true); //... //... if (_oldOnerrorHandler) { return _oldOnerrorHandler.apply(this, arguments); } return false; } 其中调用的最重要的一个函数，就是 computeStackTrace，而这个函数也是 TraceKit 的核心函数，简单来讲，它做的事情就是统一格式化报错信息调用栈，因为对于各个浏览器来说，返回的 Error 调用栈信息格式不尽相同，另外甚至还有的浏览器并不返回调用栈，computeStackTrace 函数对这些情况都做了兼容性处理，并且对于一些不返回调用栈的情况，还使用了 caller 来向上回溯函数的调用栈，最终把报错信息转化成一个键相同的对象数组，做到了报错信息格式的统一。 notifyHandlers 函数则是通知相关的回调函数。 实际上，raven.js 在 install 函数中会调用 TraceKit.report.subscribe 函数，并把对错误的处理逻辑写入回调： function subscribe(handler) { installGlobalHandler(); handlers.push(handler); } 以上过程完成了错误处理过程中的负责角色转换，并且借助 TraceKit，可以使 raven.js 得到一个结构比较清晰的带有格式化好的调用栈信息的错误内容对象，之后，raven.js 对错误内容进一步处理并最终上报。 下面我们对错误处理 raven.js 控制的部分做了一些梳理： _handleOnErrorStackInfo: function(stackInfo, options) { options.mechanism = options.mechanism || { type: 'onerror', handled: false }; // mechanism 和错误统计来源有关 if (!this._ignoreOnError) { this._handleStackInfo(stackInfo, options); } }, _handleStackInfo: function(stackInfo, options) { var frames = this._prepareFrames(stackInfo, options); this._triggerEvent('handle', { stackInfo: stackInfo, options: options }); this._processException( stackInfo.name, stackInfo.message, stackInfo.url, stackInfo.lineno, frames, options ); }, _processException: function(type, message, fileurl, lineno, frames, options) { // 首先根据 message 信息判断是否是需要忽略的错误类型 // 然后判断出错的文件是否在黑名单中或者白名单中 // 接下来对错误内容进行必要的整合与转换，构造出 data 对象 // 最后调用上报函数 this._send(data); } _send: function(data) { // 对 data 进一步处理，增加必要的信息，包括后续会提到的面包屑信息 // 交由 _sendProcessedPayload 进行进一步处理 this._sendProcessedPayload(data); } _sendProcessedPayload: function(data, callback) { // 对 data 增加一些必要的元信息 // 可以通过自定义 globalOptions.transport 的方式来自定义上报函数 (globalOptions.transport || this._makeRequest).call(this, { url: url, auth: auth, data: data, options: globalOptions, onSuccess: function success() { }, onError: function failure(error) { } }); } // 真正发起请求的函数 _makeRequest: function(opts) { // 对于支持 fetch 的浏览器，直接使用 fetch 的方式发送 POST 请求 // 如果浏览器不支持 fetch，则使用 XHR 的传统方式发送 POST 请求 } 实际上我们可以发现，从拿到已经初步格式化的报错信息，到最终真正执行数据上报，raven.js 的过程非常漫长，这其中我分析有如下几个原因： 每个函数只处理一件或者一些事情，保持函数的短小整洁。 部分函数可以做到复用（因为除了自动捕获错误的方式， raven.js 还提供通过 captureException，即 try { doSomething(a[0]) } catch(e) { Raven.captureException(e) } 的方式来上报错误，两个过程中有一些函数的调用是有重叠的）。 但是笔者认为，raven.js 的代码设计还有很多值得优化的地方，比如： 对最终上报数据（data）的属性处理和增加分散在多个函数，并且有较多可选项目，很难梳理出一个完整的 data 格式，并且不便于维护。 部分函数的拆分必要性不足，并且会增加链路的复杂性，比如 _processException 、_sendProcessedPayload 、_makeRequest 等都只在一个链路中被调用一次。 部分属性重命名会造成资源浪费，由于 TraceKit 部分最终返回的数据格式并不完全满足 raven.js 的需要，所以 raven.js 之后又在较后阶段进行了重命名等处理，实际上这些内容完全可以通过一些其他的方式避免。 最后，非常遗憾，sentry 目前完全不支持合并上报，就算是在同一个事件循环（甚至事件循环的同一个阶段，关于事件循环，可以参考我之前绘制的一张图）的两个错误，sentry 都是分开来上报的，这里有一个简单例子： Raven.config('http://8ec3f1a9f652463bb58191bd0b35f20c@localhost:9000/2').install() let s = window.ss; try{ let b = s.b } catch (e) { Raven.captureException(e) // sentry should report error now } s.nomethod(); // sentry should report error now 以上例子中，sentry 会发送两个 POST 请求。 raven.js 最终上报数据的格式这一部分，我们并不会详细地分析 raven.js 上报的数据的每一项内容，仅会给读者展示一个比较典型的情况。 我们看一下对于一个一般的 js 错误，raven.js 上报的 json 中包含哪些内容，下面是一个已经删掉一些冗余内容的典型上报信息： { &quot;project&quot;: &quot;2&quot;, &quot;logger&quot;: &quot;javascript&quot;, &quot;platform&quot;: &quot;javascript&quot;, &quot;request&quot;: { &quot;headers&quot;: { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1&quot; }, &quot;url&quot;: &quot;http://localhost:63342/sentry-test1/test1.html?_ijt=j54dmgn136gom08n8v8v9fdddu&quot; }, &quot;exception&quot;: { &quot;values&quot;: [ { &quot;type&quot;: &quot;TypeError&quot;, &quot;value&quot;: &quot;Cannot read property 'b' of undefined&quot;, &quot;stacktrace&quot;: { &quot;frames&quot;: [ { &quot;filename&quot;: &quot;http://localhost:63342/sentry-test1/test1.html?_ijt=j54dmgn136gom08n8v8v9fdddu&quot;, &quot;lineno&quot;: 19, &quot;colno&quot;: 19, &quot;function&quot;: &quot;?&quot;, &quot;in_app&quot;: true } ] } } ], &quot;mechanism&quot;: { &quot;type&quot;: &quot;generic&quot;, &quot;handled&quot;: true } }, &quot;transaction&quot;: &quot;http://localhost:63342/sentry-test1/test1.html?_ijt=j54dmgn136gom08n8v8v9fdddu&quot;, &quot;extra&quot;: { &quot;session:duration&quot;: 6 }, &quot;breadcrumbs&quot;: { &quot;values&quot;: [ { &quot;timestamp&quot;: 1534257309.996, &quot;message&quot;: &quot;_prepareFrames stackInfo: [object Object]&quot;, &quot;level&quot;: &quot;log&quot;, &quot;category&quot;: &quot;console&quot; }, // ... ] }, &quot;event_id&quot;: &quot;ea0334adaf9d43b78e72da2b10e084a9&quot;, &quot;trimHeadFrames&quot;: 0 } 其中支持的信息类型重点分为以下几种： sentry 基本配置信息，包括库本身的配置和使用者的配置信息，以及用户的一些自定义信息 错误信息，主要包括错误调用栈信息 request 信息，主要包括浏览器的 User-Agent、当前请求地址等 面包屑信息，关于面包屑具体指的是什么，我们会在下一环节进行介绍 raven.js 面包屑收集面包屑信息，也就是错误在发生之前，一些用户、浏览器的行为信息，raven.js 实现了一个简单的队列（有一个最大条目长度，默认为 100），这个队列在时刻记录着这些信息，一旦错误发生并且需要上报，raven.js 就把这个队列的信息内容，作为面包屑 breadcrumbs，发回客户端。 面包屑信息主要包括这几类： 用户对某个元素的点击或者用户对某个可输入元素的输入 发送的 http 请求 console 打印的信息（支持配置 ‘debug’, ‘info’, ‘warn’, ‘error’, ‘log’ 等不同级别） window.location 变化信息 接下来，我们对这几类面包屑信息 sentry 的记录实现进行简单的分析。 实际上，sentry 对这些信息记录的方式比较一致，都是通过对原声的函数进行包装，并且在包装好的函数中增加自己的钩子函数，来实现触发时候的事件记录，实际上，sentry 总共包装的函数有： window.setTimeout window.setInterval window.requestAnimationFrame EventTarget.addEventListener EventTarget.removeEventListener XMLHTTPRequest.open XMLHTTPRequest.send window.fetch History.pushState History.replaceState 备注：这里包装的所有函数，其中有一部分只是使 raven.js 具有捕获回调函数中错误的能力（对回调函数进行包装） 接下来我们看一段典型的代码，来分析 raven.js 是如何记录用户的点击和输入信息的（通过对 EventTarget.addEventListener 进行封装）： function wrapEventTarget(global) { var proto = _window[global] &amp;&amp; _window[global].prototype; if (proto &amp;&amp; proto.hasOwnProperty &amp;&amp; proto.hasOwnProperty('addEventListener')) { fill( proto, 'addEventListener', function(orig) { return function(evtName, fn, capture, secure) { try { if (fn &amp;&amp; fn.handleEvent) { //兼容通过 handleEvent 的方式进行绑定事件 fn.handleEvent = self.wrap( { mechanism: { type: 'instrument', data: { target: global, function: 'handleEvent', handler: (fn &amp;&amp; fn.name) || '&lt;anonymous&gt;' } } }, fn.handleEvent ); } } catch (err) { } var before, clickHandler, keypressHandler; if ( autoBreadcrumbs &amp;&amp; autoBreadcrumbs.dom &amp;&amp; (global === 'EventTarget' || global === 'Node') ) { // NOTE: generating multiple handlers per addEventListener invocation, should // revisit and verify we can just use one (almost certainly) clickHandler = self._breadcrumbEventHandler('click'); keypressHandler = self._keypressEventHandler(); before = function(evt) { // 钩子函数，用于在回调函数调用的时候记录信息 if (!evt) return; var eventType; try { eventType = evt.type; } catch (e) { // just accessing event properties can throw an exception in some rare circumstances // see: https://github.com/getsentry/raven-js/issues/838 return; } if (eventType === 'click') return clickHandler(evt); else if (eventType === 'keypress') return keypressHandler(evt); }; } return orig.call( this, evtName, self.wrap( { mechanism: { type: 'instrument', data: { target: global, function: 'addEventListener', handler: (fn &amp;&amp; fn.name) || '&lt;anonymous&gt;' } } }, fn, before ), capture, secure ); }; }, wrappedBuiltIns ); fill( proto, 'removeEventListener', function(orig) { return function(evt, fn, capture, secure) { try { fn = fn &amp;&amp; (fn.__raven_wrapper__ ? fn.__raven_wrapper__ : fn); } catch (e) { // ignore, accessing __raven_wrapper__ will throw in some Selenium environments } return orig.call(this, evt, fn, capture, secure); }; }, wrappedBuiltIns ); } } 以上代码兼容了通过 handleEvent 的方式进行绑定事件（如果没有听说过这种方式，可以在这里补充一些相关的知识）。 默认情况下，raven.js 只记录通过 EventTarget.addEventListener 绑定的点击和输入信息，实际上这是比较科学的，并且这些信息较为有效。另外，raven.js 也提供了记录所有点击和输入信息的可选项，其实现方式更为简单，直接在 document 上添加相关的监听即可。 raven.js 如何和框架配合使用raven.js 和框架配合使用的方式非常简单，但是我们要知道，很多框架内置了错误边界处理，或者对错误进行转义。以至于我们通过 window.onerror 的方式得不到完整的错误信息。同时，有些框架提供了错误处理的接口（比如 vue），利用错误处理的接口，我们能够获取到和错误有关的更多更重要的信息。 raven.js 利用各个框架的官方接口，提供了 vue、require.js、angular、ember、react-native 等各个框架的官方插件。 插件内容本身非常简单，我们可以看一下 vue 插件的代码： function formatComponentName(vm) { if (vm.$root === vm) { return 'root instance'; } var name = vm._isVue ? vm.$options.name || vm.$options._componentTag : vm.name; return ( (name ? 'component &lt;' + name + '&gt;' : 'anonymous component') + (vm._isVue &amp;&amp; vm.$options.__file ? ' at ' + vm.$options.__file : '') ); } function vuePlugin(Raven, Vue) { Vue = Vue || window.Vue; // quit if Vue isn't on the page if (!Vue || !Vue.config) return; var _oldOnError = Vue.config.errorHandler; Vue.config.errorHandler = function VueErrorHandler(error, vm, info) { var metaData = {}; // vm and lifecycleHook are not always available if (Object.prototype.toString.call(vm) === '[object Object]') { metaData.componentName = formatComponentName(vm); metaData.propsData = vm.$options.propsData; } if (typeof info !== 'undefined') { metaData.lifecycleHook = info; } Raven.captureException(error, { extra: metaData }); if (typeof _oldOnError === 'function') { _oldOnError.call(this, error, vm, info); } }; } module.exports = vuePlugin; 应该不用进行过多解释。 你也许想知道为什么没有提供 react 插件，事实上，react 16 以后才引入了Error Boundaries，这种方式由于灵活性太强，并不太适合使用插件，另外，就算不使用插件，也非常方便地使用 raven.js 进行错误上报，可以参考这里 但笔者认为，目前 react 的引入方式会对源代码进行侵入，并且比较难通过构建的方式进行 sentry 的配置，也许我们可以寻找更好的方式。 完。","link":"/2018/08/18/%E4%BB%8E%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90sentry%E7%9A%84%E9%94%99%E8%AF%AF%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/"},{"title":"从零维到十维，你真的懂吗？[待更.....]","text":"前言我这个人不多说废话，说多了你们也不听，直接切入正题 零维简介说简单点，零维就是个奇点，也就是没有维度的，没有发散和方向的维度。它没有空间，没有物质，一切皆无。也可以说它是全部，是所有，是存在。用于解释为什么有宇宙，宇宙的物质从哪里来的，时间的不间断和前进态是零维的表达。 零维的定义零维并不能被称为零维空间，因为零维既不是空间也不是时空，零维只是一个概念，就是没有任何维度。可以说，没有任何物质，在这里，没有任何感觉，一切东西都好像静止了。无论是几维空间，在零维下都将不复存在。最开始，宇宙中的所有物质能量、时间空间的概念都集中于一个体积无限小，密度无限大的点，也就是零维。后来这个点发生了大爆炸，由零维诞生出了11个维度，构成了现今的十一维空间，使时间开始流逝（时间不是一个维度，时间只是用来描述空间运动的一个物理量，因此认为四维空间是三维空间加一维时间的想法都是错的），进而形成了我们所认识的这个宇宙。零维犹如我们的思想，甚至可能我们的思想就存在于零维。它没有大小、没有维度。它只是被想象出来的、作为标志一个位置的点。它什么也没有，空间、时间通通不存在，这就是零维度。 在零维里，不像我们生存在的三维世界，这里你感受不到一切，碰不到一切，不像我们三维世界，你看得到那棵树，你摸得到你家的猫，你可以呼吸……甚至可以说，你是不存在的。 但千万别以为错了，我们的思想并不属于三维，我们只是能触碰到三维而已，具体是几维人，有待考证。这是一个富有哲理的科学问题。 关于零的东西就这么少，再多也找不到了，搞张图凑个数 一维简介一维空间是指只由一条线内的点所组成的空间，它只有长度，没有宽度和高度，只能向两边无限延展。一维实际是指的是一条线，在理解上即为左－右一个方向（如：时间）。也可理解为点动成线，指没有面积与体积的物体。在空间维系内，一维空间是最简单的空间，它只由一条线组成。实际上一条线就是一个一维空间，一条曲线如果没有建立坐标系，那么它也是一维的。简而言之，没有建立坐标系的线就是一个一维空间。如果你在一维空间中，你只能看见前面和后面。一维空间是指仅由一个要素构成的空间。就如一张纸上有两个点把这两个点连成一条直线，这一条直线没有高度和深度，只有长度。数线是其中一个一维空间的例子，借由数线上的单位长度来表示每个点的位置。 几何多胞形在一维的多胞形是一条线段，它的施莱夫利符号是：{} 超球体在一维中的超球体是一对点，因为它的表面为零维度，所以有时叫作0球。它的长度是：L=2r，r是它的半径。 定义一维实际是指的是一条线，在理解上即为左－右一个方向（如：时间）。也可理解为点动成线，指没有面积与体积的物体。他没有长，没有宽。 二维简介二维空间或译二度空间（Second Dimension）是指仅由宽度→水平线和高度→垂直线（在几何学中为X轴和Y轴）两个要素所组成的平面空间，只在平面延伸扩展，同时也是美术上的一个术语，例如绘画便是要将三维空间的事物，用二维空间来展现。二维空间是指仅由长度和宽度（在几何学中为X轴和Y轴）两个要素所组成的平面空间，只向所在平面延伸扩展。二维空间同时也是美术上的一个术语，例如绘画便是要将三维空间（三度空间）的事物，用二度空间来展现。 几何在几何中，二维空间仅指的是一个平面，上面的每一个点都可以用由两个数构成的坐标（x,y）来表示。如图《二维空间是平面》所示，坐标将平面分成了4个象限。形象例证有一位专家曾打过一个比方：让我们先假设一些生活在二维空间的扁片人，他们只有平面概念。假如要将一个二维扁片人关起来，只需要用线在他四周画一个圈即可，这样一来，在二维空间的范围内，他无论如何也走不出这个圈。 定义三维的物体在二维里可以由一处消失，在另一处出现。 线性代数线性代数中也有另一种探讨二维空间的的方式，其中彼此独立性的想法至关重要。平面有二个维度，因为长方形的长和宽的长度是彼此独立的。以线性代数的方式来说，平面是二维空间，因为平面上的任何一点都可以用二个独立向量的线性组合来表示。数量积、角度及长度二个向量A= [A1,A2]和B= [B1,B2]的数量积定义为： 向量可以画成一个箭头，量值为箭头的长度即其，向量的方向就是箭头指向的方向。向量A的长度为。以此观点来看，两个欧几里得向量A和B的数量积定义为 [2] 其中θ为A和B的角度向量A和自己的数量积为 因此 这也是向量欧几里得距离的公式。 待更…..","link":"/2021/01/17/%E4%BB%8E%E9%9B%B6%E7%BB%B4%E5%88%B0%E5%8D%81%E7%BB%B4%EF%BC%8C%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%87%82%E5%90%97%EF%BC%9F/"},{"title":"使用OpenCV实现简单的人脸识别程序","text":"本问就 Mac 系统安装 OpenCV 以及实现一个简单的人脸识别程序进行记录。 安装 OpenCV实际上，OpenCV 的安装方式比较多，这里为了避免一些第三方安装的问题，我们采用源代码方式安装。 安全前请确保本机已经安装了 CMake 和 Xcode。 我们去 OpenCV 的网站 下载源代码，选择 Release -&gt; SourceCode，可以选择最新的 4.11 版本。 这里以 4.1.1 版本为例，下载后我们解压到 opencv-4.1.1，然后进入到该目录，新建一个 release 目录用于存放我们构建好的内容，并进入到该目录： mkdir release cd release/ 然后我们依次执行以下命令安装： cmake -G “Unix Makefiles” .. make make install 全部命令执行成功后，实际上就安装完成了，我们可以从最后的输出中看到，相关内容已经被安装到了 /usr/local/include、/usr/local/lib 等文件夹下。 使用 Xcode 编写人脸识别程序我们可以使用 Xcode 建立一个命令行程序，这里我们还需要处理两个问题： OpenCV 的引入 摄像头权限的获取 OpenCV 的引入对于第一点，我们在 Build Setting 的 Search Paths 中增加 Header 和 Library 的路径： 然后我们需要在 Build Phases 的 Link Binary With Libraries 中增加动态链接库。 我们可以点击左下角加号，选择 Add Others 然后进入 /usr/local/lib 把 OpenCV 相关的库均包含进来即可。 实际上我们可以部分引入，但是由于我们是初步上手，全部引入也可以。 摄像头权限的获取这里如果我们直接运行我们的程序，在 macOS 最新的系统中是无法运行通过的，这里涉及到摄像头权限问题。 一般来说，对于 macOS，我们需要在运行程序的目录下声明 info.plist, 这样程序在运行的时候系统会自动有申请权限的弹窗，对于我们测试场景下而言，我们可以这样做： 进入我们 Product 存放的目录（注意不是项目代码目录，可以在 Products 条目右单击 Show in Finder） 复制一个 info.plist（这里我们可以随便找一个本地安装的应用程序的 info.plist，一般右单击显示包内容即可看到） 在 info.plist 中增加 NSCameraUsageDescription，value 即提示语，可以写比如 摄像头权限的获取。 书写并运行程序做完上述准备工作后，我们可以写我们的人脸识别程序了，这里给出一个成功运行的代码示例（参考了网上的一些例子）： #include &lt;iostream&gt; #include &lt;opencv2/opencv.hpp&gt; using namespace std; using namespace cv; void capture(); // 是否退出摄像头抓取线程 static bool g_quit = false; int main(int argc, char** argv) { capture(); return 0; } void capture() { // 打开摄像头 cv::VideoCapture cap(0); // 如果打开失败，返回错误 if (!cap.isOpened()) { cout&lt;&lt;&quot;Open Capture Failed&quot;&lt;&lt;endl; return; } // 人脸识别分类器 cv::CascadeClassifier faceCascadeClassifier(&quot;/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_alt2.xml&quot;); // 读取 Frame ，直到退出系统 while (!g_quit) { cv::Mat frame; if (!cap.read(frame)) { // 读取失败，返回错误 break; } // 进行人脸识别 std::vector&lt;cv::Rect&gt; faces; faceCascadeClassifier.detectMultiScale(frame, faces); // 将人脸识别结果绘制到图片上 for (const auto&amp; face : faces) { cout&lt;&lt;&quot;Find Face&quot;&lt;&lt;endl; cv::rectangle(frame, cv::Point(face.x, face.y), cv::Point(face.x + face.width, face.y + face.height), CV_RGB(255, 0, 0), 2); } imshow(&quot;Display Image&quot;, frame); waitKey(100); } } 这里值得注意的是，我们这里使用的人脸识别分类器是 OpenCV 安装后自带的，你本机的目录可能并不是这一个（这个路径实际上安装好 OpenCV 之后会打印在控制台）。 正常情况下，以上程序可以直接编译执行。","link":"/2019/09/10/%E4%BD%BF%E7%94%A8OpenCV%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%A8%8B%E5%BA%8F/"},{"title":"使用Rust WebAssembly 0拷贝进行计算加速","text":"demo: https://github.com/aircloud/rust-wasm-demo 其他资料：入门 Rust 开发 WebAssembly 一般来说，使用 WebAssembly 能够在一定程度上提高性能，不过有的时候我们也许会发现，使用 WebAssembly 之后，有的时候我们不仅发现性能没有提升，反而下降了许多甚至数倍，实际上这是因为，使用 WebAssembly 需要非常谨慎，有很多细节都会大幅度影响性能，比如： 我们编译采用的是 debug 还是 release 方式。 最后编译的结果是否采用了不同级别的优化，如果使用了 opt-level = 's' 那么通常速度也会下降很多。 是否在 JS 和 rust 之间存在大量的数据拷贝，因为很多代码是工具链生成的，也许有的时候我们会忽视这一点。 本文针对以上等一些问题特别是第三点，给出一个 wasm 优化的参考方案，并给出示例代码。 编译优化我们在优化数据拷贝之前，对于编译我们可以做一些前置的简单的工作。 检查 Cargo.toml 脚本中 [profile.release] 中的 opt-level 选项，确认我们所使用的值： This flag controls the optimization level. 0: no optimizations, also turns on cfg(debug_assertions) (the default). 1: basic optimizations. 2: some optimizations. 3: all optimizations. s: optimize for binary size. z: optimize for binary size, but also turn off loop vectorization. Note: The -O flag is an alias for -C opt-level=2. The default is 0. 如果我们使用了 ‘s’ 或者 ‘z’，那么通常会牺牲一部分性能（对于 demo 而言，使用 ‘z’， wasm 的性能也只有 js 的 20%），因为其主要是对体积进行一定的优化，所以如果优化前的体积我们可以接受的话，通常不需要这样的优化。 在以上的前提下，我们使用 --release 的方式编译，通常就可以了。 减少拷贝在这之前，我们需要有一个认知： 通过 rust 工具链编译的 wasm 代码，所有参数传入都是需要拷贝一次的，包括我们传入 ArrayBuffer 等 Buffer 类型的参数。这是由于 wasm 只能访问自己的线性内存，而这个拷贝，通常是我们在处理大规模计算的一个坎，有的时候虽然 wasm 计算快一点，但是拷贝的消耗还是比较大的，加之 js 有若干 v8 优化的加持，可能和 wasm 也相差不多。 所以我们要把计算移植到 wasm 中的话，首先要解决的就是大规模数据拷贝的问题。 这里的一般思路为： wasm 分配内存：调用 wasm 的方法，在 wasm 内存中分配空间，返回指针位置 js 写入数据：js 端在 wasm 的 memory arraybuffer 上，按指针位置和数据量建立 view，把数据写入 wasm 计算：调用 wasm 方法完成计算， 返回计算好的批量结果的指针位置和大小 js 读取数据：js 端在 wasm 的 memory arraybuffer上，按指针位置和数据量建立 view，把数据读出 接下来，我们通过一个 demo 来完成以上几点，demo 的主要功能为： 初始化一个 ImageData，内容随机。 分别使用 js 和 WebAssembly 进行高斯模糊计算，并计算二者的时间，进行对比。 这里的 demo 只是辅助进行验证改方案的可行性并且给出一个示例，并不作为一个标准的 benchmark 去对比 js 和 WebAssembly 的性能，同时，也并没有 UI 展示，计算结果输出在控制台中。 最终笔者运行的结果为，js 比 WebAssembly 慢 30% 左右。 1. wasm 分配内存这部分的通用做法，即我们在 wasm 的 rust 中分配一个数组（Vec），然后把其指针传递给 js： // rust： #[wasm_bindgen] pub fn new_buffer(key: String, len: usize) -&gt; *const u8 { // GlobalBufferStorage 是一个 lazy_static let mut global_buffer_storage = GlobalBufferStorage.lock().unwrap(); let mut buffer = vec![255; len]; let ptr = buffer.as_ptr(); global_buffer_storage.buffer_map.insert(key, buffer); ptr } 为了后续方便寻找到这段数据，我们可以使用一个 key 将这个 Vec 联系起来，并且在 Rust 中放入全局（可以使用 lazy_static!，因为这种类型的数据没有办法直接定义在全局），之后通过 key 来查找数据。 在 js 中，我们就可以建立各种 TypedArray 对其进行操作： const ptr = this.wasm!.new_buffer(key, len); const u8Arr = new Uint8ClampedArray(this.wasm!.get_wasm_buffer(), ptr, len); 这个时候，我们在 js 或 rust 任何一侧改了这个数据之后，都可以在另外一侧访问到。 实际上，在 js 侧的比如 ImageData 等一些对象中，也支持我们传递一个 TypedArray 进行初始化，这让我们在比如 canvas 等应用场景下，使用 wasm 分配的内存更为方便。 const imageData = new ImageData(u8Arr, width, height); 2. js 写入数据如果我们需要在 js 侧写入数据，实际上这个时候我们得到的 TypedArray 已经和直接使用 js new 的 TypedArray 在使用上没有差别，可以正常按照数组的方式进行数据写入。 不过，这里需要注意的是，js 写入通过 wasm 分配内存建立的 TypedArray，有些场景下在一定程度上速度要慢于直接使用 js new 的 TypedArray（不过在笔者的测试数据中，wasm 分配的方式反而是更快的），所以如果我们是一个高频的数据写入的场景，比如帧数据等，这个时候最好进行一次对比测试。 3. wasm 计算当我们真正需要进行计算的时候，我们可以调用 wasm 的计算函数，并且传入上文中定义的 key，这样 wasm 的 rust 函数可以直接找到这段数据，这里我们的 demo 为一段计算卷积的函数： #[wasm_bindgen] pub fn convolution(key: String, width: usize, height: usize, kernel: Vec&lt;i32&gt;) { let mut global_buffer_storage = GlobalBufferStorage.lock().unwrap(); let kernel_length = kernel.iter().sum::&lt;i32&gt;() as i32; if let Some(buffer) = global_buffer_storage.buffer_map.get_mut(&amp;key) { for i in 1..width-1 { for j in 1..height-1 { let mut newR: i32 = 0; let mut newG: i32 = 0; let mut newB: i32 = 0; for x in 0..3 { // 取前后左右共9个格子 for y in 0..3 { newR += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 0] as i32 * kernel[y * 3 + x] / kernel_length; newG += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 1] as i32 * kernel[y * 3 + x] / kernel_length; newB += buffer[width * (j + y - 1) * 4 + (i + x - 1) * 4 + 2] as i32 * kernel[y * 3 + x] / kernel_length; } } buffer[width * j * 4 + i * 4 + 0] = newR as u8; buffer[width * j * 4 + i * 4 + 1] = newG as u8; buffer[width * j * 4 + i * 4 + 2] = newB as u8; } } } else { return (); } } 因为这段函数对应操作的内存数据实际上已经在 wasm 和 js 之间共享了，所以也是不需要返回值的，等计算完成后 js 直接去读之前建立的 TypedArray，甚至直接使用通过 TypedArray 创建的 ImageData，进行绘制上屏等后续操作。 4. js 读取数据在 demo 中，我们可以直接通过 CanvasRenderingContext2D.putImageData() 传入之前获取的 imageData，绘制上屏。 其他方案实际上，我们如果目的是加速 js 计算，不仅仅有 WebAssembly 这一个方案可以选择，如果我们的环境中拥有可以访问 Node 的能力或者可以访问原生模块的能力（比如，我们的应用运行在 electron 环境，或者是一些移动客户端），也可以采用比如 addon 的方式来运行我们的计算部分，相比于 wasm，这部分的优缺点在于： 优点： 通常可以更好的控制优化，甚至做到汇编级别的优化定制，性能提升空间更高（同样也可能会面临数据拷贝的问题，也需要一定方式减少拷贝）。 在重 addon 的环境下（例如，其他大量功能也依赖 addon），可以更好的处理函数调用关系、依赖库使用等，一定程度上减少体积和增加开发的便捷性，而 wasm 会被编译成一个独立的二进制文件，处于沙盒环境中，无法直接调用其他的动态库。 缺点： 无法做到像 wasm 一样跨平台，并且可以同时运行在网页、桌面环境、移动端等任何 Webview 存在的环境中。 不过总之，如果使用得当，二者的性能都是可以优于原生的 js，都可以作为优化方案考虑。","link":"/2020/06/26/%E4%BD%BF%E7%94%A8RustWebAssembly0%E6%8B%B7%E8%B4%9D%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F/"},{"title":"使用Nodejs打造多用户实时监控系统","text":"背景概述首先描述一下笔者遇到的问题，我们可以设定这样一个场景：现在有一个实时监控系统的开发需求，要求同时支持多个用户（这里我们为了简化，暂时不涉及登陆态，假定一个设备即为一个用户），对于不同的用户来讲，他们需要监控的一部分内容是完全相同的，比如设备的 CPU 信息、内存信息等，而另外一部分内容是部分用户重叠的，比如对某一区域的用户来说某些监控信息是相同的，而还有一些信息，则是用户之间完全不同的。 对于每个用户来讲，当其进入页面之后即表明其开始监控，需要持续地进行数据更新，而当其退出界面或者手动点击停止监控，则停止监控。 问题描述实际上，对于以上情况，我们很容易想到通过 WebSocket，对不同的用户进行隔离处理，当一个用户开始监控的时候，通过函数来逐个启动其所有的监控项目，当其停止监控的时候，取消相关监控，并且清除无关变量等。我们可以将所有内容写到 WebSocket 的连接回调中，由于作用域隔离，不同用户之间的监控（读操作）不会产生互相影响。 这种方式可以说是最为快捷方便的方式了，并且几乎无需进行设计，但是这样有一个非常明显的效率问题： 由于不同用户的部分监控项目是有重叠的，对于这些重叠的项目，我们如果对于每一个用户都单独监控，那么就会产生非常多的浪费，如果这些监控中还涉及到数据库交互或者较为复杂的计算，那么成倍之后的性能损失是非常难以承受的。 所以，我们需要将不同用户重叠的那些监控项目，进行合并，合并成一个之后，如果有新的消息，我们就推到所有相关用户的回调函数中去处理。 也就是说，我们需要管理一个一对多的订阅发布模式。 到这里，我们发现我们想要实现这样一个监控系统，并不是非常简单，主要有下列问题： [1]对于可能有用户重叠的监控项目，我们需要抽离到用户作用域之外，并且通过统计计数等方式来”记住”当前所有的监控用户，当有新内容时推到各个用户的处理函数中，并且当最后一个用户取消监控的时候要及时清理相关对象。 [2]不同用户的重叠监控项目的监控方式也各不相同，有的是通过 setInterval 等方式的定时任务，有的是事件监听器等等。 [3]判断不同用户的项目是否重叠也有一定的争议，比如假设不同用户端监控的是同一个项目，调用的也是相同的函数，但是由于用户 ID 不同，这个时候我们如何判断是否算”同一个监控”？ 以上的这些问题，如果我们不借助现有的库和工具，自己顺着思路一点点去写，则很容易陷入修修补补的循环，无法专注监控本身，并且最后甚至在效率上适得其反。 解决方案以下解决方案基于 Rx.js，需要对 Observable 有一定了解。 多个用户的监控以及取消Monitor-RX 是对以上场景问题的一个解决方案封装，其利用了 Rx.js 对订阅发布的管理能力，可以让整个流程变的清晰。 在 Rx.js 中，我们可以通过以下方式建立一个多播对象 multicasted： var source = Rx.from([1, 2, 3]); var subject = new Rx.Subject(); var multicasted = source.pipe(multicast(subject)).refCount(); // 其属于 monitor-rx 的实现细节，无需理解亦可使用 monitor-rx subscription1 = refCounted.subscribe({ next: (v) =&gt; console.log('observerA: ' + JSON.stringify(v)) }); setTimeout(() =&gt; { subscription2 = refCounted.subscribe({ next: (v) =&gt; console.log('observerB: ' + JSON.stringify(v)) }); }, 1200); subscription1.unsubscribe(); setTimeout(() =&gt; { subscription2.unsubscribe(); // 这里 refCounted 的 unsubscribe 相关清理逻辑会自动被调用 }, 3200); 在这里采用多播，有如下几个好处： 可以随时增加新的订阅者，并且新的订阅者只会收到其加入订阅之后的数据。 可以随时对任意一个订阅者取消订阅。 当所有订阅者取消订阅之后，Observable 会自动触发 Observable 函数，从而可以对其事件循环等进行清理。 以上能力其实可以帮助我们解决上文提到的问题 [1]。 监控格式的统一实际上，在我们的监控系统中，从数据依赖的角度，我们的监控函数会有这样几类： [a]纯粹的定时任务，无数据依赖，这方面比如当前内存快照数据等。 [b]带有记忆依赖的定时任务：定时任务依赖前一次的数据（甚至更多次），需要两次数据做差等，这方面的数据比如一段时间的消耗数据，cpu 使用率的计算。 [c]带有用户依赖的定时任务：依赖用户 id 等信息，不同用户无法共用。 而从任务触发的角度，我们仍待可以对其分类： [i]简单的 setInterval 定时任务。 [ii]基于事件机制的不定时任务。 [iii]基于其他触发机制的任务。 实际上，我们如果采用 Rx.js 的模式进行编写，无需考虑任务的数据依赖和触发的方式，只需写成一个一个 Observable 实例即可。另外，对于比较简单的 [a]&amp;[i] 或 [c]&amp;[i] 类型，我们还可以通过 monitor-rx 提供的 convertToRx 或 convertToSimpleRx 转换成 Observable 实例生成函数，例如： var os = require('os'); var process = require('process'); const monitorRx = require('monitor-rx'); function getMemoryInfo() { return process.memoryUsage(); } const memory = monitorRx.Utils.convertToSimpleRx(getMemoryInfo) // 或者 //const memory = monitorRx.Utils.convertToRx({ // getMemoryInfo //}); module.exports = memory; convertToRx 相比于 convertToSimpleRx，可以支持函数配置注入（即下文中 opts 的 func 属性和 args 属性）,可以在具体生成 Observable 实例的时候具体指定使用哪些函数以及其参数。 如果是比较复杂的 Observable 类型，那么我们就无法直接通过普通函数进行转化了，这个时候我们遵循 Observable 的标准返回 Observable 生成函数即可（不是直接返回 Observable 实例） 这实际上也对问题 [2] 进行了解决。 监控唯一性：我们知道，如果两个用户都监控同一个信息，我们可以共用一个 Observable，这里的问题，就是如何定义两个用户的监控是”相同”的。 这里我们采用一个可选项 opts 的概念，其一共有如下属性： { module: 'ModuleName', func: ['FuncName'], args: [['arg1','arg2']], opts: {interval:1000}, } module 即用户是对哪一个模块进行监控（实际上是 Observable），func 和 args 则是监控过程中需要调用的函数，我们也可以通过 agrs 传入用户个人信息。于没有内部子函数调用的监控，二者为空即可，opts 是一些其他可选项，比如定义请求间隔等。 之后，我们通过 JSON.stringify(opts) 来序列化这个可选项配置，如果两个用户序列化后的可选项配置相同，那么我们就认为这两个用户可以共用一个监控，即共用一个 Observable。 更多内容实际上，借助 Monitor-RX，我们可以很方便的解决上述提出的问题，Monitor-RX 也在积极的更新中，大家可以在这里了解到更多的信息。","link":"/2018/10/21/%E4%BD%BF%E7%94%A8%20Node.js%20%E6%89%93%E9%80%A0%E5%A4%9A%E7%94%A8%E6%88%B7%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"title":"入门WebAssem并进行图像卷积处理","text":"WebAssembly 出现有很长时间了，但是由于日常工作并无直接接触，因此一直疏于尝试，最近终于利用一些业余时间简单入门了一下，因此在此总结。 简介首先我们需要知道 WebAssembly 是一个什么东西，其实际是一个字节码编码方式，比较接近机器码（但是又无法直接执行），这样可以方便地做到跨平台同时省去像 JavaScript 等语言的解释时间，所以是有一定优势的，使用起来其实也比较灵活，凡是可以转化成字节码的，都是可以使用 WebAssembly。 以下仅列举部分可以支持 WebAssembly 转化的语言： AssemblyScript: 语法和 TypeScript 一致(事实上，其是 Typescript 的一个子集)，对前端来说学习成本低，为前端编写 WebAssembly 最佳选择； c\\c++: 官方推荐的方式，详细使用见文档; Rust: 语法复杂、学习成本高，对前端来说可能会不适应。详细使用见文档; Kotlin: 语法和 Java、JS 相似，语言学习成本低，详细使用见文档; Golang: 语法简单学习成本低。但对 WebAssembly 的支持还处于未正式发布阶段，详细使用见文档。 尝试使用 WebAssembly 官方推荐的方式，我们首先可以在这里来下载。 如果用腾讯内网有的文件是下载不下来的，这个时候我们可以给命令行增加一个代理（如果我们用的 Fiddler 或 Charles，开启的时候默认命令行也可以走代理，如果是 Whistle，我们需要手动设置代理），有些文件我们还可以下载好之后使用文件代理。 export https_proxy=&quot;http://127.0.0.1:8899&quot; export http_proxy=&quot;http://127.0.0.1:8899&quot; // 文件代理： https://s3.amazonaws.com/mozilla-games/emscripten/packages/node-v8.9.1-darwin-x64.tar.gz file:///Users/niexiaotao/node-v8.9.1-darwin-x64.tar.gz 初体验这里考虑到前端同学的上手难度，我们先使用 AssemblyScript 写一个极小的例子，一个斐波那契函数： export function f(x: i32): i32 { if (x === 1 || x === 2) { return 1; } return f(x - 1) + f(x - 2) } 通过类似 asc f.ts -o f.wasm 这样的命令编译成 f.wasm 之后，我们可以分别在 Node 环境和浏览器环境来执行： Node： const fs = require(&quot;fs&quot;); const wasm = new WebAssembly.Module( fs.readFileSync(__dirname + &quot;/f.wasm&quot;), {} ); const myModule = new WebAssembly.Instance(wasm).exports; console.log(myModule.f(12)); 浏览器： fetch('f.wasm') // 网络加载 f.wasm 文件 .then(res =&gt; res.arrayBuffer()) // 转成 ArrayBuffer .then( buffer =&gt; WebAssembly.compile(buffer) ) .then(module =&gt; { // 调用模块实例上的 f 函数计算 const instance = new WebAssembly.Instance(module); const { f } = instance.exports; console.log('instance:', instance.exports); console.log('f(20):', f(20)); }); 于是，我们完成了 WebAssembly 的初体验。 当然，这个例子太简单了。 使用 WebAssembly 进行图像卷积处理实际上，WebAssembly 的目的在于解决一些复杂的计算问题，优化 JavaScript 的执行效率。所以我们可以使用 WebAssembly 来处理一些图像或者矩阵的计算问题。 接下来，我们通过 WebAssembly 来处理一些图像的卷积问题，用于图像的风格变换，我们最终的例子可以在这里体验。 每次进行卷积处理，我们的整个流程是这样的： 将原图像使用 canvas 绘制到屏幕上。 使用 getImageData 获取图像像素内容，并转化成类型数组。 将上述类型数组通过共享内存的方式传递给 WebAssembly 部分。 WebAssembly 部分接收到数据，进行计算，并且通过共享内存的方式返回。 将最终结果通过 canvas 画布更新。 上述各个步骤中，绘制的部分集中在 JavaScript 端，而计算的部分集中在 WebAssembly，这两部分相互比较独立，可以分开编写，而双端数据通信是一个比较值得注意的地方，事实上，我们可以通过 ArrayBuffer 来实现双端通信，简单的说，JavaScript 端和 WebAssembly 可以共享一部分内存，并且都拥有读写能力，当一端写入新数据之后，另一段也可以读到，这样我们就可以进行通信了。 关于数据通信的问题，这里还有一个比较直白的科普文章，可以参考。 在这里没有必要对整个项目代码进行展示，因此可以参考（代码地址），我们这里仅仅对部分关键代码进行说明。 共享内存首先，我们需要声明一块共享内存，这其实可以使用 WebAssembly 的 API 来完成： let memory = new WebAssembly.Memory({ initial: ((memSize + 0xffff) &amp; ~0xffff) &gt;&gt;&gt; 16 }); 这里经过这样的比较复杂的计算是因为 initial 传入的是以 page 为单位，详细可以参考这里，实际上 memSize 即我们共享内存的字节数。 然后这里涉及到 memSize 的计算，我们主要需要存储三块数据：卷积前的数据、卷积后的数据（由于卷积算法的特殊性以及为了避免更多麻烦，这里我们不进行数据共用），还有卷积核作为参数需要传递。 这里我们共享内存所传递的数据按照如下的规则进行设计： 传递给 WebAssembly 端的方式并不复杂，直接在 WebAssembly.instantiate 中声明即可。 fetch(wasmPath) .then(response =&gt; response.arrayBuffer()) .then(buffer =&gt; WebAssembly.instantiate(buffer, { env: { memory, abort: function() {} }, Math })).then(module =&gt; {}) 然后我们在 AssemblyScript 中就可以进行读写了： //写： store&lt;u32&gt;(position, v) // position 为位置 //读： load&lt;u32&gt;(position) // position 为位置 而在 JavaScript 端，我们也可以通过 memory.buffer 拿到数据，并且转化成类型数组： let mem = new Uint32Array(memory.buffer) //通过 mem.set(data) 可以在 JavaScript 端进行写入操作 这样，我们在 JavaScript 端和 AssemblyScript 端的读写都明晰了。 这里需要注意的是，JS端采用的是大端数据格式，而 AssemblyScript 中采用的是小端，因此其颜色数据格式为 AGBR 卷积计算我们所采用的卷积计算本身算法比较简单，并且不是本次的重点，但是这里需要注意的是： 我们无法直接在 AssemblyScript 中声明数组并使用，因此除了 Kernel 通过共享内存的方式传递过来以外，我们应当尽量避免声明数组使用（虽然也有使用非共享内存数组的相关操作，但是使用起来比较繁琐） 卷积应当对 R、G、B 三层单独进行，我这里 A 层不参与卷积。 以上都在代码中有所体现，参考相关代码便可明了。 卷积完成后，我们通过共享内存的方法写入类型数组，然后在 JavaScript 端合成数据，调用 putImageData 上屏即可。 其他当然，本次图像卷积程序仅仅是对 Webassembly 和 AssemblyScript 的初步尝试，笔者也在学习阶段，如果上述说法有问题或者你想和我交流，也欢迎留言或者提相关 issue。","link":"/2019/02/16/%E5%85%A5%E9%97%A8WebAssembly%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%85%B6%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E5%A4%84%E7%90%86/"},{"title":"化学笔记②","text":"蜡烛燃烧的实际探究点燃前 实验探究的步骤 现象 结论 制作材料 蜡心: 线状 外壳: 圆柱形 由石蜡和棉线制作 颜色，状态，气味 白色，固态，有轻微的气味 无 用刀切下一块放到水中 易切，浮水，不溶水 无 点燃中 实验探究的步骤 现象 结论 点燃蜡烛 蜡烛安静，并且持续燃烧，火焰的上方有黑烟火焰分为三层，上层黄色明亮，中层比较暗，下层呈现淡蓝色、 石蜡具有可燃性 用一根火柴平放在火焰中，大约1秒后取出 靠焰心部分大部分不变色，外焰部分变黑 火柴分为外焰，内焰，焰心三个部分，外焰的温度最高，加热时应该用外焰来加热 后续熄灭 在火焰的上方盖一个干冷的烧杯或者一个内壁有澄清石灰水的烧杯。 烧杯的内部出现了小水滴。 一段时间后，蜡烛熄灭，并且烧杯内部的澄清石灰水变混浊。 说明蜡烛燃烧会有水的生成，属于化学反应。 说明蜡烛燃烧会产生二氧化碳 熄灭蜡烛之后 实验探究的步骤 现象 结论 熄灭时发生的现象 有白烟飘出 刚熄灭产生的白烟是石蜡蒸汽冷却后产生的石蜡固态小颗粒，说明了蜡烛燃烧是 点燃熄灭的白烟 火顺着白烟将蜡烛重新点燃","link":"/2021/09/10/%E5%8C%96%E5%AD%A6%E7%AC%94%E8%AE%B0%20-2/"},{"title":"世界公祭-南京大屠杀","text":"前言写这篇文章只是为了回忆中国人民辛酸的往事，并且悼念南京大屠杀中死去的30万同胞.... 七七事变梗概七七事变，又称卢沟桥事变，发生于1937年7月7日 1937年7月7日夜，卢沟桥的日本驻军在未通知中国地方当局的情况下，径自在中国驻军阵地附近举行所谓军事演习，并诡称有一名日军士兵失踪，要求进入北平西南的宛平县城(今卢沟桥镇)搜查，被中国驻军严词拒绝，日军随即向宛平城和卢沟桥发动进攻。中国驻军第29军37师219团奋起还击，进行了顽强的抵抗 背景日本早在明治维新时期，在确立近代天皇制的同时，迅速走上了扩张侵略的军国主义道路，并制定了以中国、朝鲜为主要侵略对象的所谓“大陆政策”。20世纪初叶，日本于日俄战争后取代俄国，在中国东北扩大殖民势力，屯驻关东军，设立殖民机构“南满铁路公司”，把东北作为对中国殖民扩张的基地。第一次世界大战期间，日本利用西方列强无暇东顾，极力扩大对华侵略，出兵山东，胁迫袁世凯接受日本妄图鲸吞中国的“二十一条要求”，把侵略魔掌伸向中国内地。一次大战后，日本企图通过加紧掠夺中国、朝鲜和其他亚洲国家，摆脱政治、经济危机，在1927年的“东方会议”上对侵略中国问题进行了精心策划。1931年9月18日，日本对我国东北发动突然袭击，3个多月就占领东北全境。翌年日军进攻上海(一·二八事变)，并攻占大片华北土地，威逼平津，又在东北建立伪“满洲国”、在华北搞所谓“自治运动”，妄图长期占领这些地区。1936年日本制定的总体战略计划――“国策基准”出笼后，日本举行了一次“将官”演习，向参加演习的将官交代了全面发动侵华战争的战争部署 [2] 。日本侵略者自1931年九·一八事变侵吞我国东北后，为进一步挑起全面侵华战争，陆续运兵入关。到1936年，日军已从东、西、北三面包围了北平（今北京）。 从1937年6月起，驻丰台的日军连续举行挑衅性的军事演习 经过1937年7月7日夜10时，驻丰台日军河边旅团第一联队第三大队第八中队，由中队长清水节郎率领，在卢沟桥以北地区举行以攻取卢沟桥为假想目标的军事演习，11时许，日军诡称演习时一士兵离队失踪，要求进城搜查。在遭到中国驻军第二十九军第三十七师二一九团团长吉星文的严词拒绝后，日军迅即包围宛平县城。翌晨2时，第二十九军副军长兼北平市长秦德纯为防止事态扩大，经与日方商定，双方派员前往调查。 但日军趁交涉之际，于8日晨4时50分，向宛平县城猛烈攻击。并强占宛平东北沙岗，打响了攻城第一枪，中国守军忍无可忍，奋起还击，日军在同一天内，连续进攻宛平城三次，均遭中国守军的英勇抵抗。 7月8日，北平当局令驻军坚守卢沟桥。宋哲元致电蒋介石，报告卢沟桥事变真相。同日，国民政府外交部为卢沟桥事变向日本大使提出口头抗议。 同日，日本内阁会议提出所谓“事件不扩大，就地解决”的方针，欺骗世界舆论，麻痹国民党当局，争取时间调集部队。 9日，北平当局与日军达成协议：(1)双方立即停止射击；(2)日军撤退至永定河左岸，中国军队撤至右岸；(3)卢沟桥守备由河北保安队石友三部担任。翌日，中国军队撤退，日军不仅不履行诺言，反而大批调兵向中国军队进攻。 11日，平津当局与日军达成现地协定：(1)第二十九军代表声明向日军表示道歉，并惩办此次事变责任者；(2)取缔共产党、蓝衣社及其他抗日团体的抗日活动；(3)永定河以东不驻中国军队。 10日，各方纷纷报告，日军已由天津、古北口、榆关等处陆续开到，且有大炮、坦克等向卢沟桥前进，已将大井村五里店等处占领；平卢云路也不通行，战事即将再发。 11日起，日军时以大炮轰击宛平城及其附近一带，城内居民伤亡颇多，团长吉星文亦负伤，就将城内居民向城外比较安全地带疏散。战事由此扩大到八宝山、长辛店、廊坊、杨村等处。第二十九军各部分散于各处应敌。日军出动飞机在各处侦察扫射，战事时断时续 淞沪会战梗概淞沪会战（又称八一三战役、第二次淞沪抗战，日本称为第二次上海事变）是中日双方在抗日战争中的第一场大型会战，也是整个中日战争中进行的规模最大、战斗最惨烈的一场战役。淞沪会战开始于1937年8月13日，是卢沟桥事变后，蒋介石为了把日军由北向南的入侵方向引导改变为由东向西，以利于长期作战，而在上海采取主动反击的战役。中日双方共有约100万军队投入战斗，战役本身持续了三个月，日军投入8个师团和2个旅团20万余人，宣布死伤4万余人；中国军队投入最精锐的中央教导总队及八十七师、八十八师及148个师和62个旅80余万人，自己统计死伤30万人。 淞沪会战中日军因国民党的顽强抵抗而损失惨重，这场战役对于中国而言，标志两国之间不宣而战、全面战争的真正开始，卢沟桥事变后的地区性冲突升级为全面战争，并彻底粉碎了日本“三个月灭亡中国”的计划。国际法泰斗厉声教曾评价称：“淞沪会战为上海和长江下游工厂与物资内迁赢得了时间，为中国坚持长期抗战起到重大作用。 背景国际一战（第一次世界大战）后，日本在华扩张受到了英美列强的遏制，中国的北伐战争使日本在华利益受到削弱，促使日本政府调整对华政策，加快吞并中国东北地区的步伐；20世纪30年代初，世界经济危机发生，日本经济遭受沉重打击，陷入极端困境，并导致政治危机，在内外交困的情况下，日本法西斯势力决意冲破华盛顿体系对日本的束缚，趁英美忙于应付危机，蒋介石大规模“剿共”之际，夺取东北，以摆脱困境，并图谋争霸世界。 国内 淞沪抗战 1932年1月28日午夜，日本海军第一遣外舰队司令盐泽幸一指挥海军陆战队分三路突袭上海闸北，第十九路军在总指挥蒋光鼐、军长蔡廷锴指挥下奋起抵抗，一·二八淞沪抗战爆发。 自卫抗战 1937年日本帝国主义制造卢沟桥事变，企图在华北制造第二个满洲国。为确保首都安全，中国统帅部遵照国防计划甲案，陆军集中兵力准备歼灭上海的三千日军海军陆战队，海军堵塞江阴全歼日军长江舰队。后机密泄露，日本长江舰队仓皇逃出长江口。1937年8月9日，日本海军中尉大山勇夫等两人驾车闯入上海虹桥机场挑衅，被驻军保安队击毙。 在全民抗日浪潮推动下，国民政府第二天发表了《自卫抗战声明书》，宣告“中国决不放弃领土之任何部分，遇有侵略，惟有实行天赋之自卫权以应之”。开始总攻，中国空军也到上海协同作战，并于8月13日奉令向日本驻沪海军陆战队虹口基地发起围攻，试图赶敌下海。“八一三”淞沪抗战由此展开 数次会议 从卢沟桥事变后，统帅部为了应付“七七事变”后的复杂形势，召开了数次会议，讨论初期的战略政略和各方面准备情况。 经过开始1937年8月14日，当地国民党驻军第九集团军在总司令张治中的指挥下，指挥87、88师等部开始总攻，中国空军也到上海协同作战，并于8月13日奉令向日本驻沪海军陆战队虹口基地发起围攻，试图赶敌下海。“八一三”淞沪抗战由此展开。 中方进攻 备战中国军队准备防御上海的第一批部队是第87、88师，原为国民政府的警卫部队，是德国顾问训练出的样板师，全制式德国武器装备，为国军精锐。秘密开到上海附近后，军委会命令驻扎在苏州的装备优良的第2师补充旅第二团换上保安队服装秘密进驻虹桥机场等战略重点，以充实上海兵力（当时上海的中国驻军受限于1932年的《淞沪停战协定》，无正规陆军）。 引线 8月9日下午上海虹桥机场事件发生后，时任京沪警备司令的张治中立刻在其苏州的住所召见第2师补充旅副旅长杨文瑔（旅长钟松在庐山受训），要杨文瑔亲自到上海调查事件真相（机场守卫部队隶属第2师补充旅）。经杨文瑔实地调查核实，认为此事件属于突发事件，并非中日两国蓄意而为之。尽管如此，中日双方已经处于剑拔弩张、战争一触即发之际，二名日本军人擅自驾车持枪强闯机场警戒线是一种严重的挑衅行为，也点燃了战争的导火线。事件发生第二天，中日双方就此事开始交涉和谈判。11日，日方代表提出“中方撤退上海保安部队，撤除所有防御工事”，上海市长俞鸿钧秉奉蒋介石之命严辞拒绝。日军第3舰队司令官长谷川清命令日舰开进黄浦江、长江各口岸，所属分舰队紧急开赴上海待战，同时命令在佐世保待机的海军第1特别陆战队以及其他部队增援上海。 抢点 为抢得战争主动权，赶在日本援军到达之前消灭驻沪日军，中国组织淞沪作战部队张治中部第9集团军（下辖3个师和1个独立旅）准备围攻日军，13日战争爆发，中国军队对上海市区之敌发动全面进攻，同时出动空军，轰炸日海军陆战队司令部、汇山码头及海面舰艇。其攻击重点最初为虹口，后转向公大纱厂。“八一三”淞沪会战开始时，中国军队占了绝对优势，除2个精锐师外，还有2个装备德国火炮的重炮团，即炮兵第10团（150毫米榴弹炮）和炮兵第14团（150毫米榴弹炮），加上坦克、空军助战，按理应具有压倒性优势。其时日军在上海的部队仅海军陆战队3000多人，紧急从日本商团中动员退役军人，合计也不过4000人（国民党夸大为1万人以上），重武器也不足，但其依靠坚固工事顽强抵抗，致使中国军队一直无法完成重大突破。 增兵 经数日苦战，第87师占领沪江大学，第88师占领了五洲公墓、宝山桥、八字桥等各要点，14日到沪的第二师补充旅（已改称独立第20旅）接替第八十八师（孙元良部）防守上海爱国女校、持志大学，并担任攻击虹口公园和江湾路日军司令部的任务。15日，日本裕仁天皇命令松井石根大将为上海派遣军司令官，指挥第3师团、第11师团等军直属部队进攻上海，进一步扩大对中国的侵略战争。日军增援部队在中国军队侧后方上陆后，中方已经无力消灭日军陆战队，蒋介石为首的中国军队统帅部，考虑在上海作战比在遥远的北方大平原作战补给方便，避开机动力占优势的日军。且在有外国租借的上海开战，极有可能引起大国势力的干涉，并可能在外国调停下赢得一个光荣的和平，进而挫败日军对华北的野心，这对相对弱小的中国来说是极为有利的。8月21日，以日本长门号、陆奥号战列舰为首的庞大舰队，运输着日军上海派遣军先头部队约1万余人从日本出发奔赴马鞍群岛。22日晚上，日军陆军在马鞍群岛乘换为轻巡洋舰、驱逐舰后，分别向川沙镇、吴淞口一带驶入。日军于16日退守江湾以日本海军陆战队司令部为中心的据点，中日双方在上海一地不断投入军队。此役国民党方面先后投入8个集团军又48个师、15个独立旅、9个暂编旅、中央军校教导总队、炮兵7团、财政部税警总团、宪兵1个团、上海市保安总团、上海市警察总队、江苏省保安团4个团，3队海军舰队，兵力总数在60万人以上。日军投入5个师团1个旅团达13万人，鏖战两个月后，日军依靠强大的火力突破中国军队防线。 失利 10月20日，日军秘密组建第10军准备对中国军队实行大包围，11月5日日军第10军8万人在金山卫登陆，蒋介石因幻想九国公约签字国的干涉，拖延了撤退时机，但此时西方国家绥靖之风盛行，称中国军队主动在上海非军事区挑起战争为破坏和平，对中国的要求置之不理。几天后，日军包围网即将形成，前线中国军队大乱，部分部队为避免被围已经自行组织撤退。蒋介石仍死抱着对国联不切实际的幻想，迟迟不肯下令后撤，耽误了宝贵的时间。最终撤退时，因没有讲明各部队撤退顺序，三四十万中国将士挤在几条公路上，被日军空军轰炸，大撤退变成了大溃逃，数十万将士在撤往南京时分散，为南京保卫战的失利埋下伏笔。12万守军各自为战，无法统一作战，数天上海就告陷。此次为中国军队第一次军种（空军、海军、陆军）和诸兵种（步兵、炮兵、坦克）大规模协同作战，协同效果很差：步兵逼坦克冲锋又不予以掩护，结果坦克被日军全部击毁；步兵失去坦克掩护后攻坚伤亡惨重，甚至出现一个营部队挤在一条街内被日军堵住街口全部击毙的悲剧。陈诚回顾上海围攻未胜的教训，认为“以5师之众，对数千敌陆战队实行攻击，竟未能奏效，实在是当时部署种种不当的缘故”。史说回忆，“步兵与炮兵、战车协同作战的训练从来没做过”。 南京大屠杀梗概指1931至1945年中国抗日战争期间，中华民国在南京保卫战中失利、首都南京于1937年12月13日（学术界认为开始于12月5日）沦陷后，在华中派遣军司令松井石根和第6师团长谷寿夫指挥下，侵华日军于南京及附近地区进行长达6周的有组织、有计划、有预谋的大屠杀和奸淫、放火、抢劫等血腥暴行。在南京大屠杀中，大量平民及战俘被日军杀害，无数家庭支离破碎，南京大屠杀的遇难人数超过30万。南京大屠杀是侵华日军公然违反国际条约和人类基本道德准则，是日军在侵华战争期间无数暴行中最突出、最有代表性的一例之一。南京大屠杀期间，《纽约时报》、《中央日报》、《新华日报》等中外媒体，均对南京大屠杀进行了大量的揭露。战后，中国国民政府对南京大屠杀进行了广泛的调查。其中，南京审判战犯军事法庭经调查判定，日军集体屠杀有28案，屠杀人数19万余人；零散屠杀有858案，死亡人数15万余人，总计死亡人数达30多万，制造了惨绝人寰的特大惨案。 2014年12月13日是首个南京大屠杀死难者国家公祭日，中共中央、国务院在南京侵华日军南京大屠杀遇难同胞纪念馆举行首次南京大屠杀死难者国家公祭仪式，中共中央总书记、国家主席、中央军委主席习近平出席仪式。2015年10月9日，《南京大屠杀史档案》正式列入《世界记忆名录》。 背景淞沪会战失利1937年七七事变后，日本展开对中国全面大规模侵略。同年8月13日~11月12日日本侵略军在上海及周边地区展开淞沪会战。战役初期，日军于上海久攻不下，但日军进行战役侧翼机动，11月5日在杭州湾的全公亭、金山卫间登陆，中国军队陷入严峻形势，战局急转直下。1937年11月8日蒋中正下令全线撤退，四天后上海失守，淞沪会战结束。上海被日本占领后，日军趁势分三路急向南京进犯。中国方面就此开始准备在上海以西仅300余公里的首都南京的保卫作战，由于下达撤退命令过于仓促，后方国防工事交接发生失误，随着日军轰炸机的大范围轰炸，撤退演变为大溃败，使北路日军主力一路顺利到达南京。中华民国首都南京处于日军的直接威胁之下。由于从上海的撤退组织的极其混乱，中国军队在上海至南京沿途未能组织起有效抵抗。 南京保卫战中国统帅部此时深感事态严重，在17日和18日三次开会讨论南京防御的问题。会议上多数将领认为部队亟需休整，而南京在军事上无法防御，建议仅仅作象征性的抵抗，只有唐生智以南京是国家首都、孙中山陵寝所在，以及国际观瞻和掩护部队后撤等理由，主张固守南京。蒋介石期望保卫首都的作战对纳粹德国的外交调停有利，并且以为能够等到苏联的军事介入采纳了唐生智的建议，决定“短期固守”南京1至2个月，于11月26日任命唐（阶级上将）为南京卫戍军司令长官，负责南京保卫战。副司令长则为罗卓英及刘兴。根据坚守南京的决策，中国统帅部在12月初日军接近南京城之前共调集了约13个师又15个团共10万余人（一说约15万人）的部队保卫南京。这些部队中有很多单位刚刚经历了在上海的苦战和之后的大溃退，人员严重缺编且士气相当低落，而新补充的数万士兵大多没有完成训练。唐生智多次公开表示誓与南京城共存亡，对蒋介石则承诺没有命令决不撤退。为了防止部队私自过江撤退，唐生智采取了背水死战的态度。他下令各部队把控制的船只交给司令部，又将下关至浦口的两艘渡轮撤往武汉，还命令第36师封锁从南京城退往下关码头的唯一通道挹江门，这一“破釜沉舟”的命令给后来的悲剧性撤退埋下了隐患。1937年11月20日，中国国民党政府发表《国民政府移驻重庆宣言》，政府机关、学校纷纷迁往内地，很多市民也逃离了南京。在6月有101.5万城乡居民的南京市，到了12月初的常住人口据估计还有46.8万至56.8万人，这还不包括军人和从前方逃亡到南京的难民。 22日，本着人道主义精神留在南京的二十多位西方侨民成立了南京安全区国际委员会，他们提出在南京城的西北部设立一个给平民躲避炮火的安全区。29日，南京市市长宣布承认安全区国际委员会，并为安全区提供粮食、资金和警察。唐生智还承诺将部队撤出安全区。1937年12月5日，国际委员会收到日本政府模棱两可的回复，随即开始了安全区的工作。1937年12月1日，日军攻占江阴要塞，同日，日军下达进攻南京的作战命令，南京保卫战开始。1937年12月2日，江阴防线失守中国海军主力第一舰队和第二舰队在中日江阴海战中被全数击沉，作为南京国民政府唯一一道拱卫京畿的水上屏障失守。1937年12月10日日军发起总攻，12月12日唐生智下达突围、撤退命令，中国军队的抵抗就此瓦解。 日军进攻南京本原本打算在上海附近消灭中国军队的主力，从而迫使中国国民党政府屈服。然而，日本上海派遣军在淞沪战场苦战三个月，受到了惨重的损失，日本决策层在是否直接进攻南京的问题上产生了分歧。因为顾虑苏联在北方的军事威胁，日军参谋本部次长多田骏等人主张“不扩大”战事。因此，11月7日东京将上海派遣军与第10军临时编组为华中方面军的时候，将方面军的作战区域限制在苏州、嘉兴一线（即“制令线”）以东。而日军战地指挥官却强烈要求进攻南京：15日，柳川平助的第10军无视参谋本部的命令，决定趁中国军队溃退“独断敢行”地“全力向南京追击”；22日，方面军司令官松井石根鼓动参谋本部放弃“不扩大”方针，称“为了使事变迅速解决，乘现在敌人的劣势，必须攻占南京”。11月下旬，日军上海派遣军和第10军全面越过“制令线”，分别沿着太湖的南、北两侧开始向常州、湖州进攻。鉴于前线进展迅速的既成事实，24日东京大本营废除了“制令线”，并在12月1日下达了攻占南京的正式命令。进攻南京的作战开始后不久，疯狂前进的作战部队就把辎重部队抛在身后，由于日军原本没有深入内陆作战的后勤准备，部队立即面临着粮食供给中断的严重问题，日本军司令部于是下达了实际是要部队抢劫的“就地征收”命令。日军在抢劫中通常伴随着奸淫妇女的暴行，为了掩盖自己抢劫和强奸的罪恶，日军除了杀死受害人，经常放火烧毁整个村庄。 南京沦陷1937年12月8日，日军全面占领了南京外围一线防御阵地，开始向外廓阵地进攻。11日晚，蒋介石通过顾祝同电告唐生智“如情势不能久持时，可相继撤退，图整理而期反攻”。12日，日军第6师团一部突入中华门但未能深入，其余城垣阵地还在中国军队手中。负责防守中华门的第88师师长孙元良擅自带部分部队向下关逃跑，虽被第36师师长宋希濂劝阻返回，但已经造成城内混乱。下午，唐生智仓促召集师以上将领布置撤退。按照撤退部署，除第36师掩护司令部和直属部队从下关渡江以外，其他部队都要从正面突围，但唐生智担心属于中央军嫡系在突围中损失太大，又口头命令第87师、第88师、第74军和教导总队“如不能全部突围，有轮渡时可过江”，这个前后矛盾的命令使中国军队的撤退更加混乱。会议结束后，只有属于粤系的第66军和第83军在军长叶肇和邓龙光带领下向正面突围，在付出巨大代价后成功突破日军包围，第159师代师长罗策群战死。其他部队长官大多数没有向下完整地传达撤退部署，就各自抛下部队前往江边乘事先控制的船只逃离。这些部队听说长官退往下关，以为江边已经做好了撤退准备，于是放弃阵地涌向下关一带。负责封锁挹江门的第36师没有接到允许部队撤退的命令，和从城内退往下关的部队发生冲突，很多人被打死或踩死。12日晚，唐生智与司令部成员乘坐事先保留的小火轮从下关煤炭港逃到江北，此后第74军一部约5000人以及第36师也从煤炭港乘船过江，第88师一部和第156师在下关乘自己控制的木船过江。逃到下关的中国守军已经失去建制，成为混乱的散兵，其中有些人自己扎筏过江，很多人淹死、或是被赶到的日军射杀在江中。大部分未能过江或者突围的中国士兵流散在南京街头，不少人放弃武器，换上便装躲入南京安全区。13日晨，日军攻入南京城，开始了长达四十多天的南京大屠杀。 经过轰炸日军早在攻入南京之前就开始对南京周边地区的狂轰滥炸。1937年11月，日本陆军航空本部通过了《航空部队使用法》，其中第103条规定：“战略攻击的实施，属于破坏要地内包括政治、经济、产业等中枢机关，并且重要的是直接空袭市民，给国民造成极大恐怖，挫败其意志。”这是人类战争史上第一次明文规定可以在战争中直接以平民和居民街道为目标实施空袭，突破了战争伦理的底线。1937年9月19日，日军第三舰队司令官长谷川清下令对南京等实行“无差别级”轰炸。一部分历史学家认为，这是更广义的南京大屠杀的起始日期。这一天，日本第三舰队司令长官长谷川清下令所属第2联合航空队（1937年9月10日刚刚从大连转场到新落成的上海公大机场）对南京市区进行“无差别级”轰炸。上午8时15分，警报声大作，江阴要塞瞭望台报告：大批敌机正自下游向江阴飞来！海军各舰炮手均各就各位。几分钟后，只见一个由33架敌机组成的庞大机群在3000米高度向西南飞去。这天正是著名的“9·19空战”日，敌机被我空军第四大队击落4架，击伤1架。中国空军后来的传奇人物刘粹刚自此一战成名。 9时20分左右，警报声又起，海军见1小时前西飞的敌机群正杂乱无章错落地返航，料定必是被我空军击败，便以排炮“欢送”。敌机惊魂未定，无心恋战，未发一枪，未掷一弹，均高速向东逃窜。下午2时30分，又传来警报声，见敌机28架，又在南京被中国空军击溃。这次，该机群未敢沿江飞行，绕开中国高射炮火有效射程返航。 屠杀进城兵力约50000人，执行军纪维持的宪兵却仅有17人的日军除了个别地或小规模地对南京居民随时随地任意杀戮之外，还对中国人，特别是解除了武装的军警人员进行若干次大规模的“集体屠杀”。大规模屠杀方法有机枪射杀、集体活埋等，手段极其残忍。12月15日（日军占领第3天）：已放下武器的中国军警人员3000余人被集体解赴汉中门外用机枪密集扫射，多人当场遇难。负伤未死者亦与死者尸体同样遭受焚化。12月15日夜，押往鱼雷营的中国平民及已解除武装的中国军人9000余人被日军屠杀。又在宝塔桥一带屠杀3万余人。在中山北路防空壕附近枪杀200人。12月16日（日军占领第4天）：位于南京安全区内的华侨招待所中躲避的中国男女难民5000余人被日军集体押往中山码头，双手反绑，排列成行。日军用机枪射杀后，弃尸于长江以毁尸灭迹。5000多人中仅白增荣、梁廷芳二人于中弹负伤后泅至对岸，得免于死。日军在四条巷屠杀400余人，在阴阳营屠杀100多人。12月17日（日军占领第5天）：中国平民3000余人被日军押至煤炭港下游江边集体射杀。在放生寺、慈幼院避难的400余中国难民被集体射杀。12月18日（日军占领的第6天）夜，下关草鞋峡。日军将从南京城内逃出被拘囚于幕府山的中国难民男女老幼共57418人，除少数已被饿死或打死，全部用铅丝捆扎，驱集到下关草鞋峡，用机枪密集扫射，并对倒卧血泊中尚能呻吟挣扎者以乱刀砍戮。事后将所有尸骸浇以煤油焚化，以毁尸灭迹。此次屠杀仅有伍长德一人被焚未死，得以逃生。大方巷难民区内日军射杀4000余人。 杀人比赛1937年12月13日，《东京日日新闻》（即现在《每日新闻》）报道两名日本军官的“杀人竞赛”。日军第十六师团中岛部队两个少尉军官向井敏明和野田毅在其长官鼓励下，彼此相约“杀人竞赛”，商定在占领南京时，谁先杀满100人为胜者。他们从句容杀到汤山，向井敏明杀了89人，野田毅杀了78人，因皆未满100，“竞赛”继续进行。12月10日中午，两人在紫金山下相遇，彼此军刀已砍缺了口。野田谓杀了105人，向井谓杀了106人。又因确定不了是谁先达到杀100人之数，决定这次比赛不分胜负，重新比赛谁杀满150名中国人。这些暴行都一直在报纸上图文并茂连载，被称为“皇军的英雄”。日本投降后，这两个战犯终以在作战期间，共同连续屠杀俘虏及非战中人员“实为人类蟊贼，文明公敌”的罪名在南京执行枪决。据1946年2月中国南京军事法庭查证：日军集体大屠杀28案，19万人，零散屠杀858案，15万人。日军在南京进行了长达6个星期的大屠杀，中国军民被枪杀和活埋者达30多万人。 文化掠夺中华民族在经历这场血泪劫难的同时，中国文化珍品也遭到了大掠夺。据查，日本侵略者占领南京以后，派出特工人员330人、士兵367人、苦工830人，从1938年3月起，花费一个月的时间，每天搬走图书文献十几卡车，共抢去图书文献88万册，超过当时日本最大的图书馆东京上野帝国图书馆85万册的藏书量。 抢劫纵火抢劫和纵火造成严重财产损失。南京国际救济委员会的报告称：“南京31%的建筑被烧毁；店铺被毁比例更高；日军损毁及抢劫造成高达1亿法币的直接损失；南京周边公路沿线的农村地区被洗劫几尽，并陷入缺少种子、牲畜、劳力和工具的困境中，播种的粮食作物仅为平常年份的10%。对于日军在全城纵火造成的严重后果，据国际委员会委员斯迈思所作调查统计：全市房屋，有24%毁于纵火焚烧；城外有62%的房屋被烧毁，通济门外被烧房屋高达78%；在江宁、句容、溧水、江浦和六合（半县）四个半县中，共有30.08万间房屋被毁，占这些地区房屋总数的40%，其中多数是被烧毁的。1946年2月，南京调查敌人罪行委员会共获得500余份资料，其内容涉及日军在南京的屠杀、伤害、奸淫、劫夺、破坏、强制服役等及中岛、长谷川等29支日军部队罪行总数达295882种。南京大屠杀案敌人罪行调查委员会从1946年6月起 ，至9月底全部完成，计有确实人证案件2784件，根据调查结果制成被害人伤亡统计表、侵华日军罪行各类统计表、可出庭作证被害人住址姓名表，撰写了南京大屠杀惨案述要，分别供远东法庭和南京国防部军事法庭，作为审讯日本战犯之证据。从调查罪行种类来看，其中枪杀1159件，用刺刀刺杀667件，集体屠杀315件，拉夫285件，烧杀136件，打死69件，先刑后杀33件，先奸后杀19件，炸死19件，强奸16件等。从受害者性别来看， 男性死伤及生死不明者计2292件，女性死伤及生死不明者计478件，性别不明者计14件。在个案调查方面，该委员会提供了较为典型的10名受害者的案例，除庄少德案同南京大屠杀没有关联外，其他9人如柏鸿恩、李秀英、殷有余等均为大屠杀受害者。 ………………….","link":"/2020/12/12/%E5%8D%97%E4%BA%AC/"},{"title":"十条编写优化的 JavaScript 代码的建议","text":"本文总结了十条编写优秀的 JavaScript 代码的习惯，主要针对 V8 引擎： 1.始终以相同的顺序实例化对象属性，以便可以共享隐藏类和随后优化的代码。V8 在对 js 代码解析的时候会有构建隐藏类的过程，以相同的顺序实例化（属性赋值）的对象会共享相同的隐藏类。下面给出一个不好的实践： function Point(x, y) { this.x = x; this.y = y; } var p1 = new Point(1, 2); p1.a = 5; p1.b = 6; var p2 = new Point(3, 4); p2.b = 7; p2.a = 8; // 由于 a 和 b 的赋值顺序不同，p1 和 p2 无法共享隐藏类 2.避免分配动态属性。在实例化之后向对象添加属性将强制隐藏类更改，并减慢为先前隐藏类优化的所有方法。相反，在其构造函数中分配所有对象的属性。 3.重复执行相同方法的代码将比仅执行一次（由于内联缓存）执行许多不同方法的代码运行得更快。 4.避免创建稀疏数组。稀疏数组由于不是所有的元素都存在，因此是一个哈希表，因此访问稀疏数组中的元素代价更高。另外，尽量不要采用预分配数量的大数组，更好的办法是随着你的需要把它的容量增大。最后，尽量不要删除数组中的元素，它会让数组变得稀疏。 5.标记值：V8采用32位来表示对象和数字，其中用一位来区别对象（flag = 0）或数字（flag = 1），因此这被称之为 SMI (Small Integer)因为它只有31位。因此，如果一个数字大于31位，V8需要对其进行包装，将其变成双精度并且用一个对象来封装它，因此应该尽量使用31位有符号数字从而避免昂贵的封装操作。 6.检查你的依赖，去掉不需要 import 的内容。 7.将你的代码分割成一些小的 chunks ，而不是整个引入。 8.尽可能使用 defer 来推迟加载 JavaScript，另外只加载当前路由需要的代码段。 9.使用 dev tools 和 DeviceTiming 来寻找代码瓶颈。 10.使用诸如Optimize.js这样的工具来帮助解析器决定何时需要提前解析以及何时需要延后解析。 以上内容来源： How JavaScript works: Parsing, Abstract Syntax Trees (ASTs) + 5 tips on how to minimize parse time How JavaScript works: inside the V8 engine + 5 tips on how to write optimized code","link":"/2018/05/29/%E5%8D%81%E6%9D%A1%E7%BC%96%E5%86%99%E4%BC%98%E5%8C%96%E7%9A%84JavaScript%E4%BB%A3%E7%A0%81%E7%9A%84%E5%BB%BA%E8%AE%AE/"},{"title":"基于butterfly标签页头部透明","text":"前言这玩意只是适用于butterfly，具体效果看本文头图，没错没了。为什么我要写这玩意呢？因为群里某个叫天的人一直在那bb说要改Butterfly的头图，他一个劲的问，我一个劲的回答，然后我发现，朽木不可雕也！废话不多说，直接进入教程。 教程首先，在博客根目录找到_config.butterfly.yml，打开，然后在里面搜索配置 # Image (圖片設置) # -------------------------------------- # The banner image of home page index_img: # If the banner of page not setting, it will show the top_img default_top_img: # The banner image of archive page archive_img: # If the banner of tag page not setting, it will show the top_img # note: tag page, not tags page (子標籤頁面的 top_img) tag_img: # The banner image of tag page # format: # - tag name: xxxxx tag_per_img: # If the banner of category page not setting, it will show the top_img # note: category page, not categories page (子分類頁面的 top_img) category_img: # The banner image of category page # format: # - category name: xxxxx category_per_img: 把图片配置里面的以上项，改为空（全删了），然后在:root/themes/butterfly/source/css 里面新建一个style.css(你自己的魔改css也可以)，然后，在_config.butterfly.yml里的 inject: head: - &lt;link href=&quot;/css/style.css&quot;&gt; bottom: # - &lt;script type=&quot;text/javascript&quot; src=&quot;/js/style.js&quot;&gt;&lt;/script&gt; 在你的CSS文件里面加入如下代码 #page-header { background: transparent !important; } #page-header.post-bg:before { position: absolute; top: 0; left: 0; display: block; width: 100%; height: 100%; background-color: rgba(0, 0, 0, 0.5); /*这个rgba可以自己改*/ content: ''; }","link":"/2021/01/30/%E5%9F%BA%E4%BA%8Ebutterfly%E6%A0%87%E7%AD%BE%E9%A1%B5%E5%A4%B4%E9%83%A8%E9%80%8F%E6%98%8E/"},{"title":"多组件单页列表应用的代码组织实践","text":"本文主要对多组件单页面列表应用的代码组织实践进行总结，从而给相关应用的 Web 开发提供参考。 什么是多组件单页面列表应用？目前，其实多组件单页面列表应用非常常见，也是我们日常生活中使用非常高频的一个类别的应用，最典型的比如新闻信息流产品腾讯新闻、今日头条等这类新闻应用，在这类新闻应用中，往往图片、图文、视频、问答、投票等多种模块混杂排列。再简单一点的话，知乎、豆瓣甚至一些论坛以及一些购物软件，也可以归为此类应用。 由于笔者在负责QQ看点搜索模块的相关内容， 因此，这里给出一个QQ看点搜索的展示图： 这类应用其实有如下特点： 属于长列表滚动，内容随着滚动不断加载，一般在用户返回之前可能积累了大量的内容，因此可能会造成一定的性能问题。 模块众多，并且模块的种类和样式更新迭代快，这给我们在复用组件的选择上带来了挑战，如果我们盲目复用组件，则会造成胶水代码越来越多，如果不复用组件，那么代码量会随着业务发展线性增长，这都给我们后续的维护带来了挑战。 当然，一般的基于 Web 的应用（实际上，QQ看点搜索并不完全是纯粹的 WebView 应用）所面临的问题这里也都会遇到。不过，上述两类问题应该算是这类应用的比较重要的问题，其实归根到底，前者是性能问题（面向用户），后者是维护问题（面向开发者）。 如何解决这里的性能问题，其实已经有很多常规的方案可以借鉴了，这并不是本篇文章的重点，除了传统 Web 用到的性能优化方法，这里仅仅列举一些常规的做法： 图片等资源的懒加载。 列表虚拟滚动，即使用有限的元素，优化CSS写法等。 使用跨端融合方案渲染，例如 Weex、ReactNative、Hippy 等。 多组件单页面应用的维护困境对于这类多组件单页面应用，一般都是增量发展的，即最开始只有很个别的几个模块，随着业务越来越复杂，模块越来越多，逻辑也越来越复杂。 我们一开始，肯定可以想到一个模块（即上文中灰色分割线分割的一块）是一个组件，不同组件之间抽离出公共的函数，或者采用 mixin 将公共的部分抽离，至于数据端，由于这类应用通常在深度上不复杂，直接采用 React 或者 Vue 提供的父子组件通信的方式一般就够用了。这样设计既满足组件化的思路，也能够方便的维护项目，比较适合项目的初期。 但是随着项目发展，我们会发现，问题慢慢地产生了： 单元组件非常不好界定，比如一个左图右文的图文混排组件（例如刘亦菲的热点），之后又会增加左视频右文字，和图文展示的区别不大但是加了视频的播放时长，之后又加了左视频集合右文字（例如双世宠妃第一部分），如果我们把这多类内容当作一个组件，我们的组件中就会有非常多的判断代码，那么就会有大量的代码冗余，或者设计复杂的 mixin 和工具函数。 除了我们自身的问题，往往随着内容增多，后端返回的数据内容也会非常的不一致，在相似甚至相同的组件中，数据格式也不尽相同，我们需要在我们的单元组件中，来解析判断多种数据格式。 第三点就是样式更新隐患，当我们的组件多了之后，如果我们对我们的组件进行更新，那么很可能需要同时更新多处（嗯，全局替换也许是个不错的主意），这也是相当有风险的，也许会无意间改动我们并不想改动的 UI。 如果我们等项目复杂后面对这个问题，我们会发现改动前期的代码工作量比较巨大，但是这又是我们不得不做的事情，这类问题的产生，实际上主要原因是我们的组件设计规划的不合理，我们完全可以在最初的项目中，通过一定的设计规划，来规避这些问题。 多组件单页面应用的组件规划既然，我们现在希望设计一套比较好的组件规划，我们就需要重新审视我们的项目，对于我们的项目而言，一个业务模块一个组件的方式，的确简单方便，但是这样粗放的组件划分原则，实际上并不能完全满足我们复杂的维护需求，反而会给我们带来困扰。 经过一系列的重构和整理，目前QQ看点搜索的组件规划逻辑是这样的： 这里为了方便理解，我们采取上面样例图片中比较常见的一类业务：图文混排条目（左图右文和右图左文）来进行举例，如何设计组件来让提高我们项目的可维护性。 这里首先是零件层，零件层应该有如下内容： 图片零件，定宽，定高，自带懒加载，正常情况下只需传入一个 URL 即可使用。 标题组件，一行标题和两行标题可以设计成两个组件，但进行 CSS 层面的复用。 描述内容组件，例如双世宠妃的两行剧集描述。 元信息内容组件，例如普通图文的来源和发表时间。 时长组件，视频图文中用到。 带有描述性的图片组件，视频图文中用到。 图标组件：可以承载图标。 以上各个组件的内容，几乎都足够简单，只需传入一个 props 作为内容，一般情况下，组件中不能出现 if 或 switch 等逻辑。 接下来是组合器部分，组合器也是零件，只不过是零件的组合，其实也可以设计的比较薄弱，从而将更多的功能在布局器中完成，但是个别的时候，有这一层会给我们带来一定的方便，这里比如： 图标+文字的组合器标题。 对于零件层和组合层，一般情况下都不需要有影响外部的 margin 和 padding，即如果不增加任何多余样式罗列零件层和组合层，其上下左右四边应该是互相贴合的。 接下来是布局层，这里的布局层，其实可以进行多种方式的设计，根据设计不同其数目也不同，这里给出一种设计方式： 第一种是左图右文形式，右边可以选择普通图片、普通图片+时长组件、普通图片+描述。右边可以在一行标题、两行标题、描述零件、元信息零件中任意选择和组合。 第二种是右图左文形式，左边的可配置内容和上文右边相同。 当然，这两种整合成一种也无妨。 在布局层，是拥有事件能力的，但是其主要应该是绑定响应时间并且调用通过 props 传入的回调函数，其不应该自己执行事件的响应逻辑。 最后是控制器层，在控制器层，除了包裹标签之外，不应该出现任何 html 标签，其也不应当引用除了布局层组件以外的更深层次的组件。控制层的主要作用是进行数据处理。 控制层的分类方式和上述几层稍有不同，这里，我们就不是按照 UI 来分不同的控制器了，而是按照数据或者业务来分类，因为这里我们主要是进行数据逻辑的处理，和 UI 的关系不是那么重要了（已经将 UI 的压力进行了下沉）。 通过上述的做法，之后如果有新的需求增加进来，我们根据需要，在不同层级的组件增加内容就好了。 总结通过以上的逻辑，我们把组件划分的更加清晰明确，将 UI 展示和数据逻辑分离，并且方便我们对样式进行迭代升级。 当然，这个时候你也许还会问，如果我对部分组件样式进行升级改造，怎么样防止对原有的样式无影响呢？暂时还没有好的办法，不过，我们正在做的 UI 自动化测试套件——mangosteen，可以完美解决这个问题，敬请期待。","link":"/2018/11/10/%E5%A4%9A%E7%BB%84%E4%BB%B6%E5%8D%95%E9%A1%B5%E5%88%97%E8%A1%A8%E5%BA%94%E7%94%A8%E7%9A%84%E4%BB%A3%E7%A0%81%E7%BB%84%E7%BB%87%E5%AE%9E%E8%B7%B5/"},{"title":"如何像打王者一样学习？","text":"如何像打王者一样学习？ 　　　　王者是什么？这篇文章不是说我这个学习方法是王者，别理解错了\"王者\"指的是《王者荣耀》，什么，你不知道王者荣耀？不会吧不会吧，该不会真的没有人会不知道王者荣耀吧？我简单来说一下：《王者荣耀》是由腾讯游戏天美工作室群开发并运行的一款运营在Android、IOS、NS平台上的MOBA类手机游戏，于2015年11月26日在Android、IOS平台上正式公测，游戏前期使用名称有《英雄战迹》、《王者联盟》。《Arena Of Valor》，即《王者荣耀》的欧美版本于2018年在任天堂Switch平台发售。王者荣耀中的玩法以竞技对战为主，玩家之间进行1VS1、3VS3、5VS5等多种方式的PVP对战，还可以参加游戏的冒险模式，进行PVE的闯关模式，在满足条件后可以参加游戏的排位赛等，是属于推塔类型的游戏。对，就是你经常玩的\"王者\"都知道王者有许多的机制，比如：排位机制，反馈机制，唯我独尊... 　　　　王者的反馈机制就足以让你爱上学习，首先呢，打王者的过程中，你可以刷野，而刷野就可以返还金币，不是吗？有了这些钱，你就可以强化自己，假如我一个亚瑟，我有10万经济，我可以干嘛？当然是买装备，成为最强亚瑟啊！！！而学习也是如此，你学习知识来强化自己，你可以干嘛？在班里横着走，你就有了和他人攀比的资本（虽然攀比很不好），不是吗？想着自己可以在喜欢的妹子面前大秀特秀？但是却因为没学好知识秀不起来，自己只会打王者？为什么你只会打王者？你可以好好想想，你只会打王者，你达到了王者段位，对所有的机制啊，出装啊都烂熟于心，可是你为什么不想想怎么把这些机制运用到学习中，于其漫无目的打王者，倒不如学习天美给的机制，在实际中运用好，不就可以在妹子们面前大秀特秀？你要想想学好了以后你可以有什么利益啊，就比如说我初一的时候，我妈说你考到前十我给你买台电脑，然后呢，我就真的考到了，这是为什么？我努力考到前十，就等于我努力刷了个野，反馈机制给了我一台电脑。不是吗？你学习了，那就肯定有收获！所以，奖励机制是很重要的，不然王者也没人玩啊，一局游戏伤害都一样，那还玩什么？而阶段性的反馈机制更是重要，王者荣耀补一个兵就能得到金币，致使你最终达到摧毁水晶的目的，如果中间没有补兵、升级、击杀带来的快感、强化装备这些实时的反馈，估计没人能够坚持十几二十分钟甚至半小时（LOL时间更长）的时间来不停的摩擦手机屏幕。包括嗑瓜子，为什么人们嗑瓜子，都是一个接一个？停不下来，因为这件事情轻而易举，只需要抬抬手，就能很快得给我们反馈，让我们感到愉快，所以就会对嗑瓜子这件事情乐此不疲。为什么刷抖音一刷半天过去了，可是自己却感觉不到。可是学习，一天、两天、一周、一个月、半年，甚至一年都没有什么变化，看不到成效，可是突然有一天，你会发现自己，hia hia 流弊 ~ 可是很多人都等不到那一天。 所以我们要告诉自己： 　　　1. 只有努力地干XXX，才可以得到XXX 　　　2. 每完成一个小目标就给自己一个小小的奖励：看场电影、买一套新衣服、cherry键盘、换一个手机、换一个mac、说走就走的旅行，你能想到的自己想要的能满足自己欲望的但是平时又不敢或者不舍得且来之不易的东西。人都是有欲望的，当然如果你的欲望就是学习，那你就奖励自己再学五百年吧~哈哈。比如马上速度与激情：特别行动就要上映了，好像是八月二十三号，可以把这个当做奖励，督促自己在这段时间完成某个小目标，然后就去嘿嘿嘿~。比如每学习完某个小的阶段，奖励自己看一部电影（提前将自己最最最最最喜欢看的电影列一个清单）或者奖励自己弹两小时吉他。当你第一次出色完成任务，并得到奖励，后面再进行“反馈”，会轻松很多，如此往复，直到建立了完整的反馈机制，那你的身体就能跟着你的思想走了，也就可以把自己玩的团团转了。 　　　3. 坚持玩那个种树的游戏（具体的名字我记不说了，不是打广告），将自己的学习量化，让自己知道自己努力了（虽然看起来像是仪式感太强，但是我觉得表面努力也是一种努力，不应该完全忽略，还有学习不应该怕被别人发现）。这是我认为目前将奖励机制做的最好的时间管理软件，最后希望能种植一棵真正的树，也算小小的成就感吧~哈哈 　　　4. Leetcode等网站做题，做出其中一道题也会给人短暂的快感、成就感。 　　排位机制：王者荣耀善用朋友圈+排名的机制，每个人都是希望自己与众不同、比别人强，这也是人类能够不断进步的根本原因，和上面的阶段性反馈一样，能够得到什么和希望比别人优秀都是人的本能，希望我们能善用人的本能。排名机制能够很好的激励了我们，如果能够将排名的机制用在学习中，相信任何人也会乐此不疲！ 为此我们应该： 　　　1. 坚持写blog，写博客确实是个不错的学习方式，能够将自己的学习量化，看得见摸得着，给予实时反馈，排名、访客、徽章，增加成就感，不断激励自己。 　　　2. 坚持玩种树的那个游戏。 　　唯我独尊：你LOL打了5杀，你不是很开心？是的，人的本性就是“唯我独尊”，让别人感觉到自己很重要。还有一打五，尤其是经济落后的时候一打五，包括丝血反杀，等等比较“秀”的操作，更是给人快感，尤其是和同学、朋友、女孩子，一起的时候，别人的一句“牛x啊，兄嘚儿”，自己也会对自己说一句，“我他吗真x”，这些都能让自己浑身的血液沸腾，“越战越勇”，这都是因为人的本性就是自重，每个人都希望与众不同，认为自己是世界的中心，世界的主宰，能够拯救世界，虽然随着年龄的增长，这种自重的意识被我们隐藏起来了，但是还是很强烈！只不过游戏带给我们的这种感觉更简单，如果是编程人员，或者说技术人员，等等其他一切职业，想要一打五，恐怕不是在电脑前苦练一两周就可以达到的，需要更长的时间，一年、两年，甚至更久，相信大家都听过“一万小时理论”，没错，想要成为专家需要大概一万小时。而游戏就不一样了，能够在很短的时间内，带给我们这种被关注、被重视的感觉，所以人们都愿意沉迷于游戏，日渐消瘦，而不愿意沉迷于学习，终生不悔。其实学霸为什么厉害？因为他们希望被认可，希望被关注，“小明好厉害，差一分满分”，他们享受这种被认可的感觉，而且相对来说短期内就能够得到，这就是为什么有周考、月考（忽然感觉自己分析的很透彻，hia hia），一次得到之后，还希望有下次，所以一直在不断的努力。而学渣为什么喜欢打游戏？因为他们喜欢被重视、被关注、被需要、被认可，既然学习上不能被得到认可，那么就要在游戏上有所“建树”，让别人认为自己很厉害。可是离开校园后，没有了考试怎么办呢？为什么不把这种本能用在有益的事情上呢？为此我们要： 　　　1. 坚持写博客，短期内能够让自己感觉自己很厉害，被人关注着，其实说实话，每个人都在忙着自己的事情忙着如何被别人关注，没有太多的经历关注别人，就像我这篇文章，我写他用了小半天，你读它却只用了半分钟，但是我们得到了自我提升的小动力。 　　　2. 反复的告诉自己：成为大牛得到的认可比玩游戏得到的认可要多的多的多的多，毕竟大家都不是小孩子了嘛。 　　　3. 给自己定一个工资翻倍、进入xxx公司等目标，也能有一种唯我独尊的感觉，虽然时间稍长，但是也不是一直看不到成效。 　　　4. 努力的让自己成为，“快去找xxx，这个问题只有他能解决”。 　　等等能够在短期给自己一种通过学习，让自己“一打五”了，这种感觉的方式。但是不要过分的和朋友们吹嘘自己在努力中的“一打五”，因为人都是自重的，小心失去朋友。好吧感觉又拐到阶段性反馈上了，不过你应该懂我的意思了。题外话：那些绿茶应该也是因为人的自重性吧，所以不能怪她们，因为这是本能。 　　阶段性、强制性计划:我要在今天晚上上星耀！结果是，就差一颗星，然后一晚上都没有睡，当然了这个例子不太恰当，这个和技术有关系，哈哈哈。再举个栗子，“一个亿”的小目标，其实这是大佬无私分享的真正的成功捷径，只是我们没有到达人家的高度罢了。给自己定一个可行的、短期的、具体的计划，让自己能够得到反馈。为此我们应该： 　　　1. 制作可行的、短期的计划、具体的计划 　　　2. 如果今天的计划没有完成，熬夜也要完成，不要拖泥带水，这样第二天为了避免熬夜就会更加努力，形成良性循环。如果第二天很努力了还是需要熬夜完成，就需要调整计划了。 　　　3. 不要忘了第一条的阶段性奖励哦。 　　　4. 给自己的阶段性计划定制时间，如果完不成奖励作废！离开校园后没有阶段性的考试，很多人都会掉队，如果每天都能过成大学考试周，那么其实你已经是一个成功的人了。 　　兴趣：这个就不多说了，从小老师就教给我们“兴趣是最好的老师”，兴趣也是我们不会感到疲惫的动力源泉。可是在我看来兴趣其实就是上面的及时反馈。为什么喜欢一样东西？你喜欢王者荣耀吗？喜欢，为什么？因为我能够得到杀人的快感、因为我能在短期内比别人强，因为它能够给予我们及时的反馈。你喜欢弹吉他吗？喜欢，为什么？因为我能通过拨动琴弦发出美好的声音，让自己开心，让别人认为“哇这个人好厉害”，因为它能够给予我们及时的反馈。你喜欢女孩子嘛？喜欢，为什么？因为我追她，她会时而亲近我、时而疏远我，多奇妙的感觉，每个人都喜欢这种感觉，如果那个女孩子你都跟她告白了，她没有任何反应，那你还会持久的喜欢下去吗？当然这个例子可能不太恰当，有的人就喜欢吊着别人，这是一种恋爱学，这里就不讨论了。但是我想强调的是，因为它能给予我们及时的反馈。为此我们应该： 　　　1. 从内心深处真切的喜欢自己将要切实执行的这件事情。 　　　2. 严格执行阶段性反馈机制的那几点。 　　心理动机和生理动机：\"心理动机有释放现实中积压的负面情绪、打发时间、跟随大流一起玩、追求虚拟价值等待生理动机是肾上腺素、内啡肽以及多巴胺这三种让人兴奋开学的神经激素，而这三种神经激素就是之前的心理动机所引起的。一百年前我们使用鸦片获得内啡肽的效果，一百年后我们使用手机获得内啡肽的效果，这三种物质产生会起到什么作用？肾上腺素主要是在战斗内起作用，他会让我们感觉“刺激”与“有趣”，内啡肽主要是在战斗后起作用，它会让我们“轻松”与“满足”，多巴胺则全时期在发挥作用，让我们有极强的动力继续玩下去，让我们觉得“渴求”并“上瘾”。我们可知，从生理的角度，玩家在游戏中主要是追求肾上腺素、内啡肽与多巴胺，让这三种化学物质大量分泌的过程。本质上讲，玩乐是人的天性，是顺应人性的，所以几乎人人爱玩。而学习却需要克服人性的弱点，是反荷尔蒙的，所以学霸才让人膜拜。借鉴游戏化思维，重新设计学习体验，也许达到让人沉迷学习不容易，但至少可以让学习变得更有趣，让更多的人在快乐中学习。以上，摘要至搜狐新闻\"为此我们应该： 　　　1. 努力的建立反馈系统，一想到学习之后就能xxx，就会心潮澎湃，十分激动 　　　2. 学习的时候全神贯注，一个周期后全身放松（番茄工作法），如此往复 最后总结下比较好的学习的方法：如下 　　费曼学习法： 　　　第一步：选择目标: 　　　　选择一个想要理解的概念, 然后拿出一张白纸, 把这个概念写在白纸的最上边尽可能的完全掌握这个概念。 　　　　记住，光看不行，要写出来，最好用自己理解的话写出来。光看一遍，只是一个信息而已，觉得看懂了，其实只是了解了一人信息。 　　　　写出来，写出来。在写的过程中，会发现，光看会了不一定就能写出来。 　　　　写不出来，再回头看下概念，看看哪里还不懂。 　　　　如此，经过几个回合，能把概念写出来了，这个概念就基本掌握了。 　　　第二步：教学 　　　　把自己想像成一个老师，对面有一个学生，把这个概念讲给这个学生听。 　　　　敢打赌，在讲的时候一定会卡壳，不怕，这说明还没有完全掌握，或者说，没真正掌握，还没有抓住这个概念的实质。这就是知识概念的薄弱点。 　　　　这个时候应该恭喜自己，因为发现了自己以为会其实不会的地方。回过头，再学习一下这部分，直到真正懂了，能轻而易举地讲给对面的学生了。 　　　　 教的方式有很多，可以教别人，也可以教自己，目前特别快捷方便的一个方法就是写作。 　　　第三步：纠错并深入学习 　　　　无论何时感觉不清楚了, 都要回到原始的学习资料并重新学习让你感到不清楚的那部分，直到领会得足够顺畅,顺畅到可以在纸上解释这个部分为止。 　　　　到了这一步，才说明真正掌握了这个概念。 　　　　别急，还没结束。做到这一步，掌握的还不是很扎实。 　　　第四步：简化 　　　　记住是用自己的语言, 而不是学习资料、课程中的语言来解释概念，是用自己理解的话讲出来！ 　　　　简单化是直接找到问题的本质，和李笑来老师说的最少必要知识类似。 　　　　对面的学生听懂了么？只有用最简单清晰易懂的语言让听众听懂了叙述，才算真的牢牢掌握了这个概念。只有做到这一步，才说明真正掌握了。 　　　　有没有发现这种方法其实没有那么高深，是我们每个人都可以学会的。 　　　　最重要的还是去用。相信用一次就能体会到它的威力！ 　　　　总结一下就是用最简单的方法讲给别人听，并且使得别人容易接受。我个人认为写博客就是一个比较简单的费曼学习法，尤其是在 博客园写博客，哈哈哈。 　　康奈尔笔记法： 　　　在演讲报告现场，能够理解演讲者的意思，但日后需要回忆并使用时，演讲内容已是遗忘得一干二净；在课堂中，忙于记下已听到的内容而忽略了记笔记的同时听到的后续内容，甚至是错过了关键知识点，不能记录完整的内容，在手忙脚乱中凌乱了自我…这是因为记笔记技巧的缺失，因此只有掌握有效的记笔记技巧，才能在学习、工作和生活中抓住一切可能记录有价值的信息，才能将其真正地化为己用。 　　　康奈尔笔记法（Cornell Notes），又称5R笔记法，是康奈尔大学Walter PauK于1974年提出的一种有着固定格式的、系统的记笔记方法，通过将笔记空间进行分隔来提高记笔记的效率，是记与学、思考与运用相结合的有效方法（Pauk & Owens，2011；Broe，2013；雷慧青，2011）。康奈尔笔记法应用简单，适用范围广泛，尤其在课堂教学（Jacobs，2008；雷慧青，2011；Broe，2013；周琦等，2015；胡哲光，2016；王家蓉和李禄全，2017）、深度阅读（傅艳，2017；程亚萍，2017）等方面有着大量的实践应用，对知识的获取与理解有着明显的帮助。康奈尔笔记法的页面布局包括3个主要部分，包括笔记记录区域、提示栏、总结栏。当然，不同使用者对三个区域的命名有着些许差异，但区域功能都是一致的，如雷慧青（2011）将其划分为笔记内容、提示栏、概要区，周琦等（2015）将其划分为笔记栏、线索栏、总结，程亚萍（2017）划分为主栏、副栏、总结栏。在页面底部向上2英寸（约5厘米，相当于5-6行）的距离画一条水平直线，底部区域为summary area（总结栏）；在总结栏上部区域距离左侧2.5英寸（约6.5厘米）的距离画一条垂直直线，左侧区域为cue column（提示栏），右侧区域为笔记记录区域。但有时候为了笔记条理更加明晰，需要在笔记上方添加主题栏，记录课程名称、日期、演讲或阅读主题（Broe，2013；程亚萍，2017）。 　　　康奈尔笔记法包括：Record（记录）、Reduce（简化）、Recite（背诵）、Reflect（思考）、Review（复习）等5个关键步骤。 　　　记录：在听讲或阅读过程中，在笔记记录区域内尽量多记有意义的论据、概念等讲课内容。 　　　简化：记录完成后，及时将这些论据及概念简明扼要地概括（简化）在提示栏。 　　　背诵：遮住主栏，只用提示栏中的概要提示，尽量完整地复述听讲或阅读的内容。 　　　思考：将自己的听课随感、意见、经验体会之类的内容，写在卡片或笔记本的总结栏，加上标题和索引，编制成提纲、摘要，分成类目；总结笔记内容，促进思考消化，同时也是笔记内容的极度浓缩和升华。 　　　复习：定期花一定时间快速复习笔记，主要看总结栏和提示栏，适当看笔记内容。 　　　使用康奈尔笔记法能够帮助组织你的笔记，积极地让你参与到知识的创造中，提高你的学习技能，并带来学术上的成功（wikiHow）。这里将从“笔记准备”、“记笔记”、“复习和扩展笔记”、“利用笔记学习”等四个方面详细说明康奈尔笔记法的操作方法。 　　思维导图法: 　　　Thinking Map比较流行，用思维导图做笔记，会让人在视觉环境中轻松地整理知识、建立联系。学会使用类比，把抽象信息具体化，发挥想象力，让知识内化。在脑海中构筑画面，抽象概念也能成为有用的直觉。思维导图加强了基础概念与复杂想法之间的连接。如何把一本三十万字的书简化成一张图，属于艺术加工，而不是机械摘录。习惯使用图表做笔记，确实能提升理解和记忆，但是记忆毕竟有很大局限，最好建立自己的数据库，遇到所需有能力一键调用。 最后：人的精力是有限的，假如一个人的精力是10，工作用了7，游戏用了2，最后只要1的精力去学习，而学习是对于你来说很重要的事情，那你能做好吗？学生时代不乏听说谁谁谁，游戏打得好，学习也好，对不起不存在这样的人，就算真的有，其他他可以把学习做的更好！为此我们应该：摒弃游戏、淫欲、酒精这样强刺激的东西。可能很多人会问，种树的游戏是什么？是这个：Forest（我没打广告！！）。 > 如果说，青春，是足迹。那么，梦想，一定是远方！青春有梦，人间值得，加油！","link":"/2020/11/15/%E5%A6%82%E4%BD%95%E5%83%8F%E6%89%93%E7%8E%8B%E8%80%85%E4%B8%80%E6%A0%B7%E5%AD%A6%E4%B9%A0%EF%BC%9F/"},{"title":"搞黄色是有科学依据的？","text":"学习新思想，争做新青年 前言本文基于化学，物理，生物，Tong老师的染发技巧。化学中的电子跃迁，物理中的光色散。生物学中的眼睛。 为什么世间的万物的本质都是黄色？在弄清楚这个问题前，先搞清楚什么是黄色？ 什么是黄色？颜色词，给人愉快，充满希望和活力的感觉。黄色是电磁波的可见光部分中的中频部分，频率505525THz(对应空气中波长595570nm)，红、绿色光混合可产生黄光，类似熟柠檬或向日葵菊花色，光谱位于绿色和橙色之间的颜色。黄的光学补色是蓝，但传统上画师以紫色作为黄的互补色。 懒人懒得自己写文章 黄色是由红色光和绿色光叠加而得，颜料中红色加绿色则为棕黑色。 黄色是四个心理学基色之一，以及减法三原色之一。 注意：此义项中的“黄色”所指称的黄色这种颜色，并不具有词汇“黄色”所代表的“色情”义项。 树叶为什么会变黄？emmm，在树叶中含有绿色的叶绿素和黄色的叶黄素，夏天的阳光充足，叶绿素增加，叶子呈绿色。秋天光照减少，叶黄素增多，叶子呈现黄色。二是由于植物的生长素调节，当植物叶片衰老的一定成度时，植物分泌大量脱落酸，植物叶片脱落加快增多。三是换季时，有些植物只生活一个生长季，每当冬寒来临时树叶会枯黄并全部脱落。害虫危害：夏季是植物病虫害的高峰期，随着气温的逐渐升高，许多植物病虫害进入繁殖高峰期，多种虫害孵化成幼虫，大量食取叶片，吮吸叶液，导致树木病死。四是根部积水：当一棵植物根部积水时就很容易烂根，植物根部被泡烂，无法吸取足够的养分导致树叶枯黄。 为什么你染的头发最后会变黄？简单说，染发就是通过氧化作用，把头发中的色素拿出来，再把人工色素放进去，然后人工色素和头发中的天然色素混合，就是你看到刚染完的头发颜色。染的深浅不一样，拿掉的天然色素多少也不同，越浅的颜色天然色素褪掉的也就越多。染发一段时间，头发中的人工色素就会流失，最终你看到的就是头发中剩余天然色素和残留人工色素的颜色，大部分都是偏黄的颜色。这是因为，头发从深色到浅色分为10个色度：1代表黑色、2代表深棕色、3代表中棕色、4代表棕色、5代表浅棕色、6代表深金色、7代表中金色、8代表浅金色、9代表极浅金色、10代表极浅亚麻色。比如你染的颜色是6度的棕色，当颜色流失后，剩下的就是深金色，也就是你看到的棕黄色的颜色。 SHI，NIAO为什么是黄色的？黄色大便属于正常颜色。人体的肝脏每天都会合成和分泌很多胆汁，胆汁中的成分主要为胆色素，用于辅助脂肪类食品的消化和吸收。肝脏分泌的胆汁，可以在肠道内被吸收，形成肝肠循环。不过有少量胆汁会随着大便排出，而胆色素的颜色就偏黄，会导致大便也发黄。如果有阻塞性黄疸的时候，胆汁不能分泌到肠道，大便就会形成白陶土样颜色。血红素是血红蛋白，肌红蛋白，过氧化物酶和细胞色素等的辅基，其主要分解产物是胆色素，包括胆红素，胆绿素，胆素原和胆素等。其中胆红素呈橙黄色，是胆色素的主要成分，也是胆汁中的主要色素。包括结合胆红素和游离胆红素。 排入肠道的结合胆红素在肠道菌的作用下，还原成无色的胆素原，包括尿胆素原和粪胆素原，百分之八十到九十的胆素原在肠道下段被空气氧化成黄褐色的粪胆素，随粪便排出体外，是粪便的主要颜色。人体内每天都要代谢生成胆红素，主要来源就是老化的红细胞被破坏后血红蛋白的代谢产物。红细胞正常情况下在网状内皮系统被破坏，胆红素被血液带到肝脏，经过肝脏的摄取，转化为结合胆红素，再经过胆道排入肠道，在肠道中再转变为粪胆素，也就是粪便颜色的主要来源。肠道中的胆素原部分被吸收入血液，进入血液的其中一部分会经过肾脏随尿液排出，也就是尿液的主要颜色来源。 黄色尿液最常见的是喝水少导致的。得多喝水观察缓解就是正常。如果喝水不能缓解，得检查尿常规，看看是不是尿路感染或者是否有肝胆疾病导致。避免耽误病情 总上所述，黄色是健康的颜色,当然，除非你昨天晚上吃了红心火龙果，拉完了以后往后看有惊喜 还有一种可能性 你生病了 看东西变成黄色是色觉的改变，视神经，视网膜，黄斑及颅脑枕叶疾患都有可能出现色觉异常等。","link":"/2020/12/23/%E6%90%9E%E9%BB%84%E8%89%B2%E6%98%AF%E6%9C%89%E7%A7%91%E5%AD%A6%E4%BE%9D%E6%8D%AE%E7%9A%84%EF%BC%9F/"},{"title":"悖论","text":"悖论纪念碑谷额，在这之前，问个问题，你玩过一款游戏吗？叫做《纪念碑谷》。《纪念碑谷》（英语：Monument Valley）是一款由Ustwo独立游戏工作室在2014年开发和发行的解谜游戏。在游戏中，玩家引导主人公“公主”艾达在错视和不可能的几何物体构成的迷宫中行走，达到每个关卡的目的地。基于公司游戏设计师王友健的所绘制出概念图，到整个游戏开发出来一共花了10个月左右的时间。《纪念碑谷》的视觉风格受极简主义、日本木版画、独立游戏：《超级兄弟：剑与魔剑使-EP》、《Windosill》和《菲斯》的影响，《纪念碑谷》也被评论家们拿来与莫里茨·科内利斯·埃舍尔的画作和游戏《无限回廊》作比较。游戏中设计的每一帧可以值得像艺术品一样公开展览。《纪念碑谷》在经过内部最后测试后，于2014年4月3日在iOS平台发行。之后移植到Android平台和Windows Phone平台。游戏普遍的受到玩家的好评。评论家称赞了游戏的艺术性和音乐，但认为游戏缺乏难度以及关卡较短。纪念碑谷曾获得2014年苹果设计奖，并获得苹果2014年最佳iPad游戏的提名。在2015年1月付费下载量超过两百万。2017年6月5日在iOS平台推出游戏独立续作《纪念碑谷2》，后在2017年11月6日上架Google Play Store。在《纪念碑谷》中，玩家操纵主角艾达公主穿越各种由视错觉和不可能的几何物体所组成的迷宫。这些迷宫在游戏中被称为“神圣几何”，艾达为寻求某种宽恕而穿越它们。游戏以等轴测投影呈现，玩家需要与周围环境互动，来寻找通往地图终点的隐藏通道。游戏拥有十个不同中央机制的关卡。玩家与游戏之间的互动包括移动平台和图腾，以及创建桥梁。游戏通过颜色等设计元素间接地引导玩家，而阻碍艾达前进道路的乌鸦人则直接地引导玩家。评论员将游戏的视觉风格与的莫里茨·科内利斯·埃舍尔的画作和《无限回廊》进行比较。游戏包括摄像头模式，玩家可以在漫游关卡的途中进行屏幕截图，并可以使用与Instagram相似的滤镜功能游戏开发者大会上，王友健提到，对游戏的命名是制作过程中较为困难的一部分。最开始王友建团队使用了《幻影之塔》（Tower of Illusion）之名，但在整合完游戏要素后，游戏则被正式命名为《纪念碑谷》（Monument Valley）。王友建表示原因或许是“游戏里所有的建筑都是一座座纪念碑”，而且认为是出于便于记忆的需要 发展《纪念碑谷》由Ustwo下辖的UstwoGames工作室开发，Ustwo是一家诞生于2004年的数字产品、交互界面设计公司，自2004年以来就开始开发了iPhone应用软件。他们开发的游戏Whale Trail获得了上百万的下载量，他们其他的应用还有设计类的Granimator和图片分享类的Rando。《纪念碑谷》被设想为一款在平板电脑上的屏幕触控游戏。它自2013年起开始制作，花了10个月完成。《纪念碑谷》游戏的制作以埃舍尔风格的艺术概念画作开始，而且最终的设计不能与原始的有较大的偏差。Ustwo的管理部门并没有给设计团队提供任何预算和下明确的时间表，而是告诉他们专注于“制作出一个高质量的产品。”因为游戏的开发部门（UstwoGames）并不是Ustwo收入的主要来源，所以Ustwo才专注于它们的游戏开发部门是否能开发出“伟大的作品”，而不是关心应用能否带来巨额利润游戏的艺术风格上，担任设计师和美工师的王友健表示他的目标是能让游戏的每一帧都值得像艺术作品一样公开展示。在真正决定成为一个设计项目时，首先以王友建绘制的设计稿为开始。《纪念碑谷》的视觉风格受到了日本木版画和在雕塑设计上的极简主义和独立游戏：《超级兄弟：剑与魔剑使-EP》、《Windosill》和《菲斯》的影响。同时关卡中的“纪念碑”的设计参照物包括了蛋糕、甜甜圈的纹路、八音盒、旋转木马和陀螺以及鞋柜和暖气散热片。游戏通过颜色来指明玩家能在何处互动，这与《镜之边缘》相似[5]。同时为了在iPad或iPhone上有限的屏幕上更好将游戏内容全面展现以及让玩家有更好的游戏体验，王于是将游戏的一个关卡内划分为两到三个部分，通过到指定的位置来开启下一个部分。王友健将玩家在游戏的经历比作在玩具商店里的新奇与《狮子·女巫·魔衣橱》世界的奇幻感二者的交织[3]，并且在游戏中的故事更像是一首具有象征意义的“歌”而非仅仅是一本叙事的书或一部电影。《纪念碑谷》被设计为需要由大多数玩家来完成，希望玩家们能参与进来，发挥想象力，王友建还提到游戏在设计上需要让玩家经过一番探索来找到游戏里的目标而不是受直接的提示引导，游戏中不同寻常的风格是为普通的大众们设计的。游戏也被预期为是一段“独特的经历”而非是一项困难的挑战。 游戏于2013年12月进行内部测试[，共有一千多人参与测试并得到游戏的平均完成时间为90分钟。游戏最初也被设计为一个在iPad上的独有游戏[5]。《纪念碑谷》在2014年4月3日在iOS上首次登场，在首次发行的第二周公司收回了他们开发游戏的成本。《纪念碑谷》后被移植到了Android平台，经过两次测试后[14]于2014年5月14日首次发行。截至2014年4月，更多的游戏关卡处于开发中。Ustwo说他们正以“艺术的原因”增加关卡，他们想去尝试照着这个想法做但可能会与原版游戏内容不相配。王声称如果玩家们期望能够游戏能其移植到其他平台上，他们是会为之考虑的。《纪念碑谷》的总监说游戏自使用Unity游戏引擎后“转移至另一系统并不困难”。但是游戏以肖像画作形式的（即竖向的）屏幕方向做成，使得开发者难以将游戏改变为适合风景画方向的（即横向的）屏幕，例如不能在YouTube上发表这种视频格式的预告片或移植到PlayStation Vita上。《纪念碑谷》附加的篇章&lt;被遗忘的海岸&gt;（Forgotten Shores）于2014年11月12日在iOS平台上发布，同年11月20日登陆App Store，24日登陆Google Play Store。在原有的十个关卡下增加了八个关卡，在11月24日又推出了特别的篇章&lt;艾达的（红色）梦&gt;（Ida’s (RED) Dream），公司声称会把这个需要付费的独立关卡的收入全数捐赠给对抗艾滋病的慈善机构“Product Red”[18]，此举也是针对即将到来的2014年世界艾滋病日而发起的一个倡议。在2015年4月30日游戏被移植到Windows Phone上[20]。同年的6月25日游戏再次推出&lt;艾达的 （蓝色）梦&gt;章节（Ida’s (BLUE) Dream）。 前面水了这么多，写写自己的,纪念碑谷的话，emmm，用了大量的空间悖论你不知道空间悖论？？？放图 归根结底，什么是悖论？用Bilibili某位老师的话来讲的话，悖论分为真悖论和假悖论，假悖论呢，就是所谓的似是而非，看着是真的，但是是假的。比如说历史上著名的芝诺悖论，阿基琉斯追不上乌龟，为什么？这个悖论是个假悖论，为什么？这个故事讲的是一个人和乌龟赛跑，条件是先让乌龟跑100m，然后你去追，当你跑到100m的时候，乌龟可能向前爬行了5m，于是新的路程$S_1$出现了，你又向前跑$S_1$，乌龟向前爬行0.5m，你向前走0.5m，乌龟向前爬行0.3m，你接着向前走0.3m…..就这样一直套下去，看上去是无解的东西，我们把它放到作者的角度看看，我们猜想，芝诺可能认为，人从一个起点到一个终点，首先要经过路程的$\\frac{1}{2}$，然后，接着走剩下$\\frac{1}{2}$路程的$\\frac{1}{2}$,然后接着走剩下$\\frac{1}{4}$的$\\frac{1}{2}$，再走$\\frac{1}{8}$的 $\\frac{1}{2}$ ，接着走剩下$\\frac{1}{16}$的$\\frac{1}{2}$路程，这样就出现了无数个路程$S$,我们很好奇，0.5+0.25+0.125+0.0625+0.0325+0.015625……以后，最终值是否是1？当然那是不可能的，因为在伟大的英国，有个人叫作马克思·普朗克（Max Planck） Max Planck马克斯·卡尔·恩斯特·路德维希·普朗克（德语：Max Karl Ernst Ludwig Planck，1858年4月23日－1947年10月4日），德国物理学家，量子力学的创始人。以发现能量量子获得1918年度的诺贝尔物理学奖（1919年颁发）[1]。以之为名的普朗克常数于2019年被用于重新定义基本单位，此外还有以之为名的科学奖座、机构和学会。 普朗克出生在一个受到良好教育的传统家庭，他的曾祖父戈特利布·普朗克（Gottlieb Planck，1751年－1833年）和祖父海因里希·普朗克（Heinrich Planck，1785年－1831年）都是哥廷根的神学教授，他的父亲威廉·普朗克（Wilhelm Planck，1817年－1900年）是基尔和慕尼黑的法学教授，他的叔叔戈特利布·普朗克（Gottlieb Planck，1824年－1907年）也是哥廷根的法学家和德国民法典的重要创立者之一。 马克斯·普朗克10岁时的签名马克斯·普朗克出生于1858年4月23日的基尔，是父亲的第二任妻子母亲埃玛·帕齐希（Emma Patzig，1821年－1914年）所生的，他受洗及赐名为卡尔·恩斯特·路德维希·马克斯·普朗克，其赐名的名称简称为马克斯，而马克斯也沿用此名直到他过世。而普朗克他还有另外六个兄弟姐妹，其中四个孩子赫尔曼（Hermann）、希尔德加德（Hildegard）、阿达尔贝特（Adalbert）和奥托（Otto）是父亲的第二任妻子所生的，而父亲的第一任妻子留下了两个孩子胡戈（Hugo）和埃玛（Emma）。 普朗克在基尔度过了他童年最初的几年时光，他最早的记忆便是1864年普丹战争期间，普鲁士奥地利联军进入基尔。1867年全家搬去了慕尼黑，普朗克在慕尼黑的马克西米利安文理中学（德语：Maximiliansgymnasium München）读书，在那里他受到数学家奥斯卡·冯·米勒（Oskar von Miller，后来成为了德意志博物馆的创始人）的启发，引起青年时期的马克斯发现自己对数理方面有兴趣。米勒也教他天文学、力学和数学，从米勒那普朗克也学到了生平第一个物理定律——能量守恒定律。之后普朗克在17岁时就完成了中学的学业，在这个学校学习的这段期间内，也是普朗克第一次接触物理学这个领域。 回到正题普朗克在1900年发现了能量可以到达不可能再分割的单位，把这个单位叫做量子,我没有要水文章的意思，不必担心——也就是说，时间和空间不可能无限地细分下去，他们都有一个最小的单位，后世为了纪念他，把这最小的单位命名为普朗克长度，和普朗克时间普朗克时间 = 普朗克长度/光速普朗克时间 = $10^{-43}s$前面无限求和也可以用数学里的微积分来计算，很明显，最后结果是不可能等于一的！$|im\\sum\\limits_{n = 1}^n \\frac{1}{2^n}=|$ $n = +∞$ 常见的几个悖论祖父悖论外祖母悖论，即祖父悖论，是有关时间旅行的悖论。由法国科幻小说作家赫内·巴赫札维勒（René Barjavel）在1943年小说《不小心的旅游者》（Le Voyageur Imprudent）中提出。悖论情形如下：假如你回到过去，在自己父亲出生前把自己的祖父母杀死，但此举动会产生一矛盾的情况：你回到过去杀了你年轻的祖母，祖母死了就没有父亲，没有父亲也不会有你，那么是谁杀了祖母呢？ 或者看作：你的存在表示，祖母没有因你而死，那你何以杀死祖母？这就是祖母悖论宽矛盾。祖父悖论是一种时间旅行的悖论，科幻故事中常见的主题。最先由法国科幻小说作家赫内·巴赫札维勒（René Barjavel）在他1943年的小说《不小心的旅游者》（Le Voyageur Imprudent）中提出。情景如下：假如你回到过去，在自己父亲出生前把自己的祖父母杀死，但此举动会产生一矛盾的情况：你回到过去杀了你年轻的祖父，祖父死了就没有父亲，没有父亲也不会有你，那么是谁杀了祖父呢？ 或者看作：你的存在表示，祖父没有因你而死，那你何以杀死祖父？这就是祖父悖论宽矛盾。 平行宇宙物理学家认为，也许世界是由无数个平行宇宙组成的，而当某人回到过去杀你的祖父母时，此人杀的其实是另一个宇宙的人（或者你的这个举动也可以创造一个新的平行宇宙），而此人的“祖父”或“祖母”的死只会使那个平行宇宙的此人不再存在，而这个平行宇宙的此人则平安无事。 在量子物理中，“多个世界（世界线理论）”理论可以如此理解：对于每一个似乎随机的事件来说，只要它的可能性不是零，它所有可能的情形都会在不同的平行世界中发生，造成历史的分支。物理学家大卫·多伊奇（David Deutsch）认为，当你回到过去去杀你的祖父母时，你其实进入了另一个世界，杀的是另一个世界的人。（那个世界与你的世界的差别仅在于你祖父母死了） M理论，作为至今最有可能结合5种不同的弦论的理论，是如此解释平行宇宙的：多个三维的“膜”可以同时在一个四维的宇宙（不是爱因斯坦的三维空间加一维时间；见膜宇宙学）中存在；这些膜之间的撞击会在膜中产生大量的能量——这也可以解释大爆炸是如何起源的。可是，M理论并不能解释不同膜的历史之间的关系，也不能肯定，当你回到过去时，你会进到另一个膜里面。 M理论M理论（英语：M-theory）是物理学中将各种相容形式的超弦理论统一起来的理论。此理论最早由爱德华·威滕于1995年春季在南加州大学举行的一次弦理论会议中提出。威滕的报告启动了一股研究弦理论的热潮，被称为第二次超弦革命。弦理论学者在威滕的报告之前已经识别出五种不同的超弦理论。尽管这些理论看上去似乎非常不一样，但多位物理学家的研究指出这些理论有着微妙且有意义的关系。特别而言，物理学家们发现这些看起来相异的理论其实可以透过两种分别称为S对偶和T对偶的数学变换所统合。威滕的猜想有一部分是基于这些对偶的存在，另有一部分则是基于弦理论与11维超重力场论的关系。尽管尚未发现M理论的完整表述，这种理论应该能够描述叫膜的二维及五维物体，而且也应该能描述低能量下的11维超引力。现今表述M理论的尝试一般都是基于矩阵理论或AdS/CFT对偶。威滕表示根据个人喜好M应该代表Magic（魔术理论）、Mystery（神秘理论）或Membrane（膜理论），但应该要等到理论更基础的表述出现后才能决定这个命名的真正意义。有关M理论数学架构的研究已经在物理和数学领域产生了多个重要的理论成果。弦理论学界推测，M理论有可能为研发统合所有自然基本力的统一理论提供理论框架。当尝试把M理论与实验联系起来时，弦理论学者一般会专注于使用额外维度紧致化来建构人们所处的四维世界候选模型，但是到目前为止，物理学界还未能证实这些模型是否能产生出人们所能观测到（例如在大型强子对撞机中）的物理现象。 缸中大脑缸中之脑（英语：Brain in a vat），又称桶中之脑（brain in a jar），是知识论中的一个思想实验，由哲学家希拉里·普特南在《理性、真理和历史》（Reason, Truth, and History）一书中提出。实验的基础是人所体验到的一切最终都要在大脑中转化为神经讯号。假设一个疯子科学家、机器或其他任何意识将一个大脑从人体取出，放入一个装有营养液的桶里维持着它的生理活性，超级电脑通过神经末梢向大脑传递和原来一样的各种神经电讯号，并对于大脑发出的讯号给予和平时一样的讯号反馈，则大脑所体验到的世界其实是电脑制造的一种模拟现实[1]，则此大脑能否意识到自己生活在虚拟实境之中？这个思想实验常被参照来论证一些哲学，如知识论、怀疑论、唯我论和主观唯心主义。一个简单的论证如下：因为桶中之脑和头颅中的大脑接收一模一样的讯号，而且这是他唯一和环境交流的方式，从大脑中角度来说，它完全无法确定自己是颅中之脑还是桶中之脑。如果是前者，那它的想法是正确的，他确实走在大街上或者在划船。如果是后者，那它就是错误的，它并没有在走路或划船，只是接收到了相同的电讯号而已。一个大脑无法知道自己是在颅中还是桶中，因此这世间的一切可能都是虚假的、虚妄的。那么什么是真实？从生物学的角度讲，个体对于客观存在的认知或判别取决于他所接收的刺激，假设桶中脑生成一系列「测试用」反应用于检测自身的认知，同时「系统」又能及时给予相应的刺激作为回应，此时问题的症结就不在于桶中脑对于世界的认知，而在于「观察者」自身对于世界的认知。自身存在的客观性被质疑，在一个完全由「刺激」创造的「意识世界」中将形成一个悖论。它有许多思想原型，如庄周梦蝶、印度教的摩耶、柏拉图的「地穴寓言」、笛卡尔的「恶魔」和「我思故我在」。这一思想影响许多科幻小说和电影：《黑客帝国》《盗梦空间》《源代码》《飞出个未来》《异世奇人》《PSYCHO-PASS》 芝诺悖论这个之前讲了，在上面的: 归根结底，什么是悖论？ 空地上的奶牛它描述的是，一个农民担心自己的获奖的奶牛走丢了。这时送奶工到了农场，他告诉农民不要担心，因为他看到那头奶牛在附近的一块空地上。虽然农民很相信送奶工，但他还是亲自看了看，他看到了熟悉的黑白相间的形状并感到很满意。过了一会，送奶工到那块空地上再次确认。那头奶牛确实在那，但它躲在树林里，而且空地上还有一大张黑白相间的纸缠在树上，很明显，农民把这张纸错当成自己的奶牛了。于是问题出现了，虽然奶牛一直都在空地上，但农民说自己知道奶牛在空地上时是否正确？空地上的奶牛（The Cow in the field）最初是被Edmund Gettier用来批判主流上作为知识的定义的JTB（justified true belief）理论，即当人们相信一件事时，它就成为了知识；这件事在事实上是真的，并且人们有可以验证的理由相信它。在这个实验中，农民相信奶牛在空地上，且被送奶工的证词和他自己对于空地上的黑白相间物的观察所证实。而且经过送奶工后来的证实，这件事也是真实的。尽管如此，农民并没有真正的知道奶牛在那儿，因为他认为奶牛在那儿的推导是建立在错误的前提上的。Gettier利用这个实验和其他一些例子，解释了将知识定义为JTB的理论需要修正。 理发师悖论理发师悖论（Barber paradox）是罗素用来比喻罗素悖论的一个通俗说法，是由伯特兰·罗素在1901年提出的。罗素悖论的出现是由于朴素集合论对于集合的不加限制的定义。由于当时集合论已成为数学理论的基础，这一悖论的出现直接导致了一场数学危机，也引发了众多的数学家对这一问题的补救，最终形成了现在的公理化集合论。同时，罗素悖论的出现促使数学家认识到将数学基础公理化的必要性。小城里的理发师放出豪言：他要为城里人刮胡子，而且一定只要为城里所有“不为自己刮胡子的人”刮胡子。 但问题是：理发师该为自己刮胡子吗？如果他为自己刮胡子，那么按照他的豪言“只为城里所有不为自己刮胡子的人刮胡子”他不应该为自己刮胡子；但如果他不为自己刮胡子，同样按照他的豪言“一定要为城里所有不为自己刮胡子的人刮胡子”他又应该为自己刮胡子。 用集合论的语言来描述理发师悖论是这样的：小城里的人构成集合${\\displaystyle A={a|a\\ lives\\ in\\ the\\ town}}A={a|a\\ lives\\ in\\ the\\ town}$，对于每个小城里的人${\\displaystyle a}$a可以构造一个${\\displaystyle A}$A的子集${\\displaystyle S_{a}={x|a\\ shaves\\ x}}$$S_{a}={x|a\\ shaves\\ x}$，即${\\displaystyle a}$ a给属于 ${\\displaystyle S_{a}}S_{a}$的人刮胡子。那么，如果城里人${\\displaystyle a}$a给自己刮胡子，则${\\displaystyle a\\in S_{a}}a\\in S_{a}$，如果${\\displaystyle a}$a不给自己刮胡子，则${\\displaystyle a\\not \\in S_{a}}a\\not \\in S_{a}$，如果${\\displaystyle a}$a不给任何人刮胡子，则${\\displaystyle S_{a}}S_{a}$ 为空，即${\\displaystyle S_{a}={}}S_{a}={}$。设理发师为${\\displaystyle s}$s，则理发师的豪言就是：${\\displaystyle S_{s}={a|a\\not \\in S_{a}}}S_{s}={a|a\\not \\in S_{a}}$。问题是：如果${\\displaystyle s\\in S_{s}}s\\in S_{s}$，这将与${\\displaystyle S_{s}}S_{s}$的定义矛盾，但如果${\\displaystyle s\\not \\in S_{s}}s\\not \\in S_{s}$，根据${\\displaystyle S_{s}}S_{s}$的定义，又应该有${\\displaystyle s\\in S_{s}}s\\in S_{s}$。理发师悖论是个逻辑悖论。用集合论语言来描述并不是必需的，只是为了将来更容易说明它与罗素悖论不是一回事。德国数理逻辑大师戈特洛布·弗雷格（Frege）曾研究用集合论去描述数理逻辑，为此他还写了一本书。他在给罗素的信中提到他的工作时说他为此构造了一个特殊的集合（${\\displaystyle A}$A），这个集合由所有不包含自己的集合构成。也就是说，集合{\\displaystyle A}A的元素{\\displaystyle X}X是一个集合，${\\displaystyle X}$X自己不是自己的元素，即${\\displaystyle X\\not \\in X}X\\not \\in X$。罗素在回信中讲述了前面的理发师的故事。聪明的弗雷格看出了这实际上是指出了他所构造的集合${\\displaystyle A}$A的问题：如果${\\displaystyle A\\not \\in A}A\\not \\in A$，那么根据定义${\\displaystyle A}$A应该包含${\\displaystyle A}A$，即${\\displaystyle A\\in A}A\\in A$；但是如果${\\displaystyle A\\in A}A\\in A$，那么同样根据定义${\\displaystyle A}$A又不应该包含${\\displaystyle A}A$，即${\\displaystyle A\\not \\in A}A\\not \\in A$。可此时弗雷格的书已经付印，修改已经是不可能的了，弗雷格只能在书中加一个后记并写到：在工作结束之后而发现那大厦的基础已经动摇，对于一个科学工作者来说，没有比这更为不幸的了。虽然罗素没有直接点出那个弗雷格所构造的集合的悖论，但人们还是将那个集合的悖论称作罗素悖论。罗素悖论可以简单描述为：构造一个由所有不包含自己的集合构成的集合A，即${\\displaystyle A={X|X\\not \\in X}}A={X|X\\not \\in X}$，但我们无法断定A是否应该包含A，无论包含或者不包含都会导出矛盾。由于罗素悖论只涉及集合的定义和从属关系的判断这些集合论最基础的问题，而集合论又已成为数学理论的基础，因此罗素悖论导致了第三次数学危机。这一历史故事应该只是一个“故事”，而不完全是历史事实。从看到的一些罗素和弗雷格的通信来看，他们的交流是很学术的。但罗素悖论指出了弗雷格著作中的一个错误，使得他来不及修改他的著作而只能追加一段后记这是一个事实。尽管人们经常把理发师悖论说成是罗素悖论，或认为它们是等价的，但理发师悖论和罗素悖论并没有等价的关系，它只是一个比喻。理发师悖论中的“不给自己刮胡子”即${\\displaystyle a\\not \\in S_{a}}a\\not \\in S_{a}$和罗素悖论里的${\\displaystyle X\\not \\in X}X\\not \\in X$是不一样的。集合以自己为元素（${\\displaystyle X\\in X}X\\in X$）是一个很抽象的概念，通常需要像“所有集合的集合”这样的表达方式才能做到，一般很难用一个构造的例子来说明。但也见过一个十分有趣的例子：如果定义集合${\\displaystyle N={x|x\\ {\\text{is set discussed in this article}}}}{\\displaystyle N={x|x\\ {\\text{is set discussed in this article}}}}$。则集合${\\displaystyle N}N$是一个包含自己的集合的例子。一种新的集合论的观点认为，罗素悖论也不是一个悖论，它也是一个和上述说法类似的逻辑错误，这用到了一个新的经改进的概括公理（comprehension axiom）。但这还有待学术界的认可。 我无能为力了，上面那条杠当分割线好了。那么，再见了~亲爱的朋友。","link":"/2021/01/31/%E6%82%96%E8%AE%BA/"},{"title":"教会你写百分之九十的shell脚本！","text":"本文章主要内容来自菜鸟教程 , 也添加了一些知识点 shell脚本？在说什么是shell脚本之前，先说说什么是shell。shell是外壳的意思，就是操作系统的外壳。我们可以通过shell命令来操作和控制操作系统，比如Linux中的Shell命令就包括ls、cd、pwd等等。总结来说，Shell是一个命令解释器，它通过接受用户输入的Shell命令来启动、暂停、停止程序的运行或对计算机进行控制。shell 是一个应用程序，它连接了用户和 Linux 内核，让用户能够更加高效、安全、低成本地使用 Linux 内核，这就是 Shell 的本质。shell 本身并不是内核的一部分，它只是站在内核的基础上编写的一个应用程序。那么什么是shell脚本呢？shell脚本就是由Shell命令组成的执行文件，将一些命令整合到一个文件中，进行处理业务逻辑，脚本不用编译即可运行。它通过解释器解释运行，所以速度相对来说比较慢。shell脚本中最重要的就是对shell命令的使用与组合，再使用shell脚本支持的一些语言特性，完成想要的功能。 注释“# ”开头的就是注释，被编译器忽略 单行注释： # 多行注释： :&lt;&lt;EOF … EOF 或者 :&lt;&lt;! … ! （:&lt;&lt; 标识多行注释开始，并指定一个标识符作为开始结束的标志） 变量变量类型运行shell时，会同时存在三种变量： 局部变量：局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。 环境变量：所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。 shell变量：shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行 变量操作创建普通变量： name=“test” （=两边不可有空格） 创建只可函数体中使用的局部变量： local name=“test” （使用local修饰的变量在函数体外无法访问，并且local只能在函数体内使用） 使用变量： echo $name 或者 echo ${name} （推荐使用大括号版） 变量重新赋值： name=“new_test” （将原值覆盖） 只读变量： name=“only_read” -&gt; readonly name （使用readonly标识后的变量，不可被修改） 删除变量： unset name; （删除之后不可访问，删除不掉只读变量） 字符串变量单引号 单引号变量var=’test’ ，只能原样输出，变量无效 单引号中不能出现一个单独的单引号，转义也不可以 双引号 双引号变量var=”my name is ${name}”，变量有效 可出现转义符 拼接字符串 中间无任何+，之类的字符 name=“this is”” my name”; name=“this is my name”; name=“this” is “my name” 等效 name=‘this is’’ my nam’; name=‘this is my name’; name=‘this’ is ‘my name’ 等效 获取字符串长度``` shell 在${}中使用“#”获取长度name=“test”;echo $","link":"/2021/02/09/%E6%95%99%E4%BC%9A%E4%BD%A0%E5%86%9990-%E7%9A%84shell%E8%84%9A%E6%9C%AC%EF%BC%81/"},{"title":"深入Vue源代码解决时序问题一","text":"viola 是一个支持 Vue 的动态化框架，其 Vue 版本在 Vue 官方版本 2.5.7 上进行了少量改写，本文针对其进行具体分析。 最初，有使用者报告一个错误：在 iOS 系统，退出页面的时候，框架报错： TypeError: undefined is not an object(evaluating 'e.isDestroyed&quot; 接到这个错误之后，我首先进入 Vue 的 debug 版本，尝试获取更详细的信息： TypeError: undefined is not an object(evaluating 'componentInstance.isDestroyed&quot; 我们顺利地拿到了报错的变量名称，去 Vue 源代码中搜索，我们可以发现报错之处： destroy: function destroy (vnode) { var componentInstance = vnode.componentInstance; if (!componentInstance._isDestroyed) { // 这里报错 if (!vnode.data.keepAlive) { componentInstance.$destroy(); } else { deactivateChildComponent(componentInstance, true /* direct */); } } } 这里是 componentInstance 为 undefined，这个实际上是 vnode 的实例，其为 undefined，说明该 vue 组件在之前的阶段就已经出错不正常了，这里并不是错误的根源所在，我们需要再次进行寻找报错原因。 于是我们查看业务代码的所有日志，又发现了这样一条报错： [Vue warn]: Error in nextTick: &quot;TypeError: undefined is not an object (evaluating 'vm.$options')&quot; 初始化阶段出现这样一个错误，我们怀疑 vm 就是上文的 componentInstance，于是，我们打印报错堆栈： 调用栈: function updateChildComponent( vm, propsData, listeners, parentVnode, renderChildren ) { //... var hasChildren = !!( renderChildren || vm.$options._renderChildren || // 这里报错 parentVnode.data.scopedSlots || vm.$scopedSlots !== emptyObject ); } function prepatch(oldVnode, vnode) { var options = vnode.componentOptions; var child = vnode.componentInstance = oldVnode.componentInstance; updateChildComponent( child, options.propsData, options.listeners, vnode, options.children ); } function patchVnode(oldVnode, vnode, insertedVnodeQueue, removeOnly) {} function patch(oldVnode, vnode, hydrating, removeOnly) {} function (vnode, hydrating) {} function () { vm._update(vm._render(), hydrating); } function get() {} function getAndInvoke(cb) {} function run() {} function flushSchedulerQueue() {} function flushCallbacks() {} 调用栈实际上有点冗长，不过我们还是能发现两个有用的信息： 初始化阶段为 undefined 的 vm，就是 componentInstance，也就是和 destroy 阶段的报错属于同一个原因。 根据调用栈发现，这是一个更新阶段的报错。 这引发了我们的思考：更新阶段找不到 componentInstance 报错。 这里实际上有点阻塞了，因为一般来说，Vue 的源代码经过测试，应该不会出现这种问题的，那是不是我们的问题呢，我们回归到业务代码： created() { this.getFeedsListFromCache(); }, methods: { getFeedsListFromCache() { viola.requireAPI(&quot;cache&quot;).getItem(this.cacheKey_feeds, data =&gt; { this.processData(data.list); }); }, processData(list = [], opt = {}) { if (this.list.length &lt; cacehFeedsLength) { } this.list = []; }, } 我们对业务代码进行了抽象简化，上面是我们的最小问题 Demo，实际上我们就做了这样一件事情： 在 created 执行方法，调用端的接口，再回调函数里面更新某个 data 中声明的数据。 首先，我们可以梳理下对一般 vue 组件的初始化更新，vue 是如何做的： created 时实际上 vnode 已经建立完成，这个时候还没有 mount，但是数据监听已经建立了，这个时候如果改动数据，会把相关 update 函数放在一个名为 flushCallbacks 的函数队列中。 该函数队列会通过默认为 Promise.then 的 microtask 方式来调度，当前阶段的 mount 流程会继续，mount 结束后，会执行 flushCallbacks 队列中的更新操作。 从代码层面上来讲，这几个流程应该是这样的： ├── callHook(vm, 'created'); // 执行created 钩子 ├── proxySetter(val); // 改变数据，调用 proxy ├── Watcher.prototype.update; // 调用 Watcher，将 update 操作入栈 ├── vm.$mount(vm.$options.el); // 执行 mount 流程 ├── callHook(vm, 'beforeMount'); ├── callHook(vm, 'mounted'); // 依次调用 beforeMount 和 mounted └── flushCallbacks // 执行 更新 然后我们分析我们这里的流程，首先值得强调的是这个函数 viola.requireAPI(&quot;cache&quot;).getItem，这个函数是端注入的函数，但我们不能将其当作异步函数来对待，实际上，这是一个同步函数，（至于这个同步函数和 js 中的普通函数，是否有区别，还有待商榷，不过应该是有区别的，因为如果我们不用此函数的话，就不会出现该问题。） 接下来，我们打出详细的调用栈，根据顺序来分析实际的执行流程： ├── callHook(vm, 'created'); // 执行created 钩子 ├── proxySetter(val); // 改变数据，调用 proxy ├── Watcher.prototype.update; // 调用 Watcher，将 update 操作入栈 ├── flushCallbacks // 执行 更新 ├── vm.$mount(vm.$options.el); // 执行 mount 流程 ├── callHook(vm, 'beforeMount'); └── callHook(vm, 'mounted'); // 依次调用 beforeMount 和 mounted 我们发现，我们的执行流程出现了很大问题：在 mount 阶段未完成的时候就执行了 flushCallbacks，先执行更新操作，这里的顺序错乱导致了后续问题。 我们可看下调用 flushCallbacks 的代码： if (typeof Promise !== 'undefined' &amp;&amp; isNative(Promise)) { var p = Promise.resolve(); microTimerFunc = function () { p.then(flushCallbacks); // in problematic UIWebViews, Promise.then doesn't completely break, but // it can get stuck in a weird state where callbacks are pushed into the // microtask queue but the queue isn't being flushed, until the browser // needs to do some other work, e.g. handle a timer. Therefore we can // &quot;force&quot; the microtask queue to be flushed by adding an empty timer. if (isIOS) { setTimeout(noop); } }; } 这里 microTimerFunc 的 p.then，被同步执行了，也就是说，这里的微任务优先于当前事件循环的函数执行了（此时由于 mount 流程是同步的，mount 流程的相关函数理应在该事件循环中，优先于微任务执行）。 我们找到了根源，接下来就是分析解决方案和根本原因。 由于我们的问题在于 update 流程执行太快了，所以采用一种方式放慢一点即可： 将 vue 的微任务模式（默认）改成宏任务模式：var useMacroTask = false; =&gt; true。 在 created 阶段的加一个 setTimeout(0)。 不过对于根本原因，实际上本次仍然没有完全分析透彻，还留有如下疑问： viola.requireAPI(&quot;cache&quot;).getItem 这个函数到底做了什么？其对事件循环有什么影响？ 在执行 microTimerFunc 的时候，为什么 p.then 优先于 vm.$mount 执行了？ 该错误仅在 iOS 系统出现，iOS 系统是否会在某些情况将微任务的优先级变高？ 对于这些疑问，Vue 源代码中也做了一些评论： // Here we have async deferring wrappers using both microtasks and (macro) tasks. // In &lt; 2.4 we used microtasks everywhere, but there are some scenarios where // microtasks have too high a priority and fire in between supposedly // sequential events (e.g. #4521, #6690) or even between bubbling of the same // event (#6566). However, using (macro) tasks everywhere also has subtle problems // when state is changed right before repaint (e.g. #6813, out-in transitions). // Here we use microtask by default, but expose a way to force (macro) task when // needed (e.g. in event handlers attached by v-on). 不过，这里始终都没有找到最本质的原因，也许这和 iOS JSCore 的微任务/宏任务的处理机制有关，具体原因，待下次探究。","link":"/2019/07/06/%E6%B7%B1%E5%85%A5Vue%E6%BA%90%E4%BB%A3%E7%A0%81%E8%A7%A3%E5%86%B3%E6%97%B6%E5%BA%8F%E9%97%AE%E9%A2%98%E4%B8%80/"},{"title":"Proxy和Reflect双向数据绑定的微框架","text":"写在前面：这篇文章讲述了如何利用Proxy和Reflect实现双向数据绑定，个人系Vue早期玩家，写这个小框架的时候也没有参考Vue等源代码，之前了解过其他实现，但没有直接参考其他代码，如有雷同，纯属巧合。 代码下载地址：这里下载 综述关于Proxy和Reflect的资料推荐阮老师的教程:http://es6.ruanyifeng.com/ 这里不做过多介绍。 实现双向数据绑定的方法有很多，也可以参考本专栏之前的其他实现，我之所以选择用Proxy和Reflect，一方面是因为可以大量节约代码，并且简化逻辑，可以让我把更多的经历放在其他内容的构建上面，另外一方面本项目直接基于ES6，用这些内容也符合面向未来的JS编程规范，第三点最后说。 由于这个小框架是自己在PolarBear这个咖啡馆在一个安静的午后开始写成，暂且起名Polar，日后希望我能继续完善这个小框架，给添加上更多有趣的功能。 首先我们可以看整体功能演示：[一个gif动图，如果不能看，请点击这里的链接] 代码分析我们要做这样一个小框架，核心是要监听数据的改变，并且在数据的改变的时候进行一些操作，从而维持数据的一致。 我的思路是这样的： 将所有的数据信息放在一个属性对象中(this._data),之后给这个属性对象用Proxy包装set,在代理函数中我们更新属性对象的具体内容，同时通知所有监听者，之后返回新的代理对象(this.data)，我们之后操作的都是新的代理对象。 对于input等表单，我们需要监听input事件，在回调函数中直接设置我们代理好的数据对象，从而触发我们的代理函数。 我们同时也应该支持事件机制，这里我们以最常用的click方法作为例子实现。 下面开始第一部分，我们希望我们之后使用这个库的时候可以这样调用: &lt;div id=&quot;app&quot;&gt; &lt;form&gt; &lt;label&gt;name:&lt;/label&gt; &lt;input p-model = &quot;name&quot; /&gt; &lt;/form&gt; &lt;div&gt;name:{{name}} age:{{age}}&lt;/div&gt; &lt;i&gt;note:{{note}}&lt;/i&gt;&lt;br/&gt; &lt;button p-click=&quot;test(2)&quot;&gt;button1&lt;/button&gt; &lt;/div&gt; &lt;script&gt; var myPolar = new Polar({ el:&quot;#app&quot;, data: { name: &quot;niexiaotao&quot;, age:16, note:&quot;Student of Zhejiang University&quot; }, methods:{ test:function(e,addNumber){ console.log(&quot;e:&quot;,e); this.data.age+=Number(addNumber); } } }); &lt;/script&gt; 没错，和Vue神似吧，所以这种调用方式应当为我们所熟悉。 我们需要建立一个Polar类，这个类的构造函数应该进行一些初始化操作: constructor(configs){ this.root = this.el = document.querySelector(configs.el); this._data = configs.data; this._data.__bindings = {}; //创建代理对象 this.data = new Proxy(this._data, {set}); this.methods = configs.methods; this._compile(this.root); } 这里面的一部份内容是直接将我们传入的configs按照属性分别赋值，另外就是我们创建代理对象的过程，最后的_compile方法可以理解为一个私有的初始化方法。 实际上我把剩下的内容几乎都放在_compile方法里面了，这样理解起来方便，但是之后可能要改动。 我们还是先不能看我们代理的set该怎么写，因为这个时候我们还要先继续梳理思路： 假设我们这样&lt;div&gt;name:{{name}}&lt;/div&gt;将数据绑定到dom节点，这个时候我们需要做什么呢，或者说，我们通过什么方式让dom节点和数据对应起来，随着数据改变而改变。 看上文的__bindings。这个对象用来存储所有绑定的dom节点信息，__bindings本身是一个对象，每一个有对应dom节点绑定的数据名称都是它的属性，对应一个数组，数组中的每一个内容都是一个绑定信息，这样，我们在自己写的set代理函数中，我们一个个调用过去，就可以更新内容了： dataSet.__bindings[key].forEach(function(item){ //do something to update... }); 我这里创建了一个用于构造调用的函数，这个函数用于创建存储绑定信息的对象： function Directive(el,polar,attr,elementValue){ this.el=el;//元素本身dom节点 this.polar = polar;//对应的polar实例 this.attr = attr;//元素的被绑定的属性值，比如如果是文本节点就可以是nodeValue this.el[this.attr] = this.elementValue = elementValue;//初始化 } 这样，我们的set可以这样写: function set(target, key, value, receiver) { const result = Reflect.set(target, key, value, receiver); var dataSet = receiver || target; dataSet.__bindings[key].forEach(function(item){ item.el[item.attr] = item.elementValue = value; }); return result; } 接下来可能还有一个问题：我们的{{name}}实际上只是节点的一部分，这并不是节点啊，另外我们是不是还可以这么写：&lt;div&gt;name:{{name}} age:{{age}}&lt;/div&gt;？ 关于这两个问题，前者的答案是我们将{{name}}替换成一个文本节点，而为了应对后者的情况，我们需要将两个被绑定数据中间和前后的内容，都变成新的文本节点，然后这些文本节点组成文本节点串。(这里多说一句，html5的normalize方法可以将多个文本节点合并成一个，如果不小心调用了它，那我们的程序就要GG了) 所以我们在_compile函数首先： var _this = this; var nodes = root.children; var bindDataTester = new RegExp(&quot;{{(.*?)}}&quot;,&quot;ig&quot;); for(let i=0;i&lt;nodes.length;i++){ var node=nodes[i]; //如果还有html字节点，则递归 if(node.children.length){ this._compile(node); } var matches = node.innerHTML.match(bindDataTester); if(matches){ var newMatches = matches.map(function (item) { return item.replace(/{{(.*?)}}/,&quot;$1&quot;) }); var splitTextNodes = node.innerHTML.split(/{{.*?}}/); node.innerHTML=null; //更新DOM，处理同一个textnode里面多次绑定情况 if(splitTextNodes[0]){ node.append(document.createTextNode(splitTextNodes[0])); } for(let ii=0;ii&lt;newMatches.length;ii++){ var el = document.createTextNode(''); node.appendChild(el); if(splitTextNodes[ii+1]){ node.append(document.createTextNode(splitTextNodes[ii+1])); } //对数据和dom进行绑定 let returnCode = !this._data.__bindings[newMatches[ii]]? this._data.__bindings[newMatches[ii]] = [new Directive(el,this,&quot;nodeValue&quot;,this.data[newMatches[ii]])] :this._data.__bindings[newMatches[ii]].push(new Directive(el,this,&quot;nodeValue&quot;,this.data[newMatches[ii]])) } } 这样，我们的数据绑定阶段就写好了，接下来，我们处理&lt;input p-model = &quot;name&quot; /&gt;这样的情况。 这实际上是一个指令，我们只需要当识别到这一个指令的时候，做一些处理，即可： if(node.hasAttribute((&quot;p-model&quot;)) &amp;&amp; node.tagName.toLocaleUpperCase()==&quot;INPUT&quot; || node.tagName.toLocaleUpperCase()==&quot;TEXTAREA&quot;){ node.addEventListener(&quot;input&quot;, (function () { var attributeValue = node.getAttribute(&quot;p-model&quot;); if(_this._data.__bindings[attributeValue]) _this._data.__bindings[attributeValue].push(new Directive(node,_this,&quot;value&quot;,_this.data[attributeValue])) ; else _this._data.__bindings[attributeValue] = [new Directive(node,_this,&quot;value&quot;,_this.data[attributeValue])]; return function (event) { _this.data[attributeValue]=event.target.value } })()); } 请注意，上面调用了一个IIFE，实际绑定的函数只有返回的函数那一小部分。 最后我们处理事件的情况：&lt;button p-click=&quot;test(2)&quot;&gt;button1&lt;/button&gt; 实际上这比处理p-model还简单，但是我们为了支持函数参数的情况，处理了一下传入参数，另外我实际上将event始终作为一个参数传递，这也许并不是好的实践，因为使用的时候还要多注意。 if(node.hasAttribute(&quot;p-click&quot;)) { node.addEventListener(&quot;click&quot;,function(){ var attributeValue=node.getAttribute(&quot;p-click&quot;); var args=/\\(.*\\)/.exec(attributeValue); //允许参数 if(args) { args=args[0]; attributeValue=attributeValue.replace(args,&quot;&quot;); args=args.replace(/[\\(\\)\\'\\&quot;]/g,'').split(&quot;,&quot;); } else args=[]; return function (event) { _this.methods[attributeValue].apply(_this,[event,...args]); } }()); } 现在我们已经将所有的代码分析完了，是不是很清爽？代码除去注释约100行，所有源代码可以在这里下载。这当然不能算作一个框架了，不过可以学习学习，这学期有时间的话，还要继续完善，也欢迎大家一起探讨。 一起学习，一起提高，做技术应当是直接的，有问题欢迎指出～ 最后说的第三点：是自己还是一个学生，做这些内容也仅仅是出于兴趣，因为找暑期实习比较艰难，在等待鹅厂面试间隙写的这个程序，压压惊(然而并没有消息)。","link":"/2018/04/09/%E6%9E%84%E5%BB%BA%E5%88%A9%E7%94%A8Proxy%E5%92%8CReflect%E5%AE%9E%E7%8E%B0%E5%8F%8C%E5%90%91%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A%E7%9A%84%E5%BE%AE%E6%A1%86%E6%9E%B6/"},{"title":"深入浏览器web渲染与优化-续","text":"本篇文章接上一篇继续分析浏览器web渲染相关内容，但是更侧重优化工作。当然，主要还是基于X5来分析 上一篇文章我们主要是从浏览器内核的线程角度来分析相关工作的，对整体流程没有宏观清晰的分析，这次我们从宏观到微观，从整体到局部，来进行分析和探究可以优化的地方。 首先，一个网页的加载，需要什么工作呢？ 这个工作可以分为三部分：云(云端)、管(传输链路)、端(客户端)，从云经过管传到端，然后经过加载解析排版渲染，从而完成网页从请求到呈现的工作(当然，我们这里没有涉及协议的分析，实际上根据协议不同，这个传输可能是多次传输)。 数据到端之后，又经过以下过程，才最终显示出来： 在这个过程中，我们怎么衡量性能呢？ 固然，我们有诸多浏览器提供的API，这些API能让我们获取到较多信息并且记录上报： 但是这些具体数值表达的含义有限，并且他们实际上也不等于用户体验。 所以，找到一个科学并且可以检测的标准，并且这个标准可以和用户体验有正相关关系，这个是至关重要的。 目前这个标准是首屏时间(就之前自己的了解，具体的还区分首屏展示时间和首屏可交互时间，但是这里讲师不做区分，就下文提供的测算方法而言，显然这里指的是首屏展示时间，另外，展示后到用户的第一次操作都会有一个至少1s的延时，毕竟用户手指按下的动作是会比较慢的，这个时间js的交互都能完成了，所以首屏展示时间更加重要–from dorsywang) 那么首屏时间怎么测量呢？ 拿摄像机快速拍照测量的。这个答案可能有些吃惊，但是目前X5内核业务的相关开发人员的确就是采用这种方式测算的，通过高速相机不断拍照，然后辅助图像识别，判断首屏是否已经加载完成，最终再通过人工回归校对。因为如果采用程序检测的话，基本上都会对过程本身造成一定的影响，所以没有采用这种方式。当然，通过摄像+图像识别的这种方式也是有一定的弊端，比如说，假设首屏有一个图片，而图片的加载通常比较慢并且不影响css、js的加载，这个时候直接通过图片识别的话就可能会有一定的误判。 知道了怎么测算，那么接下来分析影响这个指标的一些原因： 资源阻塞内核线程 我们知道，一般情况下，css和JS是阻塞页面的，当然也会对首屏时间造成影响。 对这个问题，X5内核有关键子资源(阻塞资源)缓存，这里的关键资源，指的是内核经过统计判断得出的业务常用的关键子资源。 当然，这个统计也可能缺乏一定的准确性，所以相关团队也正在推进这方面的内容规范化(比如写入Web App Manifest) 中文Layout的时间过长 这个问题我之前没有听说过，但是的确是这样子，实际上，浏览器在绘制文字的时候经历的过程非常的多，其中有一个环节是找到文字的宽度和高度(因为在英文状态下，每一个字符的宽度是不同的，所以每一个字符都要查找，但是英文总共只有26个字符)，而中文由于字符比较多，常用得就有6000多个，完整的更是有2万个以上，所以这个过程需要花费更多的时间。 为了解决这个问题，X5内核考虑到中文文字几乎都是等宽等高的，所以这个过程对一个文字串来说只需要查询一次即可，实际上是节约了这个环节。 首次渲染太慢 为了解决这个问题，可以采用先绘制首屏的方式，这个也就是基于第一篇文章中讲到的浏览器的分块渲染机制 一次解析内容过多 采用首屏探测机制，优先解析首屏内容。 另外，这里可以前端配合去做首屏优化： 在首屏的位置插入首屏标签，内核解析到标签后立即终止解析并且排版上屏 &lt;meta name=‘x5-pagetype’ content=‘optpage'&gt; 然后在首屏分界的地方： &lt;first-screen/&gt; 有了这，可以专门去优化首屏标签之前的内容(这个标签前尽量展现耗时少和不需要阻塞解析的资源)。 另外，X5内核也提供了主资源预拉取的接口，并且考虑到预拉取的cookie问题，还提供了preconnect预链接。TIP:主资源中关联的子资源预拉取不用主动调用 预先操作 另外为了提供更加极致的优化，X5内核(QQ浏览器、手Q Webview)还提供了如下诸多预操作： 在”黏贴并转到”之前就开始进行网络请求和预渲染 经常访问的站点可以预解析DNS 点击地址栏时进行搜索预连接 点击链接时，先预链接，再做跳转。 …… 其他方式优化实际上上文主要讲了客户端方面的优化工作，实际上对于”云”、”管”两端，还是有很多优化工作可以讲的，但是由于这个和前端关系不是特别密切，我挑一部分讲一讲。这些在我们前端做个人项目的后台时候也可以参考 后台提速 直接使用IP，节省dns的查询时间 维持长连接 HTTP1.1启用包头节省 服务器缓存 文本资源压缩传输GZIP(6) 图片尺寸压缩、图片质量压缩、支持webp和sharpp/hevc格式。 降低网络时延 就快接入和就近接入 在选择接入点的时候，如果采用就近接入，可以保持路由稳定，有利于负载均衡，并且实现简单，便于维护。但是也有一定的缺点：经验判断，准确度不够高 ； 无法自动切换路由。 相比较而言，选择就快接入，是一个能够提效的方式。 内容防劫持运营商劫持对我们来说已经是不陌生的话题了，但是X5内核有一个比较新的防劫持手段，就是客户端和云加速服务器同时采用轻量级http加密，虽然这种方式普适性不强，但是的确可以解决腾讯自身业务的防劫持问题。 QUIC和http2QUIC 基于UDP的协议通讯方式，有这些优势： 延迟少 前向纠错 没有**线头阻塞[注1]**的多路复用 通信通道的定义基于ID而不是IP+端口，使得切换网络后继续转发链接成为可能 —————— 注1：线头阻塞： —————— 附1: 带宽和延迟对网页加载的影响：","link":"/2017/08/31/%E6%B7%B1%E5%85%A5%E6%B5%8F%E8%A7%88%E5%99%A8web%E6%B8%B2%E6%9F%93%E4%B8%8E%E4%BC%98%E5%8C%96-%E7%BB%AD/"},{"title":"浅谈前端中的二进制数据类型","text":"目前在一个项目中，WebSocket部分由于后端使用了gzip压缩，前端处理起来废了一点时间，从而发现自己在二进制数据类型这个知识点还存在一定的盲区，因此这里进行总结。 本文主要简单介绍ArrayBuffer对象、TypedArray对象、DataView对象以及Blob原始数据类型，和它们之间的互相转换方法。部分代码参考这里而非本人原创，仅做个人学习使用。 这些类型化对象，一般会在以下场景中使用： WebGL 中，浏览器和显卡之间需要使用二进制数据进行通信。 在一些 Rest 接口或者 WebSocket 中，采用压缩过的数据进行通信，这个压缩和解压缩的过程可能需要借助二进制对象。 在 Canvas 中，我们可能需要通过生成 Blob 的方式保存当前内容。 在 Img 等资源文件中，URL 可以为 Blob 原始数据类型。 在读取用户上传文件时，可能需要用到二进制数据类型进行中间转换。 下文分两部分，前一部分概述各个二进制数据类型，后一部分将它们之间的互相转换。 二进制数据类型概述ArrayBufferArrayBuffer对象代表储存二进制数据的一段内存，它不能直接读写，只能通过视图（TypedArray视图和DataView视图)来读写，视图的作用是以指定格式解读二进制数据。 ArrayBuffer也是一个构造函数，可以分配一段可以存放数据的连续内存区域。 var buf = new ArrayBuffer(32); 上面代码生成了一段32字节的内存区域，每个字节的值默认都是0。可以看到，ArrayBuffer构造函数的参数是所需要的内存大小（单位字节）。 为了读写这段内容，需要为它指定视图。DataView视图的创建，需要提供ArrayBuffer对象实例作为参数。 var buf = new ArrayBuffer(32); var dataView = new DataView(buf); dataView.getUint8(0) // 0 上面代码对一段32字节的内存，建立DataView视图，然后以不带符号的8位整数格式，读取第一个元素，结果得到0，因为原始内存的ArrayBuffer对象，默认所有位都是0。 另外，我们可以将ArrayBuffer生成的结果，传入TypedArray中： var buffer = new ArrayBuffer(12); var x1 = new Int32Array(buffer); x1[0] = 1; var x2 = new Uint8Array(buffer); x2[0] = 2; x1[0] // 2 ArrayBuffer实例的byteLength属性，返回所分配的内存区域的字节长度。 var buffer = new ArrayBuffer(32); buffer.byteLength // 32 如果要分配的内存区域很大，有可能分配失败（因为没有那么多的连续空余内存），所以有必要检查是否分配成功。 if (buffer.byteLength === n) { // 成功 } else { // 失败 } ArrayBuffer实例有一个slice方法，允许将内存区域的一部分，拷贝生成一个新的ArrayBuffer对象。 var buffer = new ArrayBuffer(8); var newBuffer = buffer.slice(0, 3); 上面代码拷贝buffer对象的前3个字节（从0开始，到第3个字节前面结束），生成一个新的ArrayBuffer对象。slice方法其实包含两步，第一步是先分配一段新内存，第二步是将原来那个ArrayBuffer对象拷贝过去。 slice方法接受两个参数，第一个参数表示拷贝开始的字节序号（含该字节），第二个参数表示拷贝截止的字节序号（不含该字节）。如果省略第二个参数，则默认到原ArrayBuffer对象的结尾。 除了slice方法，ArrayBuffer对象不提供任何直接读写内存的方法，只允许在其上方建立视图，然后通过视图读写。 ArrayBuffer有一个静态方法isView，返回一个布尔值，表示参数是否为ArrayBuffer的视图实例。这个方法大致相当于判断参数，是否为TypedArray实例或DataView实例。 var buffer = new ArrayBuffer(8); ArrayBuffer.isView(buffer) // false var v = new Int32Array(buffer); ArrayBuffer.isView(v) // true TypedArray目前，TypedArray对象一共提供9种类型的视图，每一种视图都是一种构造函数。 Int8Array：8位有符号整数，长度1个字节。 Uint8Array：8位无符号整数，长度1个字节。 Uint8ClampedArray：8位无符号整数，长度1个字节，溢出处理不同。 Int16Array：16位有符号整数，长度2个字节。 Uint16Array：16位无符号整数，长度2个字节。 Int32Array：32位有符号整数，长度4个字节。 Uint32Array：32位无符号整数，长度4个字节。 Float32Array：32位浮点数，长度4个字节。 Float64Array：64位浮点数，长度8个字节。 这9个构造函数生成的对象，统称为TypedArray对象。它们很像正常数组，都有length属性，都能用方括号运算符（[]）获取单个元素，所有数组的方法，在类型化数组上面都能使用。两者的差异主要在以下方面。 TypedArray数组的所有成员，都是同一种类型和格式。 TypedArray数组的成员是连续的，不会有空位。 Typed化数组成员的默认值为0。比如，new Array(10)返回一个正常数组，里面没有任何成员，只是10个空位；new Uint8Array(10)返回一个类型化数组，里面10个成员都是0。 TypedArray数组只是一层视图，本身不储存数据，它的数据都储存在底层的ArrayBuffer对象之中，要获取底层对象必须使用buffer属性。 构造函数TypedArray数组提供9种构造函数，用来生成相应类型的数组实例。 构造函数有多种用法。 TypedArray(buffer, byteOffset=0, length?) 同一个ArrayBuffer对象之上，可以根据不同的数据类型，建立多个视图。 // 创建一个8字节的ArrayBuffer var b = new ArrayBuffer(8); // 创建一个指向b的Int32视图，开始于字节0，直到缓冲区的末尾 var v1 = new Int32Array(b); // 创建一个指向b的Uint8视图，开始于字节2，直到缓冲区的末尾 var v2 = new Uint8Array(b, 2); // 创建一个指向b的Int16视图，开始于字节2，长度为2 var v3 = new Int16Array(b, 2, 2); 对于以上代码，v1、v2和v3是重叠的：v1[0]是一个32位整数，指向字节0～字节3；v2[0]是一个8位无符号整数，指向字节2；v3[0]是一个16位整数，指向字节2～字节3。只要任何一个视图对内存有所修改，就会在另外两个视图上反应出来。 注意，byteOffset必须与所要建立的数据类型一致，否则会报错。 var buffer = new ArrayBuffer(8); var i16 = new Int16Array(buffer, 1); // Uncaught RangeError: start offset of Int16Array should be a multiple of 2 上面代码中，新生成一个8个字节的ArrayBuffer对象，然后在这个对象的第一个字节，建立带符号的16位整数视图，结果报错。因为，带符号的16位整数需要两个字节，所以byteOffset参数必须能够被2整除。 如果想从任意字节开始解读ArrayBuffer对象，必须使用DataView视图，因为TypedArray视图只提供9种固定的解读格式。 TypedArray(length) 视图还可以不通过ArrayBuffer对象，直接分配内存而生成。 var f64a = new Float64Array(8); f64a[0] = 10; f64a[1] = 20; f64a[2] = f64a[0] + f64a[1]; TypedArray(typedArray) 类型化数组的构造函数，可以接受另一个视图实例作为参数。 var typedArray = new Int8Array(new Uint8Array(4)); 上面代码中，Int8Array构造函数接受一个Uint8Array实例作为参数。 注意，此时生成的新数组，只是复制了参数数组的值，对应的底层内存是不一样的。新数组会开辟一段新的内存储存数据，不会在原数组的内存之上建立视图。 var x = new Int8Array([1, 1]); var y = new Int8Array(x); x[0] // 1 y[0] // 1 x[0] = 2; y[0] // 1 上面代码中，数组y是以数组x为模板而生成的，当x变动的时候，y并没有变动。 如果想基于同一段内存，构造不同的视图，可以采用下面的写法。 var x = new Int8Array([1, 1]); var y = new Int8Array(x.buffer); x[0] // 1 y[0] // 1 x[0] = 2; y[0] // 2 TypedArray(arrayLikeObject) 构造函数的参数也可以是一个普通数组，然后直接生成TypedArray实例。 var typedArray = new Uint8Array([1, 2, 3, 4]); 注意，这时TypedArray视图会重新开辟内存，不会在原数组的内存上建立视图。 上面代码从一个普通的数组，生成一个8位无符号整数的TypedArray实例。 TypedArray数组也可以转换回普通数组。 var normalArray = Array.prototype.slice.call(typedArray); BYTES_PER_ELEMENT属性每一种视图的构造函数，都有一个BYTES_PER_ELEMENT属性，表示这种数据类型占据的字节数。 Int8Array.BYTES_PER_ELEMENT // 1 Uint8Array.BYTES_PER_ELEMENT // 1 Int16Array.BYTES_PER_ELEMENT // 2 Uint16Array.BYTES_PER_ELEMENT // 2 Int32Array.BYTES_PER_ELEMENT // 4 Uint32Array.BYTES_PER_ELEMENT // 4 Float32Array.BYTES_PER_ELEMENT // 4 Float64Array.BYTES_PER_ELEMENT // 8 ArrayBuffer与字符串的互相转换ArrayBuffer转为字符串，或者字符串转为ArrayBuffer，有一个前提，即字符串的编码方法是确定的。假定字符串采用UTF-16编码（JavaScript的内部编码方式），可以自己编写转换函数。 // ArrayBuffer转为字符串，参数为ArrayBuffer对象 function ab2str(buf) { return String.fromCharCode.apply(null, new Uint16Array(buf)); } // 字符串转为ArrayBuffer对象，参数为字符串 function str2ab(str) { var buf = new ArrayBuffer(str.length * 2); // 每个字符占用2个字节 var bufView = new Uint16Array(buf); for (var i = 0, strLen = str.length; i &lt; strLen; i++) { bufView[i] = str.charCodeAt(i); } return buf; } TypedArray.prototype.set()TypedArray数组的set方法用于复制数组（正常数组或TypedArray数组），也就是将一段内容完全复制到另一段内存。 var a = new Uint8Array(8); var b = new Uint8Array(8); b.set(a); 上面代码复制a数组的内容到b数组，它是整段内存的复制，比一个个拷贝成员的那种复制快得多。set方法还可以接受第二个参数，表示从b对象哪一个成员开始复制a对象。 var a = new Uint16Array(8); var b = new Uint16Array(10); b.set(a, 2) 上面代码的b数组比a数组多两个成员，所以从b[2]开始复制。 TypedArray.prototype.subarray()subarray方法是对于TypedArray数组的一部分，再建立一个新的视图。 var a = new Uint16Array(8); var b = a.subarray(2,3); a.byteLength // 16 b.byteLength // 2 subarray方法的第一个参数是起始的成员序号，第二个参数是结束的成员序号（不含该成员），如果省略则包含剩余的全部成员。所以，上面代码的a.subarray(2,3)，意味着b只包含a[2]一个成员，字节长度为2。 TypedArray.prototype.slice()TypeArray实例的slice方法，可以返回一个指定位置的新的TypedArray实例。 let ui8 = Uint8Array.of(0, 1, 2); ui8.slice(-1) // Uint8Array [ 2 ] 上面代码中，ui8是8位无符号整数数组视图的一个实例。它的slice方法可以从当前视图之中，返回一个新的视图实例。 slice方法的参数，表示原数组的具体位置，开始生成新数组。负值表示逆向的位置，即-1为倒数第一个位置，-2表示倒数第二个位置，以此类推。 TypedArray.of()TypedArray数组的所有构造函数，都有一个静态方法of，用于将参数转为一个TypedArray实例。 Float32Array.of(0.151, -8, 3.7) // Float32Array [ 0.151, -8, 3.7 ] TypedArray.from()静态方法from接受一个可遍历的数据结构（比如数组）作为参数，返回一个基于这个结构的TypedArray实例。 Uint16Array.from([0, 1, 2]) // Uint16Array [ 0, 1, 2 ] 这个方法还可以将一种TypedArray实例，转为另一种。 var ui16 = Uint16Array.from(Uint8Array.of(0, 1, 2)); ui16 instanceof Uint16Array // true from方法还可以接受一个函数，作为第二个参数，用来对每个元素进行遍历，功能类似map方法。 Int8Array.of(127, 126, 125).map(x =&gt; 2 * x) // Int8Array [ -2, -4, -6 ] Int16Array.from(Int8Array.of(127, 126, 125), x =&gt; 2 * x) // Int16Array [ 254, 252, 250 ] 上面的例子中，from方法没有发生溢出，这说明遍历是针对新生成的16位整数数组，而不是针对原来的8位整数数组。也就是说，from会将第一个参数指定的TypedArray数组，拷贝到另一段内存之中（占用内存从3字节变为6字节），然后再进行处理。 DataView如果一段数据包括多种类型（比如服务器传来的HTTP数据），这时除了建立ArrayBuffer对象的复合视图以外，还可以通过DataView视图进行操作。 DataView视图提供更多操作选项，而且支持设定字节序。本来，在设计目的上，ArrayBuffer对象的各种TypedArray视图，是用来向网卡、声卡之类的本机设备传送数据，所以使用本机的字节序就可以了；而DataView视图的设计目的，是用来处理网络设备传来的数据，所以大端字节序或小端字节序是可以自行设定的。 DataView视图本身也是构造函数，接受一个ArrayBuffer对象作为参数，生成视图。 DataView(ArrayBuffer buffer [, 字节起始位置 [, 长度]]); 下面是一个例子。 var buffer = new ArrayBuffer(24); var dv = new DataView(buffer); DataView实例有以下属性，含义与TypedArray实例的同名方法相同。 DataView.prototype.buffer：返回对应的ArrayBuffer对象 DataView.prototype.byteLength：返回占据的内存字节长度 DataView.prototype.byteOffset：返回当前视图从对应的ArrayBuffer对象的哪个字节开始 DataView实例提供8个方法读取内存。 getInt8：读取1个字节，返回一个8位整数。 getUint8：读取1个字节，返回一个无符号的8位整数。 getInt16：读取2个字节，返回一个16位整数。 getUint16：读取2个字节，返回一个无符号的16位整数。 getInt32：读取4个字节，返回一个32位整数。 getUint32：读取4个字节，返回一个无符号的32位整数。 getFloat32：读取4个字节，返回一个32位浮点数。 getFloat64：读取8个字节，返回一个64位浮点数。 这一系列get方法的参数都是一个字节序号（不能是负数，否则会报错），表示从哪个字节开始读取。 var buffer = new ArrayBuffer(24); var dv = new DataView(buffer); // 从第1个字节读取一个8位无符号整数 var v1 = dv.getUint8(0); // 从第2个字节读取一个16位无符号整数 var v2 = dv.getUint16(1); // 从第4个字节读取一个16位无符号整数 var v3 = dv.getUint16(3); 上面代码读取了ArrayBuffer对象的前5个字节，其中有一个8位整数和两个十六位整数。 如果一次读取两个或两个以上字节，就必须明确数据的存储方式，到底是小端字节序还是大端字节序。默认情况下，DataView的get方法使用大端字节序解读数据，如果需要使用小端字节序解读，必须在get方法的第二个参数指定true。 // 小端字节序 var v1 = dv.getUint16(1, true); // 大端字节序 var v2 = dv.getUint16(3, false); // 大端字节序 var v3 = dv.getUint16(3); DataView视图提供8个方法写入内存。 setInt8：写入1个字节的8位整数。 setUint8：写入1个字节的8位无符号整数。 setInt16：写入2个字节的16位整数。 setUint16：写入2个字节的16位无符号整数。 setInt32：写入4个字节的32位整数。 setUint32：写入4个字节的32位无符号整数。 setFloat32：写入4个字节的32位浮点数。 setFloat64：写入8个字节的64位浮点数。 这一系列set方法，接受两个参数，第一个参数是字节序号，表示从哪个字节开始写入，第二个参数为写入的数据。对于那些写入两个或两个以上字节的方法，需要指定第三个参数，false或者undefined表示使用大端字节序写入，true表示使用小端字节序写入。 // 在第1个字节，以大端字节序写入值为25的32位整数 dv.setInt32(0, 25, false); // 在第5个字节，以大端字节序写入值为25的32位整数 dv.setInt32(4, 25); // 在第9个字节，以小端字节序写入值为2.5的32位浮点数 dv.setFloat32(8, 2.5, true); 如果不确定正在使用的计算机的字节序，可以采用下面的判断方式。 var littleEndian = (function() { var buffer = new ArrayBuffer(2); new DataView(buffer).setInt16(0, 256, true); return new Int16Array(buffer)[0] === 256; })(); BlobBlob 对象表示一个不可变、原始数据的类文件对象。Blob 表示的不一定是JavaScript原生格式的数据。File 接口基于Blob，继承了 blob 的功能并将其扩展使其支持用户系统上的文件。 要从其他非blob对象和数据构造一个Blob，请使用 Blob() 构造函数。要创建包含另一个blob数据的子集blob，请使用 slice()方法。要获取用户文件系统上的文件对应的Blob对象，请参阅 File文档。 从Blob中读取内容的唯一方法是使用 FileReader。以下代码将 Blob 的内容作为类型数组读取： var reader = new FileReader(); reader.addEventListener(&quot;loadend&quot;, function() { // reader.result 包含转化为类型数组的blob }); reader.readAsArrayBuffer(blob); 更多关于Blob的内容，请直接查看这里 数据格式转换String转Blob//将字符串 转换成 Blob 对象 var blob = new Blob([&quot;Hello World!&quot;], { type: 'text/plain' }); console.info(blob); console.info(blob.slice(1, 3, 'text/plain')); TypeArray转Blob//将 TypeArray 转换成 Blob 对象 var array = new Uint16Array([97, 32, 72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 33]); //测试成功 //var blob = new Blob([array], { type: &quot;application/octet-binary&quot; }); //测试成功， 注意必须[]的包裹 var blob = new Blob([array]); //将 Blob对象 读成字符串 var reader = new FileReader(); reader.readAsText(blob, 'utf-8'); reader.onload = function (e) { console.info(reader.result); //a Hello world! } ArrayBuffer转Blobvar buffer = new ArrayBuffer(32); var blob = new Blob([buffer]); // 注意必须包裹[] Blob转String这里需要注意的是readAsText方法的使用。 //将字符串转换成 Blob对象 var blob = new Blob(['中文字符串'], { type: 'text/plain' }); //将Blob 对象转换成字符串 var reader = new FileReader(); reader.readAsText(blob, 'utf-8'); reader.onload = function (e) { console.info(reader.result); } Blob转ArrayBuffer这里需要注意的是readAsArrayBuffer方法的使用。 //将字符串转换成 Blob对象 var blob = new Blob(['中文字符串'], { type: 'text/plain' }); //将Blob 对象转换成 ArrayBuffer var reader = new FileReader(); reader.readAsArrayBuffer(blob); reader.onload = function (e) { console.info(reader.result); //ArrayBuffer {} //经常会遇到的异常 Uncaught RangeError: byte length of Int16Array should be a multiple of 2 //var buf = new int16array(reader.result); //console.info(buf); //将 ArrayBufferView 转换成Blob var buf = new Uint8Array(reader.result); console.info(buf); //[228, 184, 173, 230, 150, 135, 229, 173, 151, 231, 172, 166, 228, 184, 178] reader.readAsText(new Blob([buf]), 'utf-8'); reader.onload = function () { console.info(reader.result); //中文字符串 }; //将 ArrayBufferView 转换成Blob var buf = new DataView(reader.result); console.info(buf); //DataView {} reader.readAsText(new Blob([buf]), 'utf-8'); reader.onload = function () { console.info(reader.result); //中文字符串 }; }","link":"/2018/05/09/%E6%B5%85%E8%B0%88%E5%89%8D%E7%AB%AF%E4%B8%AD%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"title":"深入浏览器web渲染与优化","text":"本文主要分析和总结web内核渲染的相关内容，以及在这方面前端可以做的性能优化工作。 文章主要分为以下几个部分： blink内核的渲染机制 chrome内核架构变迁 分层渲染 动画 &amp; canvas &amp; WebGl 这里的前两部分可能会有些枯燥，如果是前端工程师并且想立即获得实际项目的建议的，可以直接阅读第三部分和第四部分 blink内核的渲染机制blink内核是Google基于Webkit内核开发的新的分支，而实际上，目前Chrome已经采用了blink内核，所以，我们接下来的有关分析大多基于blink内核的浏览器(Chrome)，就不再详细指明，当然，部分内容也会涉及到腾讯研发的X5内核(X5内核基于安卓的WebView，目前已经在手机QQ等产品中使用，基于X5内核的项目累计有数亿UV，上百亿PV)。 一个页面的显示，实际上主要经历了下面的四个流程： 加载 =&gt; 解析 =&gt; 排版 =&gt; 渲染 实际上，这里的渲染主要是指排版之后到最后的上屏绘制(这个时候内容已经排版好了)，一部分前端工程师通常会把一部分的排版工作理解到“渲染”的流程中(也就是下图中全部工作)，实际上这个理解是不准确的。 目前，浏览器的渲染采用的是分块渲染的机制，所谓的分块渲染的机制，其实应该这么理解： 浏览器首先把整个网页分成一些低分辨率的块，再把网页分成高分辨率的块，然后给这些块排列优先级。 处在可视区域内的低分辨率块的优先级会比较高，会被较先绘制。 之后浏览器会把高分辨率的块进行绘制，同样也是先绘制处于可视区域内的，再绘制可视区域外的(由近到远)。 以上讲的这些策略可以使可以使得浏览器优先展示可视区域内的内容，并且先展示大致内容，再展示高精度内容(当然，由于这个过程比较快，实际上我们大多时候是感受不到的)。 另外这里值得提醒的一点是，分块的优先级是会根据到可视区域的距离来决定的，所以有些横着的内容(比如banner的滚动实现，通常会设置横向超出屏幕来表示隐藏)，也是会按照到可视区域的距离来决定优先级的。 绘制的过程，可以被硬件加速，这里硬件加速的主要手段主要是指： 硬件加速合成上屏 2D Canvas、Video的硬件加速 GPU光栅化 GPU光栅化速度更快，内存和CPU的消耗更少 目前还没有办法对包含复杂矢量绘制的页面进行GPU光栅化 GPU光栅化是未来趋势 chrome内核架构变迁在渲染架构上，chrome也是经历了诸多变迁，早期的Chrome是这样的： 早期的chrome的架构实际上有以下缺点： Renderer线程任务繁重 无法实时响应缩放滑动操作 脏区域与滑动重绘区域有冲突 这里举个场景，假设一个gif，这个时候如果用户滑动，滑动新的需要绘制的内容和gif下一帧内容就会产生绘制冲突 当然，经过一系列的发展，Chrome现在是这样的： 在安卓上，Android 4.4的 Blink内核架构如下(4.4之前并不支持OpenGL) 当然，这种架构也有如下缺点： UI线程过于繁忙 无法支持Canvas的硬件加速以及WebGL 所以，后期发展成了这样： 总结看来，内核发展的趋势是： 多线程化(可以充分利用多核心CPU) 硬件加速(可以利用GPU) 分层渲染在阅读这一章之前，我建议读者先去亲自体验一下所谓的“分层渲染”： 打开Chrome浏览器，打开控制台，找到”Layers”，如果没有，那么在控制台右上角更多的图标-&gt;More tools 找到”Layers”，然后随便找个网页打开即可 网页的分层渲染流程主要是下面这样的： (注意：多个RenderObject可能又会对应一个或多个RenderLayer) 既然才用了分层渲染，那么肯定可以来分层处理，分层渲染有如下优点： 减少不必要的重新绘制 可以实现较为复杂的动画 能够方便实现复杂的CSS样式 当然，分层渲染是会很影响渲染效率的，可以有好的影响，使用不当也会有差的影响，我们需要合理的控制和使用分层： 如果小豆腐块分层较多，页面整体的分层数量较大，会导致每帧渲染时遍历分层和计算分层位置耗时较长啊(比较典型的是腾讯网移动端首页)。 如果可视区域内分层太多且需要绘制的面积太大，渲染性能非常差，甚至无法达到正常显示的地步(比如有一些全屏H5)。 如果页面几乎没有分层，页面变化时候需要重绘的区域较多。元素内容无变化只有位置发生变化的时候，可以利用分层来避免重绘。 那么，是什么原因可以导致分层呢？目前每一个浏览器或者不同版本的浏览器分层策略都是有些不同的(虽然总体差不太多)，但最常见的几个分层原因是：transform、Z-index；还有可以使用硬件加速的video、canvas；fixed元素；混合插件(flash等)。关于其他更具体的内容，可以见下文。 //注:Chrome中符合创建新层的情况： Layer has 3D or perspective transform CSS properties(有3D元素的属性) Layer is used by &lt;video&gt; element using accelerated video decoding(video标签并使用加速视频解码) Layer is used by a &lt;canvas&gt; element with a 3D context or accelerated 2D context(canvas元素并启用3D) Layer is used for a composited plugin(插件，比如flash) Layer uses a CSS animation for its opacity or uses an animated webkit transform(CSS动画) Layer uses accelerated CSS filters(CSS滤镜) Layer with a composited descendant has information that needs to be in the composited layer tree, such as a clip or reflection(有一个后代元素是独立的layer) Layer has a sibling with a lower z-index which has a compositing layer (in other words the layer is rendered on top of a composited layer)(元素的相邻元素是独立layer) 最后，我们总结一下如何合理的设计分层：分层总的原则是，减少渲染重绘面积与减少分层个数和分层总面积： 相对位置会发生变化的元素需要分层(比如banner图、滚动条) 元素内容更新比较频繁的需要分层(比如页面中夹杂的倒计时等) 较长较大的页面注意总的分层个数 避免某一块区域分层过多，面积过大 (如果你给一个元素添加上了-webkit-transform: translateZ(0);或者 -webkit-transform: translate3d(0,0,0);属性，那么你就等于告诉了浏览器用GPU来渲染该层，与一般的CPU渲染相比，提升了速度和性能。(我很确定这么做会在Chrome中启用了硬件加速，但在其他平台不做保证。就我得到的资料而言，在大多数浏览器比如Firefox、Safari也是适用的)) 另外值得一提的是，X5对分层方面做了一定的优化工作，当其检测到分层过多可能会出现显示问题的时候会进行层合并，牺牲显示性能换取显示正确性。 最后再提出一个小问题： 以下哪种渲染方式是最优的呢？ 这里实际上后者虽然在分层上满足总体原则，但是之前讲到浏览器的分块渲染机制，是按照到可视区域的距离排序的，考虑到这个因素，实际上后者这种方式可能会对分块渲染造成一定的困扰，并且也不是最优的。 动画 &amp; canvas &amp; WebGl讲最后一部分开始，首先抛出一个问题：CSS动画 or JS动画? 对内核来说，实际上就是Renderer线程动画还是Compositor线程动画，二者实际上过程如下： 所以我们可以看出，Renderer线程是比Compositor线程动画性能差的(在中低端尤其明显) 另外，无论是JS动画还是CSS动画，动画过程中的重绘以及样式变化都会拖慢动画执行以及引起卡顿以下是一些不会触发重绘或者排版的CSS动画属性： cursor font-variant opacity orphans perspective perspecti-origin pointer-events transform transform-style widows 想要了解更多内容，可以参考这里 这方面最终的建议参考如下： 尽量使用不会引起重绘的CSS属性动画，例如transform、opacity等 动画一定要避免触发大量元素重新排版或者大面积重绘 在有动画执行时，避免其他动画不相关因素引起排版和重绘 requestAnimationFrame另外当我们在使用动画的时候，为了避免出现掉帧的情况，最好采用requestAnimationFrame这个API，这个API迎合浏览器的流程，并且能够保证在下一帧绘制的时候上一帧一定出现了： 3D canvas还有值得注意的是，有的时候我们需要涉及大量元素的动画(比如雪花飘落、多个不规则图形变化等)，这个时候如果用CSS动画，Animation动画的元素很多。，导致分层个数非常多，浏览器每帧都需要遍历计算所有分层，导致比较耗时、 这个时候该怎么办呢？ 2D canvas上场。 和CSS动画相比，2D canvas的优点是这样的： 硬件加速渲染 渲染流程更优 其渲染流程如下： 实际上以上流程比较耗时的是JS Call这一部分，执行opengl的这一部分还是挺快的。 HTML 2D canvas 主要绘制如下三种元素： 图片 文字 矢量 这个过程可以采用硬件加速，硬件加速图片绘制的主要流程： 硬件加速文字绘制的主要流程： 但对于矢量绘制而言，简单的图形，比如点、直线等可以直接使用OpenGL渲染，复杂的图形，如曲线等，无法采用OpenGL绘制。 对于绘制效率来说，2D Canvas对绘制图片效率较高，绘制文字和矢量效率较低(所以建议是，我们如果能使用贴图就尽量使用贴图了) 还有，有的时候我们需要先绘制到离屏canvas上面，然后再上屏，这个可以充分利用缓存。 3D canvas(WebGL)目前，3D canvas(WebGL)的应用也越来越多，对于这类应用，现在已经有了不少已经成型的庫: 通用引擎：threeJS、Pixi VR视频的专业引擎：krpano、UtoVR H5游戏引擎：Egret、Layabox、Cocos WebGL虽然包含Web，但本身对前端的要求最低，但是对OpenGL、数学相关的知识要求较高，所以如果前端工程师没有一定的基础，还是采用现在的流行庫。 X5内核对于WebGl进行了性能上和耗电上的优化，并且也对兼容性错误上报和修复做了一定的工作。 本文参考腾讯内部讲座资料整理而成，并融入一部分笔者的补充，谢绝任何形式的转载。 其他优质好文： Javascript高性能动画与页面渲染","link":"/2017/08/27/%E6%B7%B1%E5%85%A5%E6%B5%8F%E8%A7%88%E5%99%A8web%E6%B8%B2%E6%9F%93%E4%B8%8E%E4%BC%98%E5%8C%96/"},{"title":"熵","text":"熵(entropy)这个概念为什么可以被引用到科学的多个不同的领域呢? (物理，计算机视觉，信息论等等) 这里我就来谈谈物理学上的熵，和信息论中的熵联系在于哪里。 为了帮助理解和应用，最后有几个关于熵的应用的有趣例子。 熵最早来原于物理学. 德国物理学家鲁道夫·克劳修斯首次提出熵的概念，用来表示任何一种能量在空间中分布的均匀程度，能量分布得越均匀，熵就越大。一滴墨水滴在清水中，部成了一杯淡蓝色溶液热水晾在空气中，热量会传到空气中，最后使得温度一致可以注意到些能量分布的变化的过程都是都是不可逆的(你不能期望清水中的蓝色分子 自动地聚成一滴墨水,放在空气中的汽水能 自动变成开水)， 所以这些系统的熵都在慢慢地增加。 而物理学第二定律描述的就是，宇宙中这些不可逆的过程的变化规律，而自然界中的一切自发过程都具有不可逆性. 所以熵增加是一个很普适地概念，说明了宇宙的发展具有方向性, 也就是向着熵增大的方向发展。 而这些推动事物向熵增大方向发展的力量（规律）， 被称为熵力。更多的一些生活中的例子:熵力的一个例子是耳机线，我们将耳机线整理好放进口袋，下次再拿出来已经乱了。让耳机线乱掉的看不见的“力”就是熵力，耳机线喜欢变成更混乱。熵力另一个具体的例子是弹性力。一根弹簧的力，就是熵力。 胡克定律其实也是一种熵力的表现。万有引力也是熵力的一种(热烈讨论的话题)。浑水澄清宇宙发展的尽头就是熵达到最大，所有物质温度达到热平衡。这样的宇宙中再也没有任何可以维持运动或是生命的能量存在（热寂）。 以上是从能量分布角度看熵的定义, 从 微观分子角度看，熵表征了这个系统的混乱程度(与微观状态数量有关，比如说粒子所处的能级(E)可以作为状态). 所有微观粒子的状态只有一种时,也就是混乱程度为0。而当3个粒子分别处于状态1,2,3 时。这个系统的熵就是k*ln(3),总而言之就是微观状态越多，熵越TM大. 于是从微观看，熵就表现了这个系统所处状态的 不确定性程度。香农，描述一个信息系统的时候就借用了熵的概念，这里熵表示的是这个信息系统的 平均信息量(平均不确定程度)。所以当我们说某句话的时候，会帮助你消除一定不确定程度,而消除程度的多少就是信息量的多少. 通过计算[2]，常用汉字的熵要大于英文字母的熵，所以你说相同长度的中文很有可能比英文表达的意思要多哦。 除了信息论，很多地方都借用了这个可爱的概念。 (信息压缩编码)霍夫曼(Huffman)编码: 设计一个信息系统，使得其熵最大，（编码的平均信息量最大）， 于是使得发送效率最高。 (计算机视觉)这文章里，介绍了用熵变化来检测出一个图片的显著点.(e.g.一只在墙上的手). 原理就是这些有突出特征的点，都是表现出很强的不确定性(熵)。于是把这些点找出来,就很有可能是你想要的（特征突出的东西） （自然语言处理） 在翻译的时候，一个 句子J, 可能有 n种翻译(f1,f2…fn),还有一些 知识Z(比如在这篇武侠小说里，f3,f4这两个翻译的可能性更大)。现在你要建立一个模型来描述这n种翻译的可能性(概率分布)是怎么样的, 最好的模型也就是让这几种翻译的概率分布的 “熵” 最大。 学术一点说，就是在已知的前提下，请将未知的东西做最不可预测(熵最大)的推断。这就是 最大熵模型的思想。 有趣的问题是， 在这些系统中，会不会也存在和宇宙一样的，熵不断增大的系统呢? 或者通过观察某些熵不断增大的信息系统(像语言系统，熵总是不断增大的，因为，人们总想更快更简单地表达一些信息)，能不能推导出这是由一种不可逆的力量产生的变化?这种力量又是什么呢? 常见科普书上说，熵，就是混乱程度的量度，一个系统越对称，就越混乱，熵就越大。这无疑给了众多的不求甚解者以艺术般的幻想，以至于跨学科地误用和错用熵概念的现象泛滥。 有个问题，即是很多物理学专业的学生，也常搞错。这个问题就是：一盆脏水，搅浑后封闭起来作为状态0；在地球上不管它，浑水会自然澄清，分层，这是状态1。问：从状态0到状态1，熵是增加了，还是减少了？ 很多人会认为熵减少了。甚至一些物理学家也犯这个错误，在科普作品中说引力是能抵抗熵增的，所谓熵增定律带来混乱，而引力可能抵抗熵增而带来秩序。 果真如此吗？当然不是。热力学第二定律，在引力下一样表现的很明显，引力丝毫不会导致熵减。只是人们头脑中被科普灌输了错误的熵图像而已。 先说一个规范。物理学家在看到自由落体下落的系统的时候，发现落体动能在增加，但这时他绝不会说：由于落体的动能在增大，所以能量不守恒，能量在增大。而是说：自由下落系统的总能量是守恒的，因为势能转化为动能，动能才因此增加。保守力提供了势能，或势场，这是始终要考虑去的能量形式。我们说封闭系统的时候，始终就把势能（势场）封闭进去考虑了。势能场是不能随意中途加入或移除的，除非你额外输入能量—你不能不做功而把地球上的物体送入无引力场的太空中去。 同样，严肃的物理学家，针对脏水澄清现象，决不会说：考虑地球，则熵增；如果不考虑地球，则脏水系统是熵减的。说到熵，一开始就要考虑各种能量分布形式的影响，包括势能。 熵在历史上有两种定义，一种是克劳修斯的热力学宏观定义，一种是波耳兹曼的微观定义。这两种定义是协调的，没有矛盾。微观定义可以为宏观定义提供几率解释。 我们先从宏观热力学上看脏水澄清系统的变化。脏水自然澄清时，比重大的泥沙会下沉，这导致系统的重心下移。系统的总势能是这样计算的：系统重心的高度x 系统的重量： U（势）=Mgh 系统重心下移，意味着系统的总势能减少了。既然是封闭系统，意味着总能量是守恒的。那么减少的势能到哪里去了呢？转化为粒子无规则的热运动，即热能了。这样，根据不可逆过程的热力学熵的定义式：dS&gt;dQ/T，热量增加即dQ&gt;0，所以熵增 dS&gt;0，熵增定律成立。 很多人感到奇怪之处就在于：脏水澄清的过程，不是使系统更有序了吗？你看，本来是混乱的浑水，现在分层了，有秩序了，难道不是这样吗？ 这是试图从熵的微观概念出发想问题，但可惜的是，这样的直觉式的熵概念是错误的。 微观的熵概念，或波耳兹曼的熵概念，不是单指粒子在三维几何空间中分布的混乱程度；而是指粒子在一定外场势能分布条件下，在粗格化的“相空间 ”–包括所有粒子的位置维度和动量维度的数学空间–中的分布的混乱程度。简单地说,粒子在相空间中对称(或混乱)与否,不是只看粒子的位置分布,而且还要看粒子的动量、能量分布状态。一个简单的例子是:一些在同一水平面上的空气分子,即使它们在平面空间上的所处位置来看是分布均匀的,但只要它们的动量或能量分布不均匀,那么它们在相空间中的分布就是不均匀的、不对称的或者说是较有序的、较不混乱的。系统的这个“混乱”程度，即波尔兹曼熵，有严格的计算方法，其结果可能完全不同于人们的几何直觉印象。 波尔兹曼熵定义是：S=klnΩ 其中S是封闭系统在某种状态下的熵，k是常数，而Ω是指这种状态下的微观态数目。 我们不要怕麻烦，一定要用图形，找出脏水澄清前后的微观状态数的变化，如果微观状态数变大了，就说明系统的熵增加了，也可说明与热力学宏观定义的理解不矛盾了。 为了简便，我们假设简单的粒子情况，这个模型推广到极多粒子情况也完全适用。 1）假设脏水系统有3个粒子，一个是泥沙类的重粒子，另外两个是水分子。 假设重粒子的质量是水分子的2倍，我们把它称为(2a)，重量为2；而把其中一个水分子称为a1，把另一个水分子称为a2. 每个水分子的重量都是1。 2）假设脏水混沌后为封闭系统，总能量守恒，总能量为9个单位。就是说，(2a)，a1和a2三个粒子的总能量是守恒为9的。再假设三粒子除了自身的动能和重力势能，别无其他能量。 3）各粒子的空间高度可以为1m,2m或3m，在这些之间的高度要做四舍五入，有微小的差别可视为全同。这叫把空间或势能粗格化。 4）设各粒子的动能可分别为0，1，2，或3…等，在这些之间的动能取值要做四舍五入，有微小的差别可视为全同。把动能粗格化。 5）粒子位置空间只考虑1维的情况, 即粒子的位置区分只有上下而没有前后左右。 先假设重粒子(2a）在系统的最上层，3m处占据。图中，符号“a1-&gt;1”，表示此状态下粒子a1的动能为1。每个系统态图的右边的数字，是每个高度上的能量分布，它等于此层上所有粒子的（动能+势能）的和，每个粒子的势能的计算方法是其重量乘以高度。 我们先看重粒子(2a）在系统的最上层的情况下，系统粒子不同能量分布的微观态的几种可能性： 微观态1： 第3m层：(2a)-&gt;0———-此层动能=0，势能=2x3=6, 总能量=6第2m层：无粒子———–此层动能=0，势能=0, 总能量=0第1m层：a1-&gt;0, a2-&gt;1—–此层动能=0+1=1，势能=1+1=2，总能量=1+2=3 微观态2： 第3m层：(2a)-&gt;0———-此层动能=0，势能=2x3=6, 总能量=6第2m层：无粒子———–此层动能=0，势能=0, 总能量=0第1m层：a1-&gt;1, a2-&gt;0—–此层动能=1+0=1，势能=1+1=2，总能量=1+2=3 微观态3： 第3m层：(2a)-&gt;0———-此层动能=0，势能=2x3=6, 总能量=6第2m层：a1-&gt;0————此层动能=0，势能=2, 总能量=2第1m层：a2-&gt;0————此层动能=0，势能=1，总能量=1 微观态4： 第3m层：(2a)-&gt;0———-此层动能=0，势能=2x3=6, 总能量=6第2m层：a2-&gt;0————此层动能=0，势能=2, 总能量=2第1m层：a1-&gt;0————此层动能=0，势能=1，总能量=1 微观态5： 第3m层：(2a)-&gt;1———-此层动能=1，势能=2x3=6, 总能量=7第2m层：无粒子———–此层动能=0，势能=0, 总能量=0第1m层：a1-&gt;0, a2-&gt;0—–此层动能=0，势能=1+1=2，总能量=2 可见在重粒子(2a）在系统的最上层的情况下，系统不同能量分布的微观态有且只有上面所示的5种可能。 读者可以检验：任何局限在此空间中的、这三粒子的其他的势能或动能分布，都不会使总能量为9。 注意，即使只考虑高度上的1维空间, 一个动能不为0的粒子, 某个确定的动能也可对应两个确定的动量, 这两个动量大小相等、方向相反, 因为动量的方向有朝上和朝下的两种可能。于是，相空间(位置和动量空间)中, 总微观态数目, 比单纯考虑能量分布形式的微观态数目要多。计算方法是: 每1个能量分布态, 若其中3个粒子动能都为0, 则其对应有1种动量分布; 如果3个粒子只有1个动能不为0, 则其对应2种动量分布; 如果动能有2个不为0, 则对应4种动量分布;如果3个粒子动能都不为0, 则对应8种动量分布。 参考各种能量分布状态再计算这种情形下相空间（能描述所有粒子的各种不同位置和不同动量的数学空间）的微观态可知： 一个重粒子在3m处的条件下, 系统微观态数应是Ω=8，即熵S=kln8. 以上相当于重力场中的浑水状态，状态0。 再看类似重粒子下沉，脏水澄清的情况下的熵。只要假设重粒子在最下层即可。实际上，还有此1重粒子伴随1个水分子同时在最下层的情况，我们暂且不考虑。 我们将知道，即使只考虑一个重粒子在最下层的情况时， 这种情形的分布可能性，也要比重粒子在最上层的情况，可能性或几率要大的多。 重粒子(2a)在最下层即1m处的不同能量分布形式下的微观态（粒子系统总能量仍恒为9）: 微观态1： 第3m层：无粒子—————-动能0，势能0第2m层：a1-&gt;0, a2-&gt;3——-动能=0+3=3，势能2+2=4，此层总能量=3+4=7第1m层：(2a)-&gt;0————–动能=0，势能=2，此层总能量=2 微观态2： 第3m层：无粒子第2m层：a1-&gt;3, a2-&gt;0第1m层：(2a)-&gt;0 微观态3： 第3m层：无粒子第2m层：a1-&gt;1, a2-&gt;2第1m层：(2a)-&gt;0 微观态4： 第3m层：无粒子第2m层：a1-&gt;2, a2-&gt;1第1m层：(2a)-&gt;0 微观态5： 第3m层：a1-&gt;0第2m层：a2-&gt;2第1m层：(2a)-&gt;0 微观态6： 第3m层：a2-&gt;0第2m层：a1-&gt;2第1m层：(2a)-&gt;0 微观态7： 第3m层：a1-&gt;2第2m层：a2-&gt;0第1m层：(2a)-&gt;0 微观态8： 第3m层：a2-&gt;2第2m层：a1-&gt;0第1m层：(2a)-&gt;0 微观态9： 第3m层：a1-&gt;1第2m层：a2-&gt;1第1m层：(2a)-&gt;0 微观态10： 第3m层：a2-&gt;1第2m层：a1-&gt;1第1m层：(2a)-&gt;0 微观态11： 第3m层：a1-&gt;0，a2-&gt;1第2m层：无粒子第1m层：(2a)-&gt;0 微观态12： 第3m层：a1-&gt;1，a2-&gt;0第2m层：无粒子第1m层：(2a)-&gt;0 微观态13： 第3m层：无粒子第2m层：a1-&gt;0，a2-&gt;2第1m层：(2a)-&gt;1 微观态14： 第3m层：无粒子第2m层：a1-&gt;2，a2-&gt;0第1m层：(2a)-&gt;1 微观态15： 第3m层：无粒子第2m层：a1-&gt;1，a2-&gt;1第1m层：(2a)-&gt;1 微观态16： 第3m层：a1-&gt;0第2m层：a2-&gt;1第1m层：(2a)-&gt;1 微观态17： 第3m层：a2-&gt;0第2m层：a1-&gt;1第1m层：(2a)-&gt;1 微观态18： 第3m层：a1-&gt;1第2m层：a2-&gt;0第1m层：(2a)-&gt;1 微观态19： 第3m层：a2-&gt;1第2m层：a1-&gt;0第1m层：(2a)-&gt;1 上面是重粒子(2a)在最下层即1m处的不同能量分布形式下的微观态的所有可能分布。要保证粒子系统的总能量（动能+势能）为9，粒子能量只有这19种分布可能性。 再依照这19种能量分布可能，计算它们在相空间(包括位置和动量)中的所有可能的微观态，可知这时粒子系统微观态数Ω=64，即熵S=kln64. 这个Ω=64远大于重粒子在最上层的可能的微观分布可能数Ω=8. 说明重粒子在引力场中位于下层的分布几率远大于其在上层的系统分布几率. 以上相当于重力场中的浑水澄清后的状态，状态1。显然这种情况下的熵，比重粒子在上的浑水状态的熵要大。 注意，这个微观态解释的直观重点是: 重粒子如果在上方,就会占据更多的能量(势能太大),而由于系统总能量守恒,其他轻粒子的能量和动量的分配可能性就减少了,微观态就少; 相对地,重粒子如果在下方,就会占据更少的能量(势能占据小),而由于系统总能量守恒,其他轻粒子的能量和动量分配可能性就增加了,微观态就多。 结论: 重粒子在下,有更大的分布可能性和几率。 所以重力场中浑水澄清的过程是朝微观态数目多、几率大的方向发展的,即熵增的过程。 从熵的微观解释看，熵大就是这种粒子分布状态的概率大。热力学第二定律，即熵增定律，就是预言系统将从概率小的分布状态，朝着概率大、可能性多的分布状态变化，朝着最可几的状态演化。 最后说说为什么很多人以为澄清分层的水更有序，熵更小。这是一种错觉，或对熵的片面理解，甚至误解导致的。错觉可能来自于无引力场的分布情况：在无引力场，或引力场的水平截面（等势能面）上，熵大常常意味着粒子在位置空间几何排列上的更无序，或更对称。 但这种直觉是不能任意推广的。 最后要说的是: 引力不会导致熵减, 这在霍金的黑洞热力学中也成立. 霍金的公式说黑洞的熵与黑洞的视界面积成正比–而黑洞的视界面积总在增加. 于是热力学第二定律–熵增定律毫无例外地适用于黑洞–有巨大引力的地方。 熵减错觉的简明心理分析 一个众所周知的常识是, 一个在引力场中封闭且绝热的单摆系统, 开始状态是单摆摆动, 但最终单摆会停止—- 单摆摆动的时候, 重力势能与动能不断转化, 但转化的效率不是100%, 而是一部分动能或势能(机械能)转化为无规则的分子热运动, 热能了. 这就是不存在永动机的热力学第二定律, 或熵增定律. 我们看,假如在引力场中封闭且绝热的单摆系统里, 有许多单摆, 初状态是在摆动, 而后逐渐都趋向于停止摆动了,那么, 同样,这个系统过程是熵增的, 机械能转化为热能了, 单摆最终都停止摆动了. 这个系统实际上与我说的浑浊的脏水孤立系统在引力场中变为澄清分层的系统过程, 完全是一样的. 但奇怪的是, 说单摆逐渐停止运动,很多人就可以理解是熵增, 而浑水澄清分层, 很多人就难以理解是熵增过程. (问题:在地球上, 把一个脏水搅浑后封闭隔热后,设为0初始状态. 这个孤立系统在引力场中自发地逐渐澄清分层, 这个状态设为1状态, 问从0状态到1状态, 系统的熵是增加了, 还是减少了?) 完全类似的熵增过程, 一个是单摆垂下不摆了, 另一个是泥沙沉淀不往上窜了, 为什么熵增熵减的心理感觉会不同? 为什么人会有这个错觉? 我想, 这可能人受生物主观需要的影响. 人对分层澄清的水更有需要(人需要喝澄清的水), 但同时人又对单摆的摆动有需要, 比如观看, 定时等. 但科学是严谨的, 要把这些主观感觉去除, 按同样的物理定义和定理, 去理解 有人帮我设计了这个模型: 把清水和称砣装在绝热容器里，初始时称砣用细绳悬吊。之后细绳老化自然断掉, 称砣沉底，重力做功，温度上升，系统熵增。 无论如何, 只要是封闭(包括把保守力外势场算上)且绝热的系统, 内部的熵规律都一样:熵增. 在这一点上看, 秤砣落下, 与单摆停摆, 或泥沙在水中沉淀, 并无二致. 泥水澄清的过程，用更通俗的语言来表达，就是：‘当把泥水混合物看做孤立体系，泥水澄清的过程表面看上去熵降低了，但实际上系统的熵是增加的。’ 需要强调的是，我们‘看到的’熵的变化，其实不是系统熵变的全部。我们看到的熵的降低，其实是混合熵的减小。注意，混合熵仅仅是这个体系中总熵的一部分，其他部分涉及到振动熵，位形熵，电子熵等等。但澄清过程与电子熵无关。 泥水澄清的过程中存在着能量的转换，势能转换为热能，尽管总能量保持恒定不变。势能变成热能导致体系温度上升，这时系统的振动熵与位形熵也随之增加。当假设体系的热容不变，这部分熵增量很容易计算。 总之，体系总熵，是多种熵变西格玛（加和）的结果。","link":"/2020/11/15/%E7%86%B5/"},{"title":"爬虫被403怎么办","text":"403先来给不知道的同学们科普一下错误码，错误码有很多啊，比如404（最常见的），那么为啥这会返还一个我们不知道是什么的码呢？我们随便编辑一个Python爬虫程序 import requests url = 'https://cn.chen-shang.top' # 举个栗子 a = requests.get(url) print(a) 拿我的博客网址举个例子，我们发现终端的输出为 Response &lt;200&gt; 看不懂？没关系，有一个规律，2打头的都是请求成功。200的看了，来看看404 import requests url = 'https://ccknbc.cc/405' # 菜狗的网址 a = requests.get(url) print(a) 输出结果是什么 Response &lt;404&gt; 也是一个道理，4打头都是请求失败，不搞5打头了，一个4打头找了我老半天。 现在，重点分析403是个什么东西403这玩意4打头看得出来是报错了，为啥报错呢？权限不够，403错误是一种在网站访问过程中，常见的错误提示，表示资源不可用。服务器理解客户的请求，但拒绝处理它，通常由于服务器上文件或目录的权限设置导致的WEB访问错误。现在很多网站的api接口返回httpcode返回码是403提示禁止访问。如果您也遇到这样的情况,请先不要急着去修改网站相关的参数第一、先进api的网站。用浏览器访问，如果浏览器访问该api接口能成功。说明是设置了权限的问题。如果不能成功的话。很可以是该接口已修改或已失效，这时候就没办法访问了。第二、如果浏览器能访问成功的话。那就好办了。调用该接口时，捕获异常中的responseBody，很有可能数据就在这里面，笔者就遇到的是这种问题。 也有可能是服务器看你不顺眼，把你挡在门外了，虽然我很喜欢用request，但是为了快，这次用 urllib3 import urllib.request as request src=![&quot;https://www.ptt.cc/bbs/movie/index.html&quot;] with request.urlopen(src) as response: data=response.read().decode('utf-8') print(data) 在这种情况下直接对网路进行连接，一般情况下会被服务器拒绝出现这样的报错“”“urllib.error.HTTPError: HTTP Error 403: Forbidden”“” 这种情况是网站认为你不是普通用户操作，所以我们需要模拟普通用户。一般用户使用会给网站发送一个这总系统和浏览器的信息，所以我们需要模拟。也要向网站发送一个这样的信息。遇到这样子的，主要是爬虫被发现了，建议用Python的正则表达式，放出我之前写的一个残次品，虽然没什么用，但是我就哪一个写了正则表达式 # coding = utf -8 import requests import re # url url = 'https://www.tukuppt.com/yinxiao/' # The detection of IP headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 FS' } # data a = requests.get(url) a = &quot;&quot;&quot;&lt;a class=&quot;title&quot; target=&quot;_blank&quot; href=“.*?”&gt;(.*?)&lt;/a&gt;&quot;&quot;&quot; b = '&lt;source src=&quot;(.*?)&quot; type=&quot;audio/mpeg&quot;&gt;' urls = re.findall(a, b.text) print(urls) for url, name in zip(urls, name): music = requests.get('http'+url,headers) with open('data.txt', 'w') as f: f.write(music.content) print('&lt;%s OK&gt;' % name) 上面那个是我爬熊猫办公的。其实还可以更简单，就是找到你浏览器的User-Agent，像我的就是 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 FS' 加入，如下是urllib3爬ptt的 #抓取PTT电影版的网页原始码（HTML） import urllib.request as req url=&quot;https://www.ptt.cc/bbs/movie/index.html&quot; #建立一个Request物件，附加Request Headers 的资讯 request=req.Request(url,headers={ &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&quot; }) with req.urlopen(request) as response: data=response.read().decode(&quot;utf-8&quot;) #资料解析 import bs4 root=bs4.BeautifulSoup(data,&quot;html.parser&quot;) titles=root.find_all(&quot;div&quot;,class_=&quot;title&quot;) print(titles)","link":"/2021/01/28/%E7%88%AC%E8%99%AB%E8%A2%AB403%E6%80%8E%E4%B9%88%E5%8A%9E/"},{"title":"Python笔记-1","text":"阿巴阿巴之前有学过Python的我，现在早就已经忘得一干二净。 Python2 与 Python3的不同之处print 函数 Py2中可以直接 print 'hello world' Py3中则要加上一对括号 print('hello world') 但是在py2.6中已经是要加括号的了 from __future__ import print_function print(&quot;fish&quot;, &quot;panda&quot;, sep=', ') py2.x想要食用py3.x的语法，可以导入__future__库 … 第一个程序print('hello world') 编码 这似乎没有什么意义 # -*- coding: cp-1252 -*- 强调这是一个UTF-8的编码文件 关键字（保留字）py默认提供了一个包叫做keyword，引入方法如下 import keyword keyword.kwlist # 查看保留字 ## 输出解果 # ['False', 'None', 'True', '__peg_parser__', 'and', 'as', 'assert', 'async', 'await', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield'] 缩进python最具特色的就是使用缩进来表示代码块，不需要使用大括号 {} if True: print (&quot;True&quot;) else: print (&quot;False&quot;) 错误的缩进会使代码发生意想不到的错误 if True: print (&quot;True&quot;) else: print (&quot;False&quot;) print('SB') &gt;&gt;&gt; if True: print (&quot;True&quot;) else: print (&quot;False&quot;) print('SB') SyntaxError: unindent does not match any outer indentation level String python中单引号和双引号使用完全相同。 使用三引号(‘’’ 或 “””)可以指定一个多行字符串。 转义符 \\ 反斜杠可以用来转义，使用r可以让反斜杠不发生转义。。 如 r”this is a line with \\n” 则\\n会显示，并不是换行。 按字面意义级联字符串，如”this “ “is “ “string”会被自动转换为this is string。 字符串可以用 + 运算符连接在一起，用 * 运算符重复。 Python 中的字符串有两种索引方式，从左往右以 0 开始，从右往左以 -1 开始。 Python中的字符串不能改变。 Python 没有单独的字符类型，一个字符就是长度为 1 的字符串。 字符串的截取的语法格式如下：变量[头下标:尾下标:步长] word = '字符串' sentence = &quot;这是一个句子。&quot; paragraph = &quot;&quot;&quot;这是一个段落， 可以由多行组成&quot;&quot;&quot; #!/usr/bin/python3 str='123456789' print(str) # 输出字符串 print(str[0:-1]) # 输出第一个到倒数第二个的所有字符 print(str[0]) # 输出字符串第一个字符 print(str[2:5]) # 输出从第三个开始到第五个的字符 print(str[2:]) # 输出从第三个开始后的所有字符 print(str[1:5:2]) # 输出从第二个开始到第五个且每隔一个的字符（步长为2） print(str * 2) # 输出字符串两次 print(str + '你好') # 连接字符串 print('------------------------------') inputinput('按下Enter就可以退出') 那么，到这里了都，就做一个小小的题目，考考你的思维能力 a = 123 b = 234 # 你可以自己添加变量，但是要保持原代码不变的情况下改变123和234的位置。 print(a ,b) 答案如下，如果你真的想看 a = 123 b = 234 c = a a = b b = c print(a,b) 在此，断片","link":"/2021/08/16/%E7%AC%94%E8%AE%B0-1/"},{"title":"如何反黑客后门程序","text":"前言此文章本该在10月4日发布，博客挂了，所以搬运了。 &amp;emsp;&amp;emsp;那什么，额不是最近国庆吗？因为疫情的缘故，我们都在家中，但发生了这么一件事，看到标题你应该知道是什么了，我被黑了！！！咳咳咳，不能说是被黑了，只能说是我下载了一个后门软件，对后门软件，比如说灰鸽子，流光这种，那边的黑客远程控制了我，我知道，这是最基础的软件了。但是我还是中了，最后，我的账号，密码都被盗取。很难受对吧，所以我写个这个文章。 如何防护这种后门，木马？&amp;emsp;&amp;emsp;很容易，不去下载就好了。哎，你这不是废话吗？咳咳，最好的方法，360。360？你在说什么？360不是毒瘤吗？360云大脑知道吗？虽然这个东西经常抽风，说这个是木马，那个是病毒。但是不去理就好了。不然你可试试不装360会怎么样，首先，我们要知道360的重要性，不然你可以换成卡巴斯基。咳咳，进入正题 360只是第一种方法 第二种linux，比如说ubuntu，本文用CentOS系统演示 防火墙软件，比如说天网 还有最后一个方法，按我说的做 第一种方法:360，腾讯电脑管家，火绒，卡巴斯基等杀毒&amp;emsp;&amp;emsp;360你不会装吗？笨蛋，自己找教程。 第二种方法：Linux下chkrootkit+RKHunter直接性防护&amp;emsp;&amp;emsp;第二种方法开始。rootkit听说过吗？没有就百度去 1. 文件级别rootkit&amp;emsp;&amp;emsp;文件级别的rootkit一般是通过程序漏洞或者系统漏洞进入系统后，通过修改系统的重要文件来达到隐藏自己的目的。在系统遭受rootkit攻击后，合法的文件被木马程序替代，变成了外壳程序，而其内部是隐藏着的后门程序。通常容易被rootkit替换的系统程序有login、ls、ps、ifconfig、du、find、netstat等，其中login程序是最经常被替换的，因为当访问Linux时，无论是通过本地登录还是远程登录，/bin/login程序都会运行，系统将通过/bin/login来收集并核对用户的账号和密码，而rootkit就是利用这个程序的特点，使用一个带有根权限后门密码的/bin/login来替换系统的/bin/login，这样攻击者通过输入设定好的密码就能轻松进入系统。此时，即使系统管理员修改root密码或者清除root密码，攻击者还是一样能通过root用户登录系统。攻击者通常在进入Linux系统后，会进行一系列的攻击动作，最常见的是安装嗅探器收集本机或者网络中其他服务器的重要数据。在默认情况下，Linux中也有一些系统文件会监控这些工具动作，例如ifconfig命令，所以，攻击者为了避免被发现，会想方设法替换其他系统文件，常见的就是ls、ps、ifconfig、du、find、netstat等。如果这些文件都被替换，那么在系统层面就很难发现rootkit已经在系统中运行了。这就是文件级别的rootkit，对系统维护很大，目前最有效的防御方法是定期对系统重要文件的完整性进行检查，如果发现文件被修改或者被替换，那么很可能系统已经遭受了rootkit入侵。检查件完整性的工具很多，常见的有Tripwire、 aide等，可以通过这些工具定期检查文件系统的完整性，以检测系统是否被rootkit入侵。 2. 内核级别的rootkit&amp;emsp;&amp;emsp;内核级rootkit是比文件级rootkit更高级的一种入侵方式，它可以使攻击者获得对系统底层的完全控制权，此时攻击者可以修改系统内核，进而截获运行程序向内核提交的命令，并将其重定向到入侵者所选择的程序并运行此程序，也就是说，当用户要运行程序A时，被入侵者修改过的内核会假装执行A程序，而实际上却执行了程序B。 内核级rootkit主要依附在内核上，它并不对系统文件做任何修改，因此一般的检测工具很难检测到它的存在，这样一旦系统内核被植入rootkit，攻击者就可以对系统为所欲为而不被发现。目前对于内核级的rootkit还没有很好的防御工具，因此，做好系统安全防范就非常重要，将系统维持在最小权限内工作，只要攻击者不能获取root权限，就无法在内核中植入rootkit。 3. 主题了解，安装，准备，使用chkrootkitchkrootkit是一个Linux系统下查找并检测rootkit后门的工具，它的官方址: http://www.chkrootkit.org/。 chkrootkit没有包含在官方的CentOS源中，因此要采取手动编译的方法来安装，不过这种安装方法也更加安全。下面简单介绍下chkrootkit的安装过程。 准备gcc编译环境 对于CentOS系统，需要安装gcc编译环境，执行下述三条命令： yum -y install gcc yum -y install gcc-c++ yum -y install make # 安装gcc,g++,CMake 安装chkrootkit 为了安全起见，建议直接从官方网站下载chkrootkit源码，然后进行安装，操作如下： tar zxvf chkrootkit.tar.gz cd chkrootkit-* make sense # 注意，上面的编译命令为make sense 使用chkrootkit 安装完的chkrootkit程序位于/usr/local/chkrootkit目录下，执行如下命令即可显示chkrootkit的详细用法： /usr/local/chkrootkit/chkrootkit -h #显示帮助信息 chkrootkit各个参数的含义如下所示。 命令 作用 -h 显示帮助信息 -v 显示版本信息 -ddebug ddebug模式，显示检测过程的相关指令程序 -q 安静模式，只显示有问题的内容 -x 高级模式，显示所有检测结果 -r dir设置指定的目录为根目录 -p dir1:dir2:dirN指定chkrootkit检测时使用系统命令的目录 -n 跳过NFS连接的目录 chkrootkit的使用比较简单，直接执行chkrootkit命令即可自动开始检测系统。下面是某个系统的检测结果： [root@server chkrootkit] # /usr/local/chkrootkit/chkrootkit Checking ` ifconfig '... INFECTED Checking ` ls '... INFECTED Checking `login'... INFECTED Checking ` netstat '... INFECTED Checking ` ps '... INFECTED Checking ` top '... INFECTED Checking `sshd'... not infected Checking `syslogd'... not tested Checking ` tar '... not infected Checking `tcpd'... not infected Checking `tcpdump'... not infected Checking `telnetd'... not found 从输出可以看出，此系统的ifconfig、ls、login、netstat、ps和top命令已经被感染。针对被感染rootkit的系统，最安全而有效的方法就是备份数据重新安装系统4. chkrootkit的缺点 chkrootkit在检查rootkit的过程中使用了部分系统命令，因此，如果服务器被黑客入侵，那么依赖的系统命令可能也已经被入侵者替换，此时chkrootkit的检测结果将变得完全不可信。为了避免chkrootkit的这个问题，可以在服务器对外开放前，事先将chkrootkit使用的系统命令进行备份，在需要的时候使用备份的原始系统命令让chkrootkit对rootkit进行检测。这个过程可以通过下面的操作实现： [root@server ~] # mkdir /usr/share/.commands [root@server ~] # cp `which --skip-alias awk cut echo find egrep id head ls netstat ps strings sed uname` /usr/share/.commands [root@server ~] # /usr/local/chkrootkit/chkrootkit -p /usr/share/.commands/ [root@server share] # cd /usr/share/ [root@server share] # tar zcvf commands.tar.gz .commands [root@server share] # rm -rf commands.tar.gz 上面这段操作是在/usr/share/下建立了一个.commands隐藏文件，然后将chkrootkit使用的系统命令进行备份到这个目录下。为了安全起见，可以将.commands目录压缩打包，然后下载到一个安全的地方进行备份，以后如果服务器遭受入侵，就可以将这个备份上传到服务器任意路径下，然后通过chkrootkit命令的”-p”参数指定这个路径进行检测即可。 rootkit后门检测工具RKHunterRKHunter是一款专业的检测系统是否感染rootkit的工具，它通过执行一系列的脚本来确认服务器是否已经感染rootkit。在官方的资料中，RKHunter可以作的事情有： MD5校验测试，检测文件是否有改动 检测rootkit使用的二进制和系统工具文件 检测特洛伊木马程序的特征码 检测常用程序的文件属性是否异常 检测系统相关的测试 检测隐藏文件 检测可疑的核心模块LKM 检测系统已启动的监听端口 下面详细讲述下RKHunter的安装与使用。 下面详细讲述下RKHunter的安装与使用。 安装RKHunter RKHunter的官方网页地址为：http://www.rootkit.nl/projects/rootkit_hunter.html 建议从这个网站下载RKHunter，这里下载的版本是rkhunter-1.4.0.tar.gz。RKHunter的安装非常简单，过程如下： [root@server ~] # ls rkhunter-1.4.0. tar .gz [root@server ~] # pwd /root [root@server ~] # tar -zxvf rkhunter-1.4.0.tar.gz [root@server ~] # cd rkhunter-1.4.0 [root@server rkhunter-1.4.0] # ./installer.sh --layout default --install 这里采用RKHunter的默认安装方式，rkhunter命令被安装到了/usr/local/bin目录下。使用rkhunter指令 rkhunter命令的参数较多，但是使用非常简单，直接运行rkhunter即可显示此命令的用法。下面简单介绍下rkhunter常用的几个参数选项。 [root@server ~]#/usr/local/bin/rkhunter–help Rkhunter常用参数以及含义如下所示： 参数 含义 –c, –check 必选参数，表示检测当前系统 –configfile 使用特定的配置文件 –cronjob 作为cron任务定期运行 –sk, –skip-keypress 自动完成所有检测，跳过键盘输入 –summary 显示检测结果的统计信息 –update 检测更新内容 -v, –version 显示版本信息 –versioncheck 检测最新版本 下面是通过rkhunter对某个系统的检测示例： [root@server rkhunter-1.4.0] # /usr/local/bin/rkhunter -c [ Rootkit Hunter version 1.4.0 ] # 下面是第一部分，先进行系统命令的检查，主要是检测系统的二进制文件，因为这些文件最容易被rootkit攻击。显示OK字样表示正常，显示Warning表示有异常，需要引起注意，而显示“Not found”字样，一般无需理会 Checking system commands... Performing 'strings' command checks Checking 'strings' command [ OK ] Performing 'shared libraries' checks Checking for preloading variables [ None found ] Checking for preloaded libraries [ None found ] Checking LD_LIBRARY_PATH variable [ Not found ] Performing file properties checks Checking for prerequisites [ Warning ] /usr/local/bin/rkhunter [ OK ] /sbin/chkconfig [ OK ] ....(略).... [Press &lt;ENTER&gt; to continue ] # 下面是第二部分，主要检测常见的rootkit程序，显示“Not found”表示系统未感染此rootkit Checking for rootkits... Performing check of known rootkit files and directories 55808 Trojan - Variant A [ Not found ] ADM Worm [ Not found ] AjaKit Rootkit [ Not found ] Adore Rootkit [ Not found ] aPa Kit [ Not found ] Apache Worm [ Not found ] Ambient (ark) Rootkit [ Not found ] Balaur Rootkit [ Not found ] BeastKit Rootkit [ Not found ] beX2 Rootkit [ Not found ] BOBKit Rootkit [ Not found ] ....(略).... [Press &lt;ENTER&gt; to continue ] # 下面是第三部分，主要是一些特殊或附加的检测，例如对rootkit文件或目录检测、对恶意软件检测以及对指定的内核模块检测 Performing additional rootkit checks Suckit Rookit additional checks [ OK ] Checking for possible rootkit files and directories [ None found ] Checking for possible rootkit strings [ None found ] Performing malware checks Checking running processes for suspicious files [ None found ] Checking for login backdoors [ None found ] Checking for suspicious directories [ None found ] Checking for sniffer log files [ None found ] Performing Linux specific checks Checking loaded kernel modules [ OK ] Checking kernel module names [ OK ] [Press &lt;ENTER&gt; to continue ] # 下面是第四部分，主要对网络、系统端口、系统启动文件、系统用户和组配置、SSH配置、文件系统等进行检测 Checking the network... Performing checks on the network ports Checking for backdoor ports [ None found ] Performing checks on the network interfaces Checking for promiscuous interfaces [ None found ] Checking the local host... Performing system boot checks Checking for local host name [ Found ] Checking for system startup files [ Found ] Checking system startup files for malware [ None found ] Performing group and account checks Checking for passwd file [ Found ] Checking for root equivalent (UID 0) accounts [ None found ] Checking for passwordless accounts [ None found ] ....(略).... [Press &lt;ENTER&gt; to continue ] # 下面是第五部分，主要是对应用程序版本进行检测 Checking application versions... Checking version of GnuPG[ OK ] Checking version of OpenSSL [ Warning ] Checking version of OpenSSH [ OK ] # 下面是最后一部分，这个部分其实是上面输出的一个总结，通过这个总结，可以大概了解服务器目录的安全状态。 System checks summary ===================== File properties checks... Required commands check failed Files checked: 137 Suspect files: 4 Rootkit checks... Rootkits checked : 311 Possible rootkits: 0 Applications checks... Applications checked: 3 Suspect applications: 1 The system checks took: 6 minutes and 41 seconds 在Linux终端使用rkhunter来检测，最大的好处在于每项的检测结果都有不同的颜色显示，如果是绿色的表示没有问题，如果是红色的，那就要引起关注了。另外，在上面执行检测的过程中，在每个部分检测完成后，需要以Enter键来继续。如果要让程序自动运行，可以执行如下命令： [root@server ~]# /usr/local/bin/rkhunter --check --skip-keypress 同时，如果想让检测程序每天定时运行，那么可以在/etc/crontab中加入如下内容： 30 09 * * * root /usr/local/bin/rkhunter --check --cronjob 这样，rkhunter检测程序就会在每天的9:30分运行一次。 第三种：防火墙软件第一个,windows自带防火墙windows自带的防火墙windows Defender，在 控制面板\\系统和安全\\Windows Defender 防火墙 中，开启即可。但是默认是开启的，反正检查一下看看有没有开启，有些软件可以关闭防火墙，检查一下就对了！ 第二个:360家庭防火墙没错，又是360，个人认为360的防火墙还可以，下载独立版的就好了，连接一下云大脑，简直是浪的飞起，虽然并没有什么卵用，定时检查一下端口就好了，我这种前端开发的，看的就是端口，wifi的近期使用情况，谁在用wifi，什么手机，电脑在用，看的就是这个，所以这个防火墙很好的解决了我的问题，自然我就推荐了。主要是我们这些开发者使用，推荐一下。 第三个：GlassWire&amp;emsp;&amp;emsp;GlassWire是windows下的一款软件，对windows的，界面很美观，很简洁就像这样 这是切换中文的图片。你不会想到这是windows下的软件，它太简洁了！所以我强推这款软件，一个字”好！” 第四个：Firewall App BlockerFirewall App Blocker 超级简单易用的bai限制软件访问网络的防火墙： &amp;emsp;&amp;emsp;对于大多数用户，Windows自带的防火墙虽然实用但并没有好好利用起来，主要是因为设置略显繁琐。使用 Firewall App Blocker (Fab) 来禁止应用联网变得超级简单方便。用户只需将需要限制的应用程序添加到软件的列表里即可，勾选状态下为禁止联网，取消勾选可以临时允许联网，就是这么简单。 这个软件很好用的，它最大的好处是解决了Windows自带防火墙的难用问题。也推荐。但是界面没有GlassWire那么好看。 也许你会说：“为什么只有windows的软件？MAC的去哪里了？”我的回答是，你也不自己去数落数落MAC的防御力，不说是木马了，来个顶级黑客攻进去也要费很多时间！至于Linux的，或许你已经看过了，就不用我来说了，如果你想秀技术，来个反黑客我没意见。如果你真的黑成功了，那你可以做什么呢？等着网警来找你？不要无罪变有罪了。“那么这么多软件，要怎么下载呢？”给出网址你认为我会告诉你密码吗？想知道密码？很容易，发邮件到我的邮箱里3225454747@qq.com关键字：密码是啥？或者陈殇好帅。都可以。 做后一种方法前言 这个方法很绕，如果实在是听不下去就别听了（博主的衷心劝告），最后一种方法是反黑客后门软件，前言不多说，直接进入正题 正题 马上进入正题！ 了解什么是后门程序 &amp;emsp;&amp;emsp;后门程序是指那些绕过安全性控制而获取对程序或系统访问权的程序方法。一般在软件开发时，程序员会在软件中创建后门程序，这样就可以修改程序设计中的缺陷。但是，如果这些后门被其他人知道，或是在发布软件之前没有删除后门程序，那么它就成了安全风险，容易被黑客当成漏洞进行攻击。通俗的讲，后门程序就是留在计算机系统中，供某位特殊使用者通过某种特殊方式控制计算机系统的途径。 一、远程控制的两个通性（1）任何一款的远程控制技术都必须与目标（被控端）建立至少一个TCP或者UPD连接。如果黑客未上线，则会每隔30秒向黑客发起连接请求。 （2）任何一款远控木马都会向系统写入至少一个随机启动项、服务启动项，或者劫持某个系统必备的正常启动项。并且会在某个目录中隐、释放木马。以方便随机启动。 二、基于远控通性反远程控制法——两条命令判断是否被控制 最简单的方法就是通过两条命令，一条是“netstat “ 。另一条就是“tasklist “命令，这两条命令可真为是绝配的反黑客远控的方法啊。首先我们就在虚拟机中测试，在本机使用灰鸽子主控端生成一个木马放入到虚拟机中运行。 netstat # 在cmd,powershell,Git等终端中运行，直接监听端口 tasklist # 查看所有程序的占用端口 确认虚拟机已经中了我们的远控木马之后我们开始执行第一条命令，首先大家先在联网的情况，把所有联网的程序都关闭，包括杀毒软件、QQ、迅雷、等存在联网的程序关闭，保存最原始的进程。这样很方便我们识别。再次打开开始菜单——运行——输入“cmd”。进入到黑色的DOS窗口下，输入命令“netstat -ano“。这条命令的意思是查看当前网络的连接状态。输入之后我们查看中主要看”state”的状态，如果是“listenning”是端口的监听这个可以放心，如果是“ESTABLISHED”可要注意了，这个状态意思是正在连接！我们肯定会想，我们都没开任何程序在联网，何来正在与远程主机连接呢？下面是中了远程控制木马的虚拟机中网络连接状态。 此时捕捉到正在连接的状态的最后一行PID值为：3920，这就是我们说的远控至少与目标建立一个TCP或UDP连接，而这里建立了一个TCP连接，并且仔细看下，“Foregin Address”意思是外网地址，这个IP地址可以百度进行查询下就可以知道是哪个地区的人在控制我们的电脑，再仔细看下IP地址后面的端口为：8000，现在很多主流的远程软件都是8000或者80端口，这又更值得怀疑了。这样我们就可以查看进程，因为木马要想进行连接就必定会在内存中进行运行，否则就无法进行连接了，我们查看内存中可疑的进程，上面捕获的连接PID为：3920。我们输入命令“tasklist /svc“这条命令是查看当前进程与PID值和启动的服务。 通过上面的命令找到了网络连接对应的PID值进程3920，并且发现该进程名是一个IE的进程，很明显这就有问题，因为我们根本没打开浏览器，何来IE进程呢？果断的就知道它的一个远程控制木马伪装的进程。我们应该马上去进行一个查杀掉该进程，从内存中干掉它。我们输入命令“taskkill /f /pid 3920” 这条命令是强制结束PID值为3920的进程。当我们强制结束掉了木马之后发现主控端远程控制软件上的肉鸡马上就下线了。这样黑客就无法进行控制了。 在这里说明，我们只是暂时现在已经让黑客无法控制我们的电脑，结束了它的远程控制的连接程序。但是我们要知道远程控制的第二个通性，就是远程控制软件为了让对方能够重启系统后继续在黑客的远控软件上面上线，就必须会在被控者的电脑上写入一个随机启动项，这个随机启动项就是当系统启动的时候立马运行木马，运行了木马就可以再次上线。所以我们还需要检测我们的启动项。很多启动项都是写入注册表的，我们这里给大家列出一些木马可能写入的启动键值。 HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Run HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon 下的shell键值 HKEY_CURRENT_USER\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Windows 下的load键值 在CMD下切换到该目录下进程一个强制删除吧，切换到目录后输入命令“del /ah /f svchot.exe “ 就可以强制删除隐藏的木马了。 此时我们把隐藏的以服务启动的木马干掉了，你可以去停止服务，或者通过sc delete 去删除服务，这里就不多讲了，因为服务启动的木马已经被干掉了，即使服务存在也无法找到启动程序了。我们这里将虚拟机重启下，再查看下网络连接是否还会与黑客建立TCP远程控制连接呢？ 三、基于远控的通性反黑客远程控制法——两个软件判断是否存在后门 这两个工具分别是icesword（中文：冰刃）和SSM软件。第一个软件主要是应对一些DLL进程注入或者是存在Rootkit的木马，所谓的Rootkit就是隐藏的意思，这样的木马有隐藏网络连接状态、隐藏进程的功能。但是使用iceword查看就能查看到这种内核级隐藏的木马。例如下面就是GHOST木马的DLL注入，它是通过DLL注入到svchost.exe进程的，从icesword就可以找到可疑的dll模块。并且大家都说”Svchost.exe“如果与外界的IP连接就肯定是被控制了，这是有道理的。因为现在的远控比如ghost、白金远控就是会有这种现象就是DLL注入到“svhochst.exe“进程进行控制的，所以会有连接，一般来说“svchost.exe“除了在微软更新的时候可能存在与美国IP的连接，但是其它时候都不会存在与外界进行IP连接的。通过360的网络连接就可以直接看的出来。 icesword里面的进程都是黑色显示的，如果出现有红色的进程，一般都是运用了内核级的rootkit技术的木马。这样的木马通过任务管理器或者tasklist /svc 一般都是查看不到进程的，但是用冰刃却可以很快的查看到。 icesword的软件很强大这里就不多说了，上面已经举例说了。下面说下SSM工具的使用，首先我先在虚拟机里面安装下这个软件吧。并且开启这个软件，开启这个软件后只要我们运行任何一个程序都会报警说明软件执行了什么动作！这里我们将一个灰鸽子远控木马拷贝进到我们的虚拟机，当我们点击远控木马的时候SSM马上就报警了，提示程序启动，这个动作是正常的，因为该程序需要explorer图形化程序进程启动的。 当我们运行之后会发现，这时候程序突然来了一个注册表修改的动作，懂注册表的都知道这个就是向HKLC\\System\\CurretcontrolSet\\services里面写入服务。这个就不太正常了，不是安装什么程序，一个简单的程序居然写入服务，增加服务，可疑！ 当我们允许此次操作的时候，你会发现不停的会向注册表写入服务键值，这个肯定就是个可疑的动作，最后发现木马又释放了程序到系统目录。照理说一个执行程序不会随意释放程序到系统目录，可疑！ 此允许发现最后一步又有一个进程尝试注入到IE里面进行以IE后台启动木马，很明显就能分析出就是个可疑的木马程序，很可能就是后门木马，它有写入服务的这一通性！通过SSM的拦截程序动作就可以分析一个程序是不是绑有后门木马。 以上就是我分享的反黑客教程，希望可以帮助你😉","link":"/2021/09/10/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"title":"腾讯云北美服务器搭建ShadowSocks代理","text":"注：本教程适合centos系列和red hat系列 登陆SSH新的VPS可以先升级 yum -y update 有些VPS 没有wget这种要先装 yum -y install wget 输入以下命令：（可以复制） wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh chmod +x shadowsocks.sh ./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 第一行是下载命令，下载东西，第二行是修改权限，第三行是安装命令 下面是按照配置图 配置： 密码：（默认是teddysun.com） 端口：默认是8989 然后按任意键安装，退出按 Ctrl+c 安装完成会有一个配置 Congratulations, shadowsocks install completed!Your Server IP: ***** VPS的IP地址Your Server Port: ***** 你刚才设置的端口Your Password: **** 你刚才设置的密码Your Local IP: 127.0.0.1 Your Local Port: 1080 Your Encryption Method: aes-256-cfb Welcome to visit:https://teddysun.com/342.htmlEnjoy it! 然后即可以使用 卸载方法： 使用 root 用户登录，运行以下命令： ./shadowsocksR.sh uninstall 安装完成后即已后台启动 ShadowsocksR ，运行： /etc/init.d/shadowsocks status","link":"/2016/08/08/%E8%85%BE%E8%AE%AF%E4%BA%91%E5%8C%97%E7%BE%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BAShadowSocks%E4%BB%A3%E7%90%86/"}],"tags":[{"name":"网易云","slug":"网易云","link":"/tags/%E7%BD%91%E6%98%93%E4%BA%91/"},{"name":"VSCode","slug":"VSCode","link":"/tags/VSCode/"},{"name":"插件","slug":"插件","link":"/tags/%E6%8F%92%E4%BB%B6/"},{"name":"live2d","slug":"live2d","link":"/tags/live2d/"},{"name":"centOS","slug":"centOS","link":"/tags/centOS/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"Node.js","slug":"Node-js","link":"/tags/Node-js/"},{"name":"开发工具","slug":"开发工具","link":"/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"测试","slug":"测试","link":"/tags/%E6%B5%8B%E8%AF%95/"},{"name":"Fiddler","slug":"Fiddler","link":"/tags/Fiddler/"},{"name":"Firefox","slug":"Firefox","link":"/tags/Firefox/"},{"name":"game","slug":"game","link":"/tags/game/"},{"name":"Genshin-Impact","slug":"Genshin-Impact","link":"/tags/Genshin-Impact/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"教程","slug":"教程","link":"/tags/%E6%95%99%E7%A8%8B/"},{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","link":"/tags/IntelliJ-IDEA/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"javascript","slug":"javascript","link":"/tags/javascript/"},{"name":"JAVA","slug":"JAVA","link":"/tags/JAVA/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"Homebrew","slug":"Homebrew","link":"/tags/Homebrew/"},{"name":"终端","slug":"终端","link":"/tags/%E7%BB%88%E7%AB%AF/"},{"name":"Maven","slug":"Maven","link":"/tags/Maven/"},{"name":"CI","slug":"CI","link":"/tags/CI/"},{"name":"TCP","slug":"TCP","link":"/tags/TCP/"},{"name":"PWA","slug":"PWA","link":"/tags/PWA/"},{"name":"flask","slug":"flask","link":"/tags/flask/"},{"name":"games","slug":"games","link":"/tags/games/"},{"name":"data analysis","slug":"data-analysis","link":"/tags/data-analysis/"},{"name":"pandas","slug":"pandas","link":"/tags/pandas/"},{"name":"TeamCity","slug":"TeamCity","link":"/tags/TeamCity/"},{"name":"持续集成","slug":"持续集成","link":"/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"VPS","slug":"VPS","link":"/tags/VPS/"},{"name":"Shadowsocks","slug":"Shadowsocks","link":"/tags/Shadowsocks/"},{"name":"Vultr","slug":"Vultr","link":"/tags/Vultr/"},{"name":"Biological","slug":"Biological","link":"/tags/Biological/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"主題","slug":"主題","link":"/tags/%E4%B8%BB%E9%A1%8C/"},{"name":"butterfly","slug":"butterfly","link":"/tags/butterfly/"},{"name":"Aplayer","slug":"Aplayer","link":"/tags/Aplayer/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"系统","slug":"系统","link":"/tags/%E7%B3%BB%E7%BB%9F/"},{"name":"Toss Note","slug":"Toss-Note","link":"/tags/Toss-Note/"},{"name":"前端框架","slug":"前端框架","link":"/tags/%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6/"},{"name":"Flink","slug":"Flink","link":"/tags/Flink/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"gradle","slug":"gradle","link":"/tags/gradle/"},{"name":"gulp","slug":"gulp","link":"/tags/gulp/"},{"name":"化学","slug":"化学","link":"/tags/%E5%8C%96%E5%AD%A6/"},{"name":"笔记","slug":"笔记","link":"/tags/%E7%AC%94%E8%AE%B0/"},{"name":"图床","slug":"图床","link":"/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"白嫖","slug":"白嫖","link":"/tags/%E7%99%BD%E5%AB%96/"},{"name":"PicGo","slug":"PicGo","link":"/tags/PicGo/"},{"name":"JS","slug":"JS","link":"/tags/JS/"},{"name":"cdn","slug":"cdn","link":"/tags/cdn/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"jsdelivr","slug":"jsdelivr","link":"/tags/jsdelivr/"},{"name":"music","slug":"music","link":"/tags/music/"},{"name":"电脑","slug":"电脑","link":"/tags/%E7%94%B5%E8%84%91/"},{"name":"Apple","slug":"Apple","link":"/tags/Apple/"},{"name":"serverless","slug":"serverless","link":"/tags/serverless/"},{"name":"skill","slug":"skill","link":"/tags/skill/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"turtle绘图","slug":"turtle绘图","link":"/tags/turtle%E7%BB%98%E5%9B%BE/"},{"name":"Vue.js","slug":"Vue-js","link":"/tags/Vue-js/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"跨端融合","slug":"跨端融合","link":"/tags/%E8%B7%A8%E7%AB%AF%E8%9E%8D%E5%90%88/"},{"name":"前端构建","slug":"前端构建","link":"/tags/%E5%89%8D%E7%AB%AF%E6%9E%84%E5%BB%BA/"},{"name":"windows11","slug":"windows11","link":"/tags/windows11/"},{"name":"bug","slug":"bug","link":"/tags/bug/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"terminal","slug":"terminal","link":"/tags/terminal/"},{"name":"Movie","slug":"Movie","link":"/tags/Movie/"},{"name":"react","slug":"react","link":"/tags/react/"},{"name":"物理学","slug":"物理学","link":"/tags/%E7%89%A9%E7%90%86%E5%AD%A6/"},{"name":"科幻历险记","slug":"科幻历险记","link":"/tags/%E7%A7%91%E5%B9%BB%E5%8E%86%E9%99%A9%E8%AE%B0/"},{"name":"前端监控","slug":"前端监控","link":"/tags/%E5%89%8D%E7%AB%AF%E7%9B%91%E6%8E%A7/"},{"name":"OpenCV","slug":"OpenCV","link":"/tags/OpenCV/"},{"name":"rust","slug":"rust","link":"/tags/rust/"},{"name":"Rx.js","slug":"Rx-js","link":"/tags/Rx-js/"},{"name":"WebAssembly","slug":"WebAssembly","link":"/tags/WebAssembly/"},{"name":"历史","slug":"历史","link":"/tags/%E5%8E%86%E5%8F%B2/"},{"name":"组件化","slug":"组件化","link":"/tags/%E7%BB%84%E4%BB%B6%E5%8C%96/"},{"name":"学习方法","slug":"学习方法","link":"/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"},{"name":"化工","slug":"化工","link":"/tags/%E5%8C%96%E5%B7%A5/"},{"name":"颜色","slug":"颜色","link":"/tags/%E9%A2%9C%E8%89%B2/"},{"name":"数学","slug":"数学","link":"/tags/%E6%95%B0%E5%AD%A6/"},{"name":"go","slug":"go","link":"/tags/go/"},{"name":"Vue","slug":"Vue","link":"/tags/Vue/"},{"name":"viola","slug":"viola","link":"/tags/viola/"},{"name":"MVVM","slug":"MVVM","link":"/tags/MVVM/"},{"name":"性能优化","slug":"性能优化","link":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"学习日记","slug":"学习日记","link":"/tags/%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0/"},{"name":"网络安全","slug":"网络安全","link":"/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"ShadowSocks","slug":"ShadowSocks","link":"/tags/ShadowSocks/"}],"categories":[{"name":"开发工具","slug":"开发工具","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"软件","slug":"软件","link":"/categories/%E8%BD%AF%E4%BB%B6/"},{"name":"游戏","slug":"游戏","link":"/categories/%E6%B8%B8%E6%88%8F/"},{"name":"Toss Note","slug":"Toss-Note","link":"/categories/Toss-Note/"},{"name":"测试","slug":"开发工具/测试","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/%E6%B5%8B%E8%AF%95/"},{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","link":"/categories/IntelliJ-IDEA/"},{"name":"web","slug":"web","link":"/categories/web/"},{"name":"原神","slug":"游戏/原神","link":"/categories/%E6%B8%B8%E6%88%8F/%E5%8E%9F%E7%A5%9E/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"HEXO","slug":"Toss-Note/HEXO","link":"/categories/Toss-Note/HEXO/"},{"name":"Mac","slug":"Mac","link":"/categories/Mac/"},{"name":"Java","slug":"IntelliJ-IDEA/Java","link":"/categories/IntelliJ-IDEA/Java/"},{"name":"JS","slug":"web/JS","link":"/categories/web/JS/"},{"name":"TeamCity","slug":"TeamCity","link":"/categories/TeamCity/"},{"name":"Github","slug":"Toss-Note/HEXO/Github","link":"/categories/Toss-Note/HEXO/Github/"},{"name":"進階教程","slug":"進階教程","link":"/categories/%E9%80%B2%E9%9A%8E%E6%95%99%E7%A8%8B/"},{"name":"系统","slug":"系统","link":"/categories/%E7%B3%BB%E7%BB%9F/"},{"name":"gulp","slug":"gulp","link":"/categories/gulp/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"},{"name":"教程","slug":"教程","link":"/categories/%E6%95%99%E7%A8%8B/"},{"name":"JS逆向","slug":"web/JS/JS逆向","link":"/categories/web/JS/JS%E9%80%86%E5%90%91/"},{"name":"搞机","slug":"搞机","link":"/categories/%E6%90%9E%E6%9C%BA/"},{"name":"小技巧","slug":"小技巧","link":"/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"ssh","slug":"ssh","link":"/categories/ssh/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"Java","slug":"TeamCity/Java","link":"/categories/TeamCity/Java/"},{"name":"Vue.JS","slug":"Vue-JS","link":"/categories/Vue-JS/"},{"name":"linux","slug":"系统/linux","link":"/categories/%E7%B3%BB%E7%BB%9F/linux/"},{"name":"学习日记","slug":"学习日记","link":"/categories/%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0/"},{"name":"笔记","slug":"随笔/笔记","link":"/categories/%E9%9A%8F%E7%AC%94/%E7%AC%94%E8%AE%B0/"},{"name":"历史","slug":"历史","link":"/categories/%E5%8E%86%E5%8F%B2/"},{"name":"MAC","slug":"搞机/MAC","link":"/categories/%E6%90%9E%E6%9C%BA/MAC/"},{"name":"主题","slug":"教程/主题","link":"/categories/%E6%95%99%E7%A8%8B/%E4%B8%BB%E9%A2%98/"},{"name":"学习方法","slug":"学习方法","link":"/categories/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"},{"name":"黄色","slug":"黄色","link":"/categories/%E9%BB%84%E8%89%B2/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"turtle","slug":"python/turtle","link":"/categories/python/turtle/"},{"name":"网络爬虫","slug":"python/网络爬虫","link":"/categories/python/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/"},{"name":"软件","slug":"教程/软件","link":"/categories/%E6%95%99%E7%A8%8B/%E8%BD%AF%E4%BB%B6/"},{"name":"deepin","slug":"系统/linux/deepin","link":"/categories/%E7%B3%BB%E7%BB%9F/linux/deepin/"},{"name":"物理学","slug":"学习日记/物理学","link":"/categories/%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0/%E7%89%A9%E7%90%86%E5%AD%A6/"},{"name":"科幻历险记","slug":"学习日记/物理学/科幻历险记","link":"/categories/%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0/%E7%89%A9%E7%90%86%E5%AD%A6/%E7%A7%91%E5%B9%BB%E5%8E%86%E9%99%A9%E8%AE%B0/"}]}